data has been loaded
model, optimizer, and criterion have been defined
starting the run!
training epoch 0 / 500, batch #0 / 625
Loss:	10.136726379394531

training epoch 0 / 500, batch #25 / 625
Loss:	2.2981374263763428

training epoch 0 / 500, batch #50 / 625
Loss:	2.3093953132629395

training epoch 0 / 500, batch #75 / 625
Loss:	2.291421413421631

training epoch 0 / 500, batch #100 / 625
Loss:	2.306671142578125

training epoch 0 / 500, batch #125 / 625
Loss:	2.2981653213500977

training epoch 0 / 500, batch #150 / 625
Loss:	2.3008759021759033

training epoch 0 / 500, batch #175 / 625
Loss:	2.30707049369812

training epoch 0 / 500, batch #200 / 625
Loss:	2.305995464324951

training epoch 0 / 500, batch #225 / 625
Loss:	2.2991838455200195

training epoch 0 / 500, batch #250 / 625
Loss:	2.298729181289673

training epoch 0 / 500, batch #275 / 625
Loss:	2.3026251792907715

training epoch 0 / 500, batch #300 / 625
Loss:	2.317455291748047

training epoch 0 / 500, batch #325 / 625
Loss:	2.2926409244537354

training epoch 0 / 500, batch #350 / 625
Loss:	2.3084497451782227

training epoch 0 / 500, batch #375 / 625
Loss:	2.3006608486175537

training epoch 0 / 500, batch #400 / 625
Loss:	2.310223340988159

training epoch 0 / 500, batch #425 / 625
Loss:	2.308082342147827

training epoch 0 / 500, batch #450 / 625
Loss:	2.2933449745178223

training epoch 0 / 500, batch #475 / 625
Loss:	2.297952890396118

training epoch 0 / 500, batch #500 / 625
Loss:	2.2980124950408936

training epoch 0 / 500, batch #525 / 625
Loss:	2.299476146697998

training epoch 0 / 500, batch #550 / 625
Loss:	2.296718120574951

training epoch 0 / 500, batch #575 / 625
Loss:	2.292923927307129

training epoch 0 / 500, batch #600 / 625
Loss:	2.3020901679992676

training epoch 1 / 500, batch #0 / 625
Loss:	2.2895493507385254

training epoch 1 / 500, batch #25 / 625
Loss:	2.327030897140503

training epoch 1 / 500, batch #50 / 625
Loss:	2.3099796772003174

training epoch 1 / 500, batch #75 / 625
Loss:	2.303297519683838

training epoch 1 / 500, batch #100 / 625
Loss:	2.294077157974243

training epoch 1 / 500, batch #125 / 625
Loss:	2.2880969047546387

training epoch 1 / 500, batch #150 / 625
Loss:	2.302133083343506

training epoch 1 / 500, batch #175 / 625
Loss:	2.3032891750335693

training epoch 1 / 500, batch #200 / 625
Loss:	2.299144983291626

training epoch 1 / 500, batch #225 / 625
Loss:	2.2940845489501953

training epoch 1 / 500, batch #250 / 625
Loss:	2.287149429321289

training epoch 1 / 500, batch #275 / 625
Loss:	2.2974801063537598

training epoch 1 / 500, batch #300 / 625
Loss:	2.2915546894073486

training epoch 1 / 500, batch #325 / 625
Loss:	2.2857069969177246

training epoch 1 / 500, batch #350 / 625
Loss:	2.2945127487182617

training epoch 1 / 500, batch #375 / 625
Loss:	2.3024697303771973

training epoch 1 / 500, batch #400 / 625
Loss:	2.3069162368774414

training epoch 1 / 500, batch #425 / 625
Loss:	2.308187484741211

training epoch 1 / 500, batch #450 / 625
Loss:	2.289426326751709

training epoch 1 / 500, batch #475 / 625
Loss:	2.292128086090088

training epoch 1 / 500, batch #500 / 625
Loss:	2.2976627349853516

training epoch 1 / 500, batch #525 / 625
Loss:	2.3001983165740967

training epoch 1 / 500, batch #550 / 625
Loss:	2.298214912414551

training epoch 1 / 500, batch #575 / 625
Loss:	2.305002212524414

training epoch 1 / 500, batch #600 / 625
Loss:	2.2958548069000244

training epoch 2 / 500, batch #0 / 625
Loss:	2.3082756996154785

training epoch 2 / 500, batch #25 / 625
Loss:	2.314770221710205

training epoch 2 / 500, batch #50 / 625
Loss:	2.2903330326080322

training epoch 2 / 500, batch #75 / 625
Loss:	2.29862904548645

training epoch 2 / 500, batch #100 / 625
Loss:	2.3028621673583984

training epoch 2 / 500, batch #125 / 625
Loss:	2.2985124588012695

training epoch 2 / 500, batch #150 / 625
Loss:	2.3328375816345215

training epoch 2 / 500, batch #175 / 625
Loss:	2.303187370300293

training epoch 2 / 500, batch #200 / 625
Loss:	2.302631378173828

training epoch 2 / 500, batch #225 / 625
Loss:	2.302445888519287

training epoch 2 / 500, batch #250 / 625
Loss:	2.3038837909698486

training epoch 2 / 500, batch #275 / 625
Loss:	2.304636240005493

training epoch 2 / 500, batch #300 / 625
Loss:	2.3056273460388184

training epoch 2 / 500, batch #325 / 625
Loss:	2.300011157989502

training epoch 2 / 500, batch #350 / 625
Loss:	2.2937867641448975

training epoch 2 / 500, batch #375 / 625
Loss:	2.308887243270874

training epoch 2 / 500, batch #400 / 625
Loss:	2.282778739929199

training epoch 2 / 500, batch #425 / 625
Loss:	2.294325590133667

training epoch 2 / 500, batch #450 / 625
Loss:	2.30155611038208

training epoch 2 / 500, batch #475 / 625
Loss:	2.309159755706787

training epoch 2 / 500, batch #500 / 625
Loss:	2.3019967079162598

training epoch 2 / 500, batch #525 / 625
Loss:	2.2943646907806396

training epoch 2 / 500, batch #550 / 625
Loss:	2.285125732421875

training epoch 2 / 500, batch #575 / 625
Loss:	2.2945973873138428

training epoch 2 / 500, batch #600 / 625
Loss:	2.303778886795044

training epoch 3 / 500, batch #0 / 625
Loss:	2.289285898208618

training epoch 3 / 500, batch #25 / 625
Loss:	2.2980339527130127

training epoch 3 / 500, batch #50 / 625
Loss:	2.2898433208465576

training epoch 3 / 500, batch #75 / 625
Loss:	2.3150057792663574

training epoch 3 / 500, batch #100 / 625
Loss:	2.3001761436462402

training epoch 3 / 500, batch #125 / 625
Loss:	2.2954020500183105

training epoch 3 / 500, batch #150 / 625
Loss:	2.298259973526001

training epoch 3 / 500, batch #175 / 625
Loss:	2.3032283782958984

training epoch 3 / 500, batch #200 / 625
Loss:	2.291017532348633

training epoch 3 / 500, batch #225 / 625
Loss:	2.2946808338165283

training epoch 3 / 500, batch #250 / 625
Loss:	2.2864160537719727

training epoch 3 / 500, batch #275 / 625
Loss:	2.289442300796509

training epoch 3 / 500, batch #300 / 625
Loss:	2.297211170196533

training epoch 3 / 500, batch #325 / 625
Loss:	2.2924797534942627

training epoch 3 / 500, batch #350 / 625
Loss:	2.2993297576904297

training epoch 3 / 500, batch #375 / 625
Loss:	2.29435396194458

training epoch 3 / 500, batch #400 / 625
Loss:	2.3093373775482178

training epoch 3 / 500, batch #425 / 625
Loss:	2.304309844970703

training epoch 3 / 500, batch #450 / 625
Loss:	2.2975010871887207

training epoch 3 / 500, batch #475 / 625
Loss:	2.262491226196289

training epoch 3 / 500, batch #500 / 625
Loss:	2.2938663959503174

training epoch 3 / 500, batch #525 / 625
Loss:	2.3166050910949707

training epoch 3 / 500, batch #550 / 625
Loss:	2.2861924171447754

training epoch 3 / 500, batch #575 / 625
Loss:	2.3040757179260254

training epoch 3 / 500, batch #600 / 625
Loss:	2.308590888977051

training epoch 4 / 500, batch #0 / 625
Loss:	2.2941412925720215

training epoch 4 / 500, batch #25 / 625
Loss:	2.2776548862457275

training epoch 4 / 500, batch #50 / 625
Loss:	2.2770557403564453

training epoch 4 / 500, batch #75 / 625
Loss:	2.3014862537384033

training epoch 4 / 500, batch #100 / 625
Loss:	2.2985148429870605

training epoch 4 / 500, batch #125 / 625
Loss:	2.304203987121582

training epoch 4 / 500, batch #150 / 625
Loss:	2.3000924587249756

training epoch 4 / 500, batch #175 / 625
Loss:	2.301093578338623

training epoch 4 / 500, batch #200 / 625
Loss:	2.281911611557007

training epoch 4 / 500, batch #225 / 625
Loss:	2.295833110809326

training epoch 4 / 500, batch #250 / 625
Loss:	2.301539897918701

training epoch 4 / 500, batch #275 / 625
Loss:	2.3049163818359375

training epoch 4 / 500, batch #300 / 625
Loss:	2.2972137928009033

training epoch 4 / 500, batch #325 / 625
Loss:	2.30631947517395

training epoch 4 / 500, batch #350 / 625
Loss:	2.2954208850860596

training epoch 4 / 500, batch #375 / 625
Loss:	2.317315101623535

training epoch 4 / 500, batch #400 / 625
Loss:	2.3006246089935303

training epoch 4 / 500, batch #425 / 625
Loss:	2.2664637565612793

training epoch 4 / 500, batch #450 / 625
Loss:	2.301759719848633

training epoch 4 / 500, batch #475 / 625
Loss:	2.3032100200653076

training epoch 4 / 500, batch #500 / 625
Loss:	2.3003337383270264

training epoch 4 / 500, batch #525 / 625
Loss:	2.2879488468170166

training epoch 4 / 500, batch #550 / 625
Loss:	2.2944376468658447

training epoch 4 / 500, batch #575 / 625
Loss:	2.2963016033172607

training epoch 4 / 500, batch #600 / 625
Loss:	2.2845113277435303

training epoch 5 / 500, batch #0 / 625
Loss:	2.2793281078338623

training epoch 5 / 500, batch #25 / 625
Loss:	2.284970760345459

training epoch 5 / 500, batch #50 / 625
Loss:	2.3085248470306396

training epoch 5 / 500, batch #75 / 625
Loss:	2.275669574737549

training epoch 5 / 500, batch #100 / 625
Loss:	2.280586004257202

training epoch 5 / 500, batch #125 / 625
Loss:	2.3036699295043945

training epoch 5 / 500, batch #150 / 625
Loss:	2.3131134510040283

training epoch 5 / 500, batch #175 / 625
Loss:	2.2784929275512695

training epoch 5 / 500, batch #200 / 625
Loss:	2.314523935317993

training epoch 5 / 500, batch #225 / 625
Loss:	2.2530171871185303

training epoch 5 / 500, batch #250 / 625
Loss:	2.288397789001465

training epoch 5 / 500, batch #275 / 625
Loss:	2.306535243988037

training epoch 5 / 500, batch #300 / 625
Loss:	2.2775137424468994

training epoch 5 / 500, batch #325 / 625
Loss:	2.308675765991211

training epoch 5 / 500, batch #350 / 625
Loss:	2.287299156188965

training epoch 5 / 500, batch #375 / 625
Loss:	2.2951221466064453

training epoch 5 / 500, batch #400 / 625
Loss:	2.292151689529419

training epoch 5 / 500, batch #425 / 625
Loss:	2.2907989025115967

training epoch 5 / 500, batch #450 / 625
Loss:	2.2941269874572754

training epoch 5 / 500, batch #475 / 625
Loss:	2.296435594558716

training epoch 5 / 500, batch #500 / 625
Loss:	2.288336753845215

training epoch 5 / 500, batch #525 / 625
Loss:	2.31754732131958

training epoch 5 / 500, batch #550 / 625
Loss:	2.305452585220337

training epoch 5 / 500, batch #575 / 625
Loss:	2.2744462490081787

training epoch 5 / 500, batch #600 / 625
Loss:	2.294273853302002

training epoch 6 / 500, batch #0 / 625
Loss:	2.2838973999023438

training epoch 6 / 500, batch #25 / 625
Loss:	2.309236764907837

training epoch 6 / 500, batch #50 / 625
Loss:	2.288907051086426

training epoch 6 / 500, batch #75 / 625
Loss:	2.3036398887634277

training epoch 6 / 500, batch #100 / 625
Loss:	2.271958589553833

training epoch 6 / 500, batch #125 / 625
Loss:	2.2742269039154053

training epoch 6 / 500, batch #150 / 625
Loss:	2.302263021469116

training epoch 6 / 500, batch #175 / 625
Loss:	2.281571626663208

training epoch 6 / 500, batch #200 / 625
Loss:	2.279569149017334

training epoch 6 / 500, batch #225 / 625
Loss:	2.3242313861846924

training epoch 6 / 500, batch #250 / 625
Loss:	2.2896878719329834

training epoch 6 / 500, batch #275 / 625
Loss:	2.2848660945892334

training epoch 6 / 500, batch #300 / 625
Loss:	2.3127591609954834

training epoch 6 / 500, batch #325 / 625
Loss:	2.2967963218688965

training epoch 6 / 500, batch #350 / 625
Loss:	2.3042900562286377

training epoch 6 / 500, batch #375 / 625
Loss:	2.281184673309326

training epoch 6 / 500, batch #400 / 625
Loss:	2.2801103591918945

training epoch 6 / 500, batch #425 / 625
Loss:	2.3066890239715576

training epoch 6 / 500, batch #450 / 625
Loss:	2.304924726486206

training epoch 6 / 500, batch #475 / 625
Loss:	2.299194097518921

training epoch 6 / 500, batch #500 / 625
Loss:	2.246523141860962

training epoch 6 / 500, batch #525 / 625
Loss:	2.284069061279297

training epoch 6 / 500, batch #550 / 625
Loss:	2.277027130126953

training epoch 6 / 500, batch #575 / 625
Loss:	2.2979981899261475

training epoch 6 / 500, batch #600 / 625
Loss:	2.278308629989624

training epoch 7 / 500, batch #0 / 625
Loss:	2.2916245460510254

training epoch 7 / 500, batch #25 / 625
Loss:	2.2789206504821777

training epoch 7 / 500, batch #50 / 625
Loss:	2.265927791595459

training epoch 7 / 500, batch #75 / 625
Loss:	2.2742836475372314

training epoch 7 / 500, batch #100 / 625
Loss:	2.281665086746216

training epoch 7 / 500, batch #125 / 625
Loss:	2.2497212886810303

training epoch 7 / 500, batch #150 / 625
Loss:	2.2598671913146973

training epoch 7 / 500, batch #175 / 625
Loss:	2.3320937156677246

training epoch 7 / 500, batch #200 / 625
Loss:	2.321830987930298

training epoch 7 / 500, batch #225 / 625
Loss:	2.310256242752075

training epoch 7 / 500, batch #250 / 625
Loss:	2.3051347732543945

training epoch 7 / 500, batch #275 / 625
Loss:	2.280346155166626

training epoch 7 / 500, batch #300 / 625
Loss:	2.278881311416626

training epoch 7 / 500, batch #325 / 625
Loss:	2.2636072635650635

training epoch 7 / 500, batch #350 / 625
Loss:	2.311370849609375

training epoch 7 / 500, batch #375 / 625
Loss:	2.278989791870117

training epoch 7 / 500, batch #400 / 625
Loss:	2.30051589012146

training epoch 7 / 500, batch #425 / 625
Loss:	2.274101495742798

training epoch 7 / 500, batch #450 / 625
Loss:	2.292757511138916

training epoch 7 / 500, batch #475 / 625
Loss:	2.3114328384399414

training epoch 7 / 500, batch #500 / 625
Loss:	2.289281129837036

training epoch 7 / 500, batch #525 / 625
Loss:	2.282496452331543

training epoch 7 / 500, batch #550 / 625
Loss:	2.2979345321655273

training epoch 7 / 500, batch #575 / 625
Loss:	2.3001868724823

training epoch 7 / 500, batch #600 / 625
Loss:	2.2938427925109863

training epoch 8 / 500, batch #0 / 625
Loss:	2.294633150100708

training epoch 8 / 500, batch #25 / 625
Loss:	2.283937692642212

training epoch 8 / 500, batch #50 / 625
Loss:	2.3186206817626953

training epoch 8 / 500, batch #75 / 625
Loss:	2.3171191215515137

training epoch 8 / 500, batch #100 / 625
Loss:	2.3214669227600098

training epoch 8 / 500, batch #125 / 625
Loss:	2.273866653442383

training epoch 8 / 500, batch #150 / 625
Loss:	2.312995433807373

training epoch 8 / 500, batch #175 / 625
Loss:	2.298949956893921

training epoch 8 / 500, batch #200 / 625
Loss:	2.3109891414642334

training epoch 8 / 500, batch #225 / 625
Loss:	2.257965326309204

training epoch 8 / 500, batch #250 / 625
Loss:	2.273043394088745

training epoch 8 / 500, batch #275 / 625
Loss:	2.2649240493774414

training epoch 8 / 500, batch #300 / 625
Loss:	2.281081438064575

training epoch 8 / 500, batch #325 / 625
Loss:	2.309171199798584

training epoch 8 / 500, batch #350 / 625
Loss:	2.2922189235687256

training epoch 8 / 500, batch #375 / 625
Loss:	2.322427749633789

training epoch 8 / 500, batch #400 / 625
Loss:	2.308413505554199

training epoch 8 / 500, batch #425 / 625
Loss:	2.280874490737915

training epoch 8 / 500, batch #450 / 625
Loss:	2.277937889099121

training epoch 8 / 500, batch #475 / 625
Loss:	2.3050315380096436

training epoch 8 / 500, batch #500 / 625
Loss:	2.2839272022247314

training epoch 8 / 500, batch #525 / 625
Loss:	2.300950288772583

training epoch 8 / 500, batch #550 / 625
Loss:	2.2880449295043945

training epoch 8 / 500, batch #575 / 625
Loss:	2.2875115871429443

training epoch 8 / 500, batch #600 / 625
Loss:	2.2543296813964844

training epoch 9 / 500, batch #0 / 625
Loss:	2.200793981552124

training epoch 9 / 500, batch #25 / 625
Loss:	2.2838335037231445

training epoch 9 / 500, batch #50 / 625
Loss:	2.3159918785095215

training epoch 9 / 500, batch #75 / 625
Loss:	2.28497052192688

training epoch 9 / 500, batch #100 / 625
Loss:	2.2477777004241943

training epoch 9 / 500, batch #125 / 625
Loss:	2.23157000541687

training epoch 9 / 500, batch #150 / 625
Loss:	2.218614101409912

training epoch 9 / 500, batch #175 / 625
Loss:	2.3140408992767334

training epoch 9 / 500, batch #200 / 625
Loss:	2.2552874088287354

training epoch 9 / 500, batch #225 / 625
Loss:	2.314422130584717

training epoch 9 / 500, batch #250 / 625
Loss:	2.311136245727539

training epoch 9 / 500, batch #275 / 625
Loss:	2.3019893169403076

training epoch 9 / 500, batch #300 / 625
Loss:	2.289316177368164

training epoch 9 / 500, batch #325 / 625
Loss:	2.2853076457977295

training epoch 9 / 500, batch #350 / 625
Loss:	2.2778921127319336

training epoch 9 / 500, batch #375 / 625
Loss:	2.2798960208892822

training epoch 9 / 500, batch #400 / 625
Loss:	2.2925596237182617

training epoch 9 / 500, batch #425 / 625
Loss:	2.3074512481689453

training epoch 9 / 500, batch #450 / 625
Loss:	2.2566134929656982

training epoch 9 / 500, batch #475 / 625
Loss:	2.2850892543792725

training epoch 9 / 500, batch #500 / 625
Loss:	2.291078567504883

training epoch 9 / 500, batch #525 / 625
Loss:	2.296682357788086

training epoch 9 / 500, batch #550 / 625
Loss:	2.281083822250366

training epoch 9 / 500, batch #575 / 625
Loss:	2.2910025119781494

training epoch 9 / 500, batch #600 / 625
Loss:	2.2912702560424805

training epoch 10 / 500, batch #0 / 625
Loss:	2.307191848754883

training epoch 10 / 500, batch #25 / 625
Loss:	2.273681879043579

training epoch 10 / 500, batch #50 / 625
Loss:	2.3288190364837646

training epoch 10 / 500, batch #75 / 625
Loss:	2.3351542949676514

training epoch 10 / 500, batch #100 / 625
Loss:	2.3011393547058105

training epoch 10 / 500, batch #125 / 625
Loss:	2.2608461380004883

training epoch 10 / 500, batch #150 / 625
Loss:	2.267484188079834

training epoch 10 / 500, batch #175 / 625
Loss:	2.2709834575653076

training epoch 10 / 500, batch #200 / 625
Loss:	2.2731008529663086

training epoch 10 / 500, batch #225 / 625
Loss:	2.3134381771087646

training epoch 10 / 500, batch #250 / 625
Loss:	2.316287040710449

training epoch 10 / 500, batch #275 / 625
Loss:	2.286176919937134

training epoch 10 / 500, batch #300 / 625
Loss:	2.2518105506896973

training epoch 10 / 500, batch #325 / 625
Loss:	2.2322540283203125

training epoch 10 / 500, batch #350 / 625
Loss:	2.2957873344421387

training epoch 10 / 500, batch #375 / 625
Loss:	2.2826499938964844

training epoch 10 / 500, batch #400 / 625
Loss:	2.274482488632202

training epoch 10 / 500, batch #425 / 625
Loss:	2.238286256790161

training epoch 10 / 500, batch #450 / 625
Loss:	2.2445902824401855

training epoch 10 / 500, batch #475 / 625
Loss:	2.250253438949585

training epoch 10 / 500, batch #500 / 625
Loss:	2.2276690006256104

training epoch 10 / 500, batch #525 / 625
Loss:	2.2671306133270264

training epoch 10 / 500, batch #550 / 625
Loss:	2.3286802768707275

training epoch 10 / 500, batch #575 / 625
Loss:	2.234313726425171

training epoch 10 / 500, batch #600 / 625
Loss:	2.2342026233673096

training epoch 11 / 500, batch #0 / 625
Loss:	2.277629852294922

training epoch 11 / 500, batch #25 / 625
Loss:	2.2414419651031494

training epoch 11 / 500, batch #50 / 625
Loss:	2.278163194656372

training epoch 11 / 500, batch #75 / 625
Loss:	2.233175039291382

training epoch 11 / 500, batch #100 / 625
Loss:	2.31622576713562

training epoch 11 / 500, batch #125 / 625
Loss:	2.23758602142334

training epoch 11 / 500, batch #150 / 625
Loss:	2.206634521484375

training epoch 11 / 500, batch #175 / 625
Loss:	2.255108594894409

training epoch 11 / 500, batch #200 / 625
Loss:	2.2200405597686768

training epoch 11 / 500, batch #225 / 625
Loss:	2.2483043670654297

training epoch 11 / 500, batch #250 / 625
Loss:	2.285784959793091

training epoch 11 / 500, batch #275 / 625
Loss:	2.264472723007202

training epoch 11 / 500, batch #300 / 625
Loss:	2.233905792236328

training epoch 11 / 500, batch #325 / 625
Loss:	2.2852299213409424

training epoch 11 / 500, batch #350 / 625
Loss:	2.2874019145965576

training epoch 11 / 500, batch #375 / 625
Loss:	2.3155109882354736

training epoch 11 / 500, batch #400 / 625
Loss:	2.2424910068511963

training epoch 11 / 500, batch #425 / 625
Loss:	2.2696776390075684

training epoch 11 / 500, batch #450 / 625
Loss:	2.237394094467163

training epoch 11 / 500, batch #475 / 625
Loss:	2.306516647338867

training epoch 11 / 500, batch #500 / 625
Loss:	2.294619083404541

training epoch 11 / 500, batch #525 / 625
Loss:	2.316436767578125

training epoch 11 / 500, batch #550 / 625
Loss:	2.284027338027954

training epoch 11 / 500, batch #575 / 625
Loss:	2.2604291439056396

training epoch 11 / 500, batch #600 / 625
Loss:	2.2793924808502197

training epoch 12 / 500, batch #0 / 625
Loss:	2.2924482822418213

training epoch 12 / 500, batch #25 / 625
Loss:	2.259000778198242

training epoch 12 / 500, batch #50 / 625
Loss:	2.2478532791137695

training epoch 12 / 500, batch #75 / 625
Loss:	2.206007719039917

training epoch 12 / 500, batch #100 / 625
Loss:	2.288686990737915

training epoch 12 / 500, batch #125 / 625
Loss:	2.227954387664795

training epoch 12 / 500, batch #150 / 625
Loss:	2.2008066177368164

training epoch 12 / 500, batch #175 / 625
Loss:	2.245927333831787

training epoch 12 / 500, batch #200 / 625
Loss:	2.2642078399658203

training epoch 12 / 500, batch #225 / 625
Loss:	2.2509067058563232

training epoch 12 / 500, batch #250 / 625
Loss:	2.3045244216918945

training epoch 12 / 500, batch #275 / 625
Loss:	2.2257609367370605

training epoch 12 / 500, batch #300 / 625
Loss:	2.3006033897399902

training epoch 12 / 500, batch #325 / 625
Loss:	2.302335500717163

training epoch 12 / 500, batch #350 / 625
Loss:	2.2506279945373535

training epoch 12 / 500, batch #375 / 625
Loss:	2.2910945415496826

training epoch 12 / 500, batch #400 / 625
Loss:	2.2685492038726807

training epoch 12 / 500, batch #425 / 625
Loss:	2.316134214401245

training epoch 12 / 500, batch #450 / 625
Loss:	2.223543405532837

training epoch 12 / 500, batch #475 / 625
Loss:	2.2330896854400635

training epoch 12 / 500, batch #500 / 625
Loss:	2.300473928451538

training epoch 12 / 500, batch #525 / 625
Loss:	2.2544353008270264

training epoch 12 / 500, batch #550 / 625
Loss:	2.300123453140259

training epoch 12 / 500, batch #575 / 625
Loss:	2.257681369781494

training epoch 12 / 500, batch #600 / 625
Loss:	2.2845382690429688

training epoch 13 / 500, batch #0 / 625
Loss:	2.2565503120422363

training epoch 13 / 500, batch #25 / 625
Loss:	2.2643771171569824

training epoch 13 / 500, batch #50 / 625
Loss:	2.238454580307007

training epoch 13 / 500, batch #75 / 625
Loss:	2.239847421646118

training epoch 13 / 500, batch #100 / 625
Loss:	2.256659746170044

training epoch 13 / 500, batch #125 / 625
Loss:	2.2503163814544678

training epoch 13 / 500, batch #150 / 625
Loss:	2.2798802852630615

training epoch 13 / 500, batch #175 / 625
Loss:	2.2447073459625244

training epoch 13 / 500, batch #200 / 625
Loss:	2.264942169189453

training epoch 13 / 500, batch #225 / 625
Loss:	2.266094207763672

training epoch 13 / 500, batch #250 / 625
Loss:	2.2588932514190674

training epoch 13 / 500, batch #275 / 625
Loss:	2.2518656253814697

training epoch 13 / 500, batch #300 / 625
Loss:	2.2405240535736084

training epoch 13 / 500, batch #325 / 625
Loss:	2.2592217922210693

training epoch 13 / 500, batch #350 / 625
Loss:	2.250308036804199

training epoch 13 / 500, batch #375 / 625
Loss:	2.2497165203094482

training epoch 13 / 500, batch #400 / 625
Loss:	2.27807879447937

training epoch 13 / 500, batch #425 / 625
Loss:	2.25111985206604

training epoch 13 / 500, batch #450 / 625
Loss:	2.282834529876709

training epoch 13 / 500, batch #475 / 625
Loss:	2.190619707107544

training epoch 13 / 500, batch #500 / 625
Loss:	2.2270827293395996

training epoch 13 / 500, batch #525 / 625
Loss:	2.207096815109253

training epoch 13 / 500, batch #550 / 625
Loss:	2.2888782024383545

training epoch 13 / 500, batch #575 / 625
Loss:	2.246129274368286

training epoch 13 / 500, batch #600 / 625
Loss:	2.2499868869781494

training epoch 14 / 500, batch #0 / 625
Loss:	2.221116065979004

training epoch 14 / 500, batch #25 / 625
Loss:	2.214125394821167

training epoch 14 / 500, batch #50 / 625
Loss:	2.26424503326416

training epoch 14 / 500, batch #75 / 625
Loss:	2.2901015281677246

training epoch 14 / 500, batch #100 / 625
Loss:	2.2980685234069824

training epoch 14 / 500, batch #125 / 625
Loss:	2.301417112350464

training epoch 14 / 500, batch #150 / 625
Loss:	2.2288601398468018

training epoch 14 / 500, batch #175 / 625
Loss:	2.292509078979492

training epoch 14 / 500, batch #200 / 625
Loss:	2.2270731925964355

training epoch 14 / 500, batch #225 / 625
Loss:	2.2356128692626953

training epoch 14 / 500, batch #250 / 625
Loss:	2.264101982116699

training epoch 14 / 500, batch #275 / 625
Loss:	2.2021517753601074

training epoch 14 / 500, batch #300 / 625
Loss:	2.2853636741638184

training epoch 14 / 500, batch #325 / 625
Loss:	2.334627151489258

training epoch 14 / 500, batch #350 / 625
Loss:	2.2201926708221436

training epoch 14 / 500, batch #375 / 625
Loss:	2.293773889541626

training epoch 14 / 500, batch #400 / 625
Loss:	2.264104127883911

training epoch 14 / 500, batch #425 / 625
Loss:	2.253559112548828

training epoch 14 / 500, batch #450 / 625
Loss:	2.243983745574951

training epoch 14 / 500, batch #475 / 625
Loss:	2.2746922969818115

training epoch 14 / 500, batch #500 / 625
Loss:	2.2612383365631104

training epoch 14 / 500, batch #525 / 625
Loss:	2.24078631401062

training epoch 14 / 500, batch #550 / 625
Loss:	2.223360061645508

training epoch 14 / 500, batch #575 / 625
Loss:	2.2009122371673584

training epoch 14 / 500, batch #600 / 625
Loss:	2.220031499862671

training epoch 15 / 500, batch #0 / 625
Loss:	2.3060529232025146

training epoch 15 / 500, batch #25 / 625
Loss:	2.192054510116577

training epoch 15 / 500, batch #50 / 625
Loss:	2.247802495956421

training epoch 15 / 500, batch #75 / 625
Loss:	2.2719109058380127

training epoch 15 / 500, batch #100 / 625
Loss:	2.261427402496338

training epoch 15 / 500, batch #125 / 625
Loss:	2.152967929840088

training epoch 15 / 500, batch #150 / 625
Loss:	2.277240037918091

training epoch 15 / 500, batch #175 / 625
Loss:	2.2692763805389404

training epoch 15 / 500, batch #200 / 625
Loss:	2.216010093688965

training epoch 15 / 500, batch #225 / 625
Loss:	2.2159104347229004

training epoch 15 / 500, batch #250 / 625
Loss:	2.203833818435669

training epoch 15 / 500, batch #275 / 625
Loss:	2.217216730117798

training epoch 15 / 500, batch #300 / 625
Loss:	2.2003333568573

training epoch 15 / 500, batch #325 / 625
Loss:	2.3298888206481934

training epoch 15 / 500, batch #350 / 625
Loss:	2.2270045280456543

training epoch 15 / 500, batch #375 / 625
Loss:	2.2767770290374756

training epoch 15 / 500, batch #400 / 625
Loss:	2.2454142570495605

training epoch 15 / 500, batch #425 / 625
Loss:	2.2835683822631836

training epoch 15 / 500, batch #450 / 625
Loss:	2.285956621170044

training epoch 15 / 500, batch #475 / 625
Loss:	2.139842987060547

training epoch 15 / 500, batch #500 / 625
Loss:	2.1999619007110596

training epoch 15 / 500, batch #525 / 625
Loss:	2.2874255180358887

training epoch 15 / 500, batch #550 / 625
Loss:	2.2288057804107666

training epoch 15 / 500, batch #575 / 625
Loss:	2.217782735824585

training epoch 15 / 500, batch #600 / 625
Loss:	2.17508864402771

training epoch 16 / 500, batch #0 / 625
Loss:	2.2055280208587646

training epoch 16 / 500, batch #25 / 625
Loss:	2.2216250896453857

training epoch 16 / 500, batch #50 / 625
Loss:	2.214219570159912

training epoch 16 / 500, batch #75 / 625
Loss:	2.215637683868408

training epoch 16 / 500, batch #100 / 625
Loss:	2.2033445835113525

training epoch 16 / 500, batch #125 / 625
Loss:	2.2521984577178955

training epoch 16 / 500, batch #150 / 625
Loss:	2.276076555252075

training epoch 16 / 500, batch #175 / 625
Loss:	2.2116904258728027

training epoch 16 / 500, batch #200 / 625
Loss:	2.1789238452911377

training epoch 16 / 500, batch #225 / 625
Loss:	2.2287142276763916

training epoch 16 / 500, batch #250 / 625
Loss:	2.142265558242798

training epoch 16 / 500, batch #275 / 625
Loss:	2.227512836456299

training epoch 16 / 500, batch #300 / 625
Loss:	2.215876579284668

training epoch 16 / 500, batch #325 / 625
Loss:	2.2929561138153076

training epoch 16 / 500, batch #350 / 625
Loss:	2.259916067123413

training epoch 16 / 500, batch #375 / 625
Loss:	2.1710736751556396

training epoch 16 / 500, batch #400 / 625
Loss:	2.237269878387451

training epoch 16 / 500, batch #425 / 625
Loss:	2.290581703186035

training epoch 16 / 500, batch #450 / 625
Loss:	2.276679039001465

training epoch 16 / 500, batch #475 / 625
Loss:	2.261502265930176

training epoch 16 / 500, batch #500 / 625
Loss:	2.212057113647461

training epoch 16 / 500, batch #525 / 625
Loss:	2.2300055027008057

training epoch 16 / 500, batch #550 / 625
Loss:	2.1347908973693848

training epoch 16 / 500, batch #575 / 625
Loss:	2.1353766918182373

training epoch 16 / 500, batch #600 / 625
Loss:	2.2192749977111816

training epoch 17 / 500, batch #0 / 625
Loss:	2.2194066047668457

training epoch 17 / 500, batch #25 / 625
Loss:	2.255997657775879

training epoch 17 / 500, batch #50 / 625
Loss:	2.2354419231414795

training epoch 17 / 500, batch #75 / 625
Loss:	2.1617276668548584

training epoch 17 / 500, batch #100 / 625
Loss:	2.1991724967956543

training epoch 17 / 500, batch #125 / 625
Loss:	2.2273366451263428

training epoch 17 / 500, batch #150 / 625
Loss:	2.2624752521514893

training epoch 17 / 500, batch #175 / 625
Loss:	2.2080087661743164

training epoch 17 / 500, batch #200 / 625
Loss:	2.1888983249664307

training epoch 17 / 500, batch #225 / 625
Loss:	2.187147378921509

training epoch 17 / 500, batch #250 / 625
Loss:	2.1657583713531494

training epoch 17 / 500, batch #275 / 625
Loss:	2.1841917037963867

training epoch 17 / 500, batch #300 / 625
Loss:	2.2052130699157715

training epoch 17 / 500, batch #325 / 625
Loss:	2.2043917179107666

training epoch 17 / 500, batch #350 / 625
Loss:	2.1509346961975098

training epoch 17 / 500, batch #375 / 625
Loss:	2.2075350284576416

training epoch 17 / 500, batch #400 / 625
Loss:	2.226358652114868

training epoch 17 / 500, batch #425 / 625
Loss:	2.2644011974334717

training epoch 17 / 500, batch #450 / 625
Loss:	2.223004102706909

training epoch 17 / 500, batch #475 / 625
Loss:	2.280935764312744

training epoch 17 / 500, batch #500 / 625
Loss:	2.1955721378326416

training epoch 17 / 500, batch #525 / 625
Loss:	2.196458339691162

training epoch 17 / 500, batch #550 / 625
Loss:	2.222399950027466

training epoch 17 / 500, batch #575 / 625
Loss:	2.1132102012634277

training epoch 17 / 500, batch #600 / 625
Loss:	2.228569746017456

training epoch 18 / 500, batch #0 / 625
Loss:	2.15053653717041

training epoch 18 / 500, batch #25 / 625
Loss:	2.1710147857666016

training epoch 18 / 500, batch #50 / 625
Loss:	2.211113214492798

training epoch 18 / 500, batch #75 / 625
Loss:	2.1710259914398193

training epoch 18 / 500, batch #100 / 625
Loss:	2.263716697692871

training epoch 18 / 500, batch #125 / 625
Loss:	2.1578404903411865

training epoch 18 / 500, batch #150 / 625
Loss:	2.2490766048431396

training epoch 18 / 500, batch #175 / 625
Loss:	2.2568047046661377

training epoch 18 / 500, batch #200 / 625
Loss:	2.1430563926696777

training epoch 18 / 500, batch #225 / 625
Loss:	2.2256650924682617

training epoch 18 / 500, batch #250 / 625
Loss:	2.255037784576416

training epoch 18 / 500, batch #275 / 625
Loss:	2.309892416000366

training epoch 18 / 500, batch #300 / 625
Loss:	2.1360669136047363

training epoch 18 / 500, batch #325 / 625
Loss:	2.183462619781494

training epoch 18 / 500, batch #350 / 625
Loss:	2.2328810691833496

training epoch 18 / 500, batch #375 / 625
Loss:	2.159372091293335

training epoch 18 / 500, batch #400 / 625
Loss:	2.267889976501465

training epoch 18 / 500, batch #425 / 625
Loss:	2.2711167335510254

training epoch 18 / 500, batch #450 / 625
Loss:	2.1891393661499023

training epoch 18 / 500, batch #475 / 625
Loss:	2.096226692199707

training epoch 18 / 500, batch #500 / 625
Loss:	2.2781732082366943

training epoch 18 / 500, batch #525 / 625
Loss:	2.1391024589538574

training epoch 18 / 500, batch #550 / 625
Loss:	2.3672780990600586

training epoch 18 / 500, batch #575 / 625
Loss:	2.1542739868164062

training epoch 18 / 500, batch #600 / 625
Loss:	2.2687017917633057

training epoch 19 / 500, batch #0 / 625
Loss:	2.227994441986084

training epoch 19 / 500, batch #25 / 625
Loss:	2.2547638416290283

training epoch 19 / 500, batch #50 / 625
Loss:	2.175013780593872

training epoch 19 / 500, batch #75 / 625
Loss:	2.1759989261627197

training epoch 19 / 500, batch #100 / 625
Loss:	2.331277847290039

training epoch 19 / 500, batch #125 / 625
Loss:	2.1858644485473633

training epoch 19 / 500, batch #150 / 625
Loss:	2.234158515930176

training epoch 19 / 500, batch #175 / 625
Loss:	2.1982693672180176

training epoch 19 / 500, batch #200 / 625
Loss:	2.2316932678222656

training epoch 19 / 500, batch #225 / 625
Loss:	2.133129835128784

training epoch 19 / 500, batch #250 / 625
Loss:	2.1768484115600586

training epoch 19 / 500, batch #275 / 625
Loss:	2.1135575771331787

training epoch 19 / 500, batch #300 / 625
Loss:	2.213590621948242

training epoch 19 / 500, batch #325 / 625
Loss:	2.1611950397491455

training epoch 19 / 500, batch #350 / 625
Loss:	2.230905532836914

training epoch 19 / 500, batch #375 / 625
Loss:	2.118361234664917

training epoch 19 / 500, batch #400 / 625
Loss:	2.2262392044067383

training epoch 19 / 500, batch #425 / 625
Loss:	2.108618974685669

training epoch 19 / 500, batch #450 / 625
Loss:	2.151766300201416

training epoch 19 / 500, batch #475 / 625
Loss:	2.1382088661193848

training epoch 19 / 500, batch #500 / 625
Loss:	2.2003095149993896

training epoch 19 / 500, batch #525 / 625
Loss:	2.154691219329834

training epoch 19 / 500, batch #550 / 625
Loss:	2.27429461479187

training epoch 19 / 500, batch #575 / 625
Loss:	2.310170888900757

training epoch 19 / 500, batch #600 / 625
Loss:	2.1600475311279297

training epoch 20 / 500, batch #0 / 625
Loss:	2.1173622608184814

training epoch 20 / 500, batch #25 / 625
Loss:	2.0830183029174805

training epoch 20 / 500, batch #50 / 625
Loss:	2.147306442260742

training epoch 20 / 500, batch #75 / 625
Loss:	2.1637449264526367

training epoch 20 / 500, batch #100 / 625
Loss:	2.2634871006011963

training epoch 20 / 500, batch #125 / 625
Loss:	2.2700295448303223

training epoch 20 / 500, batch #150 / 625
Loss:	2.166193723678589

training epoch 20 / 500, batch #175 / 625
Loss:	2.1598219871520996

training epoch 20 / 500, batch #200 / 625
Loss:	2.261174201965332

training epoch 20 / 500, batch #225 / 625
Loss:	2.1311614513397217

training epoch 20 / 500, batch #250 / 625
Loss:	2.170067071914673

training epoch 20 / 500, batch #275 / 625
Loss:	2.137077569961548

training epoch 20 / 500, batch #300 / 625
Loss:	2.157045602798462

training epoch 20 / 500, batch #325 / 625
Loss:	2.265169143676758

training epoch 20 / 500, batch #350 / 625
Loss:	2.064438819885254

training epoch 20 / 500, batch #375 / 625
Loss:	2.1560046672821045

training epoch 20 / 500, batch #400 / 625
Loss:	2.1584291458129883

training epoch 20 / 500, batch #425 / 625
Loss:	2.1895618438720703

training epoch 20 / 500, batch #450 / 625
Loss:	2.2135396003723145

training epoch 20 / 500, batch #475 / 625
Loss:	2.206920862197876

training epoch 20 / 500, batch #500 / 625
Loss:	2.182992935180664

training epoch 20 / 500, batch #525 / 625
Loss:	2.116853952407837

training epoch 20 / 500, batch #550 / 625
Loss:	2.2335946559906006

training epoch 20 / 500, batch #575 / 625
Loss:	2.1760685443878174

training epoch 20 / 500, batch #600 / 625
Loss:	2.179593801498413

training epoch 21 / 500, batch #0 / 625
Loss:	2.235253095626831

training epoch 21 / 500, batch #25 / 625
Loss:	2.0914809703826904

training epoch 21 / 500, batch #50 / 625
Loss:	2.1835575103759766

training epoch 21 / 500, batch #75 / 625
Loss:	2.1902003288269043

training epoch 21 / 500, batch #100 / 625
Loss:	2.1222646236419678

training epoch 21 / 500, batch #125 / 625
Loss:	2.0945842266082764

training epoch 21 / 500, batch #150 / 625
Loss:	2.0623488426208496

training epoch 21 / 500, batch #175 / 625
Loss:	2.3159728050231934

training epoch 21 / 500, batch #200 / 625
Loss:	2.0550143718719482

training epoch 21 / 500, batch #225 / 625
Loss:	2.1618988513946533

training epoch 21 / 500, batch #250 / 625
Loss:	2.1015357971191406

training epoch 21 / 500, batch #275 / 625
Loss:	2.257249116897583

training epoch 21 / 500, batch #300 / 625
Loss:	2.274862051010132

training epoch 21 / 500, batch #325 / 625
Loss:	2.145979166030884

training epoch 21 / 500, batch #350 / 625
Loss:	2.088186264038086

training epoch 21 / 500, batch #375 / 625
Loss:	1.999765157699585

training epoch 21 / 500, batch #400 / 625
Loss:	2.3072423934936523

training epoch 21 / 500, batch #425 / 625
Loss:	2.244136095046997

training epoch 21 / 500, batch #450 / 625
Loss:	2.106387138366699

training epoch 21 / 500, batch #475 / 625
Loss:	2.1287572383880615

training epoch 21 / 500, batch #500 / 625
Loss:	2.1620075702667236

training epoch 21 / 500, batch #525 / 625
Loss:	2.152655601501465

training epoch 21 / 500, batch #550 / 625
Loss:	2.2954976558685303

training epoch 21 / 500, batch #575 / 625
Loss:	2.0584592819213867

training epoch 21 / 500, batch #600 / 625
Loss:	2.178053855895996

training epoch 22 / 500, batch #0 / 625
Loss:	2.2253048419952393

training epoch 22 / 500, batch #25 / 625
Loss:	2.1414453983306885

training epoch 22 / 500, batch #50 / 625
Loss:	2.0393004417419434

training epoch 22 / 500, batch #75 / 625
Loss:	2.2958948612213135

training epoch 22 / 500, batch #100 / 625
Loss:	2.1404223442077637

training epoch 22 / 500, batch #125 / 625
Loss:	2.152756452560425

training epoch 22 / 500, batch #150 / 625
Loss:	2.0937163829803467

training epoch 22 / 500, batch #175 / 625
Loss:	2.055393934249878

training epoch 22 / 500, batch #200 / 625
Loss:	2.1528549194335938

training epoch 22 / 500, batch #225 / 625
Loss:	2.061211347579956

training epoch 22 / 500, batch #250 / 625
Loss:	2.124567985534668

training epoch 22 / 500, batch #275 / 625
Loss:	2.140544891357422

training epoch 22 / 500, batch #300 / 625
Loss:	2.14813494682312

training epoch 22 / 500, batch #325 / 625
Loss:	2.015087127685547

training epoch 22 / 500, batch #350 / 625
Loss:	2.089447498321533

training epoch 22 / 500, batch #375 / 625
Loss:	2.141611099243164

training epoch 22 / 500, batch #400 / 625
Loss:	2.174692392349243

training epoch 22 / 500, batch #425 / 625
Loss:	2.1922335624694824

training epoch 22 / 500, batch #450 / 625
Loss:	2.0777385234832764

training epoch 22 / 500, batch #475 / 625
Loss:	2.1227874755859375

training epoch 22 / 500, batch #500 / 625
Loss:	2.152416467666626

training epoch 22 / 500, batch #525 / 625
Loss:	2.0710957050323486

training epoch 22 / 500, batch #550 / 625
Loss:	2.0850701332092285

training epoch 22 / 500, batch #575 / 625
Loss:	2.110645294189453

training epoch 22 / 500, batch #600 / 625
Loss:	2.2045884132385254

training epoch 23 / 500, batch #0 / 625
Loss:	2.265073537826538

training epoch 23 / 500, batch #25 / 625
Loss:	2.003085136413574

training epoch 23 / 500, batch #50 / 625
Loss:	2.1703927516937256

training epoch 23 / 500, batch #75 / 625
Loss:	2.0344760417938232

training epoch 23 / 500, batch #100 / 625
Loss:	2.2114765644073486

training epoch 23 / 500, batch #125 / 625
Loss:	2.1208417415618896

training epoch 23 / 500, batch #150 / 625
Loss:	2.1128339767456055

training epoch 23 / 500, batch #175 / 625
Loss:	2.0756123065948486

training epoch 23 / 500, batch #200 / 625
Loss:	2.0036163330078125

training epoch 23 / 500, batch #225 / 625
Loss:	1.9362938404083252

training epoch 23 / 500, batch #250 / 625
Loss:	2.098719596862793

training epoch 23 / 500, batch #275 / 625
Loss:	1.9320166110992432

training epoch 23 / 500, batch #300 / 625
Loss:	1.9154003858566284

training epoch 23 / 500, batch #325 / 625
Loss:	2.061513900756836

training epoch 23 / 500, batch #350 / 625
Loss:	2.161770820617676

training epoch 23 / 500, batch #375 / 625
Loss:	2.057494640350342

training epoch 23 / 500, batch #400 / 625
Loss:	2.1509640216827393

training epoch 23 / 500, batch #425 / 625
Loss:	2.091874361038208

training epoch 23 / 500, batch #450 / 625
Loss:	1.9707096815109253

training epoch 23 / 500, batch #475 / 625
Loss:	1.9867885112762451

training epoch 23 / 500, batch #500 / 625
Loss:	2.048088550567627

training epoch 23 / 500, batch #525 / 625
Loss:	2.1120309829711914

training epoch 23 / 500, batch #550 / 625
Loss:	2.092822790145874

training epoch 23 / 500, batch #575 / 625
Loss:	2.0887584686279297

training epoch 23 / 500, batch #600 / 625
Loss:	2.144951105117798

training epoch 24 / 500, batch #0 / 625
Loss:	2.031480550765991

training epoch 24 / 500, batch #25 / 625
Loss:	2.173740863800049

training epoch 24 / 500, batch #50 / 625
Loss:	2.120387077331543

training epoch 24 / 500, batch #75 / 625
Loss:	2.0374598503112793

training epoch 24 / 500, batch #100 / 625
Loss:	2.168900728225708

training epoch 24 / 500, batch #125 / 625
Loss:	2.051619291305542

training epoch 24 / 500, batch #150 / 625
Loss:	2.1245861053466797

training epoch 24 / 500, batch #175 / 625
Loss:	2.1756350994110107

training epoch 24 / 500, batch #200 / 625
Loss:	2.1084258556365967

training epoch 24 / 500, batch #225 / 625
Loss:	2.0734307765960693

training epoch 24 / 500, batch #250 / 625
Loss:	1.982611894607544

training epoch 24 / 500, batch #275 / 625
Loss:	2.10022234916687

training epoch 24 / 500, batch #300 / 625
Loss:	2.109654664993286

training epoch 24 / 500, batch #325 / 625
Loss:	2.223680019378662

training epoch 24 / 500, batch #350 / 625
Loss:	1.93239164352417

training epoch 24 / 500, batch #375 / 625
Loss:	2.2809300422668457

training epoch 24 / 500, batch #400 / 625
Loss:	2.0327072143554688

training epoch 24 / 500, batch #425 / 625
Loss:	2.170520782470703

training epoch 24 / 500, batch #450 / 625
Loss:	2.075532913208008

training epoch 24 / 500, batch #475 / 625
Loss:	1.8885931968688965

training epoch 24 / 500, batch #500 / 625
Loss:	1.932375431060791

training epoch 24 / 500, batch #525 / 625
Loss:	2.1469180583953857

training epoch 24 / 500, batch #550 / 625
Loss:	1.9248355627059937

training epoch 24 / 500, batch #575 / 625
Loss:	2.0779592990875244

training epoch 24 / 500, batch #600 / 625
Loss:	2.1446449756622314

training epoch 25 / 500, batch #0 / 625
Loss:	1.9762636423110962

training epoch 25 / 500, batch #25 / 625
Loss:	2.0507631301879883

training epoch 25 / 500, batch #50 / 625
Loss:	2.030303478240967

training epoch 25 / 500, batch #75 / 625
Loss:	2.044295310974121

training epoch 25 / 500, batch #100 / 625
Loss:	2.0811822414398193

training epoch 25 / 500, batch #125 / 625
Loss:	2.052577018737793

training epoch 25 / 500, batch #150 / 625
Loss:	2.0755550861358643

training epoch 25 / 500, batch #175 / 625
Loss:	2.132282018661499

training epoch 25 / 500, batch #200 / 625
Loss:	1.8169450759887695

training epoch 25 / 500, batch #225 / 625
Loss:	2.0382137298583984

training epoch 25 / 500, batch #250 / 625
Loss:	2.0805375576019287

training epoch 25 / 500, batch #275 / 625
Loss:	1.9791322946548462

training epoch 25 / 500, batch #300 / 625
Loss:	1.9674570560455322

training epoch 25 / 500, batch #325 / 625
Loss:	2.0702710151672363

training epoch 25 / 500, batch #350 / 625
Loss:	1.991779088973999

training epoch 25 / 500, batch #375 / 625
Loss:	2.066868305206299

training epoch 25 / 500, batch #400 / 625
Loss:	2.0271246433258057

training epoch 25 / 500, batch #425 / 625
Loss:	2.1123030185699463

training epoch 25 / 500, batch #450 / 625
Loss:	2.1227025985717773

training epoch 25 / 500, batch #475 / 625
Loss:	2.1096065044403076

training epoch 25 / 500, batch #500 / 625
Loss:	1.9179022312164307

training epoch 25 / 500, batch #525 / 625
Loss:	2.096639394760132

training epoch 25 / 500, batch #550 / 625
Loss:	2.0965049266815186

training epoch 25 / 500, batch #575 / 625
Loss:	1.9949896335601807

training epoch 25 / 500, batch #600 / 625
Loss:	2.084662437438965

training epoch 26 / 500, batch #0 / 625
Loss:	2.076625347137451

training epoch 26 / 500, batch #25 / 625
Loss:	2.066370725631714

training epoch 26 / 500, batch #50 / 625
Loss:	2.0428383350372314

training epoch 26 / 500, batch #75 / 625
Loss:	1.9774739742279053

training epoch 26 / 500, batch #100 / 625
Loss:	1.930696964263916

training epoch 26 / 500, batch #125 / 625
Loss:	2.052638292312622

training epoch 26 / 500, batch #150 / 625
Loss:	1.9536956548690796

training epoch 26 / 500, batch #175 / 625
Loss:	2.1937735080718994

training epoch 26 / 500, batch #200 / 625
Loss:	2.1373448371887207

training epoch 26 / 500, batch #225 / 625
Loss:	2.1009931564331055

training epoch 26 / 500, batch #250 / 625
Loss:	1.9485770463943481

training epoch 26 / 500, batch #275 / 625
Loss:	2.2104859352111816

training epoch 26 / 500, batch #300 / 625
Loss:	2.1174428462982178

training epoch 26 / 500, batch #325 / 625
Loss:	2.2009177207946777

training epoch 26 / 500, batch #350 / 625
Loss:	2.0873560905456543

training epoch 26 / 500, batch #375 / 625
Loss:	1.9906812906265259

training epoch 26 / 500, batch #400 / 625
Loss:	2.0354979038238525

training epoch 26 / 500, batch #425 / 625
Loss:	2.0557639598846436

training epoch 26 / 500, batch #450 / 625
Loss:	1.8589617013931274

training epoch 26 / 500, batch #475 / 625
Loss:	2.1060683727264404

training epoch 26 / 500, batch #500 / 625
Loss:	2.0015203952789307

training epoch 26 / 500, batch #525 / 625
Loss:	2.1256372928619385

training epoch 26 / 500, batch #550 / 625
Loss:	2.1229372024536133

training epoch 26 / 500, batch #575 / 625
Loss:	2.012539863586426

training epoch 26 / 500, batch #600 / 625
Loss:	2.0650553703308105

training epoch 27 / 500, batch #0 / 625
Loss:	2.0144476890563965

training epoch 27 / 500, batch #25 / 625
Loss:	1.9577512741088867

training epoch 27 / 500, batch #50 / 625
Loss:	2.0749459266662598

training epoch 27 / 500, batch #75 / 625
Loss:	2.083270788192749

training epoch 27 / 500, batch #100 / 625
Loss:	1.9710530042648315

training epoch 27 / 500, batch #125 / 625
Loss:	2.134385824203491

training epoch 27 / 500, batch #150 / 625
Loss:	2.086294174194336

training epoch 27 / 500, batch #175 / 625
Loss:	2.0002543926239014

training epoch 27 / 500, batch #200 / 625
Loss:	2.2116665840148926

training epoch 27 / 500, batch #225 / 625
Loss:	2.1813414096832275

training epoch 27 / 500, batch #250 / 625
Loss:	2.037971019744873

training epoch 27 / 500, batch #275 / 625
Loss:	2.133683919906616

training epoch 27 / 500, batch #300 / 625
Loss:	2.100749969482422

training epoch 27 / 500, batch #325 / 625
Loss:	2.019456148147583

training epoch 27 / 500, batch #350 / 625
Loss:	2.0525636672973633

training epoch 27 / 500, batch #375 / 625
Loss:	1.983716368675232

training epoch 27 / 500, batch #400 / 625
Loss:	1.936429738998413

training epoch 27 / 500, batch #425 / 625
Loss:	1.8370225429534912

training epoch 27 / 500, batch #450 / 625
Loss:	1.9761056900024414

training epoch 27 / 500, batch #475 / 625
Loss:	2.0670270919799805

training epoch 27 / 500, batch #500 / 625
Loss:	2.056736946105957

training epoch 27 / 500, batch #525 / 625
Loss:	2.212949275970459

training epoch 27 / 500, batch #550 / 625
Loss:	2.2097253799438477

training epoch 27 / 500, batch #575 / 625
Loss:	2.2936630249023438

training epoch 27 / 500, batch #600 / 625
Loss:	2.103576183319092

training epoch 28 / 500, batch #0 / 625
Loss:	2.015521287918091

training epoch 28 / 500, batch #25 / 625
Loss:	2.014251232147217

training epoch 28 / 500, batch #50 / 625
Loss:	2.1110687255859375

training epoch 28 / 500, batch #75 / 625
Loss:	1.9730029106140137

training epoch 28 / 500, batch #100 / 625
Loss:	2.183594226837158

training epoch 28 / 500, batch #125 / 625
Loss:	1.993922233581543

training epoch 28 / 500, batch #150 / 625
Loss:	1.8459935188293457

training epoch 28 / 500, batch #175 / 625
Loss:	2.1159987449645996

training epoch 28 / 500, batch #200 / 625
Loss:	2.01229190826416

training epoch 28 / 500, batch #225 / 625
Loss:	2.1233832836151123

training epoch 28 / 500, batch #250 / 625
Loss:	2.062014102935791

training epoch 28 / 500, batch #275 / 625
Loss:	2.00191068649292

training epoch 28 / 500, batch #300 / 625
Loss:	1.8817131519317627

training epoch 28 / 500, batch #325 / 625
Loss:	2.0987894535064697

training epoch 28 / 500, batch #350 / 625
Loss:	2.093827962875366

training epoch 28 / 500, batch #375 / 625
Loss:	2.2224926948547363

training epoch 28 / 500, batch #400 / 625
Loss:	1.9627219438552856

training epoch 28 / 500, batch #425 / 625
Loss:	1.9623805284500122

training epoch 28 / 500, batch #450 / 625
Loss:	2.077484130859375

training epoch 28 / 500, batch #475 / 625
Loss:	2.0725553035736084

training epoch 28 / 500, batch #500 / 625
Loss:	2.0298683643341064

training epoch 28 / 500, batch #525 / 625
Loss:	2.0457842350006104

training epoch 28 / 500, batch #550 / 625
Loss:	2.1388373374938965

training epoch 28 / 500, batch #575 / 625
Loss:	2.048168420791626

training epoch 28 / 500, batch #600 / 625
Loss:	1.9359248876571655

training epoch 29 / 500, batch #0 / 625
Loss:	2.077970266342163

training epoch 29 / 500, batch #25 / 625
Loss:	1.9596590995788574

training epoch 29 / 500, batch #50 / 625
Loss:	1.928721308708191

training epoch 29 / 500, batch #75 / 625
Loss:	2.1679368019104004

training epoch 29 / 500, batch #100 / 625
Loss:	2.0518240928649902

training epoch 29 / 500, batch #125 / 625
Loss:	1.950606107711792

training epoch 29 / 500, batch #150 / 625
Loss:	2.129554033279419

training epoch 29 / 500, batch #175 / 625
Loss:	2.001288652420044

training epoch 29 / 500, batch #200 / 625
Loss:	2.1876513957977295

training epoch 29 / 500, batch #225 / 625
Loss:	1.970473051071167

training epoch 29 / 500, batch #250 / 625
Loss:	2.1109695434570312

training epoch 29 / 500, batch #275 / 625
Loss:	1.9266988039016724

training epoch 29 / 500, batch #300 / 625
Loss:	2.1495673656463623

training epoch 29 / 500, batch #325 / 625
Loss:	1.9697996377944946

training epoch 29 / 500, batch #350 / 625
Loss:	1.9694116115570068

training epoch 29 / 500, batch #375 / 625
Loss:	2.2282145023345947

training epoch 29 / 500, batch #400 / 625
Loss:	1.9244107007980347

training epoch 29 / 500, batch #425 / 625
Loss:	2.11493182182312

training epoch 29 / 500, batch #450 / 625
Loss:	1.9672691822052002

training epoch 29 / 500, batch #475 / 625
Loss:	2.0140745639801025

training epoch 29 / 500, batch #500 / 625
Loss:	1.905667781829834

training epoch 29 / 500, batch #525 / 625
Loss:	2.1135265827178955

training epoch 29 / 500, batch #550 / 625
Loss:	1.9865648746490479

training epoch 29 / 500, batch #575 / 625
Loss:	2.056880235671997

training epoch 29 / 500, batch #600 / 625
Loss:	2.0475010871887207

training epoch 30 / 500, batch #0 / 625
Loss:	1.8564260005950928

training epoch 30 / 500, batch #25 / 625
Loss:	2.0852138996124268

training epoch 30 / 500, batch #50 / 625
Loss:	1.9410958290100098

training epoch 30 / 500, batch #75 / 625
Loss:	2.104998826980591

training epoch 30 / 500, batch #100 / 625
Loss:	2.0717883110046387

training epoch 30 / 500, batch #125 / 625
Loss:	2.0798776149749756

training epoch 30 / 500, batch #150 / 625
Loss:	1.9240477085113525

training epoch 30 / 500, batch #175 / 625
Loss:	2.13118314743042

training epoch 30 / 500, batch #200 / 625
Loss:	1.9689868688583374

training epoch 30 / 500, batch #225 / 625
Loss:	1.9586960077285767

training epoch 30 / 500, batch #250 / 625
Loss:	2.0603036880493164

training epoch 30 / 500, batch #275 / 625
Loss:	2.120530366897583

training epoch 30 / 500, batch #300 / 625
Loss:	1.9652079343795776

training epoch 30 / 500, batch #325 / 625
Loss:	1.9968458414077759

training epoch 30 / 500, batch #350 / 625
Loss:	1.8451205492019653

training epoch 30 / 500, batch #375 / 625
Loss:	2.1100575923919678

training epoch 30 / 500, batch #400 / 625
Loss:	2.0840718746185303

training epoch 30 / 500, batch #425 / 625
Loss:	2.1558189392089844

training epoch 30 / 500, batch #450 / 625
Loss:	2.1101012229919434

training epoch 30 / 500, batch #475 / 625
Loss:	1.9719582796096802

training epoch 30 / 500, batch #500 / 625
Loss:	1.9512406587600708

training epoch 30 / 500, batch #525 / 625
Loss:	2.1593809127807617

training epoch 30 / 500, batch #550 / 625
Loss:	2.191706895828247

training epoch 30 / 500, batch #575 / 625
Loss:	1.9725757837295532

training epoch 30 / 500, batch #600 / 625
Loss:	1.9968702793121338

training epoch 31 / 500, batch #0 / 625
Loss:	2.111670970916748

training epoch 31 / 500, batch #25 / 625
Loss:	1.8970428705215454

training epoch 31 / 500, batch #50 / 625
Loss:	2.0195565223693848

training epoch 31 / 500, batch #75 / 625
Loss:	2.1755406856536865

training epoch 31 / 500, batch #100 / 625
Loss:	1.8883601427078247

training epoch 31 / 500, batch #125 / 625
Loss:	2.224212408065796

training epoch 31 / 500, batch #150 / 625
Loss:	2.1237070560455322

training epoch 31 / 500, batch #175 / 625
Loss:	2.044837236404419

training epoch 31 / 500, batch #200 / 625
Loss:	2.0044162273406982

training epoch 31 / 500, batch #225 / 625
Loss:	2.1556894779205322

training epoch 31 / 500, batch #250 / 625
Loss:	1.9785280227661133

training epoch 31 / 500, batch #275 / 625
Loss:	1.8974238634109497

training epoch 31 / 500, batch #300 / 625
Loss:	1.9375834465026855

training epoch 31 / 500, batch #325 / 625
Loss:	1.9968223571777344

training epoch 31 / 500, batch #350 / 625
Loss:	1.9036318063735962

training epoch 31 / 500, batch #375 / 625
Loss:	1.9345884323120117

training epoch 31 / 500, batch #400 / 625
Loss:	2.156778335571289

training epoch 31 / 500, batch #425 / 625
Loss:	2.038212776184082

training epoch 31 / 500, batch #450 / 625
Loss:	1.9407058954238892

training epoch 31 / 500, batch #475 / 625
Loss:	1.94692862033844

training epoch 31 / 500, batch #500 / 625
Loss:	1.8222800493240356

training epoch 31 / 500, batch #525 / 625
Loss:	2.1079633235931396

training epoch 31 / 500, batch #550 / 625
Loss:	2.064516305923462

training epoch 31 / 500, batch #575 / 625
Loss:	2.1074392795562744

training epoch 31 / 500, batch #600 / 625
Loss:	1.8432739973068237

training epoch 32 / 500, batch #0 / 625
Loss:	2.2109580039978027

training epoch 32 / 500, batch #25 / 625
Loss:	1.8859201669692993

training epoch 32 / 500, batch #50 / 625
Loss:	2.1732161045074463

training epoch 32 / 500, batch #75 / 625
Loss:	2.0633115768432617

training epoch 32 / 500, batch #100 / 625
Loss:	1.8954373598098755

training epoch 32 / 500, batch #125 / 625
Loss:	2.0846445560455322

training epoch 32 / 500, batch #150 / 625
Loss:	1.952940583229065

training epoch 32 / 500, batch #175 / 625
Loss:	1.970337152481079

training epoch 32 / 500, batch #200 / 625
Loss:	1.88436758518219

training epoch 32 / 500, batch #225 / 625
Loss:	2.1394999027252197

training epoch 32 / 500, batch #250 / 625
Loss:	1.9709224700927734

training epoch 32 / 500, batch #275 / 625
Loss:	2.075995445251465

training epoch 32 / 500, batch #300 / 625
Loss:	2.0435564517974854

training epoch 32 / 500, batch #325 / 625
Loss:	2.0904452800750732

training epoch 32 / 500, batch #350 / 625
Loss:	1.8502134084701538

training epoch 32 / 500, batch #375 / 625
Loss:	2.0272674560546875

training epoch 32 / 500, batch #400 / 625
Loss:	2.210886240005493

training epoch 32 / 500, batch #425 / 625
Loss:	2.0471065044403076

training epoch 32 / 500, batch #450 / 625
Loss:	2.0281670093536377

training epoch 32 / 500, batch #475 / 625
Loss:	1.9407165050506592

training epoch 32 / 500, batch #500 / 625
Loss:	2.049777030944824

training epoch 32 / 500, batch #525 / 625
Loss:	2.004682779312134

training epoch 32 / 500, batch #550 / 625
Loss:	1.984588861465454

training epoch 32 / 500, batch #575 / 625
Loss:	1.9879968166351318

training epoch 32 / 500, batch #600 / 625
Loss:	2.0510292053222656

training epoch 33 / 500, batch #0 / 625
Loss:	1.9978941679000854

training epoch 33 / 500, batch #25 / 625
Loss:	2.0843710899353027

training epoch 33 / 500, batch #50 / 625
Loss:	2.057828187942505

training epoch 33 / 500, batch #75 / 625
Loss:	2.149789571762085

training epoch 33 / 500, batch #100 / 625
Loss:	1.9276539087295532

training epoch 33 / 500, batch #125 / 625
Loss:	2.040172815322876

training epoch 33 / 500, batch #150 / 625
Loss:	2.014401912689209

training epoch 33 / 500, batch #175 / 625
Loss:	2.1259589195251465

training epoch 33 / 500, batch #200 / 625
Loss:	2.080014705657959

training epoch 33 / 500, batch #225 / 625
Loss:	2.14164400100708

training epoch 33 / 500, batch #250 / 625
Loss:	2.1078362464904785

training epoch 33 / 500, batch #275 / 625
Loss:	1.9067368507385254

training epoch 33 / 500, batch #300 / 625
Loss:	1.8388410806655884

training epoch 33 / 500, batch #325 / 625
Loss:	2.0974960327148438

training epoch 33 / 500, batch #350 / 625
Loss:	1.9771193265914917

training epoch 33 / 500, batch #375 / 625
Loss:	2.1134350299835205

training epoch 33 / 500, batch #400 / 625
Loss:	2.0540120601654053

training epoch 33 / 500, batch #425 / 625
Loss:	1.9129518270492554

training epoch 33 / 500, batch #450 / 625
Loss:	2.016380786895752

training epoch 33 / 500, batch #475 / 625
Loss:	2.008443832397461

training epoch 33 / 500, batch #500 / 625
Loss:	2.109663486480713

training epoch 33 / 500, batch #525 / 625
Loss:	1.9689384698867798

training epoch 33 / 500, batch #550 / 625
Loss:	1.9597363471984863

training epoch 33 / 500, batch #575 / 625
Loss:	2.041130781173706

training epoch 33 / 500, batch #600 / 625
Loss:	2.125399351119995

training epoch 34 / 500, batch #0 / 625
Loss:	1.938019871711731

training epoch 34 / 500, batch #25 / 625
Loss:	1.9713258743286133

training epoch 34 / 500, batch #50 / 625
Loss:	2.018707752227783

training epoch 34 / 500, batch #75 / 625
Loss:	1.852495789527893

training epoch 34 / 500, batch #100 / 625
Loss:	2.0954501628875732

training epoch 34 / 500, batch #125 / 625
Loss:	2.1492831707000732

training epoch 34 / 500, batch #150 / 625
Loss:	2.1313998699188232

training epoch 34 / 500, batch #175 / 625
Loss:	1.9147316217422485

training epoch 34 / 500, batch #200 / 625
Loss:	2.08380126953125

training epoch 34 / 500, batch #225 / 625
Loss:	1.961588978767395

training epoch 34 / 500, batch #250 / 625
Loss:	1.9493260383605957

training epoch 34 / 500, batch #275 / 625
Loss:	2.105982780456543

training epoch 34 / 500, batch #300 / 625
Loss:	2.0945403575897217

training epoch 34 / 500, batch #325 / 625
Loss:	2.0572493076324463

training epoch 34 / 500, batch #350 / 625
Loss:	2.1165430545806885

training epoch 34 / 500, batch #375 / 625
Loss:	2.0141549110412598

training epoch 34 / 500, batch #400 / 625
Loss:	2.239072799682617

training epoch 34 / 500, batch #425 / 625
Loss:	1.9806112051010132

training epoch 34 / 500, batch #450 / 625
Loss:	1.9958139657974243

training epoch 34 / 500, batch #475 / 625
Loss:	2.0524446964263916

training epoch 34 / 500, batch #500 / 625
Loss:	2.113971710205078

training epoch 34 / 500, batch #525 / 625
Loss:	1.8831260204315186

training epoch 34 / 500, batch #550 / 625
Loss:	1.911022663116455

training epoch 34 / 500, batch #575 / 625
Loss:	2.143578290939331

training epoch 34 / 500, batch #600 / 625
Loss:	1.8805692195892334

training epoch 35 / 500, batch #0 / 625
Loss:	1.985394835472107

training epoch 35 / 500, batch #25 / 625
Loss:	2.1106860637664795

training epoch 35 / 500, batch #50 / 625
Loss:	2.0927019119262695

training epoch 35 / 500, batch #75 / 625
Loss:	2.024996280670166

training epoch 35 / 500, batch #100 / 625
Loss:	1.9231685400009155

training epoch 35 / 500, batch #125 / 625
Loss:	1.9673550128936768

training epoch 35 / 500, batch #150 / 625
Loss:	2.044532537460327

training epoch 35 / 500, batch #175 / 625
Loss:	1.8910915851593018

training epoch 35 / 500, batch #200 / 625
Loss:	2.0662567615509033

training epoch 35 / 500, batch #225 / 625
Loss:	2.0781545639038086

training epoch 35 / 500, batch #250 / 625
Loss:	1.934084415435791

training epoch 35 / 500, batch #275 / 625
Loss:	1.9247641563415527

training epoch 35 / 500, batch #300 / 625
Loss:	2.0924668312072754

training epoch 35 / 500, batch #325 / 625
Loss:	2.1387386322021484

training epoch 35 / 500, batch #350 / 625
Loss:	1.9075461626052856

training epoch 35 / 500, batch #375 / 625
Loss:	1.933161735534668

training epoch 35 / 500, batch #400 / 625
Loss:	1.998976230621338

training epoch 35 / 500, batch #425 / 625
Loss:	2.062906265258789

training epoch 35 / 500, batch #450 / 625
Loss:	1.8871605396270752

training epoch 35 / 500, batch #475 / 625
Loss:	2.166163206100464

training epoch 35 / 500, batch #500 / 625
Loss:	2.0345349311828613

training epoch 35 / 500, batch #525 / 625
Loss:	2.0582728385925293

training epoch 35 / 500, batch #550 / 625
Loss:	1.7300680875778198

training epoch 35 / 500, batch #575 / 625
Loss:	2.1130027770996094

training epoch 35 / 500, batch #600 / 625
Loss:	2.0447330474853516

training epoch 36 / 500, batch #0 / 625
Loss:	1.9046744108200073

training epoch 36 / 500, batch #25 / 625
Loss:	2.0553174018859863

training epoch 36 / 500, batch #50 / 625
Loss:	2.0609612464904785

training epoch 36 / 500, batch #75 / 625
Loss:	2.076876163482666

training epoch 36 / 500, batch #100 / 625
Loss:	2.231290340423584

training epoch 36 / 500, batch #125 / 625
Loss:	2.007183313369751

training epoch 36 / 500, batch #150 / 625
Loss:	1.809216022491455

training epoch 36 / 500, batch #175 / 625
Loss:	2.0883874893188477

training epoch 36 / 500, batch #200 / 625
Loss:	2.1316208839416504

training epoch 36 / 500, batch #225 / 625
Loss:	1.9639071226119995

training epoch 36 / 500, batch #250 / 625
Loss:	2.0042684078216553

training epoch 36 / 500, batch #275 / 625
Loss:	1.9628719091415405

training epoch 36 / 500, batch #300 / 625
Loss:	1.9932230710983276

training epoch 36 / 500, batch #325 / 625
Loss:	2.0054519176483154

training epoch 36 / 500, batch #350 / 625
Loss:	2.073901414871216

training epoch 36 / 500, batch #375 / 625
Loss:	2.1642706394195557

training epoch 36 / 500, batch #400 / 625
Loss:	1.9924676418304443

training epoch 36 / 500, batch #425 / 625
Loss:	2.0025384426116943

training epoch 36 / 500, batch #450 / 625
Loss:	1.953060507774353

training epoch 36 / 500, batch #475 / 625
Loss:	2.1040074825286865

training epoch 36 / 500, batch #500 / 625
Loss:	2.051335096359253

training epoch 36 / 500, batch #525 / 625
Loss:	1.8890248537063599

training epoch 36 / 500, batch #550 / 625
Loss:	1.9922027587890625

training epoch 36 / 500, batch #575 / 625
Loss:	1.8674395084381104

training epoch 36 / 500, batch #600 / 625
Loss:	1.999096155166626

training epoch 37 / 500, batch #0 / 625
Loss:	1.9816588163375854

training epoch 37 / 500, batch #25 / 625
Loss:	2.0449132919311523

training epoch 37 / 500, batch #50 / 625
Loss:	1.746770977973938

training epoch 37 / 500, batch #75 / 625
Loss:	1.911730170249939

training epoch 37 / 500, batch #100 / 625
Loss:	1.940873622894287

training epoch 37 / 500, batch #125 / 625
Loss:	1.8896290063858032

training epoch 37 / 500, batch #150 / 625
Loss:	1.9632833003997803

training epoch 37 / 500, batch #175 / 625
Loss:	2.229785203933716

training epoch 37 / 500, batch #200 / 625
Loss:	1.893035650253296

training epoch 37 / 500, batch #225 / 625
Loss:	1.9657500982284546

training epoch 37 / 500, batch #250 / 625
Loss:	1.9461394548416138

training epoch 37 / 500, batch #275 / 625
Loss:	2.0229921340942383

training epoch 37 / 500, batch #300 / 625
Loss:	1.9145961999893188

training epoch 37 / 500, batch #325 / 625
Loss:	2.004042387008667

training epoch 37 / 500, batch #350 / 625
Loss:	2.0198802947998047

training epoch 37 / 500, batch #375 / 625
Loss:	1.9555091857910156

training epoch 37 / 500, batch #400 / 625
Loss:	1.9721189737319946

training epoch 37 / 500, batch #425 / 625
Loss:	2.0666162967681885

training epoch 37 / 500, batch #450 / 625
Loss:	2.109415292739868

training epoch 37 / 500, batch #475 / 625
Loss:	1.8694416284561157

training epoch 37 / 500, batch #500 / 625
Loss:	2.2769110202789307

training epoch 37 / 500, batch #525 / 625
Loss:	1.8144209384918213

training epoch 37 / 500, batch #550 / 625
Loss:	2.1545445919036865

training epoch 37 / 500, batch #575 / 625
Loss:	2.0802512168884277

training epoch 37 / 500, batch #600 / 625
Loss:	1.8962889909744263

training epoch 38 / 500, batch #0 / 625
Loss:	1.7054640054702759

training epoch 38 / 500, batch #25 / 625
Loss:	1.9120609760284424

training epoch 38 / 500, batch #50 / 625
Loss:	2.0973193645477295

training epoch 38 / 500, batch #75 / 625
Loss:	1.9638605117797852

training epoch 38 / 500, batch #100 / 625
Loss:	1.9376479387283325

training epoch 38 / 500, batch #125 / 625
Loss:	2.0294995307922363

training epoch 38 / 500, batch #150 / 625
Loss:	2.1183249950408936

training epoch 38 / 500, batch #175 / 625
Loss:	2.1610817909240723

training epoch 38 / 500, batch #200 / 625
Loss:	2.061518907546997

training epoch 38 / 500, batch #225 / 625
Loss:	2.028061866760254

training epoch 38 / 500, batch #250 / 625
Loss:	2.0016207695007324

training epoch 38 / 500, batch #275 / 625
Loss:	2.1111207008361816

training epoch 38 / 500, batch #300 / 625
Loss:	2.011418581008911

training epoch 38 / 500, batch #325 / 625
Loss:	1.891635775566101

training epoch 38 / 500, batch #350 / 625
Loss:	2.0862550735473633

training epoch 38 / 500, batch #375 / 625
Loss:	2.084219455718994

training epoch 38 / 500, batch #400 / 625
Loss:	2.1894826889038086

training epoch 38 / 500, batch #425 / 625
Loss:	2.0683746337890625

training epoch 38 / 500, batch #450 / 625
Loss:	1.8696364164352417

training epoch 38 / 500, batch #475 / 625
Loss:	2.1136996746063232

training epoch 38 / 500, batch #500 / 625
Loss:	2.0094103813171387

training epoch 38 / 500, batch #525 / 625
Loss:	1.9282163381576538

training epoch 38 / 500, batch #550 / 625
Loss:	2.251248598098755

training epoch 38 / 500, batch #575 / 625
Loss:	2.0145263671875

training epoch 38 / 500, batch #600 / 625
Loss:	1.890013575553894

training epoch 39 / 500, batch #0 / 625
Loss:	1.962546944618225

training epoch 39 / 500, batch #25 / 625
Loss:	1.8443489074707031

training epoch 39 / 500, batch #50 / 625
Loss:	1.9442760944366455

training epoch 39 / 500, batch #75 / 625
Loss:	2.0361344814300537

training epoch 39 / 500, batch #100 / 625
Loss:	2.0508179664611816

training epoch 39 / 500, batch #125 / 625
Loss:	1.98271644115448

training epoch 39 / 500, batch #150 / 625
Loss:	2.162950038909912

training epoch 39 / 500, batch #175 / 625
Loss:	1.8793461322784424

training epoch 39 / 500, batch #200 / 625
Loss:	1.9082589149475098

training epoch 39 / 500, batch #225 / 625
Loss:	2.076162576675415

training epoch 39 / 500, batch #250 / 625
Loss:	1.9675664901733398

training epoch 39 / 500, batch #275 / 625
Loss:	2.0816383361816406

training epoch 39 / 500, batch #300 / 625
Loss:	1.9411780834197998

training epoch 39 / 500, batch #325 / 625
Loss:	2.107975959777832

training epoch 39 / 500, batch #350 / 625
Loss:	1.9051553010940552

training epoch 39 / 500, batch #375 / 625
Loss:	1.9893274307250977

training epoch 39 / 500, batch #400 / 625
Loss:	2.0504965782165527

training epoch 39 / 500, batch #425 / 625
Loss:	1.9378148317337036

training epoch 39 / 500, batch #450 / 625
Loss:	1.9971193075180054

training epoch 39 / 500, batch #475 / 625
Loss:	2.0318236351013184

training epoch 39 / 500, batch #500 / 625
Loss:	1.947573184967041

training epoch 39 / 500, batch #525 / 625
Loss:	1.941325068473816

training epoch 39 / 500, batch #550 / 625
Loss:	1.8684688806533813

training epoch 39 / 500, batch #575 / 625
Loss:	2.085308313369751

training epoch 39 / 500, batch #600 / 625
Loss:	1.8854559659957886

training epoch 40 / 500, batch #0 / 625
Loss:	1.8554500341415405

training epoch 40 / 500, batch #25 / 625
Loss:	1.9118430614471436

training epoch 40 / 500, batch #50 / 625
Loss:	1.895442247390747

training epoch 40 / 500, batch #75 / 625
Loss:	2.027768135070801

training epoch 40 / 500, batch #100 / 625
Loss:	1.866671085357666

training epoch 40 / 500, batch #125 / 625
Loss:	1.7552446126937866

training epoch 40 / 500, batch #150 / 625
Loss:	2.057279586791992

training epoch 40 / 500, batch #175 / 625
Loss:	1.9568147659301758

training epoch 40 / 500, batch #200 / 625
Loss:	1.958184003829956

training epoch 40 / 500, batch #225 / 625
Loss:	2.1934337615966797

training epoch 40 / 500, batch #250 / 625
Loss:	1.7272146940231323

training epoch 40 / 500, batch #275 / 625
Loss:	2.159707546234131

training epoch 40 / 500, batch #300 / 625
Loss:	1.9234293699264526

training epoch 40 / 500, batch #325 / 625
Loss:	2.3934333324432373

training epoch 40 / 500, batch #350 / 625
Loss:	1.9378622770309448

training epoch 40 / 500, batch #375 / 625
Loss:	2.034719944000244

training epoch 40 / 500, batch #400 / 625
Loss:	2.0186078548431396

training epoch 40 / 500, batch #425 / 625
Loss:	2.144336700439453

training epoch 40 / 500, batch #450 / 625
Loss:	2.105006217956543

training epoch 40 / 500, batch #475 / 625
Loss:	2.0203616619110107

training epoch 40 / 500, batch #500 / 625
Loss:	2.047776222229004

training epoch 40 / 500, batch #525 / 625
Loss:	1.856245517730713

training epoch 40 / 500, batch #550 / 625
Loss:	2.1224582195281982

training epoch 40 / 500, batch #575 / 625
Loss:	2.1275887489318848

training epoch 40 / 500, batch #600 / 625
Loss:	1.9335503578186035

training epoch 41 / 500, batch #0 / 625
Loss:	1.916314721107483

training epoch 41 / 500, batch #25 / 625
Loss:	2.0227067470550537

training epoch 41 / 500, batch #50 / 625
Loss:	1.8902543783187866

training epoch 41 / 500, batch #75 / 625
Loss:	1.8493949174880981

training epoch 41 / 500, batch #100 / 625
Loss:	1.9153777360916138

training epoch 41 / 500, batch #125 / 625
Loss:	1.9501385688781738

training epoch 41 / 500, batch #150 / 625
Loss:	1.8925689458847046

training epoch 41 / 500, batch #175 / 625
Loss:	2.019747734069824

training epoch 41 / 500, batch #200 / 625
Loss:	1.9462791681289673

training epoch 41 / 500, batch #225 / 625
Loss:	2.0158779621124268

training epoch 41 / 500, batch #250 / 625
Loss:	1.8193583488464355

training epoch 41 / 500, batch #275 / 625
Loss:	1.9231542348861694

training epoch 41 / 500, batch #300 / 625
Loss:	1.9561455249786377

training epoch 41 / 500, batch #325 / 625
Loss:	1.99448823928833

training epoch 41 / 500, batch #350 / 625
Loss:	1.7997092008590698

training epoch 41 / 500, batch #375 / 625
Loss:	1.9366984367370605

training epoch 41 / 500, batch #400 / 625
Loss:	1.890748143196106

training epoch 41 / 500, batch #425 / 625
Loss:	2.02445912361145

training epoch 41 / 500, batch #450 / 625
Loss:	1.7829535007476807

training epoch 41 / 500, batch #475 / 625
Loss:	1.9086288213729858

training epoch 41 / 500, batch #500 / 625
Loss:	2.014242172241211

training epoch 41 / 500, batch #525 / 625
Loss:	1.9269689321517944

training epoch 41 / 500, batch #550 / 625
Loss:	2.1481597423553467

training epoch 41 / 500, batch #575 / 625
Loss:	2.0457921028137207

training epoch 41 / 500, batch #600 / 625
Loss:	2.103560447692871

training epoch 42 / 500, batch #0 / 625
Loss:	2.0020644664764404

training epoch 42 / 500, batch #25 / 625
Loss:	1.7768394947052002

training epoch 42 / 500, batch #50 / 625
Loss:	2.1921985149383545

training epoch 42 / 500, batch #75 / 625
Loss:	1.998229742050171

training epoch 42 / 500, batch #100 / 625
Loss:	1.9034755229949951

training epoch 42 / 500, batch #125 / 625
Loss:	1.9311779737472534

training epoch 42 / 500, batch #150 / 625
Loss:	1.9798173904418945

training epoch 42 / 500, batch #175 / 625
Loss:	2.0412445068359375

training epoch 42 / 500, batch #200 / 625
Loss:	1.9929951429367065

training epoch 42 / 500, batch #225 / 625
Loss:	1.9656187295913696

training epoch 42 / 500, batch #250 / 625
Loss:	1.8114185333251953

training epoch 42 / 500, batch #275 / 625
Loss:	1.9176727533340454

training epoch 42 / 500, batch #300 / 625
Loss:	1.8480669260025024

training epoch 42 / 500, batch #325 / 625
Loss:	1.9545401334762573

training epoch 42 / 500, batch #350 / 625
Loss:	1.880056619644165

training epoch 42 / 500, batch #375 / 625
Loss:	1.8859471082687378

training epoch 42 / 500, batch #400 / 625
Loss:	1.9778165817260742

training epoch 42 / 500, batch #425 / 625
Loss:	2.144216537475586

training epoch 42 / 500, batch #450 / 625
Loss:	2.0284552574157715

training epoch 42 / 500, batch #475 / 625
Loss:	2.0206499099731445

training epoch 42 / 500, batch #500 / 625
Loss:	2.010467529296875

training epoch 42 / 500, batch #525 / 625
Loss:	2.167454957962036

training epoch 42 / 500, batch #550 / 625
Loss:	1.93169367313385

training epoch 42 / 500, batch #575 / 625
Loss:	1.8624267578125

training epoch 42 / 500, batch #600 / 625
Loss:	2.054628849029541

training epoch 43 / 500, batch #0 / 625
Loss:	1.973860502243042

training epoch 43 / 500, batch #25 / 625
Loss:	2.0638785362243652

training epoch 43 / 500, batch #50 / 625
Loss:	1.8308167457580566

training epoch 43 / 500, batch #75 / 625
Loss:	1.9022420644760132

training epoch 43 / 500, batch #100 / 625
Loss:	1.836601972579956

training epoch 43 / 500, batch #125 / 625
Loss:	2.1322381496429443

training epoch 43 / 500, batch #150 / 625
Loss:	1.787161111831665

training epoch 43 / 500, batch #175 / 625
Loss:	2.1699416637420654

training epoch 43 / 500, batch #200 / 625
Loss:	1.9187302589416504

training epoch 43 / 500, batch #225 / 625
Loss:	2.1924710273742676

training epoch 43 / 500, batch #250 / 625
Loss:	2.010772228240967

training epoch 43 / 500, batch #275 / 625
Loss:	1.9170063734054565

training epoch 43 / 500, batch #300 / 625
Loss:	1.9745163917541504

training epoch 43 / 500, batch #325 / 625
Loss:	1.851412296295166

training epoch 43 / 500, batch #350 / 625
Loss:	2.3435394763946533

training epoch 43 / 500, batch #375 / 625
Loss:	2.0995421409606934

training epoch 43 / 500, batch #400 / 625
Loss:	1.9803153276443481

training epoch 43 / 500, batch #425 / 625
Loss:	2.064368963241577

training epoch 43 / 500, batch #450 / 625
Loss:	2.2098724842071533

training epoch 43 / 500, batch #475 / 625
Loss:	1.8410269021987915

training epoch 43 / 500, batch #500 / 625
Loss:	1.875486969947815

training epoch 43 / 500, batch #525 / 625
Loss:	1.9423397779464722

training epoch 43 / 500, batch #550 / 625
Loss:	1.9321646690368652

training epoch 43 / 500, batch #575 / 625
Loss:	1.9113425016403198

training epoch 43 / 500, batch #600 / 625
Loss:	1.77181875705719

training epoch 44 / 500, batch #0 / 625
Loss:	2.1039633750915527

training epoch 44 / 500, batch #25 / 625
Loss:	2.1106231212615967

training epoch 44 / 500, batch #50 / 625
Loss:	1.9942015409469604

training epoch 44 / 500, batch #75 / 625
Loss:	2.088540554046631

training epoch 44 / 500, batch #100 / 625
Loss:	1.8505570888519287

training epoch 44 / 500, batch #125 / 625
Loss:	2.0266990661621094

training epoch 44 / 500, batch #150 / 625
Loss:	2.1149213314056396

training epoch 44 / 500, batch #175 / 625
Loss:	1.6451821327209473

training epoch 44 / 500, batch #200 / 625
Loss:	1.896847128868103

training epoch 44 / 500, batch #225 / 625
Loss:	2.0114023685455322

training epoch 44 / 500, batch #250 / 625
Loss:	1.9455631971359253

training epoch 44 / 500, batch #275 / 625
Loss:	1.8967723846435547

training epoch 44 / 500, batch #300 / 625
Loss:	2.004153251647949

training epoch 44 / 500, batch #325 / 625
Loss:	1.7964454889297485

training epoch 44 / 500, batch #350 / 625
Loss:	2.05703067779541

training epoch 44 / 500, batch #375 / 625
Loss:	2.017087459564209

training epoch 44 / 500, batch #400 / 625
Loss:	1.9477617740631104

training epoch 44 / 500, batch #425 / 625
Loss:	1.869762659072876

training epoch 44 / 500, batch #450 / 625
Loss:	1.8508046865463257

training epoch 44 / 500, batch #475 / 625
Loss:	1.8779723644256592

training epoch 44 / 500, batch #500 / 625
Loss:	2.0967230796813965

training epoch 44 / 500, batch #525 / 625
Loss:	1.9029089212417603

training epoch 44 / 500, batch #550 / 625
Loss:	1.9664051532745361

training epoch 44 / 500, batch #575 / 625
Loss:	1.7861154079437256

training epoch 44 / 500, batch #600 / 625
Loss:	2.1275134086608887

training epoch 45 / 500, batch #0 / 625
Loss:	2.003643274307251

training epoch 45 / 500, batch #25 / 625
Loss:	1.8936660289764404

training epoch 45 / 500, batch #50 / 625
Loss:	1.8594533205032349

training epoch 45 / 500, batch #75 / 625
Loss:	1.9587644338607788

training epoch 45 / 500, batch #100 / 625
Loss:	1.8788541555404663

training epoch 45 / 500, batch #125 / 625
Loss:	2.0402379035949707

training epoch 45 / 500, batch #150 / 625
Loss:	1.8715012073516846

training epoch 45 / 500, batch #175 / 625
Loss:	2.0579304695129395

training epoch 45 / 500, batch #200 / 625
Loss:	1.8951518535614014

training epoch 45 / 500, batch #225 / 625
Loss:	1.9929280281066895

training epoch 45 / 500, batch #250 / 625
Loss:	1.9559413194656372

training epoch 45 / 500, batch #275 / 625
Loss:	1.9580234289169312

training epoch 45 / 500, batch #300 / 625
Loss:	1.962585687637329

training epoch 45 / 500, batch #325 / 625
Loss:	1.886767864227295

training epoch 45 / 500, batch #350 / 625
Loss:	1.895063877105713

training epoch 45 / 500, batch #375 / 625
Loss:	1.9838148355484009

training epoch 45 / 500, batch #400 / 625
Loss:	1.982383131980896

training epoch 45 / 500, batch #425 / 625
Loss:	1.9104336500167847

training epoch 45 / 500, batch #450 / 625
Loss:	1.8730236291885376

training epoch 45 / 500, batch #475 / 625
Loss:	1.778257966041565

training epoch 45 / 500, batch #500 / 625
Loss:	1.8582488298416138

training epoch 45 / 500, batch #525 / 625
Loss:	1.767046332359314

training epoch 45 / 500, batch #550 / 625
Loss:	1.9828962087631226

training epoch 45 / 500, batch #575 / 625
Loss:	1.9866539239883423

training epoch 45 / 500, batch #600 / 625
Loss:	1.8299390077590942

training epoch 46 / 500, batch #0 / 625
Loss:	1.9981234073638916

training epoch 46 / 500, batch #25 / 625
Loss:	2.0181448459625244

training epoch 46 / 500, batch #50 / 625
Loss:	1.7421047687530518

training epoch 46 / 500, batch #75 / 625
Loss:	1.9655070304870605

training epoch 46 / 500, batch #100 / 625
Loss:	1.7733052968978882

training epoch 46 / 500, batch #125 / 625
Loss:	1.8860431909561157

training epoch 46 / 500, batch #150 / 625
Loss:	1.7396734952926636

training epoch 46 / 500, batch #175 / 625
Loss:	1.9263077974319458

training epoch 46 / 500, batch #200 / 625
Loss:	2.0051207542419434

training epoch 46 / 500, batch #225 / 625
Loss:	1.8640741109848022

training epoch 46 / 500, batch #250 / 625
Loss:	1.9139479398727417

training epoch 46 / 500, batch #275 / 625
Loss:	1.9529953002929688

training epoch 46 / 500, batch #300 / 625
Loss:	1.941714882850647

training epoch 46 / 500, batch #325 / 625
Loss:	1.8965197801589966

training epoch 46 / 500, batch #350 / 625
Loss:	1.9967732429504395

training epoch 46 / 500, batch #375 / 625
Loss:	1.928572416305542

training epoch 46 / 500, batch #400 / 625
Loss:	1.8347651958465576

training epoch 46 / 500, batch #425 / 625
Loss:	2.0365166664123535

training epoch 46 / 500, batch #450 / 625
Loss:	1.7465959787368774

training epoch 46 / 500, batch #475 / 625
Loss:	1.8823424577713013

training epoch 46 / 500, batch #500 / 625
Loss:	1.8014042377471924

training epoch 46 / 500, batch #525 / 625
Loss:	1.723772644996643

training epoch 46 / 500, batch #550 / 625
Loss:	2.0676321983337402

training epoch 46 / 500, batch #575 / 625
Loss:	2.0298190116882324

training epoch 46 / 500, batch #600 / 625
Loss:	1.8713704347610474

training epoch 47 / 500, batch #0 / 625
Loss:	1.9696176052093506

training epoch 47 / 500, batch #25 / 625
Loss:	2.1111996173858643

training epoch 47 / 500, batch #50 / 625
Loss:	2.0181455612182617

training epoch 47 / 500, batch #75 / 625
Loss:	1.8379344940185547

training epoch 47 / 500, batch #100 / 625
Loss:	2.0111076831817627

training epoch 47 / 500, batch #125 / 625
Loss:	1.8513299226760864

training epoch 47 / 500, batch #150 / 625
Loss:	1.9174621105194092

training epoch 47 / 500, batch #175 / 625
Loss:	1.8955374956130981

training epoch 47 / 500, batch #200 / 625
Loss:	1.7991057634353638

training epoch 47 / 500, batch #225 / 625
Loss:	1.7973977327346802

training epoch 47 / 500, batch #250 / 625
Loss:	1.9289650917053223

training epoch 47 / 500, batch #275 / 625
Loss:	1.8745689392089844

training epoch 47 / 500, batch #300 / 625
Loss:	1.9969319105148315

training epoch 47 / 500, batch #325 / 625
Loss:	1.9717074632644653

training epoch 47 / 500, batch #350 / 625
Loss:	1.9573955535888672

training epoch 47 / 500, batch #375 / 625
Loss:	1.8816230297088623

training epoch 47 / 500, batch #400 / 625
Loss:	1.8692399263381958

training epoch 47 / 500, batch #425 / 625
Loss:	2.0680148601531982

training epoch 47 / 500, batch #450 / 625
Loss:	2.0117175579071045

training epoch 47 / 500, batch #475 / 625
Loss:	1.9057440757751465

training epoch 47 / 500, batch #500 / 625
Loss:	1.9810830354690552

training epoch 47 / 500, batch #525 / 625
Loss:	2.140862464904785

training epoch 47 / 500, batch #550 / 625
Loss:	1.9700764417648315

training epoch 47 / 500, batch #575 / 625
Loss:	1.8975868225097656

training epoch 47 / 500, batch #600 / 625
Loss:	1.904068112373352

training epoch 48 / 500, batch #0 / 625
Loss:	1.8825873136520386

training epoch 48 / 500, batch #25 / 625
Loss:	1.913817048072815

training epoch 48 / 500, batch #50 / 625
Loss:	2.0721049308776855

training epoch 48 / 500, batch #75 / 625
Loss:	1.8082568645477295

training epoch 48 / 500, batch #100 / 625
Loss:	2.157174825668335

training epoch 48 / 500, batch #125 / 625
Loss:	1.8736581802368164

training epoch 48 / 500, batch #150 / 625
Loss:	1.9004160165786743

training epoch 48 / 500, batch #175 / 625
Loss:	1.9455273151397705

training epoch 48 / 500, batch #200 / 625
Loss:	1.7985607385635376

training epoch 48 / 500, batch #225 / 625
Loss:	1.788223385810852

training epoch 48 / 500, batch #250 / 625
Loss:	2.1251392364501953

training epoch 48 / 500, batch #275 / 625
Loss:	2.0413899421691895

training epoch 48 / 500, batch #300 / 625
Loss:	1.9287216663360596

training epoch 48 / 500, batch #325 / 625
Loss:	1.9125505685806274

training epoch 48 / 500, batch #350 / 625
Loss:	2.1093151569366455

training epoch 48 / 500, batch #375 / 625
Loss:	1.9627732038497925

training epoch 48 / 500, batch #400 / 625
Loss:	2.179525852203369

training epoch 48 / 500, batch #425 / 625
Loss:	1.860671043395996

training epoch 48 / 500, batch #450 / 625
Loss:	2.0858137607574463

training epoch 48 / 500, batch #475 / 625
Loss:	1.857795238494873

training epoch 48 / 500, batch #500 / 625
Loss:	1.8512041568756104

training epoch 48 / 500, batch #525 / 625
Loss:	1.9390184879302979

training epoch 48 / 500, batch #550 / 625
Loss:	2.151669979095459

training epoch 48 / 500, batch #575 / 625
Loss:	2.0307276248931885

training epoch 48 / 500, batch #600 / 625
Loss:	2.0300025939941406

training epoch 49 / 500, batch #0 / 625
Loss:	1.851222276687622

training epoch 49 / 500, batch #25 / 625
Loss:	1.9008195400238037

training epoch 49 / 500, batch #50 / 625
Loss:	2.016080617904663

training epoch 49 / 500, batch #75 / 625
Loss:	2.0566365718841553

training epoch 49 / 500, batch #100 / 625
Loss:	1.8740719556808472

training epoch 49 / 500, batch #125 / 625
Loss:	1.9468132257461548

training epoch 49 / 500, batch #150 / 625
Loss:	1.9160398244857788

training epoch 49 / 500, batch #175 / 625
Loss:	1.8921822309494019

training epoch 49 / 500, batch #200 / 625
Loss:	2.047699451446533

training epoch 49 / 500, batch #225 / 625
Loss:	1.8438767194747925

training epoch 49 / 500, batch #250 / 625
Loss:	1.9470298290252686

training epoch 49 / 500, batch #275 / 625
Loss:	1.8924423456192017

training epoch 49 / 500, batch #300 / 625
Loss:	2.0242459774017334

training epoch 49 / 500, batch #325 / 625
Loss:	2.034052848815918

training epoch 49 / 500, batch #350 / 625
Loss:	1.900978684425354

training epoch 49 / 500, batch #375 / 625
Loss:	1.8892637491226196

training epoch 49 / 500, batch #400 / 625
Loss:	2.140897750854492

training epoch 49 / 500, batch #425 / 625
Loss:	1.8664354085922241

training epoch 49 / 500, batch #450 / 625
Loss:	1.9469791650772095

training epoch 49 / 500, batch #475 / 625
Loss:	2.2263333797454834

training epoch 49 / 500, batch #500 / 625
Loss:	1.8638118505477905

training epoch 49 / 500, batch #525 / 625
Loss:	1.7516298294067383

training epoch 49 / 500, batch #550 / 625
Loss:	1.950081467628479

training epoch 49 / 500, batch #575 / 625
Loss:	1.8740894794464111

training epoch 49 / 500, batch #600 / 625
Loss:	2.0375285148620605

training epoch 50 / 500, batch #0 / 625
Loss:	1.9683516025543213

training epoch 50 / 500, batch #25 / 625
Loss:	2.196272850036621

training epoch 50 / 500, batch #50 / 625
Loss:	2.0011277198791504

training epoch 50 / 500, batch #75 / 625
Loss:	2.025970697402954

training epoch 50 / 500, batch #100 / 625
Loss:	1.804647445678711

training epoch 50 / 500, batch #125 / 625
Loss:	1.9688423871994019

training epoch 50 / 500, batch #150 / 625
Loss:	1.8070006370544434

training epoch 50 / 500, batch #175 / 625
Loss:	1.9776031970977783

training epoch 50 / 500, batch #200 / 625
Loss:	2.0486865043640137

training epoch 50 / 500, batch #225 / 625
Loss:	1.9120646715164185

training epoch 50 / 500, batch #250 / 625
Loss:	1.817766547203064

training epoch 50 / 500, batch #275 / 625
Loss:	2.0929408073425293

training epoch 50 / 500, batch #300 / 625
Loss:	1.909766435623169

training epoch 50 / 500, batch #325 / 625
Loss:	2.028449058532715

training epoch 50 / 500, batch #350 / 625
Loss:	2.059353828430176

training epoch 50 / 500, batch #375 / 625
Loss:	1.9877241849899292

training epoch 50 / 500, batch #400 / 625
Loss:	1.914920449256897

training epoch 50 / 500, batch #425 / 625
Loss:	1.90841543674469

training epoch 50 / 500, batch #450 / 625
Loss:	2.115795612335205

training epoch 50 / 500, batch #475 / 625
Loss:	1.8791489601135254

training epoch 50 / 500, batch #500 / 625
Loss:	1.9189014434814453

training epoch 50 / 500, batch #525 / 625
Loss:	1.9560950994491577

training epoch 50 / 500, batch #550 / 625
Loss:	1.9838112592697144

training epoch 50 / 500, batch #575 / 625
Loss:	1.8151708841323853

training epoch 50 / 500, batch #600 / 625
Loss:	1.9318081140518188

training epoch 51 / 500, batch #0 / 625
Loss:	1.9184435606002808

training epoch 51 / 500, batch #25 / 625
Loss:	1.9993408918380737

training epoch 51 / 500, batch #50 / 625
Loss:	1.9133108854293823

training epoch 51 / 500, batch #75 / 625
Loss:	1.8429442644119263

training epoch 51 / 500, batch #100 / 625
Loss:	1.8903882503509521

training epoch 51 / 500, batch #125 / 625
Loss:	1.8640906810760498

training epoch 51 / 500, batch #150 / 625
Loss:	1.9944660663604736

training epoch 51 / 500, batch #175 / 625
Loss:	1.8127202987670898

training epoch 51 / 500, batch #200 / 625
Loss:	1.9385273456573486

training epoch 51 / 500, batch #225 / 625
Loss:	1.861608624458313

training epoch 51 / 500, batch #250 / 625
Loss:	1.90763258934021

training epoch 51 / 500, batch #275 / 625
Loss:	2.1076161861419678

training epoch 51 / 500, batch #300 / 625
Loss:	1.9357231855392456

training epoch 51 / 500, batch #325 / 625
Loss:	2.0297906398773193

training epoch 51 / 500, batch #350 / 625
Loss:	1.8806192874908447

training epoch 51 / 500, batch #375 / 625
Loss:	1.8879483938217163

training epoch 51 / 500, batch #400 / 625
Loss:	1.9190175533294678

training epoch 51 / 500, batch #425 / 625
Loss:	1.8925399780273438

training epoch 51 / 500, batch #450 / 625
Loss:	1.8508776426315308

training epoch 51 / 500, batch #475 / 625
Loss:	1.8195836544036865

training epoch 51 / 500, batch #500 / 625
Loss:	1.9110991954803467

training epoch 51 / 500, batch #525 / 625
Loss:	1.8664606809616089

training epoch 51 / 500, batch #550 / 625
Loss:	2.0959157943725586

training epoch 51 / 500, batch #575 / 625
Loss:	2.0349037647247314

training epoch 51 / 500, batch #600 / 625
Loss:	2.1447319984436035

training epoch 52 / 500, batch #0 / 625
Loss:	1.6754214763641357

training epoch 52 / 500, batch #25 / 625
Loss:	2.095396041870117

training epoch 52 / 500, batch #50 / 625
Loss:	1.8164275884628296

training epoch 52 / 500, batch #75 / 625
Loss:	1.8926045894622803

training epoch 52 / 500, batch #100 / 625
Loss:	1.9086077213287354

training epoch 52 / 500, batch #125 / 625
Loss:	1.7533988952636719

training epoch 52 / 500, batch #150 / 625
Loss:	1.901902675628662

training epoch 52 / 500, batch #175 / 625
Loss:	2.0434153079986572

training epoch 52 / 500, batch #200 / 625
Loss:	1.8888638019561768

training epoch 52 / 500, batch #225 / 625
Loss:	1.8259930610656738

training epoch 52 / 500, batch #250 / 625
Loss:	1.767525315284729

training epoch 52 / 500, batch #275 / 625
Loss:	1.9945147037506104

training epoch 52 / 500, batch #300 / 625
Loss:	2.069016695022583

training epoch 52 / 500, batch #325 / 625
Loss:	1.9060101509094238

training epoch 52 / 500, batch #350 / 625
Loss:	1.9367461204528809

training epoch 52 / 500, batch #375 / 625
Loss:	1.8192017078399658

training epoch 52 / 500, batch #400 / 625
Loss:	1.9224011898040771

training epoch 52 / 500, batch #425 / 625
Loss:	1.9399847984313965

training epoch 52 / 500, batch #450 / 625
Loss:	1.8029584884643555

training epoch 52 / 500, batch #475 / 625
Loss:	1.9865286350250244

training epoch 52 / 500, batch #500 / 625
Loss:	1.8098466396331787

training epoch 52 / 500, batch #525 / 625
Loss:	1.9512715339660645

training epoch 52 / 500, batch #550 / 625
Loss:	1.935820460319519

training epoch 52 / 500, batch #575 / 625
Loss:	2.1659605503082275

training epoch 52 / 500, batch #600 / 625
Loss:	1.9922950267791748

training epoch 53 / 500, batch #0 / 625
Loss:	1.710245966911316

training epoch 53 / 500, batch #25 / 625
Loss:	1.9182759523391724

training epoch 53 / 500, batch #50 / 625
Loss:	1.9577399492263794

training epoch 53 / 500, batch #75 / 625
Loss:	1.9207093715667725

training epoch 53 / 500, batch #100 / 625
Loss:	1.953413486480713

training epoch 53 / 500, batch #125 / 625
Loss:	1.9587911367416382

training epoch 53 / 500, batch #150 / 625
Loss:	1.90053129196167

training epoch 53 / 500, batch #175 / 625
Loss:	2.0472710132598877

training epoch 53 / 500, batch #200 / 625
Loss:	1.9598913192749023

training epoch 53 / 500, batch #225 / 625
Loss:	1.9788663387298584

training epoch 53 / 500, batch #250 / 625
Loss:	1.798485517501831

training epoch 53 / 500, batch #275 / 625
Loss:	1.8121258020401

training epoch 53 / 500, batch #300 / 625
Loss:	1.818094253540039

training epoch 53 / 500, batch #325 / 625
Loss:	1.8461761474609375

training epoch 53 / 500, batch #350 / 625
Loss:	2.3099586963653564

training epoch 53 / 500, batch #375 / 625
Loss:	1.7960370779037476

training epoch 53 / 500, batch #400 / 625
Loss:	1.953680396080017

training epoch 53 / 500, batch #425 / 625
Loss:	2.0046815872192383

training epoch 53 / 500, batch #450 / 625
Loss:	1.9760593175888062

training epoch 53 / 500, batch #475 / 625
Loss:	1.8998562097549438

training epoch 53 / 500, batch #500 / 625
Loss:	1.9539073705673218

training epoch 53 / 500, batch #525 / 625
Loss:	1.8499714136123657

training epoch 53 / 500, batch #550 / 625
Loss:	1.783351182937622

training epoch 53 / 500, batch #575 / 625
Loss:	1.9057163000106812

training epoch 53 / 500, batch #600 / 625
Loss:	1.927827000617981

training epoch 54 / 500, batch #0 / 625
Loss:	1.9376384019851685

training epoch 54 / 500, batch #25 / 625
Loss:	1.6884385347366333

training epoch 54 / 500, batch #50 / 625
Loss:	1.9925400018692017

training epoch 54 / 500, batch #75 / 625
Loss:	1.8269480466842651

training epoch 54 / 500, batch #100 / 625
Loss:	1.921260952949524

training epoch 54 / 500, batch #125 / 625
Loss:	1.9416927099227905

training epoch 54 / 500, batch #150 / 625
Loss:	2.0960285663604736

training epoch 54 / 500, batch #175 / 625
Loss:	1.891674280166626

training epoch 54 / 500, batch #200 / 625
Loss:	2.0033299922943115

training epoch 54 / 500, batch #225 / 625
Loss:	1.969792366027832

training epoch 54 / 500, batch #250 / 625
Loss:	2.0162627696990967

training epoch 54 / 500, batch #275 / 625
Loss:	2.029724359512329

training epoch 54 / 500, batch #300 / 625
Loss:	2.082653522491455

training epoch 54 / 500, batch #325 / 625
Loss:	1.6567530632019043

training epoch 54 / 500, batch #350 / 625
Loss:	1.9412449598312378

training epoch 54 / 500, batch #375 / 625
Loss:	2.023798942565918

training epoch 54 / 500, batch #400 / 625
Loss:	1.9095358848571777

training epoch 54 / 500, batch #425 / 625
Loss:	1.983530044555664

training epoch 54 / 500, batch #450 / 625
Loss:	1.8775506019592285

training epoch 54 / 500, batch #475 / 625
Loss:	1.869650959968567

training epoch 54 / 500, batch #500 / 625
Loss:	1.8396481275558472

training epoch 54 / 500, batch #525 / 625
Loss:	1.8657459020614624

training epoch 54 / 500, batch #550 / 625
Loss:	2.1473755836486816

training epoch 54 / 500, batch #575 / 625
Loss:	1.8202507495880127

training epoch 54 / 500, batch #600 / 625
Loss:	2.0148680210113525

training epoch 55 / 500, batch #0 / 625
Loss:	1.8681132793426514

training epoch 55 / 500, batch #25 / 625
Loss:	1.6734291315078735

training epoch 55 / 500, batch #50 / 625
Loss:	1.8442214727401733

training epoch 55 / 500, batch #75 / 625
Loss:	2.069782018661499

training epoch 55 / 500, batch #100 / 625
Loss:	1.9107506275177002

training epoch 55 / 500, batch #125 / 625
Loss:	1.8726991415023804

training epoch 55 / 500, batch #150 / 625
Loss:	1.793674349784851

training epoch 55 / 500, batch #175 / 625
Loss:	1.9993577003479004

training epoch 55 / 500, batch #200 / 625
Loss:	1.671701192855835

training epoch 55 / 500, batch #225 / 625
Loss:	2.124661684036255

training epoch 55 / 500, batch #250 / 625
Loss:	1.8765389919281006

training epoch 55 / 500, batch #275 / 625
Loss:	1.940290093421936

training epoch 55 / 500, batch #300 / 625
Loss:	1.7969605922698975

training epoch 55 / 500, batch #325 / 625
Loss:	1.9400476217269897

training epoch 55 / 500, batch #350 / 625
Loss:	1.7576919794082642

training epoch 55 / 500, batch #375 / 625
Loss:	2.147346258163452

training epoch 55 / 500, batch #400 / 625
Loss:	1.785581350326538

training epoch 55 / 500, batch #425 / 625
Loss:	1.9078742265701294

training epoch 55 / 500, batch #450 / 625
Loss:	1.9637624025344849

training epoch 55 / 500, batch #475 / 625
Loss:	2.058971881866455

training epoch 55 / 500, batch #500 / 625
Loss:	1.9889711141586304

training epoch 55 / 500, batch #525 / 625
Loss:	1.5340220928192139

training epoch 55 / 500, batch #550 / 625
Loss:	2.1763763427734375

training epoch 55 / 500, batch #575 / 625
Loss:	1.9871538877487183

training epoch 55 / 500, batch #600 / 625
Loss:	1.9181272983551025

training epoch 56 / 500, batch #0 / 625
Loss:	1.8886724710464478

training epoch 56 / 500, batch #25 / 625
Loss:	1.806391716003418

training epoch 56 / 500, batch #50 / 625
Loss:	1.8988696336746216

training epoch 56 / 500, batch #75 / 625
Loss:	1.976606845855713

training epoch 56 / 500, batch #100 / 625
Loss:	1.796871542930603

training epoch 56 / 500, batch #125 / 625
Loss:	1.7090812921524048

training epoch 56 / 500, batch #150 / 625
Loss:	2.111487627029419

training epoch 56 / 500, batch #175 / 625
Loss:	1.909594178199768

training epoch 56 / 500, batch #200 / 625
Loss:	1.869667887687683

training epoch 56 / 500, batch #225 / 625
Loss:	1.7209793329238892

training epoch 56 / 500, batch #250 / 625
Loss:	1.9707149267196655

training epoch 56 / 500, batch #275 / 625
Loss:	2.020366668701172

training epoch 56 / 500, batch #300 / 625
Loss:	1.8542379140853882

training epoch 56 / 500, batch #325 / 625
Loss:	1.9687355756759644

training epoch 56 / 500, batch #350 / 625
Loss:	1.8486063480377197

training epoch 56 / 500, batch #375 / 625
Loss:	1.8854289054870605

training epoch 56 / 500, batch #400 / 625
Loss:	1.8561955690383911

training epoch 56 / 500, batch #425 / 625
Loss:	1.9660996198654175

training epoch 56 / 500, batch #450 / 625
Loss:	1.8630530834197998

training epoch 56 / 500, batch #475 / 625
Loss:	1.8348599672317505

training epoch 56 / 500, batch #500 / 625
Loss:	1.844752550125122

training epoch 56 / 500, batch #525 / 625
Loss:	1.933526873588562

training epoch 56 / 500, batch #550 / 625
Loss:	1.919779658317566

training epoch 56 / 500, batch #575 / 625
Loss:	2.165294885635376

training epoch 56 / 500, batch #600 / 625
Loss:	1.8853228092193604

training epoch 57 / 500, batch #0 / 625
Loss:	2.0249083042144775

training epoch 57 / 500, batch #25 / 625
Loss:	1.855550765991211

training epoch 57 / 500, batch #50 / 625
Loss:	1.6941343545913696

training epoch 57 / 500, batch #75 / 625
Loss:	2.3302934169769287

training epoch 57 / 500, batch #100 / 625
Loss:	2.1546287536621094

training epoch 57 / 500, batch #125 / 625
Loss:	2.0457117557525635

training epoch 57 / 500, batch #150 / 625
Loss:	1.8396360874176025

training epoch 57 / 500, batch #175 / 625
Loss:	1.7401319742202759

training epoch 57 / 500, batch #200 / 625
Loss:	1.6785755157470703

training epoch 57 / 500, batch #225 / 625
Loss:	1.8718703985214233

training epoch 57 / 500, batch #250 / 625
Loss:	2.093954563140869

training epoch 57 / 500, batch #275 / 625
Loss:	1.9319255352020264

training epoch 57 / 500, batch #300 / 625
Loss:	1.8614946603775024

training epoch 57 / 500, batch #325 / 625
Loss:	1.7884465456008911

training epoch 57 / 500, batch #350 / 625
Loss:	2.0607545375823975

training epoch 57 / 500, batch #375 / 625
Loss:	1.9952181577682495

training epoch 57 / 500, batch #400 / 625
Loss:	2.079371213912964

training epoch 57 / 500, batch #425 / 625
Loss:	2.0537750720977783

training epoch 57 / 500, batch #450 / 625
Loss:	1.8183213472366333

training epoch 57 / 500, batch #475 / 625
Loss:	1.7958945035934448

training epoch 57 / 500, batch #500 / 625
Loss:	1.889902114868164

training epoch 57 / 500, batch #525 / 625
Loss:	1.7380698919296265

training epoch 57 / 500, batch #550 / 625
Loss:	2.100890874862671

training epoch 57 / 500, batch #575 / 625
Loss:	1.9829778671264648

training epoch 57 / 500, batch #600 / 625
Loss:	1.8276509046554565

training epoch 58 / 500, batch #0 / 625
Loss:	1.9231624603271484

training epoch 58 / 500, batch #25 / 625
Loss:	1.7550976276397705

training epoch 58 / 500, batch #50 / 625
Loss:	1.9476619958877563

training epoch 58 / 500, batch #75 / 625
Loss:	1.9468777179718018

training epoch 58 / 500, batch #100 / 625
Loss:	1.9954068660736084

training epoch 58 / 500, batch #125 / 625
Loss:	1.8865655660629272

training epoch 58 / 500, batch #150 / 625
Loss:	1.9289588928222656

training epoch 58 / 500, batch #175 / 625
Loss:	1.7057009935379028

training epoch 58 / 500, batch #200 / 625
Loss:	1.7682428359985352

training epoch 58 / 500, batch #225 / 625
Loss:	1.7582340240478516

training epoch 58 / 500, batch #250 / 625
Loss:	1.9583569765090942

training epoch 58 / 500, batch #275 / 625
Loss:	1.9809132814407349

training epoch 58 / 500, batch #300 / 625
Loss:	1.9835433959960938

training epoch 58 / 500, batch #325 / 625
Loss:	1.9082859754562378

training epoch 58 / 500, batch #350 / 625
Loss:	1.8093396425247192

training epoch 58 / 500, batch #375 / 625
Loss:	1.690967082977295

training epoch 58 / 500, batch #400 / 625
Loss:	1.8177756071090698

training epoch 58 / 500, batch #425 / 625
Loss:	1.9391552209854126

training epoch 58 / 500, batch #450 / 625
Loss:	1.84756600856781

training epoch 58 / 500, batch #475 / 625
Loss:	1.8360340595245361

training epoch 58 / 500, batch #500 / 625
Loss:	1.8857802152633667

training epoch 58 / 500, batch #525 / 625
Loss:	1.6681740283966064

training epoch 58 / 500, batch #550 / 625
Loss:	2.2393722534179688

training epoch 58 / 500, batch #575 / 625
Loss:	1.7952598333358765

training epoch 58 / 500, batch #600 / 625
Loss:	1.9176748991012573

training epoch 59 / 500, batch #0 / 625
Loss:	1.8901041746139526

training epoch 59 / 500, batch #25 / 625
Loss:	1.7852654457092285

training epoch 59 / 500, batch #50 / 625
Loss:	1.9433684349060059

training epoch 59 / 500, batch #75 / 625
Loss:	1.843015193939209

training epoch 59 / 500, batch #100 / 625
Loss:	1.91676664352417

training epoch 59 / 500, batch #125 / 625
Loss:	1.8869229555130005

training epoch 59 / 500, batch #150 / 625
Loss:	2.0001468658447266

training epoch 59 / 500, batch #175 / 625
Loss:	2.168689250946045

training epoch 59 / 500, batch #200 / 625
Loss:	2.0758419036865234

training epoch 59 / 500, batch #225 / 625
Loss:	1.8580430746078491

training epoch 59 / 500, batch #250 / 625
Loss:	1.7971222400665283

training epoch 59 / 500, batch #275 / 625
Loss:	1.9439910650253296

training epoch 59 / 500, batch #300 / 625
Loss:	1.9896818399429321

training epoch 59 / 500, batch #325 / 625
Loss:	1.8601287603378296

training epoch 59 / 500, batch #350 / 625
Loss:	1.870084285736084

training epoch 59 / 500, batch #375 / 625
Loss:	1.9144372940063477

training epoch 59 / 500, batch #400 / 625
Loss:	2.056959867477417

training epoch 59 / 500, batch #425 / 625
Loss:	1.8484045267105103

training epoch 59 / 500, batch #450 / 625
Loss:	2.015137195587158

training epoch 59 / 500, batch #475 / 625
Loss:	1.8127096891403198

training epoch 59 / 500, batch #500 / 625
Loss:	1.8435434103012085

training epoch 59 / 500, batch #525 / 625
Loss:	1.7133917808532715

training epoch 59 / 500, batch #550 / 625
Loss:	1.8588991165161133

training epoch 59 / 500, batch #575 / 625
Loss:	2.0456109046936035

training epoch 59 / 500, batch #600 / 625
Loss:	1.8254430294036865

training epoch 60 / 500, batch #0 / 625
Loss:	1.9950603246688843

training epoch 60 / 500, batch #25 / 625
Loss:	1.8410207033157349

training epoch 60 / 500, batch #50 / 625
Loss:	1.8980685472488403

training epoch 60 / 500, batch #75 / 625
Loss:	2.1147258281707764

training epoch 60 / 500, batch #100 / 625
Loss:	1.8256804943084717

training epoch 60 / 500, batch #125 / 625
Loss:	1.9380782842636108

training epoch 60 / 500, batch #150 / 625
Loss:	1.8561553955078125

training epoch 60 / 500, batch #175 / 625
Loss:	1.757561206817627

training epoch 60 / 500, batch #200 / 625
Loss:	1.8013527393341064

training epoch 60 / 500, batch #225 / 625
Loss:	1.8146533966064453

training epoch 60 / 500, batch #250 / 625
Loss:	2.029601812362671

training epoch 60 / 500, batch #275 / 625
Loss:	1.9108154773712158

training epoch 60 / 500, batch #300 / 625
Loss:	1.7781912088394165

training epoch 60 / 500, batch #325 / 625
Loss:	1.970491886138916

training epoch 60 / 500, batch #350 / 625
Loss:	2.0472054481506348

training epoch 60 / 500, batch #375 / 625
Loss:	1.773743748664856

training epoch 60 / 500, batch #400 / 625
Loss:	2.019334316253662

training epoch 60 / 500, batch #425 / 625
Loss:	1.8655129671096802

training epoch 60 / 500, batch #450 / 625
Loss:	1.994223952293396

training epoch 60 / 500, batch #475 / 625
Loss:	1.7456473112106323

training epoch 60 / 500, batch #500 / 625
Loss:	1.8807791471481323

training epoch 60 / 500, batch #525 / 625
Loss:	1.8443553447723389

training epoch 60 / 500, batch #550 / 625
Loss:	1.8940410614013672

training epoch 60 / 500, batch #575 / 625
Loss:	1.7441139221191406

training epoch 60 / 500, batch #600 / 625
Loss:	2.0546762943267822

training epoch 61 / 500, batch #0 / 625
Loss:	1.923387050628662

training epoch 61 / 500, batch #25 / 625
Loss:	1.7599948644638062

training epoch 61 / 500, batch #50 / 625
Loss:	1.9789578914642334

training epoch 61 / 500, batch #75 / 625
Loss:	1.94930100440979

training epoch 61 / 500, batch #100 / 625
Loss:	1.9890260696411133

training epoch 61 / 500, batch #125 / 625
Loss:	1.7290103435516357

training epoch 61 / 500, batch #150 / 625
Loss:	1.9547008275985718

training epoch 61 / 500, batch #175 / 625
Loss:	2.0257391929626465

training epoch 61 / 500, batch #200 / 625
Loss:	1.9216947555541992

training epoch 61 / 500, batch #225 / 625
Loss:	1.7494794130325317

training epoch 61 / 500, batch #250 / 625
Loss:	1.9034740924835205

training epoch 61 / 500, batch #275 / 625
Loss:	1.78384268283844

training epoch 61 / 500, batch #300 / 625
Loss:	1.9065920114517212

training epoch 61 / 500, batch #325 / 625
Loss:	1.7137165069580078

training epoch 61 / 500, batch #350 / 625
Loss:	1.9344637393951416

training epoch 61 / 500, batch #375 / 625
Loss:	2.007803201675415

training epoch 61 / 500, batch #400 / 625
Loss:	1.9577831029891968

training epoch 61 / 500, batch #425 / 625
Loss:	2.004995346069336

training epoch 61 / 500, batch #450 / 625
Loss:	2.0257582664489746

training epoch 61 / 500, batch #475 / 625
Loss:	1.8463431596755981

training epoch 61 / 500, batch #500 / 625
Loss:	1.9575705528259277

training epoch 61 / 500, batch #525 / 625
Loss:	2.0025315284729004

training epoch 61 / 500, batch #550 / 625
Loss:	1.819236159324646

training epoch 61 / 500, batch #575 / 625
Loss:	1.7309690713882446

training epoch 61 / 500, batch #600 / 625
Loss:	1.761682152748108

training epoch 62 / 500, batch #0 / 625
Loss:	1.8570342063903809

training epoch 62 / 500, batch #25 / 625
Loss:	1.9464776515960693

training epoch 62 / 500, batch #50 / 625
Loss:	1.8433605432510376

training epoch 62 / 500, batch #75 / 625
Loss:	1.8510147333145142

training epoch 62 / 500, batch #100 / 625
Loss:	1.884392261505127

training epoch 62 / 500, batch #125 / 625
Loss:	1.9482108354568481

training epoch 62 / 500, batch #150 / 625
Loss:	1.7303409576416016

training epoch 62 / 500, batch #175 / 625
Loss:	1.957375407218933

training epoch 62 / 500, batch #200 / 625
Loss:	1.9149683713912964

training epoch 62 / 500, batch #225 / 625
Loss:	1.823720932006836

training epoch 62 / 500, batch #250 / 625
Loss:	1.9777650833129883

training epoch 62 / 500, batch #275 / 625
Loss:	1.6771032810211182

training epoch 62 / 500, batch #300 / 625
Loss:	2.0412275791168213

training epoch 62 / 500, batch #325 / 625
Loss:	1.7065531015396118

training epoch 62 / 500, batch #350 / 625
Loss:	2.048560380935669

training epoch 62 / 500, batch #375 / 625
Loss:	2.1447558403015137

training epoch 62 / 500, batch #400 / 625
Loss:	1.931539535522461

training epoch 62 / 500, batch #425 / 625
Loss:	2.0230586528778076

training epoch 62 / 500, batch #450 / 625
Loss:	1.7597315311431885

training epoch 62 / 500, batch #475 / 625
Loss:	1.741528034210205

training epoch 62 / 500, batch #500 / 625
Loss:	1.8579490184783936

training epoch 62 / 500, batch #525 / 625
Loss:	1.7587887048721313

training epoch 62 / 500, batch #550 / 625
Loss:	1.9910579919815063

training epoch 62 / 500, batch #575 / 625
Loss:	1.8311432600021362

training epoch 62 / 500, batch #600 / 625
Loss:	1.9599363803863525

training epoch 63 / 500, batch #0 / 625
Loss:	1.8313467502593994

training epoch 63 / 500, batch #25 / 625
Loss:	1.5907472372055054

training epoch 63 / 500, batch #50 / 625
Loss:	1.8168094158172607

training epoch 63 / 500, batch #75 / 625
Loss:	1.975326657295227

training epoch 63 / 500, batch #100 / 625
Loss:	1.821889042854309

training epoch 63 / 500, batch #125 / 625
Loss:	1.9779102802276611

training epoch 63 / 500, batch #150 / 625
Loss:	1.7833772897720337

training epoch 63 / 500, batch #175 / 625
Loss:	1.7155168056488037

training epoch 63 / 500, batch #200 / 625
Loss:	1.939773440361023

training epoch 63 / 500, batch #225 / 625
Loss:	1.9244120121002197

training epoch 63 / 500, batch #250 / 625
Loss:	2.0170164108276367

training epoch 63 / 500, batch #275 / 625
Loss:	1.8979895114898682

training epoch 63 / 500, batch #300 / 625
Loss:	1.9806478023529053

training epoch 63 / 500, batch #325 / 625
Loss:	1.8477519750595093

training epoch 63 / 500, batch #350 / 625
Loss:	1.8685108423233032

training epoch 63 / 500, batch #375 / 625
Loss:	2.083423137664795

training epoch 63 / 500, batch #400 / 625
Loss:	1.7996695041656494

training epoch 63 / 500, batch #425 / 625
Loss:	1.8488049507141113

training epoch 63 / 500, batch #450 / 625
Loss:	1.9788762331008911

training epoch 63 / 500, batch #475 / 625
Loss:	1.7876263856887817

training epoch 63 / 500, batch #500 / 625
Loss:	1.8909658193588257

training epoch 63 / 500, batch #525 / 625
Loss:	1.784414529800415

training epoch 63 / 500, batch #550 / 625
Loss:	1.8496952056884766

training epoch 63 / 500, batch #575 / 625
Loss:	1.876578450202942

training epoch 63 / 500, batch #600 / 625
Loss:	1.6691887378692627

training epoch 64 / 500, batch #0 / 625
Loss:	1.648592472076416

training epoch 64 / 500, batch #25 / 625
Loss:	2.0088627338409424

training epoch 64 / 500, batch #50 / 625
Loss:	2.0628910064697266

training epoch 64 / 500, batch #75 / 625
Loss:	1.8979827165603638

training epoch 64 / 500, batch #100 / 625
Loss:	1.8575183153152466

training epoch 64 / 500, batch #125 / 625
Loss:	1.9218544960021973

training epoch 64 / 500, batch #150 / 625
Loss:	1.9191162586212158

training epoch 64 / 500, batch #175 / 625
Loss:	1.8772779703140259

training epoch 64 / 500, batch #200 / 625
Loss:	1.8978735208511353

training epoch 64 / 500, batch #225 / 625
Loss:	1.8338838815689087

training epoch 64 / 500, batch #250 / 625
Loss:	1.865339756011963

training epoch 64 / 500, batch #275 / 625
Loss:	1.7729103565216064

training epoch 64 / 500, batch #300 / 625
Loss:	1.922823429107666

training epoch 64 / 500, batch #325 / 625
Loss:	1.6199636459350586

training epoch 64 / 500, batch #350 / 625
Loss:	1.6749147176742554

training epoch 64 / 500, batch #375 / 625
Loss:	2.141705274581909

training epoch 64 / 500, batch #400 / 625
Loss:	1.8524821996688843

training epoch 64 / 500, batch #425 / 625
Loss:	1.7000988721847534

training epoch 64 / 500, batch #450 / 625
Loss:	1.825539469718933

training epoch 64 / 500, batch #475 / 625
Loss:	1.8228484392166138

training epoch 64 / 500, batch #500 / 625
Loss:	1.919238805770874

training epoch 64 / 500, batch #525 / 625
Loss:	1.8815654516220093

training epoch 64 / 500, batch #550 / 625
Loss:	1.9658019542694092

training epoch 64 / 500, batch #575 / 625
Loss:	2.024028778076172

training epoch 64 / 500, batch #600 / 625
Loss:	1.7394728660583496

training epoch 65 / 500, batch #0 / 625
Loss:	1.8359960317611694

training epoch 65 / 500, batch #25 / 625
Loss:	1.79912269115448

training epoch 65 / 500, batch #50 / 625
Loss:	1.8906562328338623

training epoch 65 / 500, batch #75 / 625
Loss:	2.0049827098846436

training epoch 65 / 500, batch #100 / 625
Loss:	1.7594306468963623

training epoch 65 / 500, batch #125 / 625
Loss:	1.6995985507965088

training epoch 65 / 500, batch #150 / 625
Loss:	1.6932308673858643

training epoch 65 / 500, batch #175 / 625
Loss:	1.850766897201538

training epoch 65 / 500, batch #200 / 625
Loss:	1.8256759643554688

training epoch 65 / 500, batch #225 / 625
Loss:	1.8412938117980957

training epoch 65 / 500, batch #250 / 625
Loss:	1.9623807668685913

training epoch 65 / 500, batch #275 / 625
Loss:	1.8840810060501099

training epoch 65 / 500, batch #300 / 625
Loss:	1.6993770599365234

training epoch 65 / 500, batch #325 / 625
Loss:	1.8703076839447021

training epoch 65 / 500, batch #350 / 625
Loss:	1.8821598291397095

training epoch 65 / 500, batch #375 / 625
Loss:	1.8242672681808472

training epoch 65 / 500, batch #400 / 625
Loss:	1.925944209098816

training epoch 65 / 500, batch #425 / 625
Loss:	1.7311503887176514

training epoch 65 / 500, batch #450 / 625
Loss:	1.9597669839859009

training epoch 65 / 500, batch #475 / 625
Loss:	1.8891453742980957

training epoch 65 / 500, batch #500 / 625
Loss:	2.015880584716797

training epoch 65 / 500, batch #525 / 625
Loss:	2.04351544380188

training epoch 65 / 500, batch #550 / 625
Loss:	1.9801433086395264

training epoch 65 / 500, batch #575 / 625
Loss:	1.8518085479736328

training epoch 65 / 500, batch #600 / 625
Loss:	1.9011714458465576

training epoch 66 / 500, batch #0 / 625
Loss:	1.9569159746170044

training epoch 66 / 500, batch #25 / 625
Loss:	1.94375479221344

training epoch 66 / 500, batch #50 / 625
Loss:	1.7029612064361572

training epoch 66 / 500, batch #75 / 625
Loss:	1.8962352275848389

training epoch 66 / 500, batch #100 / 625
Loss:	1.8701086044311523

training epoch 66 / 500, batch #125 / 625
Loss:	1.856762409210205

training epoch 66 / 500, batch #150 / 625
Loss:	1.9439557790756226

training epoch 66 / 500, batch #175 / 625
Loss:	1.8147464990615845

training epoch 66 / 500, batch #200 / 625
Loss:	1.7688062191009521

training epoch 66 / 500, batch #225 / 625
Loss:	1.809874176979065

training epoch 66 / 500, batch #250 / 625
Loss:	1.971264123916626

training epoch 66 / 500, batch #275 / 625
Loss:	1.7878048419952393

training epoch 66 / 500, batch #300 / 625
Loss:	1.9404481649398804

training epoch 66 / 500, batch #325 / 625
Loss:	1.7836498022079468

training epoch 66 / 500, batch #350 / 625
Loss:	1.9334536790847778

training epoch 66 / 500, batch #375 / 625
Loss:	1.8544385433197021

training epoch 66 / 500, batch #400 / 625
Loss:	1.974065899848938

training epoch 66 / 500, batch #425 / 625
Loss:	1.94979727268219

training epoch 66 / 500, batch #450 / 625
Loss:	1.757145643234253

training epoch 66 / 500, batch #475 / 625
Loss:	1.8681511878967285

training epoch 66 / 500, batch #500 / 625
Loss:	1.8223458528518677

training epoch 66 / 500, batch #525 / 625
Loss:	1.9080610275268555

training epoch 66 / 500, batch #550 / 625
Loss:	2.0580954551696777

training epoch 66 / 500, batch #575 / 625
Loss:	1.8197022676467896

training epoch 66 / 500, batch #600 / 625
Loss:	1.8764094114303589

training epoch 67 / 500, batch #0 / 625
Loss:	1.9170501232147217

training epoch 67 / 500, batch #25 / 625
Loss:	1.8230623006820679

training epoch 67 / 500, batch #50 / 625
Loss:	1.9384461641311646

training epoch 67 / 500, batch #75 / 625
Loss:	1.676889181137085

training epoch 67 / 500, batch #100 / 625
Loss:	1.9334286451339722

training epoch 67 / 500, batch #125 / 625
Loss:	1.7326152324676514

training epoch 67 / 500, batch #150 / 625
Loss:	2.0741963386535645

training epoch 67 / 500, batch #175 / 625
Loss:	1.805556297302246

training epoch 67 / 500, batch #200 / 625
Loss:	1.9522186517715454

training epoch 67 / 500, batch #225 / 625
Loss:	1.8834497928619385

training epoch 67 / 500, batch #250 / 625
Loss:	1.7764538526535034

training epoch 67 / 500, batch #275 / 625
Loss:	1.7900280952453613

training epoch 67 / 500, batch #300 / 625
Loss:	1.8500566482543945

training epoch 67 / 500, batch #325 / 625
Loss:	1.861731767654419

training epoch 67 / 500, batch #350 / 625
Loss:	1.8683723211288452

training epoch 67 / 500, batch #375 / 625
Loss:	2.058465003967285

training epoch 67 / 500, batch #400 / 625
Loss:	1.8106801509857178

training epoch 67 / 500, batch #425 / 625
Loss:	1.6873478889465332

training epoch 67 / 500, batch #450 / 625
Loss:	1.8640971183776855

training epoch 67 / 500, batch #475 / 625
Loss:	2.149667263031006

training epoch 67 / 500, batch #500 / 625
Loss:	2.1880478858947754

training epoch 67 / 500, batch #525 / 625
Loss:	1.9421800374984741

training epoch 67 / 500, batch #550 / 625
Loss:	1.6462979316711426

training epoch 67 / 500, batch #575 / 625
Loss:	1.8413325548171997

training epoch 67 / 500, batch #600 / 625
Loss:	1.9251229763031006

training epoch 68 / 500, batch #0 / 625
Loss:	1.9421743154525757

training epoch 68 / 500, batch #25 / 625
Loss:	1.9803844690322876

training epoch 68 / 500, batch #50 / 625
Loss:	2.2110588550567627

training epoch 68 / 500, batch #75 / 625
Loss:	1.6873490810394287

training epoch 68 / 500, batch #100 / 625
Loss:	1.67188560962677

training epoch 68 / 500, batch #125 / 625
Loss:	1.8977621793746948

training epoch 68 / 500, batch #150 / 625
Loss:	1.7576508522033691

training epoch 68 / 500, batch #175 / 625
Loss:	1.9348928928375244

training epoch 68 / 500, batch #200 / 625
Loss:	1.792731761932373

training epoch 68 / 500, batch #225 / 625
Loss:	1.9632333517074585

training epoch 68 / 500, batch #250 / 625
Loss:	1.9039733409881592

training epoch 68 / 500, batch #275 / 625
Loss:	1.977986216545105

training epoch 68 / 500, batch #300 / 625
Loss:	1.7780518531799316

training epoch 68 / 500, batch #325 / 625
Loss:	1.751265287399292

training epoch 68 / 500, batch #350 / 625
Loss:	1.803078055381775

training epoch 68 / 500, batch #375 / 625
Loss:	1.6557384729385376

training epoch 68 / 500, batch #400 / 625
Loss:	1.9274063110351562

training epoch 68 / 500, batch #425 / 625
Loss:	2.01013445854187

training epoch 68 / 500, batch #450 / 625
Loss:	1.957801103591919

training epoch 68 / 500, batch #475 / 625
Loss:	1.736928105354309

training epoch 68 / 500, batch #500 / 625
Loss:	1.7440682649612427

training epoch 68 / 500, batch #525 / 625
Loss:	1.658159613609314

training epoch 68 / 500, batch #550 / 625
Loss:	1.9541469812393188

training epoch 68 / 500, batch #575 / 625
Loss:	1.8506327867507935

training epoch 68 / 500, batch #600 / 625
Loss:	1.7175726890563965

training epoch 69 / 500, batch #0 / 625
Loss:	1.7559832334518433

training epoch 69 / 500, batch #25 / 625
Loss:	1.8000789880752563

training epoch 69 / 500, batch #50 / 625
Loss:	2.007655382156372

training epoch 69 / 500, batch #75 / 625
Loss:	1.9202892780303955

training epoch 69 / 500, batch #100 / 625
Loss:	1.802042007446289

training epoch 69 / 500, batch #125 / 625
Loss:	1.9700464010238647

training epoch 69 / 500, batch #150 / 625
Loss:	1.905022144317627

training epoch 69 / 500, batch #175 / 625
Loss:	2.082575798034668

training epoch 69 / 500, batch #200 / 625
Loss:	1.8489683866500854

training epoch 69 / 500, batch #225 / 625
Loss:	2.10306978225708

training epoch 69 / 500, batch #250 / 625
Loss:	1.696669101715088

training epoch 69 / 500, batch #275 / 625
Loss:	1.878940224647522

training epoch 69 / 500, batch #300 / 625
Loss:	1.8885666131973267

training epoch 69 / 500, batch #325 / 625
Loss:	2.0678772926330566

training epoch 69 / 500, batch #350 / 625
Loss:	1.7594355344772339

training epoch 69 / 500, batch #375 / 625
Loss:	1.7468265295028687

training epoch 69 / 500, batch #400 / 625
Loss:	1.9422361850738525

training epoch 69 / 500, batch #425 / 625
Loss:	1.7508716583251953

training epoch 69 / 500, batch #450 / 625
Loss:	2.0863449573516846

training epoch 69 / 500, batch #475 / 625
Loss:	1.957232117652893

training epoch 69 / 500, batch #500 / 625
Loss:	1.996561884880066

training epoch 69 / 500, batch #525 / 625
Loss:	1.8753831386566162

training epoch 69 / 500, batch #550 / 625
Loss:	1.771865725517273

training epoch 69 / 500, batch #575 / 625
Loss:	1.7464346885681152

training epoch 69 / 500, batch #600 / 625
Loss:	1.9310493469238281

training epoch 70 / 500, batch #0 / 625
Loss:	1.8576551675796509

training epoch 70 / 500, batch #25 / 625
Loss:	1.7944753170013428

training epoch 70 / 500, batch #50 / 625
Loss:	1.740246295928955

training epoch 70 / 500, batch #75 / 625
Loss:	1.6624090671539307

training epoch 70 / 500, batch #100 / 625
Loss:	1.7987170219421387

training epoch 70 / 500, batch #125 / 625
Loss:	2.02536940574646

training epoch 70 / 500, batch #150 / 625
Loss:	1.7315561771392822

training epoch 70 / 500, batch #175 / 625
Loss:	2.1781582832336426

training epoch 70 / 500, batch #200 / 625
Loss:	1.7798470258712769

training epoch 70 / 500, batch #225 / 625
Loss:	1.9430601596832275

training epoch 70 / 500, batch #250 / 625
Loss:	1.8673763275146484

training epoch 70 / 500, batch #275 / 625
Loss:	1.7648851871490479

training epoch 70 / 500, batch #300 / 625
Loss:	1.9115697145462036

training epoch 70 / 500, batch #325 / 625
Loss:	1.8172986507415771

training epoch 70 / 500, batch #350 / 625
Loss:	1.9295183420181274

training epoch 70 / 500, batch #375 / 625
Loss:	1.814250111579895

training epoch 70 / 500, batch #400 / 625
Loss:	1.9361019134521484

training epoch 70 / 500, batch #425 / 625
Loss:	1.8767982721328735

training epoch 70 / 500, batch #450 / 625
Loss:	2.091595411300659

training epoch 70 / 500, batch #475 / 625
Loss:	1.9296684265136719

training epoch 70 / 500, batch #500 / 625
Loss:	1.9364210367202759

training epoch 70 / 500, batch #525 / 625
Loss:	2.0449483394622803

training epoch 70 / 500, batch #550 / 625
Loss:	1.8758225440979004

training epoch 70 / 500, batch #575 / 625
Loss:	2.0512590408325195

training epoch 70 / 500, batch #600 / 625
Loss:	1.7426403760910034

training epoch 71 / 500, batch #0 / 625
Loss:	1.804684042930603

training epoch 71 / 500, batch #25 / 625
Loss:	1.7742180824279785

training epoch 71 / 500, batch #50 / 625
Loss:	1.8093912601470947

training epoch 71 / 500, batch #75 / 625
Loss:	1.6657865047454834

training epoch 71 / 500, batch #100 / 625
Loss:	1.7828150987625122

training epoch 71 / 500, batch #125 / 625
Loss:	1.8937708139419556

training epoch 71 / 500, batch #150 / 625
Loss:	1.5205051898956299

training epoch 71 / 500, batch #175 / 625
Loss:	1.9198498725891113

training epoch 71 / 500, batch #200 / 625
Loss:	2.0973289012908936

training epoch 71 / 500, batch #225 / 625
Loss:	1.8461151123046875

training epoch 71 / 500, batch #250 / 625
Loss:	1.8369377851486206

training epoch 71 / 500, batch #275 / 625
Loss:	1.8157330751419067

training epoch 71 / 500, batch #300 / 625
Loss:	2.0328409671783447

training epoch 71 / 500, batch #325 / 625
Loss:	1.7279689311981201

training epoch 71 / 500, batch #350 / 625
Loss:	1.922848105430603

training epoch 71 / 500, batch #375 / 625
Loss:	1.9349122047424316

training epoch 71 / 500, batch #400 / 625
Loss:	1.7699066400527954

training epoch 71 / 500, batch #425 / 625
Loss:	1.8026108741760254

training epoch 71 / 500, batch #450 / 625
Loss:	1.7293332815170288

training epoch 71 / 500, batch #475 / 625
Loss:	1.889646053314209

training epoch 71 / 500, batch #500 / 625
Loss:	1.8805677890777588

training epoch 71 / 500, batch #525 / 625
Loss:	1.7934763431549072

training epoch 71 / 500, batch #550 / 625
Loss:	1.9532537460327148

training epoch 71 / 500, batch #575 / 625
Loss:	2.0598294734954834

training epoch 71 / 500, batch #600 / 625
Loss:	1.9348210096359253

training epoch 72 / 500, batch #0 / 625
Loss:	1.7869324684143066

training epoch 72 / 500, batch #25 / 625
Loss:	1.8745259046554565

training epoch 72 / 500, batch #50 / 625
Loss:	1.9608120918273926

training epoch 72 / 500, batch #75 / 625
Loss:	1.8499988317489624

training epoch 72 / 500, batch #100 / 625
Loss:	1.9891530275344849

training epoch 72 / 500, batch #125 / 625
Loss:	2.043595314025879

training epoch 72 / 500, batch #150 / 625
Loss:	1.7473530769348145

training epoch 72 / 500, batch #175 / 625
Loss:	1.7914472818374634

training epoch 72 / 500, batch #200 / 625
Loss:	2.1392855644226074

training epoch 72 / 500, batch #225 / 625
Loss:	1.9400508403778076

training epoch 72 / 500, batch #250 / 625
Loss:	2.0366241931915283

training epoch 72 / 500, batch #275 / 625
Loss:	1.8172426223754883

training epoch 72 / 500, batch #300 / 625
Loss:	1.9467612504959106

training epoch 72 / 500, batch #325 / 625
Loss:	1.93993079662323

training epoch 72 / 500, batch #350 / 625
Loss:	1.8633350133895874

training epoch 72 / 500, batch #375 / 625
Loss:	1.8625906705856323

training epoch 72 / 500, batch #400 / 625
Loss:	2.0485596656799316

training epoch 72 / 500, batch #425 / 625
Loss:	1.8705135583877563

training epoch 72 / 500, batch #450 / 625
Loss:	1.963230848312378

training epoch 72 / 500, batch #475 / 625
Loss:	1.7068836688995361

training epoch 72 / 500, batch #500 / 625
Loss:	1.914648413658142

training epoch 72 / 500, batch #525 / 625
Loss:	1.9024759531021118

training epoch 72 / 500, batch #550 / 625
Loss:	1.8129500150680542

training epoch 72 / 500, batch #575 / 625
Loss:	1.8166236877441406

training epoch 72 / 500, batch #600 / 625
Loss:	2.0032596588134766

training epoch 73 / 500, batch #0 / 625
Loss:	1.9369043111801147

training epoch 73 / 500, batch #25 / 625
Loss:	1.8835636377334595

training epoch 73 / 500, batch #50 / 625
Loss:	1.8931461572647095

training epoch 73 / 500, batch #75 / 625
Loss:	1.9338605403900146

training epoch 73 / 500, batch #100 / 625
Loss:	1.981619954109192

training epoch 73 / 500, batch #125 / 625
Loss:	1.8617684841156006

training epoch 73 / 500, batch #150 / 625
Loss:	2.1830034255981445

training epoch 73 / 500, batch #175 / 625
Loss:	1.867258906364441

training epoch 73 / 500, batch #200 / 625
Loss:	1.7176563739776611

training epoch 73 / 500, batch #225 / 625
Loss:	1.7478443384170532

training epoch 73 / 500, batch #250 / 625
Loss:	1.8229683637619019

training epoch 73 / 500, batch #275 / 625
Loss:	2.0257561206817627

training epoch 73 / 500, batch #300 / 625
Loss:	2.1092820167541504

training epoch 73 / 500, batch #325 / 625
Loss:	1.9543524980545044

training epoch 73 / 500, batch #350 / 625
Loss:	1.9070625305175781

training epoch 73 / 500, batch #375 / 625
Loss:	1.9777253866195679

training epoch 73 / 500, batch #400 / 625
Loss:	1.9774118661880493

training epoch 73 / 500, batch #425 / 625
Loss:	1.7236520051956177

training epoch 73 / 500, batch #450 / 625
Loss:	1.8704012632369995

training epoch 73 / 500, batch #475 / 625
Loss:	1.7770824432373047

training epoch 73 / 500, batch #500 / 625
Loss:	1.972550868988037

training epoch 73 / 500, batch #525 / 625
Loss:	1.798346757888794

training epoch 73 / 500, batch #550 / 625
Loss:	2.0583386421203613

training epoch 73 / 500, batch #575 / 625
Loss:	2.0742061138153076

training epoch 73 / 500, batch #600 / 625
Loss:	1.6317048072814941

training epoch 74 / 500, batch #0 / 625
Loss:	1.888824224472046

training epoch 74 / 500, batch #25 / 625
Loss:	2.043083667755127

training epoch 74 / 500, batch #50 / 625
Loss:	2.053244113922119

training epoch 74 / 500, batch #75 / 625
Loss:	1.8260966539382935

training epoch 74 / 500, batch #100 / 625
Loss:	1.9220387935638428

training epoch 74 / 500, batch #125 / 625
Loss:	1.6300561428070068

training epoch 74 / 500, batch #150 / 625
Loss:	1.7927011251449585

training epoch 74 / 500, batch #175 / 625
Loss:	1.6883649826049805

training epoch 74 / 500, batch #200 / 625
Loss:	1.8521572351455688

training epoch 74 / 500, batch #225 / 625
Loss:	1.6945979595184326

training epoch 74 / 500, batch #250 / 625
Loss:	1.8364367485046387

training epoch 74 / 500, batch #275 / 625
Loss:	1.928562045097351

training epoch 74 / 500, batch #300 / 625
Loss:	1.8914178609848022

training epoch 74 / 500, batch #325 / 625
Loss:	1.9203922748565674

training epoch 74 / 500, batch #350 / 625
Loss:	2.251211166381836

training epoch 74 / 500, batch #375 / 625
Loss:	1.9145749807357788

training epoch 74 / 500, batch #400 / 625
Loss:	1.9054203033447266

training epoch 74 / 500, batch #425 / 625
Loss:	1.799500823020935

training epoch 74 / 500, batch #450 / 625
Loss:	2.002432346343994

training epoch 74 / 500, batch #475 / 625
Loss:	1.8438514471054077

training epoch 74 / 500, batch #500 / 625
Loss:	1.9756088256835938

training epoch 74 / 500, batch #525 / 625
Loss:	1.9290964603424072

training epoch 74 / 500, batch #550 / 625
Loss:	2.003618001937866

training epoch 74 / 500, batch #575 / 625
Loss:	1.8291945457458496

training epoch 74 / 500, batch #600 / 625
Loss:	1.9145547151565552

training epoch 75 / 500, batch #0 / 625
Loss:	1.7388885021209717

training epoch 75 / 500, batch #25 / 625
Loss:	1.841516375541687

training epoch 75 / 500, batch #50 / 625
Loss:	2.047687292098999

training epoch 75 / 500, batch #75 / 625
Loss:	1.8749175071716309

training epoch 75 / 500, batch #100 / 625
Loss:	1.9717636108398438

training epoch 75 / 500, batch #125 / 625
Loss:	1.9857110977172852

training epoch 75 / 500, batch #150 / 625
Loss:	1.8473454713821411

training epoch 75 / 500, batch #175 / 625
Loss:	1.8987631797790527

training epoch 75 / 500, batch #200 / 625
Loss:	1.8378899097442627

training epoch 75 / 500, batch #225 / 625
Loss:	1.7146153450012207

training epoch 75 / 500, batch #250 / 625
Loss:	1.7240017652511597

training epoch 75 / 500, batch #275 / 625
Loss:	1.9492930173873901

training epoch 75 / 500, batch #300 / 625
Loss:	1.9833990335464478

training epoch 75 / 500, batch #325 / 625
Loss:	1.9408711194992065

training epoch 75 / 500, batch #350 / 625
Loss:	1.8346843719482422

training epoch 75 / 500, batch #375 / 625
Loss:	1.7736753225326538

training epoch 75 / 500, batch #400 / 625
Loss:	1.8878036737442017

training epoch 75 / 500, batch #425 / 625
Loss:	1.8292933702468872

training epoch 75 / 500, batch #450 / 625
Loss:	1.9126355648040771

training epoch 75 / 500, batch #475 / 625
Loss:	1.8230483531951904

training epoch 75 / 500, batch #500 / 625
Loss:	1.8987202644348145

training epoch 75 / 500, batch #525 / 625
Loss:	2.1486189365386963

training epoch 75 / 500, batch #550 / 625
Loss:	1.9223414659500122

training epoch 75 / 500, batch #575 / 625
Loss:	1.9659032821655273

training epoch 75 / 500, batch #600 / 625
Loss:	2.005692481994629

training epoch 76 / 500, batch #0 / 625
Loss:	2.177515745162964

training epoch 76 / 500, batch #25 / 625
Loss:	2.0519847869873047

training epoch 76 / 500, batch #50 / 625
Loss:	1.8166486024856567

training epoch 76 / 500, batch #75 / 625
Loss:	1.9994343519210815

training epoch 76 / 500, batch #100 / 625
Loss:	1.8715341091156006

training epoch 76 / 500, batch #125 / 625
Loss:	1.775307059288025

training epoch 76 / 500, batch #150 / 625
Loss:	1.9650799036026

training epoch 76 / 500, batch #175 / 625
Loss:	1.9487745761871338

training epoch 76 / 500, batch #200 / 625
Loss:	1.7878934144973755

training epoch 76 / 500, batch #225 / 625
Loss:	1.814703345298767

training epoch 76 / 500, batch #250 / 625
Loss:	1.8024629354476929

training epoch 76 / 500, batch #275 / 625
Loss:	1.8001620769500732

training epoch 76 / 500, batch #300 / 625
Loss:	1.878516674041748

training epoch 76 / 500, batch #325 / 625
Loss:	1.866701364517212

training epoch 76 / 500, batch #350 / 625
Loss:	1.912957787513733

training epoch 76 / 500, batch #375 / 625
Loss:	1.8601680994033813

training epoch 76 / 500, batch #400 / 625
Loss:	1.9983417987823486

training epoch 76 / 500, batch #425 / 625
Loss:	1.9614957571029663

training epoch 76 / 500, batch #450 / 625
Loss:	1.940814733505249

training epoch 76 / 500, batch #475 / 625
Loss:	2.090555429458618

training epoch 76 / 500, batch #500 / 625
Loss:	1.966711401939392

training epoch 76 / 500, batch #525 / 625
Loss:	1.8785282373428345

training epoch 76 / 500, batch #550 / 625
Loss:	1.9661891460418701

training epoch 76 / 500, batch #575 / 625
Loss:	1.6117042303085327

training epoch 76 / 500, batch #600 / 625
Loss:	2.1173529624938965

training epoch 77 / 500, batch #0 / 625
Loss:	1.6889333724975586

training epoch 77 / 500, batch #25 / 625
Loss:	1.8497869968414307

training epoch 77 / 500, batch #50 / 625
Loss:	1.885083556175232

training epoch 77 / 500, batch #75 / 625
Loss:	1.7090859413146973

training epoch 77 / 500, batch #100 / 625
Loss:	1.7999558448791504

training epoch 77 / 500, batch #125 / 625
Loss:	1.5670822858810425

training epoch 77 / 500, batch #150 / 625
Loss:	1.9447340965270996

training epoch 77 / 500, batch #175 / 625
Loss:	1.9444016218185425

training epoch 77 / 500, batch #200 / 625
Loss:	1.7836238145828247

training epoch 77 / 500, batch #225 / 625
Loss:	1.9338164329528809

training epoch 77 / 500, batch #250 / 625
Loss:	1.687015175819397

training epoch 77 / 500, batch #275 / 625
Loss:	1.7483375072479248

training epoch 77 / 500, batch #300 / 625
Loss:	1.803521752357483

training epoch 77 / 500, batch #325 / 625
Loss:	1.886988639831543

training epoch 77 / 500, batch #350 / 625
Loss:	2.145320177078247

training epoch 77 / 500, batch #375 / 625
Loss:	1.9286000728607178

training epoch 77 / 500, batch #400 / 625
Loss:	2.1170239448547363

training epoch 77 / 500, batch #425 / 625
Loss:	1.854111909866333

training epoch 77 / 500, batch #450 / 625
Loss:	1.8144688606262207

training epoch 77 / 500, batch #475 / 625
Loss:	1.7928715944290161

training epoch 77 / 500, batch #500 / 625
Loss:	1.9688935279846191

training epoch 77 / 500, batch #525 / 625
Loss:	1.7732934951782227

training epoch 77 / 500, batch #550 / 625
Loss:	1.9380803108215332

training epoch 77 / 500, batch #575 / 625
Loss:	1.6787350177764893

training epoch 77 / 500, batch #600 / 625
Loss:	2.0780138969421387

training epoch 78 / 500, batch #0 / 625
Loss:	1.8364651203155518

training epoch 78 / 500, batch #25 / 625
Loss:	1.936885952949524

training epoch 78 / 500, batch #50 / 625
Loss:	1.6122652292251587

training epoch 78 / 500, batch #75 / 625
Loss:	1.993301272392273

training epoch 78 / 500, batch #100 / 625
Loss:	1.6361972093582153

training epoch 78 / 500, batch #125 / 625
Loss:	1.6819156408309937

training epoch 78 / 500, batch #150 / 625
Loss:	1.692548155784607

training epoch 78 / 500, batch #175 / 625
Loss:	1.8560984134674072

training epoch 78 / 500, batch #200 / 625
Loss:	1.8063410520553589

training epoch 78 / 500, batch #225 / 625
Loss:	1.8723236322402954

training epoch 78 / 500, batch #250 / 625
Loss:	1.9369683265686035

training epoch 78 / 500, batch #275 / 625
Loss:	1.943116545677185

training epoch 78 / 500, batch #300 / 625
Loss:	2.007070302963257

training epoch 78 / 500, batch #325 / 625
Loss:	1.8459261655807495

training epoch 78 / 500, batch #350 / 625
Loss:	1.8581743240356445

training epoch 78 / 500, batch #375 / 625
Loss:	1.6836066246032715

training epoch 78 / 500, batch #400 / 625
Loss:	1.8507224321365356

training epoch 78 / 500, batch #425 / 625
Loss:	1.8458131551742554

training epoch 78 / 500, batch #450 / 625
Loss:	1.8930151462554932

training epoch 78 / 500, batch #475 / 625
Loss:	1.6421785354614258

training epoch 78 / 500, batch #500 / 625
Loss:	1.7228525876998901

training epoch 78 / 500, batch #525 / 625
Loss:	1.8440762758255005

training epoch 78 / 500, batch #550 / 625
Loss:	2.0080811977386475

training epoch 78 / 500, batch #575 / 625
Loss:	1.9514662027359009

training epoch 78 / 500, batch #600 / 625
Loss:	1.8559726476669312

training epoch 79 / 500, batch #0 / 625
Loss:	1.7372249364852905

training epoch 79 / 500, batch #25 / 625
Loss:	1.8233870267868042

training epoch 79 / 500, batch #50 / 625
Loss:	1.7550172805786133

training epoch 79 / 500, batch #75 / 625
Loss:	2.0026841163635254

training epoch 79 / 500, batch #100 / 625
Loss:	1.9770420789718628

training epoch 79 / 500, batch #125 / 625
Loss:	2.241248369216919

training epoch 79 / 500, batch #150 / 625
Loss:	1.9592522382736206

training epoch 79 / 500, batch #175 / 625
Loss:	1.8186194896697998

training epoch 79 / 500, batch #200 / 625
Loss:	1.857460856437683

training epoch 79 / 500, batch #225 / 625
Loss:	1.8556605577468872

training epoch 79 / 500, batch #250 / 625
Loss:	1.9308485984802246

training epoch 79 / 500, batch #275 / 625
Loss:	1.8782179355621338

training epoch 79 / 500, batch #300 / 625
Loss:	1.9095356464385986

training epoch 79 / 500, batch #325 / 625
Loss:	1.7832404375076294

training epoch 79 / 500, batch #350 / 625
Loss:	2.003392219543457

training epoch 79 / 500, batch #375 / 625
Loss:	1.8314287662506104

training epoch 79 / 500, batch #400 / 625
Loss:	1.9245296716690063

training epoch 79 / 500, batch #425 / 625
Loss:	1.9243351221084595

training epoch 79 / 500, batch #450 / 625
Loss:	1.881973147392273

training epoch 79 / 500, batch #475 / 625
Loss:	1.9226932525634766

training epoch 79 / 500, batch #500 / 625
Loss:	1.7540090084075928

training epoch 79 / 500, batch #525 / 625
Loss:	1.634047031402588

training epoch 79 / 500, batch #550 / 625
Loss:	1.9336793422698975

training epoch 79 / 500, batch #575 / 625
Loss:	1.7908045053482056

training epoch 79 / 500, batch #600 / 625
Loss:	1.87828528881073

training epoch 80 / 500, batch #0 / 625
Loss:	1.7971616983413696

training epoch 80 / 500, batch #25 / 625
Loss:	1.7962942123413086

training epoch 80 / 500, batch #50 / 625
Loss:	1.6146824359893799

training epoch 80 / 500, batch #75 / 625
Loss:	2.0328736305236816

training epoch 80 / 500, batch #100 / 625
Loss:	1.6771975755691528

training epoch 80 / 500, batch #125 / 625
Loss:	1.7823638916015625

training epoch 80 / 500, batch #150 / 625
Loss:	2.034679412841797

training epoch 80 / 500, batch #175 / 625
Loss:	1.8365018367767334

training epoch 80 / 500, batch #200 / 625
Loss:	2.097975969314575

training epoch 80 / 500, batch #225 / 625
Loss:	1.6705682277679443

training epoch 80 / 500, batch #250 / 625
Loss:	1.8053641319274902

training epoch 80 / 500, batch #275 / 625
Loss:	1.8565462827682495

training epoch 80 / 500, batch #300 / 625
Loss:	1.8592039346694946

training epoch 80 / 500, batch #325 / 625
Loss:	1.9771459102630615

training epoch 80 / 500, batch #350 / 625
Loss:	1.8550491333007812

training epoch 80 / 500, batch #375 / 625
Loss:	1.9308162927627563

training epoch 80 / 500, batch #400 / 625
Loss:	1.892229676246643

training epoch 80 / 500, batch #425 / 625
Loss:	2.091205358505249

training epoch 80 / 500, batch #450 / 625
Loss:	1.8732093572616577

training epoch 80 / 500, batch #475 / 625
Loss:	1.8163690567016602

training epoch 80 / 500, batch #500 / 625
Loss:	1.8685740232467651

training epoch 80 / 500, batch #525 / 625
Loss:	1.8430006504058838

training epoch 80 / 500, batch #550 / 625
Loss:	2.0269651412963867

training epoch 80 / 500, batch #575 / 625
Loss:	2.099445104598999

training epoch 80 / 500, batch #600 / 625
Loss:	1.7209954261779785

training epoch 81 / 500, batch #0 / 625
Loss:	1.8727918863296509

training epoch 81 / 500, batch #25 / 625
Loss:	1.6047565937042236

training epoch 81 / 500, batch #50 / 625
Loss:	1.9918360710144043

training epoch 81 / 500, batch #75 / 625
Loss:	2.155764579772949

training epoch 81 / 500, batch #100 / 625
Loss:	1.7875186204910278

training epoch 81 / 500, batch #125 / 625
Loss:	1.7680420875549316

training epoch 81 / 500, batch #150 / 625
Loss:	1.8506646156311035

training epoch 81 / 500, batch #175 / 625
Loss:	1.8751546144485474

training epoch 81 / 500, batch #200 / 625
Loss:	2.112233877182007

training epoch 81 / 500, batch #225 / 625
Loss:	1.9339736700057983

training epoch 81 / 500, batch #250 / 625
Loss:	1.4796905517578125

training epoch 81 / 500, batch #275 / 625
Loss:	2.0099880695343018

training epoch 81 / 500, batch #300 / 625
Loss:	1.7112765312194824

training epoch 81 / 500, batch #325 / 625
Loss:	1.742209553718567

training epoch 81 / 500, batch #350 / 625
Loss:	1.6464638710021973

training epoch 81 / 500, batch #375 / 625
Loss:	1.6967999935150146

training epoch 81 / 500, batch #400 / 625
Loss:	2.132626533508301

training epoch 81 / 500, batch #425 / 625
Loss:	1.8537201881408691

training epoch 81 / 500, batch #450 / 625
Loss:	2.003242254257202

training epoch 81 / 500, batch #475 / 625
Loss:	1.8814351558685303

training epoch 81 / 500, batch #500 / 625
Loss:	1.901826024055481

training epoch 81 / 500, batch #525 / 625
Loss:	1.6173609495162964

training epoch 81 / 500, batch #550 / 625
Loss:	1.9890965223312378

training epoch 81 / 500, batch #575 / 625
Loss:	1.8018265962600708

training epoch 81 / 500, batch #600 / 625
Loss:	1.892006754875183

training epoch 82 / 500, batch #0 / 625
Loss:	1.8997184038162231

training epoch 82 / 500, batch #25 / 625
Loss:	1.7512532472610474

training epoch 82 / 500, batch #50 / 625
Loss:	1.8749549388885498

training epoch 82 / 500, batch #75 / 625
Loss:	1.836353063583374

training epoch 82 / 500, batch #100 / 625
Loss:	1.7504314184188843

training epoch 82 / 500, batch #125 / 625
Loss:	1.8987547159194946

training epoch 82 / 500, batch #150 / 625
Loss:	1.8167095184326172

training epoch 82 / 500, batch #175 / 625
Loss:	1.7762749195098877

training epoch 82 / 500, batch #200 / 625
Loss:	1.8484108448028564

training epoch 82 / 500, batch #225 / 625
Loss:	1.726169228553772

training epoch 82 / 500, batch #250 / 625
Loss:	1.9192551374435425

training epoch 82 / 500, batch #275 / 625
Loss:	1.6025729179382324

training epoch 82 / 500, batch #300 / 625
Loss:	1.7655779123306274

training epoch 82 / 500, batch #325 / 625
Loss:	1.839460015296936

training epoch 82 / 500, batch #350 / 625
Loss:	1.8222901821136475

training epoch 82 / 500, batch #375 / 625
Loss:	2.0746896266937256

training epoch 82 / 500, batch #400 / 625
Loss:	1.88506019115448

training epoch 82 / 500, batch #425 / 625
Loss:	1.7956339120864868

training epoch 82 / 500, batch #450 / 625
Loss:	1.9989995956420898

training epoch 82 / 500, batch #475 / 625
Loss:	2.0772852897644043

training epoch 82 / 500, batch #500 / 625
Loss:	1.8916667699813843

training epoch 82 / 500, batch #525 / 625
Loss:	1.9867455959320068

training epoch 82 / 500, batch #550 / 625
Loss:	1.8747893571853638

training epoch 82 / 500, batch #575 / 625
Loss:	2.126682758331299

training epoch 82 / 500, batch #600 / 625
Loss:	1.8890306949615479

training epoch 83 / 500, batch #0 / 625
Loss:	1.834869623184204

training epoch 83 / 500, batch #25 / 625
Loss:	2.2117769718170166

training epoch 83 / 500, batch #50 / 625
Loss:	1.8574676513671875

training epoch 83 / 500, batch #75 / 625
Loss:	1.9276517629623413

training epoch 83 / 500, batch #100 / 625
Loss:	1.857068657875061

training epoch 83 / 500, batch #125 / 625
Loss:	1.877177357673645

training epoch 83 / 500, batch #150 / 625
Loss:	1.7844973802566528

training epoch 83 / 500, batch #175 / 625
Loss:	2.0340611934661865

training epoch 83 / 500, batch #200 / 625
Loss:	1.9179211854934692

training epoch 83 / 500, batch #225 / 625
Loss:	1.9722379446029663

training epoch 83 / 500, batch #250 / 625
Loss:	2.0637426376342773

training epoch 83 / 500, batch #275 / 625
Loss:	1.947034478187561

training epoch 83 / 500, batch #300 / 625
Loss:	1.927011489868164

training epoch 83 / 500, batch #325 / 625
Loss:	2.0334854125976562

training epoch 83 / 500, batch #350 / 625
Loss:	1.7025365829467773

training epoch 83 / 500, batch #375 / 625
Loss:	1.7260935306549072

training epoch 83 / 500, batch #400 / 625
Loss:	1.807755470275879

training epoch 83 / 500, batch #425 / 625
Loss:	1.8717514276504517

training epoch 83 / 500, batch #450 / 625
Loss:	1.7849533557891846

training epoch 83 / 500, batch #475 / 625
Loss:	1.7317616939544678

training epoch 83 / 500, batch #500 / 625
Loss:	2.0348095893859863

training epoch 83 / 500, batch #525 / 625
Loss:	1.920964002609253

training epoch 83 / 500, batch #550 / 625
Loss:	1.774786353111267

training epoch 83 / 500, batch #575 / 625
Loss:	1.8128310441970825

training epoch 83 / 500, batch #600 / 625
Loss:	2.0809621810913086

training epoch 84 / 500, batch #0 / 625
Loss:	1.8690965175628662

training epoch 84 / 500, batch #25 / 625
Loss:	1.7194366455078125

training epoch 84 / 500, batch #50 / 625
Loss:	2.319012403488159

training epoch 84 / 500, batch #75 / 625
Loss:	1.639190435409546

training epoch 84 / 500, batch #100 / 625
Loss:	1.810146689414978

training epoch 84 / 500, batch #125 / 625
Loss:	1.9628340005874634

training epoch 84 / 500, batch #150 / 625
Loss:	2.0842998027801514

training epoch 84 / 500, batch #175 / 625
Loss:	1.9988616704940796

training epoch 84 / 500, batch #200 / 625
Loss:	1.8883930444717407

training epoch 84 / 500, batch #225 / 625
Loss:	1.788977026939392

training epoch 84 / 500, batch #250 / 625
Loss:	1.9035415649414062

training epoch 84 / 500, batch #275 / 625
Loss:	1.9351669549942017

training epoch 84 / 500, batch #300 / 625
Loss:	1.8387211561203003

training epoch 84 / 500, batch #325 / 625
Loss:	2.0739386081695557

training epoch 84 / 500, batch #350 / 625
Loss:	1.8604408502578735

training epoch 84 / 500, batch #375 / 625
Loss:	2.065507173538208

training epoch 84 / 500, batch #400 / 625
Loss:	1.8448922634124756

training epoch 84 / 500, batch #425 / 625
Loss:	1.7725772857666016

training epoch 84 / 500, batch #450 / 625
Loss:	1.7336043119430542

training epoch 84 / 500, batch #475 / 625
Loss:	1.936453104019165

training epoch 84 / 500, batch #500 / 625
Loss:	1.5729143619537354

training epoch 84 / 500, batch #525 / 625
Loss:	2.0574517250061035

training epoch 84 / 500, batch #550 / 625
Loss:	2.0006492137908936

training epoch 84 / 500, batch #575 / 625
Loss:	1.8742939233779907

training epoch 84 / 500, batch #600 / 625
Loss:	1.9008889198303223

training epoch 85 / 500, batch #0 / 625
Loss:	1.7775603532791138

training epoch 85 / 500, batch #25 / 625
Loss:	2.050060510635376

training epoch 85 / 500, batch #50 / 625
Loss:	1.9266983270645142

training epoch 85 / 500, batch #75 / 625
Loss:	1.724487066268921

training epoch 85 / 500, batch #100 / 625
Loss:	1.6910252571105957

training epoch 85 / 500, batch #125 / 625
Loss:	1.8743102550506592

training epoch 85 / 500, batch #150 / 625
Loss:	1.86427640914917

training epoch 85 / 500, batch #175 / 625
Loss:	1.8903950452804565

training epoch 85 / 500, batch #200 / 625
Loss:	1.7524280548095703

training epoch 85 / 500, batch #225 / 625
Loss:	1.7324771881103516

training epoch 85 / 500, batch #250 / 625
Loss:	1.910110592842102

training epoch 85 / 500, batch #275 / 625
Loss:	1.8157367706298828

training epoch 85 / 500, batch #300 / 625
Loss:	1.8182768821716309

training epoch 85 / 500, batch #325 / 625
Loss:	1.7477962970733643

training epoch 85 / 500, batch #350 / 625
Loss:	1.8166240453720093

training epoch 85 / 500, batch #375 / 625
Loss:	1.8878896236419678

training epoch 85 / 500, batch #400 / 625
Loss:	1.890769362449646

training epoch 85 / 500, batch #425 / 625
Loss:	1.7276923656463623

training epoch 85 / 500, batch #450 / 625
Loss:	1.919851303100586

training epoch 85 / 500, batch #475 / 625
Loss:	1.6975831985473633

training epoch 85 / 500, batch #500 / 625
Loss:	1.8847957849502563

training epoch 85 / 500, batch #525 / 625
Loss:	1.829549789428711

training epoch 85 / 500, batch #550 / 625
Loss:	1.7318363189697266

training epoch 85 / 500, batch #575 / 625
Loss:	1.8711072206497192

training epoch 85 / 500, batch #600 / 625
Loss:	1.9166148900985718

training epoch 86 / 500, batch #0 / 625
Loss:	1.8355880975723267

training epoch 86 / 500, batch #25 / 625
Loss:	2.060147285461426

training epoch 86 / 500, batch #50 / 625
Loss:	1.9758459329605103

training epoch 86 / 500, batch #75 / 625
Loss:	1.8350367546081543

training epoch 86 / 500, batch #100 / 625
Loss:	2.1315112113952637

training epoch 86 / 500, batch #125 / 625
Loss:	1.9033735990524292

training epoch 86 / 500, batch #150 / 625
Loss:	1.7285352945327759

training epoch 86 / 500, batch #175 / 625
Loss:	1.5730646848678589

training epoch 86 / 500, batch #200 / 625
Loss:	1.7547264099121094

training epoch 86 / 500, batch #225 / 625
Loss:	2.0622196197509766

training epoch 86 / 500, batch #250 / 625
Loss:	1.8191566467285156

training epoch 86 / 500, batch #275 / 625
Loss:	1.93238365650177

training epoch 86 / 500, batch #300 / 625
Loss:	1.9394813776016235

training epoch 86 / 500, batch #325 / 625
Loss:	1.9706792831420898

training epoch 86 / 500, batch #350 / 625
Loss:	1.8836020231246948

training epoch 86 / 500, batch #375 / 625
Loss:	1.8038252592086792

training epoch 86 / 500, batch #400 / 625
Loss:	2.0544750690460205

training epoch 86 / 500, batch #425 / 625
Loss:	1.8701668977737427

training epoch 86 / 500, batch #450 / 625
Loss:	1.7492138147354126

training epoch 86 / 500, batch #475 / 625
Loss:	1.7860232591629028

training epoch 86 / 500, batch #500 / 625
Loss:	1.9813770055770874

training epoch 86 / 500, batch #525 / 625
Loss:	1.7197262048721313

training epoch 86 / 500, batch #550 / 625
Loss:	1.912430763244629

training epoch 86 / 500, batch #575 / 625
Loss:	1.9522135257720947

training epoch 86 / 500, batch #600 / 625
Loss:	1.8802140951156616

training epoch 87 / 500, batch #0 / 625
Loss:	1.9600673913955688

training epoch 87 / 500, batch #25 / 625
Loss:	2.0436840057373047

training epoch 87 / 500, batch #50 / 625
Loss:	1.9522144794464111

training epoch 87 / 500, batch #75 / 625
Loss:	1.768614411354065

training epoch 87 / 500, batch #100 / 625
Loss:	1.7417093515396118

training epoch 87 / 500, batch #125 / 625
Loss:	2.1006386280059814

training epoch 87 / 500, batch #150 / 625
Loss:	1.839639663696289

training epoch 87 / 500, batch #175 / 625
Loss:	1.8791700601577759

training epoch 87 / 500, batch #200 / 625
Loss:	1.7511745691299438

training epoch 87 / 500, batch #225 / 625
Loss:	1.8500714302062988

training epoch 87 / 500, batch #250 / 625
Loss:	1.673413872718811

training epoch 87 / 500, batch #275 / 625
Loss:	1.5883744955062866

training epoch 87 / 500, batch #300 / 625
Loss:	1.8209216594696045

training epoch 87 / 500, batch #325 / 625
Loss:	2.0787501335144043

training epoch 87 / 500, batch #350 / 625
Loss:	1.8143558502197266

training epoch 87 / 500, batch #375 / 625
Loss:	1.8712503910064697

training epoch 87 / 500, batch #400 / 625
Loss:	2.020683526992798

training epoch 87 / 500, batch #425 / 625
Loss:	1.7555224895477295

training epoch 87 / 500, batch #450 / 625
Loss:	1.798290491104126

training epoch 87 / 500, batch #475 / 625
Loss:	1.8787453174591064

training epoch 87 / 500, batch #500 / 625
Loss:	1.9412426948547363

training epoch 87 / 500, batch #525 / 625
Loss:	1.7571866512298584

training epoch 87 / 500, batch #550 / 625
Loss:	1.8554344177246094

training epoch 87 / 500, batch #575 / 625
Loss:	1.9920498132705688

training epoch 87 / 500, batch #600 / 625
Loss:	1.8263416290283203

training epoch 88 / 500, batch #0 / 625
Loss:	1.9110782146453857

training epoch 88 / 500, batch #25 / 625
Loss:	1.806499719619751

training epoch 88 / 500, batch #50 / 625
Loss:	1.9229506254196167

training epoch 88 / 500, batch #75 / 625
Loss:	2.0086922645568848

training epoch 88 / 500, batch #100 / 625
Loss:	1.8667643070220947

training epoch 88 / 500, batch #125 / 625
Loss:	1.7809150218963623

training epoch 88 / 500, batch #150 / 625
Loss:	1.7377678155899048

training epoch 88 / 500, batch #175 / 625
Loss:	2.0181190967559814

training epoch 88 / 500, batch #200 / 625
Loss:	1.8843936920166016

training epoch 88 / 500, batch #225 / 625
Loss:	1.634068250656128

training epoch 88 / 500, batch #250 / 625
Loss:	1.6599524021148682

training epoch 88 / 500, batch #275 / 625
Loss:	1.844163417816162

training epoch 88 / 500, batch #300 / 625
Loss:	1.8811986446380615

training epoch 88 / 500, batch #325 / 625
Loss:	1.9887661933898926

training epoch 88 / 500, batch #350 / 625
Loss:	1.7332274913787842

training epoch 88 / 500, batch #375 / 625
Loss:	2.0039219856262207

training epoch 88 / 500, batch #400 / 625
Loss:	1.9578801393508911

training epoch 88 / 500, batch #425 / 625
Loss:	2.0459609031677246

training epoch 88 / 500, batch #450 / 625
Loss:	2.01639723777771

training epoch 88 / 500, batch #475 / 625
Loss:	1.9949135780334473

training epoch 88 / 500, batch #500 / 625
Loss:	1.806038737297058

training epoch 88 / 500, batch #525 / 625
Loss:	1.9325237274169922

training epoch 88 / 500, batch #550 / 625
Loss:	1.8516758680343628

training epoch 88 / 500, batch #575 / 625
Loss:	1.862864375114441

training epoch 88 / 500, batch #600 / 625
Loss:	1.843153715133667

training epoch 89 / 500, batch #0 / 625
Loss:	1.7459522485733032

training epoch 89 / 500, batch #25 / 625
Loss:	1.7470484972000122

training epoch 89 / 500, batch #50 / 625
Loss:	1.9357659816741943

training epoch 89 / 500, batch #75 / 625
Loss:	1.7610026597976685

training epoch 89 / 500, batch #100 / 625
Loss:	1.8497374057769775

training epoch 89 / 500, batch #125 / 625
Loss:	1.976691722869873

training epoch 89 / 500, batch #150 / 625
Loss:	2.0226471424102783

training epoch 89 / 500, batch #175 / 625
Loss:	1.8683345317840576

training epoch 89 / 500, batch #200 / 625
Loss:	1.8484693765640259

training epoch 89 / 500, batch #225 / 625
Loss:	1.864436388015747

training epoch 89 / 500, batch #250 / 625
Loss:	1.7887059450149536

training epoch 89 / 500, batch #275 / 625
Loss:	1.7682307958602905

training epoch 89 / 500, batch #300 / 625
Loss:	1.7678765058517456

training epoch 89 / 500, batch #325 / 625
Loss:	2.0454649925231934

training epoch 89 / 500, batch #350 / 625
Loss:	1.814667820930481

training epoch 89 / 500, batch #375 / 625
Loss:	1.970048427581787

training epoch 89 / 500, batch #400 / 625
Loss:	1.8750286102294922

training epoch 89 / 500, batch #425 / 625
Loss:	1.9738099575042725

training epoch 89 / 500, batch #450 / 625
Loss:	2.0203723907470703

training epoch 89 / 500, batch #475 / 625
Loss:	1.8628761768341064

training epoch 89 / 500, batch #500 / 625
Loss:	1.8649874925613403

training epoch 89 / 500, batch #525 / 625
Loss:	1.8215577602386475

training epoch 89 / 500, batch #550 / 625
Loss:	1.8828349113464355

training epoch 89 / 500, batch #575 / 625
Loss:	1.8600375652313232

training epoch 89 / 500, batch #600 / 625
Loss:	1.7188730239868164

training epoch 90 / 500, batch #0 / 625
Loss:	2.018690586090088

training epoch 90 / 500, batch #25 / 625
Loss:	1.6032321453094482

training epoch 90 / 500, batch #50 / 625
Loss:	1.7715275287628174

training epoch 90 / 500, batch #75 / 625
Loss:	1.8666638135910034

training epoch 90 / 500, batch #100 / 625
Loss:	1.6771372556686401

training epoch 90 / 500, batch #125 / 625
Loss:	1.8877830505371094

training epoch 90 / 500, batch #150 / 625
Loss:	1.7801337242126465

training epoch 90 / 500, batch #175 / 625
Loss:	1.9579553604125977

training epoch 90 / 500, batch #200 / 625
Loss:	1.902038335800171

training epoch 90 / 500, batch #225 / 625
Loss:	1.9121583700180054

training epoch 90 / 500, batch #250 / 625
Loss:	1.8389065265655518

training epoch 90 / 500, batch #275 / 625
Loss:	1.6264119148254395

training epoch 90 / 500, batch #300 / 625
Loss:	1.914263367652893

training epoch 90 / 500, batch #325 / 625
Loss:	1.9543354511260986

training epoch 90 / 500, batch #350 / 625
Loss:	1.8949165344238281

training epoch 90 / 500, batch #375 / 625
Loss:	1.6632927656173706

training epoch 90 / 500, batch #400 / 625
Loss:	1.7428689002990723

training epoch 90 / 500, batch #425 / 625
Loss:	2.0397961139678955

training epoch 90 / 500, batch #450 / 625
Loss:	1.7322900295257568

training epoch 90 / 500, batch #475 / 625
Loss:	1.909088134765625

training epoch 90 / 500, batch #500 / 625
Loss:	1.8108254671096802

training epoch 90 / 500, batch #525 / 625
Loss:	1.7666099071502686

training epoch 90 / 500, batch #550 / 625
Loss:	1.9731327295303345

training epoch 90 / 500, batch #575 / 625
Loss:	1.4582561254501343

training epoch 90 / 500, batch #600 / 625
Loss:	1.9841164350509644

training epoch 91 / 500, batch #0 / 625
Loss:	1.7626231908798218

training epoch 91 / 500, batch #25 / 625
Loss:	1.8680397272109985

training epoch 91 / 500, batch #50 / 625
Loss:	1.8323521614074707

training epoch 91 / 500, batch #75 / 625
Loss:	1.778336524963379

training epoch 91 / 500, batch #100 / 625
Loss:	1.723824381828308

training epoch 91 / 500, batch #125 / 625
Loss:	1.7922697067260742

training epoch 91 / 500, batch #150 / 625
Loss:	1.7473984956741333

training epoch 91 / 500, batch #175 / 625
Loss:	1.9215744733810425

training epoch 91 / 500, batch #200 / 625
Loss:	1.766202688217163

training epoch 91 / 500, batch #225 / 625
Loss:	2.001676082611084

training epoch 91 / 500, batch #250 / 625
Loss:	1.5828615427017212

training epoch 91 / 500, batch #275 / 625
Loss:	1.6574656963348389

training epoch 91 / 500, batch #300 / 625
Loss:	1.8844940662384033

training epoch 91 / 500, batch #325 / 625
Loss:	1.7634590864181519

training epoch 91 / 500, batch #350 / 625
Loss:	1.9939286708831787

training epoch 91 / 500, batch #375 / 625
Loss:	1.8871327638626099

training epoch 91 / 500, batch #400 / 625
Loss:	1.894970178604126

training epoch 91 / 500, batch #425 / 625
Loss:	1.8264117240905762

training epoch 91 / 500, batch #450 / 625
Loss:	1.8410948514938354

training epoch 91 / 500, batch #475 / 625
Loss:	1.9662779569625854

training epoch 91 / 500, batch #500 / 625
Loss:	1.855280876159668

training epoch 91 / 500, batch #525 / 625
Loss:	1.6840306520462036

training epoch 91 / 500, batch #550 / 625
Loss:	1.8181304931640625

training epoch 91 / 500, batch #575 / 625
Loss:	1.8761277198791504

training epoch 91 / 500, batch #600 / 625
Loss:	1.8954213857650757

training epoch 92 / 500, batch #0 / 625
Loss:	1.8535699844360352

training epoch 92 / 500, batch #25 / 625
Loss:	2.090087890625

training epoch 92 / 500, batch #50 / 625
Loss:	1.7571356296539307

training epoch 92 / 500, batch #75 / 625
Loss:	1.7267603874206543

training epoch 92 / 500, batch #100 / 625
Loss:	2.030647039413452

training epoch 92 / 500, batch #125 / 625
Loss:	1.9403245449066162

training epoch 92 / 500, batch #150 / 625
Loss:	1.863486886024475

training epoch 92 / 500, batch #175 / 625
Loss:	1.7088062763214111

training epoch 92 / 500, batch #200 / 625
Loss:	1.6425144672393799

training epoch 92 / 500, batch #225 / 625
Loss:	2.1930432319641113

training epoch 92 / 500, batch #250 / 625
Loss:	2.0014407634735107

training epoch 92 / 500, batch #275 / 625
Loss:	1.8232287168502808

training epoch 92 / 500, batch #300 / 625
Loss:	1.757173776626587

training epoch 92 / 500, batch #325 / 625
Loss:	1.9073330163955688

training epoch 92 / 500, batch #350 / 625
Loss:	1.7056993246078491

training epoch 92 / 500, batch #375 / 625
Loss:	1.8598805665969849

training epoch 92 / 500, batch #400 / 625
Loss:	1.8303378820419312

training epoch 92 / 500, batch #425 / 625
Loss:	2.0614848136901855

training epoch 92 / 500, batch #450 / 625
Loss:	1.8666132688522339

training epoch 92 / 500, batch #475 / 625
Loss:	1.983093023300171

training epoch 92 / 500, batch #500 / 625
Loss:	1.6513712406158447

training epoch 92 / 500, batch #525 / 625
Loss:	1.7216860055923462

training epoch 92 / 500, batch #550 / 625
Loss:	2.00290584564209

training epoch 92 / 500, batch #575 / 625
Loss:	1.7774920463562012

training epoch 92 / 500, batch #600 / 625
Loss:	2.095740556716919

training epoch 93 / 500, batch #0 / 625
Loss:	1.989559531211853

training epoch 93 / 500, batch #25 / 625
Loss:	1.704101324081421

training epoch 93 / 500, batch #50 / 625
Loss:	1.7280141115188599

training epoch 93 / 500, batch #75 / 625
Loss:	1.813096284866333

training epoch 93 / 500, batch #100 / 625
Loss:	1.764609456062317

training epoch 93 / 500, batch #125 / 625
Loss:	1.9764931201934814

training epoch 93 / 500, batch #150 / 625
Loss:	1.8283839225769043

training epoch 93 / 500, batch #175 / 625
Loss:	2.0887959003448486

training epoch 93 / 500, batch #200 / 625
Loss:	1.7860052585601807

training epoch 93 / 500, batch #225 / 625
Loss:	1.728966474533081

training epoch 93 / 500, batch #250 / 625
Loss:	2.1105661392211914

training epoch 93 / 500, batch #275 / 625
Loss:	1.828932762145996

training epoch 93 / 500, batch #300 / 625
Loss:	1.6863529682159424

training epoch 93 / 500, batch #325 / 625
Loss:	2.0619194507598877

training epoch 93 / 500, batch #350 / 625
Loss:	1.8503819704055786

training epoch 93 / 500, batch #375 / 625
Loss:	1.8117440938949585

training epoch 93 / 500, batch #400 / 625
Loss:	1.988966703414917

training epoch 93 / 500, batch #425 / 625
Loss:	1.928816556930542

training epoch 93 / 500, batch #450 / 625
Loss:	2.0371131896972656

training epoch 93 / 500, batch #475 / 625
Loss:	1.9898468255996704

training epoch 93 / 500, batch #500 / 625
Loss:	1.8250917196273804

training epoch 93 / 500, batch #525 / 625
Loss:	1.7694377899169922

training epoch 93 / 500, batch #550 / 625
Loss:	1.9090348482131958

training epoch 93 / 500, batch #575 / 625
Loss:	1.6248387098312378

training epoch 93 / 500, batch #600 / 625
Loss:	1.7570459842681885

training epoch 94 / 500, batch #0 / 625
Loss:	1.8455262184143066

training epoch 94 / 500, batch #25 / 625
Loss:	1.8869205713272095

training epoch 94 / 500, batch #50 / 625
Loss:	1.9826602935791016

training epoch 94 / 500, batch #75 / 625
Loss:	2.0244908332824707

training epoch 94 / 500, batch #100 / 625
Loss:	1.8055678606033325

training epoch 94 / 500, batch #125 / 625
Loss:	1.8961929082870483

training epoch 94 / 500, batch #150 / 625
Loss:	1.6673225164413452

training epoch 94 / 500, batch #175 / 625
Loss:	1.708172082901001

training epoch 94 / 500, batch #200 / 625
Loss:	2.0869061946868896

training epoch 94 / 500, batch #225 / 625
Loss:	2.013432741165161

training epoch 94 / 500, batch #250 / 625
Loss:	1.8825609683990479

training epoch 94 / 500, batch #275 / 625
Loss:	1.7163439989089966

training epoch 94 / 500, batch #300 / 625
Loss:	2.0750889778137207

training epoch 94 / 500, batch #325 / 625
Loss:	1.835052490234375

training epoch 94 / 500, batch #350 / 625
Loss:	1.725287675857544

training epoch 94 / 500, batch #375 / 625
Loss:	1.7748453617095947

training epoch 94 / 500, batch #400 / 625
Loss:	1.7440922260284424

training epoch 94 / 500, batch #425 / 625
Loss:	1.913086175918579

training epoch 94 / 500, batch #450 / 625
Loss:	1.6844127178192139

training epoch 94 / 500, batch #475 / 625
Loss:	1.8788440227508545

training epoch 94 / 500, batch #500 / 625
Loss:	1.9693598747253418

training epoch 94 / 500, batch #525 / 625
Loss:	1.7484917640686035

training epoch 94 / 500, batch #550 / 625
Loss:	1.8300198316574097

training epoch 94 / 500, batch #575 / 625
Loss:	1.7667053937911987

training epoch 94 / 500, batch #600 / 625
Loss:	1.8917597532272339

training epoch 95 / 500, batch #0 / 625
Loss:	1.9523944854736328

training epoch 95 / 500, batch #25 / 625
Loss:	1.9087659120559692

training epoch 95 / 500, batch #50 / 625
Loss:	1.761082649230957

training epoch 95 / 500, batch #75 / 625
Loss:	1.635884404182434

training epoch 95 / 500, batch #100 / 625
Loss:	1.869726300239563

training epoch 95 / 500, batch #125 / 625
Loss:	1.9583237171173096

training epoch 95 / 500, batch #150 / 625
Loss:	1.70743989944458

training epoch 95 / 500, batch #175 / 625
Loss:	1.9611539840698242

training epoch 95 / 500, batch #200 / 625
Loss:	1.854419231414795

training epoch 95 / 500, batch #225 / 625
Loss:	1.7749769687652588

training epoch 95 / 500, batch #250 / 625
Loss:	1.619006872177124

training epoch 95 / 500, batch #275 / 625
Loss:	1.696027398109436

training epoch 95 / 500, batch #300 / 625
Loss:	1.8616923093795776

training epoch 95 / 500, batch #325 / 625
Loss:	2.0085055828094482

training epoch 95 / 500, batch #350 / 625
Loss:	1.7592867612838745

training epoch 95 / 500, batch #375 / 625
Loss:	1.6648081541061401

training epoch 95 / 500, batch #400 / 625
Loss:	1.7105486392974854

training epoch 95 / 500, batch #425 / 625
Loss:	1.7203729152679443

training epoch 95 / 500, batch #450 / 625
Loss:	1.8101011514663696

training epoch 95 / 500, batch #475 / 625
Loss:	1.7673004865646362

training epoch 95 / 500, batch #500 / 625
Loss:	1.977277159690857

training epoch 95 / 500, batch #525 / 625
Loss:	1.8498351573944092

training epoch 95 / 500, batch #550 / 625
Loss:	1.6898146867752075

training epoch 95 / 500, batch #575 / 625
Loss:	1.7853329181671143

training epoch 95 / 500, batch #600 / 625
Loss:	1.8596916198730469

training epoch 96 / 500, batch #0 / 625
Loss:	2.0524520874023438

training epoch 96 / 500, batch #25 / 625
Loss:	1.9040651321411133

training epoch 96 / 500, batch #50 / 625
Loss:	1.8177582025527954

training epoch 96 / 500, batch #75 / 625
Loss:	1.8876385688781738

training epoch 96 / 500, batch #100 / 625
Loss:	1.7745976448059082

training epoch 96 / 500, batch #125 / 625
Loss:	1.8137739896774292

training epoch 96 / 500, batch #150 / 625
Loss:	1.8788028955459595

training epoch 96 / 500, batch #175 / 625
Loss:	1.84414541721344

training epoch 96 / 500, batch #200 / 625
Loss:	1.6971251964569092

training epoch 96 / 500, batch #225 / 625
Loss:	1.7712368965148926

training epoch 96 / 500, batch #250 / 625
Loss:	1.7526651620864868

training epoch 96 / 500, batch #275 / 625
Loss:	1.9619636535644531

training epoch 96 / 500, batch #300 / 625
Loss:	1.7894705533981323

training epoch 96 / 500, batch #325 / 625
Loss:	1.7524093389511108

training epoch 96 / 500, batch #350 / 625
Loss:	1.9743547439575195

training epoch 96 / 500, batch #375 / 625
Loss:	1.6615221500396729

training epoch 96 / 500, batch #400 / 625
Loss:	1.8950011730194092

training epoch 96 / 500, batch #425 / 625
Loss:	2.0008883476257324

training epoch 96 / 500, batch #450 / 625
Loss:	1.677577018737793

training epoch 96 / 500, batch #475 / 625
Loss:	1.9190468788146973

training epoch 96 / 500, batch #500 / 625
Loss:	1.8381383419036865

training epoch 96 / 500, batch #525 / 625
Loss:	1.833833932876587

training epoch 96 / 500, batch #550 / 625
Loss:	1.6705108880996704

training epoch 96 / 500, batch #575 / 625
Loss:	1.9307271242141724

training epoch 96 / 500, batch #600 / 625
Loss:	1.9817641973495483

training epoch 97 / 500, batch #0 / 625
Loss:	2.1864755153656006

training epoch 97 / 500, batch #25 / 625
Loss:	1.8022866249084473

training epoch 97 / 500, batch #50 / 625
Loss:	1.6641873121261597

training epoch 97 / 500, batch #75 / 625
Loss:	1.903663158416748

training epoch 97 / 500, batch #100 / 625
Loss:	1.6175740957260132

training epoch 97 / 500, batch #125 / 625
Loss:	1.8343230485916138

training epoch 97 / 500, batch #150 / 625
Loss:	1.7620245218276978

training epoch 97 / 500, batch #175 / 625
Loss:	1.9905354976654053

training epoch 97 / 500, batch #200 / 625
Loss:	1.7700815200805664

training epoch 97 / 500, batch #225 / 625
Loss:	2.0019986629486084

training epoch 97 / 500, batch #250 / 625
Loss:	1.6437857151031494

training epoch 97 / 500, batch #275 / 625
Loss:	1.6524900197982788

training epoch 97 / 500, batch #300 / 625
Loss:	1.6176202297210693

training epoch 97 / 500, batch #325 / 625
Loss:	1.7079575061798096

training epoch 97 / 500, batch #350 / 625
Loss:	2.000842571258545

training epoch 97 / 500, batch #375 / 625
Loss:	1.8948897123336792

training epoch 97 / 500, batch #400 / 625
Loss:	1.8035967350006104

training epoch 97 / 500, batch #425 / 625
Loss:	1.9092836380004883

training epoch 97 / 500, batch #450 / 625
Loss:	1.8228569030761719

training epoch 97 / 500, batch #475 / 625
Loss:	1.9487533569335938

training epoch 97 / 500, batch #500 / 625
Loss:	1.82164466381073

training epoch 97 / 500, batch #525 / 625
Loss:	1.837180733680725

training epoch 97 / 500, batch #550 / 625
Loss:	1.837755799293518

training epoch 97 / 500, batch #575 / 625
Loss:	2.133183002471924

training epoch 97 / 500, batch #600 / 625
Loss:	1.9021625518798828

training epoch 98 / 500, batch #0 / 625
Loss:	1.7640721797943115

training epoch 98 / 500, batch #25 / 625
Loss:	1.7641960382461548

training epoch 98 / 500, batch #50 / 625
Loss:	1.6211955547332764

training epoch 98 / 500, batch #75 / 625
Loss:	1.8424382209777832

training epoch 98 / 500, batch #100 / 625
Loss:	1.8407632112503052

training epoch 98 / 500, batch #125 / 625
Loss:	1.8208321332931519

training epoch 98 / 500, batch #150 / 625
Loss:	1.7979644536972046

training epoch 98 / 500, batch #175 / 625
Loss:	2.156883478164673

training epoch 98 / 500, batch #200 / 625
Loss:	1.7197262048721313

training epoch 98 / 500, batch #225 / 625
Loss:	1.9583814144134521

training epoch 98 / 500, batch #250 / 625
Loss:	1.909930944442749

training epoch 98 / 500, batch #275 / 625
Loss:	1.7367773056030273

training epoch 98 / 500, batch #300 / 625
Loss:	1.9315850734710693

training epoch 98 / 500, batch #325 / 625
Loss:	1.8899433612823486

training epoch 98 / 500, batch #350 / 625
Loss:	2.028829574584961

training epoch 98 / 500, batch #375 / 625
Loss:	1.9841654300689697

training epoch 98 / 500, batch #400 / 625
Loss:	1.7640414237976074

training epoch 98 / 500, batch #425 / 625
Loss:	2.0036561489105225

training epoch 98 / 500, batch #450 / 625
Loss:	2.0075395107269287

training epoch 98 / 500, batch #475 / 625
Loss:	1.7123717069625854

training epoch 98 / 500, batch #500 / 625
Loss:	1.6207611560821533

training epoch 98 / 500, batch #525 / 625
Loss:	1.970810055732727

training epoch 98 / 500, batch #550 / 625
Loss:	1.7309578657150269

training epoch 98 / 500, batch #575 / 625
Loss:	2.045753240585327

training epoch 98 / 500, batch #600 / 625
Loss:	1.8307974338531494

training epoch 99 / 500, batch #0 / 625
Loss:	1.5620380640029907

training epoch 99 / 500, batch #25 / 625
Loss:	1.8462674617767334

training epoch 99 / 500, batch #50 / 625
Loss:	1.8474067449569702

training epoch 99 / 500, batch #75 / 625
Loss:	1.8865243196487427

training epoch 99 / 500, batch #100 / 625
Loss:	1.83732008934021

training epoch 99 / 500, batch #125 / 625
Loss:	1.883644461631775

training epoch 99 / 500, batch #150 / 625
Loss:	1.7237043380737305

training epoch 99 / 500, batch #175 / 625
Loss:	1.9415383338928223

training epoch 99 / 500, batch #200 / 625
Loss:	1.8711518049240112

training epoch 99 / 500, batch #225 / 625
Loss:	1.7156904935836792

training epoch 99 / 500, batch #250 / 625
Loss:	1.9539332389831543

training epoch 99 / 500, batch #275 / 625
Loss:	1.7711384296417236

training epoch 99 / 500, batch #300 / 625
Loss:	1.9967138767242432

training epoch 99 / 500, batch #325 / 625
Loss:	1.7563302516937256

training epoch 99 / 500, batch #350 / 625
Loss:	1.723301649093628

training epoch 99 / 500, batch #375 / 625
Loss:	1.7146823406219482

training epoch 99 / 500, batch #400 / 625
Loss:	2.0134096145629883

training epoch 99 / 500, batch #425 / 625
Loss:	1.9244403839111328

training epoch 99 / 500, batch #450 / 625
Loss:	1.9589546918869019

training epoch 99 / 500, batch #475 / 625
Loss:	1.7292066812515259

training epoch 99 / 500, batch #500 / 625
Loss:	1.9176058769226074

training epoch 99 / 500, batch #525 / 625
Loss:	1.9023196697235107

training epoch 99 / 500, batch #550 / 625
Loss:	1.8868554830551147

training epoch 99 / 500, batch #575 / 625
Loss:	1.904142141342163

training epoch 99 / 500, batch #600 / 625
Loss:	1.8102267980575562

training epoch 100 / 500, batch #0 / 625
Loss:	1.9690749645233154

training epoch 100 / 500, batch #25 / 625
Loss:	1.800193428993225

training epoch 100 / 500, batch #50 / 625
Loss:	1.7938356399536133

training epoch 100 / 500, batch #75 / 625
Loss:	1.8101036548614502

training epoch 100 / 500, batch #100 / 625
Loss:	1.788582682609558

training epoch 100 / 500, batch #125 / 625
Loss:	1.6502575874328613

training epoch 100 / 500, batch #150 / 625
Loss:	1.867250680923462

training epoch 100 / 500, batch #175 / 625
Loss:	1.8995916843414307

training epoch 100 / 500, batch #200 / 625
Loss:	1.733469009399414

training epoch 100 / 500, batch #225 / 625
Loss:	1.7330552339553833

training epoch 100 / 500, batch #250 / 625
Loss:	1.8037399053573608

training epoch 100 / 500, batch #275 / 625
Loss:	1.8694988489151

training epoch 100 / 500, batch #300 / 625
Loss:	1.9031548500061035

training epoch 100 / 500, batch #325 / 625
Loss:	1.777206301689148

training epoch 100 / 500, batch #350 / 625
Loss:	1.9341195821762085

training epoch 100 / 500, batch #375 / 625
Loss:	1.6479634046554565

training epoch 100 / 500, batch #400 / 625
Loss:	1.7593318223953247

training epoch 100 / 500, batch #425 / 625
Loss:	1.913671612739563

training epoch 100 / 500, batch #450 / 625
Loss:	1.6992884874343872

training epoch 100 / 500, batch #475 / 625
Loss:	1.7656610012054443

training epoch 100 / 500, batch #500 / 625
Loss:	1.8971003293991089

training epoch 100 / 500, batch #525 / 625
Loss:	1.7350009679794312

training epoch 100 / 500, batch #550 / 625
Loss:	1.8772032260894775

training epoch 100 / 500, batch #575 / 625
Loss:	1.7794651985168457

training epoch 100 / 500, batch #600 / 625
Loss:	1.6864054203033447

training epoch 101 / 500, batch #0 / 625
Loss:	1.7456752061843872

training epoch 101 / 500, batch #25 / 625
Loss:	1.8798253536224365

training epoch 101 / 500, batch #50 / 625
Loss:	1.9369655847549438

training epoch 101 / 500, batch #75 / 625
Loss:	1.7817394733428955

training epoch 101 / 500, batch #100 / 625
Loss:	1.831436276435852

training epoch 101 / 500, batch #125 / 625
Loss:	1.7651256322860718

training epoch 101 / 500, batch #150 / 625
Loss:	1.5952244997024536

training epoch 101 / 500, batch #175 / 625
Loss:	1.7881510257720947

training epoch 101 / 500, batch #200 / 625
Loss:	1.6906070709228516

training epoch 101 / 500, batch #225 / 625
Loss:	1.9162590503692627

training epoch 101 / 500, batch #250 / 625
Loss:	1.7710471153259277

training epoch 101 / 500, batch #275 / 625
Loss:	1.7693657875061035

training epoch 101 / 500, batch #300 / 625
Loss:	1.5255038738250732

training epoch 101 / 500, batch #325 / 625
Loss:	1.8161460161209106

training epoch 101 / 500, batch #350 / 625
Loss:	1.9064186811447144

training epoch 101 / 500, batch #375 / 625
Loss:	1.8098556995391846

training epoch 101 / 500, batch #400 / 625
Loss:	1.8913453817367554

training epoch 101 / 500, batch #425 / 625
Loss:	1.8458690643310547

training epoch 101 / 500, batch #450 / 625
Loss:	1.9505316019058228

training epoch 101 / 500, batch #475 / 625
Loss:	1.9008498191833496

training epoch 101 / 500, batch #500 / 625
Loss:	1.975145697593689

training epoch 101 / 500, batch #525 / 625
Loss:	1.9294953346252441

training epoch 101 / 500, batch #550 / 625
Loss:	1.841105580329895

training epoch 101 / 500, batch #575 / 625
Loss:	1.6365879774093628

training epoch 101 / 500, batch #600 / 625
Loss:	1.9545167684555054

training epoch 102 / 500, batch #0 / 625
Loss:	1.684308409690857

training epoch 102 / 500, batch #25 / 625
Loss:	1.7612221240997314

training epoch 102 / 500, batch #50 / 625
Loss:	1.854987621307373

training epoch 102 / 500, batch #75 / 625
Loss:	1.9760301113128662

training epoch 102 / 500, batch #100 / 625
Loss:	1.704443097114563

training epoch 102 / 500, batch #125 / 625
Loss:	1.8260890245437622

training epoch 102 / 500, batch #150 / 625
Loss:	1.7646774053573608

training epoch 102 / 500, batch #175 / 625
Loss:	1.8369320631027222

training epoch 102 / 500, batch #200 / 625
Loss:	1.9168596267700195

training epoch 102 / 500, batch #225 / 625
Loss:	1.9242331981658936

training epoch 102 / 500, batch #250 / 625
Loss:	1.9592136144638062

training epoch 102 / 500, batch #275 / 625
Loss:	1.8354229927062988

training epoch 102 / 500, batch #300 / 625
Loss:	1.6613041162490845

training epoch 102 / 500, batch #325 / 625
Loss:	1.8034405708312988

training epoch 102 / 500, batch #350 / 625
Loss:	1.8453435897827148

training epoch 102 / 500, batch #375 / 625
Loss:	1.8440544605255127

training epoch 102 / 500, batch #400 / 625
Loss:	1.9103425741195679

training epoch 102 / 500, batch #425 / 625
Loss:	1.582027554512024

training epoch 102 / 500, batch #450 / 625
Loss:	1.8639270067214966

training epoch 102 / 500, batch #475 / 625
Loss:	1.995674967765808

training epoch 102 / 500, batch #500 / 625
Loss:	1.6841890811920166

training epoch 102 / 500, batch #525 / 625
Loss:	1.799874186515808

training epoch 102 / 500, batch #550 / 625
Loss:	1.7729606628417969

training epoch 102 / 500, batch #575 / 625
Loss:	1.711208701133728

training epoch 102 / 500, batch #600 / 625
Loss:	1.907745361328125

training epoch 103 / 500, batch #0 / 625
Loss:	1.989282488822937

training epoch 103 / 500, batch #25 / 625
Loss:	1.8533982038497925

training epoch 103 / 500, batch #50 / 625
Loss:	1.8398517370224

training epoch 103 / 500, batch #75 / 625
Loss:	1.795123815536499

training epoch 103 / 500, batch #100 / 625
Loss:	1.8952466249465942

training epoch 103 / 500, batch #125 / 625
Loss:	1.8065720796585083

training epoch 103 / 500, batch #150 / 625
Loss:	1.640682578086853

training epoch 103 / 500, batch #175 / 625
Loss:	1.734307050704956

training epoch 103 / 500, batch #200 / 625
Loss:	1.6042721271514893

training epoch 103 / 500, batch #225 / 625
Loss:	1.822144627571106

training epoch 103 / 500, batch #250 / 625
Loss:	1.649214744567871

training epoch 103 / 500, batch #275 / 625
Loss:	2.103891611099243

training epoch 103 / 500, batch #300 / 625
Loss:	1.8785415887832642

training epoch 103 / 500, batch #325 / 625
Loss:	1.967276930809021

training epoch 103 / 500, batch #350 / 625
Loss:	1.8432278633117676

training epoch 103 / 500, batch #375 / 625
Loss:	1.8922789096832275

training epoch 103 / 500, batch #400 / 625
Loss:	2.1265363693237305

training epoch 103 / 500, batch #425 / 625
Loss:	1.7863781452178955

training epoch 103 / 500, batch #450 / 625
Loss:	1.7392257452011108

training epoch 103 / 500, batch #475 / 625
Loss:	1.967184066772461

training epoch 103 / 500, batch #500 / 625
Loss:	1.899880051612854

training epoch 103 / 500, batch #525 / 625
Loss:	1.498930811882019

training epoch 103 / 500, batch #550 / 625
Loss:	1.7158483266830444

training epoch 103 / 500, batch #575 / 625
Loss:	1.9147825241088867

training epoch 103 / 500, batch #600 / 625
Loss:	1.8521614074707031

training epoch 104 / 500, batch #0 / 625
Loss:	1.6284072399139404

training epoch 104 / 500, batch #25 / 625
Loss:	2.1133246421813965

training epoch 104 / 500, batch #50 / 625
Loss:	1.8684422969818115

training epoch 104 / 500, batch #75 / 625
Loss:	1.8512604236602783

training epoch 104 / 500, batch #100 / 625
Loss:	1.9232913255691528

training epoch 104 / 500, batch #125 / 625
Loss:	1.8698636293411255

training epoch 104 / 500, batch #150 / 625
Loss:	1.9263166189193726

training epoch 104 / 500, batch #175 / 625
Loss:	1.810746192932129

training epoch 104 / 500, batch #200 / 625
Loss:	1.770106554031372

training epoch 104 / 500, batch #225 / 625
Loss:	1.8881020545959473

training epoch 104 / 500, batch #250 / 625
Loss:	1.593453049659729

training epoch 104 / 500, batch #275 / 625
Loss:	1.888551115989685

training epoch 104 / 500, batch #300 / 625
Loss:	1.7511142492294312

training epoch 104 / 500, batch #325 / 625
Loss:	1.9918956756591797

training epoch 104 / 500, batch #350 / 625
Loss:	1.7671399116516113

training epoch 104 / 500, batch #375 / 625
Loss:	1.8452866077423096

training epoch 104 / 500, batch #400 / 625
Loss:	1.6544156074523926

training epoch 104 / 500, batch #425 / 625
Loss:	1.718924641609192

training epoch 104 / 500, batch #450 / 625
Loss:	1.8336317539215088

training epoch 104 / 500, batch #475 / 625
Loss:	1.9650743007659912

training epoch 104 / 500, batch #500 / 625
Loss:	1.740562081336975

training epoch 104 / 500, batch #525 / 625
Loss:	1.6828745603561401

training epoch 104 / 500, batch #550 / 625
Loss:	1.9809207916259766

training epoch 104 / 500, batch #575 / 625
Loss:	1.7645971775054932

training epoch 104 / 500, batch #600 / 625
Loss:	1.8801262378692627

training epoch 105 / 500, batch #0 / 625
Loss:	1.8803287744522095

training epoch 105 / 500, batch #25 / 625
Loss:	1.758467674255371

training epoch 105 / 500, batch #50 / 625
Loss:	1.8226583003997803

training epoch 105 / 500, batch #75 / 625
Loss:	1.6932485103607178

training epoch 105 / 500, batch #100 / 625
Loss:	1.881725549697876

training epoch 105 / 500, batch #125 / 625
Loss:	1.8332016468048096

training epoch 105 / 500, batch #150 / 625
Loss:	1.900343894958496

training epoch 105 / 500, batch #175 / 625
Loss:	2.0824921131134033

training epoch 105 / 500, batch #200 / 625
Loss:	1.6871174573898315

training epoch 105 / 500, batch #225 / 625
Loss:	1.608259916305542

training epoch 105 / 500, batch #250 / 625
Loss:	1.5479483604431152

training epoch 105 / 500, batch #275 / 625
Loss:	1.9480382204055786

training epoch 105 / 500, batch #300 / 625
Loss:	1.8761245012283325

training epoch 105 / 500, batch #325 / 625
Loss:	1.7499920129776

training epoch 105 / 500, batch #350 / 625
Loss:	1.9542165994644165

training epoch 105 / 500, batch #375 / 625
Loss:	2.009305238723755

training epoch 105 / 500, batch #400 / 625
Loss:	1.8877065181732178

training epoch 105 / 500, batch #425 / 625
Loss:	1.8948349952697754

training epoch 105 / 500, batch #450 / 625
Loss:	1.999251365661621

training epoch 105 / 500, batch #475 / 625
Loss:	1.8069440126419067

training epoch 105 / 500, batch #500 / 625
Loss:	1.8976441621780396

training epoch 105 / 500, batch #525 / 625
Loss:	1.8869390487670898

training epoch 105 / 500, batch #550 / 625
Loss:	1.9254835844039917

training epoch 105 / 500, batch #575 / 625
Loss:	1.7064886093139648

training epoch 105 / 500, batch #600 / 625
Loss:	2.040255069732666

training epoch 106 / 500, batch #0 / 625
Loss:	1.7348015308380127

training epoch 106 / 500, batch #25 / 625
Loss:	1.9883953332901

training epoch 106 / 500, batch #50 / 625
Loss:	1.8797581195831299

training epoch 106 / 500, batch #75 / 625
Loss:	1.6948679685592651

training epoch 106 / 500, batch #100 / 625
Loss:	1.9508476257324219

training epoch 106 / 500, batch #125 / 625
Loss:	1.6588600873947144

training epoch 106 / 500, batch #150 / 625
Loss:	1.9271613359451294

training epoch 106 / 500, batch #175 / 625
Loss:	1.7406829595565796

training epoch 106 / 500, batch #200 / 625
Loss:	1.6458070278167725

training epoch 106 / 500, batch #225 / 625
Loss:	1.8911793231964111

training epoch 106 / 500, batch #250 / 625
Loss:	1.966227412223816

training epoch 106 / 500, batch #275 / 625
Loss:	1.9440864324569702

training epoch 106 / 500, batch #300 / 625
Loss:	1.8695639371871948

training epoch 106 / 500, batch #325 / 625
Loss:	1.5764079093933105

training epoch 106 / 500, batch #350 / 625
Loss:	1.506184697151184

training epoch 106 / 500, batch #375 / 625
Loss:	1.8147469758987427

training epoch 106 / 500, batch #400 / 625
Loss:	1.7004812955856323

training epoch 106 / 500, batch #425 / 625
Loss:	1.6576474905014038

training epoch 106 / 500, batch #450 / 625
Loss:	1.6402089595794678

training epoch 106 / 500, batch #475 / 625
Loss:	2.0011589527130127

training epoch 106 / 500, batch #500 / 625
Loss:	1.7319891452789307

training epoch 106 / 500, batch #525 / 625
Loss:	1.6964099407196045

training epoch 106 / 500, batch #550 / 625
Loss:	1.837878704071045

training epoch 106 / 500, batch #575 / 625
Loss:	1.8241963386535645

training epoch 106 / 500, batch #600 / 625
Loss:	1.8934276103973389

training epoch 107 / 500, batch #0 / 625
Loss:	1.71734619140625

training epoch 107 / 500, batch #25 / 625
Loss:	1.7534009218215942

training epoch 107 / 500, batch #50 / 625
Loss:	1.8137108087539673

training epoch 107 / 500, batch #75 / 625
Loss:	1.6336331367492676

training epoch 107 / 500, batch #100 / 625
Loss:	1.8758518695831299

training epoch 107 / 500, batch #125 / 625
Loss:	1.720698595046997

training epoch 107 / 500, batch #150 / 625
Loss:	1.9400829076766968

training epoch 107 / 500, batch #175 / 625
Loss:	1.957237958908081

training epoch 107 / 500, batch #200 / 625
Loss:	1.738020420074463

training epoch 107 / 500, batch #225 / 625
Loss:	1.8118902444839478

training epoch 107 / 500, batch #250 / 625
Loss:	1.6175347566604614

training epoch 107 / 500, batch #275 / 625
Loss:	1.6182841062545776

training epoch 107 / 500, batch #300 / 625
Loss:	1.9031360149383545

training epoch 107 / 500, batch #325 / 625
Loss:	1.8271886110305786

training epoch 107 / 500, batch #350 / 625
Loss:	1.8385027647018433

training epoch 107 / 500, batch #375 / 625
Loss:	1.829683780670166

training epoch 107 / 500, batch #400 / 625
Loss:	1.798958659172058

training epoch 107 / 500, batch #425 / 625
Loss:	1.5637714862823486

training epoch 107 / 500, batch #450 / 625
Loss:	1.8907160758972168

training epoch 107 / 500, batch #475 / 625
Loss:	1.994174599647522

training epoch 107 / 500, batch #500 / 625
Loss:	1.9590312242507935

training epoch 107 / 500, batch #525 / 625
Loss:	1.660788655281067

training epoch 107 / 500, batch #550 / 625
Loss:	1.8330237865447998

training epoch 107 / 500, batch #575 / 625
Loss:	1.6560587882995605

training epoch 107 / 500, batch #600 / 625
Loss:	1.9348974227905273

training epoch 108 / 500, batch #0 / 625
Loss:	1.565500259399414

training epoch 108 / 500, batch #25 / 625
Loss:	1.8215131759643555

training epoch 108 / 500, batch #50 / 625
Loss:	1.8748699426651

training epoch 108 / 500, batch #75 / 625
Loss:	1.8946037292480469

training epoch 108 / 500, batch #100 / 625
Loss:	1.905398964881897

training epoch 108 / 500, batch #125 / 625
Loss:	1.7392690181732178

training epoch 108 / 500, batch #150 / 625
Loss:	1.8598873615264893

training epoch 108 / 500, batch #175 / 625
Loss:	1.7195725440979004

training epoch 108 / 500, batch #200 / 625
Loss:	1.7535581588745117

training epoch 108 / 500, batch #225 / 625
Loss:	1.9121721982955933

training epoch 108 / 500, batch #250 / 625
Loss:	2.0113000869750977

training epoch 108 / 500, batch #275 / 625
Loss:	1.6374388933181763

training epoch 108 / 500, batch #300 / 625
Loss:	1.7803841829299927

training epoch 108 / 500, batch #325 / 625
Loss:	1.8207039833068848

training epoch 108 / 500, batch #350 / 625
Loss:	1.8427531719207764

training epoch 108 / 500, batch #375 / 625
Loss:	1.7264823913574219

training epoch 108 / 500, batch #400 / 625
Loss:	2.0574605464935303

training epoch 108 / 500, batch #425 / 625
Loss:	1.6200486421585083

training epoch 108 / 500, batch #450 / 625
Loss:	1.7652685642242432

training epoch 108 / 500, batch #475 / 625
Loss:	1.7564998865127563

training epoch 108 / 500, batch #500 / 625
Loss:	1.8181872367858887

training epoch 108 / 500, batch #525 / 625
Loss:	1.7626714706420898

training epoch 108 / 500, batch #550 / 625
Loss:	1.9695433378219604

training epoch 108 / 500, batch #575 / 625
Loss:	1.9068074226379395

training epoch 108 / 500, batch #600 / 625
Loss:	1.807105541229248

training epoch 109 / 500, batch #0 / 625
Loss:	1.691407322883606

training epoch 109 / 500, batch #25 / 625
Loss:	2.0316078662872314

training epoch 109 / 500, batch #50 / 625
Loss:	1.9354217052459717

training epoch 109 / 500, batch #75 / 625
Loss:	1.774826169013977

training epoch 109 / 500, batch #100 / 625
Loss:	1.945428490638733

training epoch 109 / 500, batch #125 / 625
Loss:	1.7219023704528809

training epoch 109 / 500, batch #150 / 625
Loss:	1.9478495121002197

training epoch 109 / 500, batch #175 / 625
Loss:	1.8192360401153564

training epoch 109 / 500, batch #200 / 625
Loss:	1.8345831632614136

training epoch 109 / 500, batch #225 / 625
Loss:	1.8764644861221313

training epoch 109 / 500, batch #250 / 625
Loss:	1.9350955486297607

training epoch 109 / 500, batch #275 / 625
Loss:	1.9280017614364624

training epoch 109 / 500, batch #300 / 625
Loss:	1.6817313432693481

training epoch 109 / 500, batch #325 / 625
Loss:	2.084594964981079

training epoch 109 / 500, batch #350 / 625
Loss:	1.6037988662719727

training epoch 109 / 500, batch #375 / 625
Loss:	1.641310691833496

training epoch 109 / 500, batch #400 / 625
Loss:	1.6420693397521973

training epoch 109 / 500, batch #425 / 625
Loss:	1.9288578033447266

training epoch 109 / 500, batch #450 / 625
Loss:	1.77787446975708

training epoch 109 / 500, batch #475 / 625
Loss:	1.8082027435302734

training epoch 109 / 500, batch #500 / 625
Loss:	1.9782108068466187

training epoch 109 / 500, batch #525 / 625
Loss:	1.8847626447677612

training epoch 109 / 500, batch #550 / 625
Loss:	1.819170594215393

training epoch 109 / 500, batch #575 / 625
Loss:	1.8852143287658691

training epoch 109 / 500, batch #600 / 625
Loss:	2.112916946411133

training epoch 110 / 500, batch #0 / 625
Loss:	1.8312604427337646

training epoch 110 / 500, batch #25 / 625
Loss:	1.923223614692688

training epoch 110 / 500, batch #50 / 625
Loss:	1.8109811544418335

training epoch 110 / 500, batch #75 / 625
Loss:	1.8069336414337158

training epoch 110 / 500, batch #100 / 625
Loss:	1.8379281759262085

training epoch 110 / 500, batch #125 / 625
Loss:	1.7293028831481934

training epoch 110 / 500, batch #150 / 625
Loss:	1.6902992725372314

training epoch 110 / 500, batch #175 / 625
Loss:	1.924788475036621

training epoch 110 / 500, batch #200 / 625
Loss:	1.7578054666519165

training epoch 110 / 500, batch #225 / 625
Loss:	1.8736586570739746

training epoch 110 / 500, batch #250 / 625
Loss:	2.0699875354766846

training epoch 110 / 500, batch #275 / 625
Loss:	1.7351949214935303

training epoch 110 / 500, batch #300 / 625
Loss:	1.820374608039856

training epoch 110 / 500, batch #325 / 625
Loss:	1.8626294136047363

training epoch 110 / 500, batch #350 / 625
Loss:	2.127119541168213

training epoch 110 / 500, batch #375 / 625
Loss:	1.732995629310608

training epoch 110 / 500, batch #400 / 625
Loss:	1.7297325134277344

training epoch 110 / 500, batch #425 / 625
Loss:	1.9064770936965942

training epoch 110 / 500, batch #450 / 625
Loss:	1.6462002992630005

training epoch 110 / 500, batch #475 / 625
Loss:	1.4396342039108276

training epoch 110 / 500, batch #500 / 625
Loss:	1.8477877378463745

training epoch 110 / 500, batch #525 / 625
Loss:	2.1091463565826416

training epoch 110 / 500, batch #550 / 625
Loss:	1.7321537733078003

training epoch 110 / 500, batch #575 / 625
Loss:	1.8806662559509277

training epoch 110 / 500, batch #600 / 625
Loss:	1.866398572921753

training epoch 111 / 500, batch #0 / 625
Loss:	1.998192310333252

training epoch 111 / 500, batch #25 / 625
Loss:	1.6914794445037842

training epoch 111 / 500, batch #50 / 625
Loss:	1.7667235136032104

training epoch 111 / 500, batch #75 / 625
Loss:	2.0014872550964355

training epoch 111 / 500, batch #100 / 625
Loss:	1.6813559532165527

training epoch 111 / 500, batch #125 / 625
Loss:	1.7902660369873047

training epoch 111 / 500, batch #150 / 625
Loss:	1.8309755325317383

training epoch 111 / 500, batch #175 / 625
Loss:	1.8351426124572754

training epoch 111 / 500, batch #200 / 625
Loss:	1.8037831783294678

training epoch 111 / 500, batch #225 / 625
Loss:	1.947616457939148

training epoch 111 / 500, batch #250 / 625
Loss:	1.7677615880966187

training epoch 111 / 500, batch #275 / 625
Loss:	1.8581531047821045

training epoch 111 / 500, batch #300 / 625
Loss:	1.830575704574585

training epoch 111 / 500, batch #325 / 625
Loss:	2.0312345027923584

training epoch 111 / 500, batch #350 / 625
Loss:	2.110837459564209

training epoch 111 / 500, batch #375 / 625
Loss:	1.5931581258773804

training epoch 111 / 500, batch #400 / 625
Loss:	1.7455037832260132

training epoch 111 / 500, batch #425 / 625
Loss:	1.7645275592803955

training epoch 111 / 500, batch #450 / 625
Loss:	1.858302354812622

training epoch 111 / 500, batch #475 / 625
Loss:	1.6404496431350708

training epoch 111 / 500, batch #500 / 625
Loss:	1.8075222969055176

training epoch 111 / 500, batch #525 / 625
Loss:	1.8239225149154663

training epoch 111 / 500, batch #550 / 625
Loss:	1.8426406383514404

training epoch 111 / 500, batch #575 / 625
Loss:	1.7677834033966064

training epoch 111 / 500, batch #600 / 625
Loss:	1.6778631210327148

training epoch 112 / 500, batch #0 / 625
Loss:	1.7081493139266968

training epoch 112 / 500, batch #25 / 625
Loss:	1.6220937967300415

training epoch 112 / 500, batch #50 / 625
Loss:	1.7153643369674683

training epoch 112 / 500, batch #75 / 625
Loss:	1.6137160062789917

training epoch 112 / 500, batch #100 / 625
Loss:	1.6112630367279053

training epoch 112 / 500, batch #125 / 625
Loss:	1.6643015146255493

training epoch 112 / 500, batch #150 / 625
Loss:	1.779999017715454

training epoch 112 / 500, batch #175 / 625
Loss:	2.1419503688812256

training epoch 112 / 500, batch #200 / 625
Loss:	1.8640789985656738

training epoch 112 / 500, batch #225 / 625
Loss:	1.776203989982605

training epoch 112 / 500, batch #250 / 625
Loss:	1.9542052745819092

training epoch 112 / 500, batch #275 / 625
Loss:	1.814782977104187

training epoch 112 / 500, batch #300 / 625
Loss:	1.726651906967163

training epoch 112 / 500, batch #325 / 625
Loss:	1.882645606994629

training epoch 112 / 500, batch #350 / 625
Loss:	1.8546266555786133

training epoch 112 / 500, batch #375 / 625
Loss:	1.674056053161621

training epoch 112 / 500, batch #400 / 625
Loss:	1.8070001602172852

training epoch 112 / 500, batch #425 / 625
Loss:	1.8240437507629395

training epoch 112 / 500, batch #450 / 625
Loss:	1.4792718887329102

training epoch 112 / 500, batch #475 / 625
Loss:	1.9375066757202148

training epoch 112 / 500, batch #500 / 625
Loss:	2.0189554691314697

training epoch 112 / 500, batch #525 / 625
Loss:	1.837876796722412

training epoch 112 / 500, batch #550 / 625
Loss:	1.7672539949417114

training epoch 112 / 500, batch #575 / 625
Loss:	1.8329205513000488

training epoch 112 / 500, batch #600 / 625
Loss:	1.8129854202270508

training epoch 113 / 500, batch #0 / 625
Loss:	1.8096250295639038

training epoch 113 / 500, batch #25 / 625
Loss:	1.7258806228637695

training epoch 113 / 500, batch #50 / 625
Loss:	2.0019776821136475

training epoch 113 / 500, batch #75 / 625
Loss:	1.8030833005905151

training epoch 113 / 500, batch #100 / 625
Loss:	1.6928527355194092

training epoch 113 / 500, batch #125 / 625
Loss:	1.9901657104492188

training epoch 113 / 500, batch #150 / 625
Loss:	1.8830868005752563

training epoch 113 / 500, batch #175 / 625
Loss:	2.032177448272705

training epoch 113 / 500, batch #200 / 625
Loss:	1.7568410634994507

training epoch 113 / 500, batch #225 / 625
Loss:	1.814730167388916

training epoch 113 / 500, batch #250 / 625
Loss:	1.8898379802703857

training epoch 113 / 500, batch #275 / 625
Loss:	1.7693349123001099

training epoch 113 / 500, batch #300 / 625
Loss:	1.8126535415649414

training epoch 113 / 500, batch #325 / 625
Loss:	1.8108528852462769

training epoch 113 / 500, batch #350 / 625
Loss:	1.98023521900177

training epoch 113 / 500, batch #375 / 625
Loss:	1.701269268989563

training epoch 113 / 500, batch #400 / 625
Loss:	1.5768558979034424

training epoch 113 / 500, batch #425 / 625
Loss:	2.035630226135254

training epoch 113 / 500, batch #450 / 625
Loss:	1.8105337619781494

training epoch 113 / 500, batch #475 / 625
Loss:	1.7724003791809082

training epoch 113 / 500, batch #500 / 625
Loss:	1.822462797164917

training epoch 113 / 500, batch #525 / 625
Loss:	1.5927839279174805

training epoch 113 / 500, batch #550 / 625
Loss:	1.6522315740585327

training epoch 113 / 500, batch #575 / 625
Loss:	1.791077733039856

training epoch 113 / 500, batch #600 / 625
Loss:	1.8104993104934692

training epoch 114 / 500, batch #0 / 625
Loss:	1.6939630508422852

training epoch 114 / 500, batch #25 / 625
Loss:	1.7490661144256592

training epoch 114 / 500, batch #50 / 625
Loss:	1.8353047370910645

training epoch 114 / 500, batch #75 / 625
Loss:	1.865954041481018

training epoch 114 / 500, batch #100 / 625
Loss:	1.725241780281067

training epoch 114 / 500, batch #125 / 625
Loss:	1.6674872636795044

training epoch 114 / 500, batch #150 / 625
Loss:	1.635345220565796

training epoch 114 / 500, batch #175 / 625
Loss:	1.9280461072921753

training epoch 114 / 500, batch #200 / 625
Loss:	1.8605228662490845

training epoch 114 / 500, batch #225 / 625
Loss:	1.8255770206451416

training epoch 114 / 500, batch #250 / 625
Loss:	1.8593143224716187

training epoch 114 / 500, batch #275 / 625
Loss:	1.6703025102615356

training epoch 114 / 500, batch #300 / 625
Loss:	1.9075725078582764

training epoch 114 / 500, batch #325 / 625
Loss:	2.3214504718780518

training epoch 114 / 500, batch #350 / 625
Loss:	1.9274026155471802

training epoch 114 / 500, batch #375 / 625
Loss:	1.7857210636138916

training epoch 114 / 500, batch #400 / 625
Loss:	1.8138643503189087

training epoch 114 / 500, batch #425 / 625
Loss:	1.843039870262146

training epoch 114 / 500, batch #450 / 625
Loss:	1.9990612268447876

training epoch 114 / 500, batch #475 / 625
Loss:	1.3414651155471802

training epoch 114 / 500, batch #500 / 625
Loss:	1.6975325345993042

training epoch 114 / 500, batch #525 / 625
Loss:	1.9438621997833252

training epoch 114 / 500, batch #550 / 625
Loss:	1.6684706211090088

training epoch 114 / 500, batch #575 / 625
Loss:	1.8179503679275513

training epoch 114 / 500, batch #600 / 625
Loss:	2.0874853134155273

training epoch 115 / 500, batch #0 / 625
Loss:	1.9169002771377563

training epoch 115 / 500, batch #25 / 625
Loss:	1.8142387866973877

training epoch 115 / 500, batch #50 / 625
Loss:	1.999511480331421

training epoch 115 / 500, batch #75 / 625
Loss:	1.7579891681671143

training epoch 115 / 500, batch #100 / 625
Loss:	2.0159592628479004

training epoch 115 / 500, batch #125 / 625
Loss:	1.6896384954452515

training epoch 115 / 500, batch #150 / 625
Loss:	1.6604108810424805

training epoch 115 / 500, batch #175 / 625
Loss:	2.0787136554718018

training epoch 115 / 500, batch #200 / 625
Loss:	1.984254002571106

training epoch 115 / 500, batch #225 / 625
Loss:	1.7231285572052002

training epoch 115 / 500, batch #250 / 625
Loss:	1.8390668630599976

training epoch 115 / 500, batch #275 / 625
Loss:	1.5368770360946655

training epoch 115 / 500, batch #300 / 625
Loss:	1.8579310178756714

training epoch 115 / 500, batch #325 / 625
Loss:	1.784414529800415

training epoch 115 / 500, batch #350 / 625
Loss:	1.7283161878585815

training epoch 115 / 500, batch #375 / 625
Loss:	1.868739366531372

training epoch 115 / 500, batch #400 / 625
Loss:	1.62779700756073

training epoch 115 / 500, batch #425 / 625
Loss:	1.779924988746643

training epoch 115 / 500, batch #450 / 625
Loss:	1.8038092851638794

training epoch 115 / 500, batch #475 / 625
Loss:	1.7765400409698486

training epoch 115 / 500, batch #500 / 625
Loss:	1.8354718685150146

training epoch 115 / 500, batch #525 / 625
Loss:	1.9204093217849731

training epoch 115 / 500, batch #550 / 625
Loss:	1.7503137588500977

training epoch 115 / 500, batch #575 / 625
Loss:	1.8132749795913696

training epoch 115 / 500, batch #600 / 625
Loss:	1.8695464134216309

training epoch 116 / 500, batch #0 / 625
Loss:	1.8556898832321167

training epoch 116 / 500, batch #25 / 625
Loss:	1.856126308441162

training epoch 116 / 500, batch #50 / 625
Loss:	1.8285140991210938

training epoch 116 / 500, batch #75 / 625
Loss:	1.835906982421875

training epoch 116 / 500, batch #100 / 625
Loss:	1.7948204278945923

training epoch 116 / 500, batch #125 / 625
Loss:	1.8422623872756958

training epoch 116 / 500, batch #150 / 625
Loss:	1.9025746583938599

training epoch 116 / 500, batch #175 / 625
Loss:	1.6698505878448486

training epoch 116 / 500, batch #200 / 625
Loss:	1.8152306079864502

training epoch 116 / 500, batch #225 / 625
Loss:	1.9950357675552368

training epoch 116 / 500, batch #250 / 625
Loss:	1.8579081296920776

training epoch 116 / 500, batch #275 / 625
Loss:	1.749950885772705

training epoch 116 / 500, batch #300 / 625
Loss:	1.7150956392288208

training epoch 116 / 500, batch #325 / 625
Loss:	1.8033279180526733

training epoch 116 / 500, batch #350 / 625
Loss:	1.6373354196548462

training epoch 116 / 500, batch #375 / 625
Loss:	1.7857017517089844

training epoch 116 / 500, batch #400 / 625
Loss:	2.085148811340332

training epoch 116 / 500, batch #425 / 625
Loss:	1.976631999015808

training epoch 116 / 500, batch #450 / 625
Loss:	2.0461668968200684

training epoch 116 / 500, batch #475 / 625
Loss:	1.581438660621643

training epoch 116 / 500, batch #500 / 625
Loss:	1.8450050354003906

training epoch 116 / 500, batch #525 / 625
Loss:	1.7749874591827393

training epoch 116 / 500, batch #550 / 625
Loss:	1.9980320930480957

training epoch 116 / 500, batch #575 / 625
Loss:	1.9199758768081665

training epoch 116 / 500, batch #600 / 625
Loss:	1.972730278968811

training epoch 117 / 500, batch #0 / 625
Loss:	1.7856441736221313

training epoch 117 / 500, batch #25 / 625
Loss:	1.8512498140335083

training epoch 117 / 500, batch #50 / 625
Loss:	1.7830723524093628

training epoch 117 / 500, batch #75 / 625
Loss:	2.011749267578125

training epoch 117 / 500, batch #100 / 625
Loss:	1.7038596868515015

training epoch 117 / 500, batch #125 / 625
Loss:	1.7556051015853882

training epoch 117 / 500, batch #150 / 625
Loss:	1.6210289001464844

training epoch 117 / 500, batch #175 / 625
Loss:	1.9746077060699463

training epoch 117 / 500, batch #200 / 625
Loss:	1.8846238851547241

training epoch 117 / 500, batch #225 / 625
Loss:	1.9016525745391846

training epoch 117 / 500, batch #250 / 625
Loss:	1.970885157585144

training epoch 117 / 500, batch #275 / 625
Loss:	1.7139885425567627

training epoch 117 / 500, batch #300 / 625
Loss:	1.956536889076233

training epoch 117 / 500, batch #325 / 625
Loss:	1.7458689212799072

training epoch 117 / 500, batch #350 / 625
Loss:	1.795441746711731

training epoch 117 / 500, batch #375 / 625
Loss:	1.905828833580017

training epoch 117 / 500, batch #400 / 625
Loss:	1.906339406967163

training epoch 117 / 500, batch #425 / 625
Loss:	1.7619737386703491

training epoch 117 / 500, batch #450 / 625
Loss:	1.7039768695831299

training epoch 117 / 500, batch #475 / 625
Loss:	1.865373134613037

training epoch 117 / 500, batch #500 / 625
Loss:	2.0105948448181152

training epoch 117 / 500, batch #525 / 625
Loss:	1.6450856924057007

training epoch 117 / 500, batch #550 / 625
Loss:	1.6301252841949463

training epoch 117 / 500, batch #575 / 625
Loss:	1.7776892185211182

training epoch 117 / 500, batch #600 / 625
Loss:	1.5274754762649536

training epoch 118 / 500, batch #0 / 625
Loss:	1.792907953262329

training epoch 118 / 500, batch #25 / 625
Loss:	1.5162626504898071

training epoch 118 / 500, batch #50 / 625
Loss:	2.154975175857544

training epoch 118 / 500, batch #75 / 625
Loss:	1.9010992050170898

training epoch 118 / 500, batch #100 / 625
Loss:	1.84139084815979

training epoch 118 / 500, batch #125 / 625
Loss:	1.5117098093032837

training epoch 118 / 500, batch #150 / 625
Loss:	1.8782429695129395

training epoch 118 / 500, batch #175 / 625
Loss:	1.966447114944458

training epoch 118 / 500, batch #200 / 625
Loss:	1.8343422412872314

training epoch 118 / 500, batch #225 / 625
Loss:	1.8005974292755127

training epoch 118 / 500, batch #250 / 625
Loss:	1.8390672206878662

training epoch 118 / 500, batch #275 / 625
Loss:	1.6866587400436401

training epoch 118 / 500, batch #300 / 625
Loss:	1.9343339204788208

training epoch 118 / 500, batch #325 / 625
Loss:	1.8885706663131714

training epoch 118 / 500, batch #350 / 625
Loss:	1.8966364860534668

training epoch 118 / 500, batch #375 / 625
Loss:	2.0222017765045166

training epoch 118 / 500, batch #400 / 625
Loss:	1.9878915548324585

training epoch 118 / 500, batch #425 / 625
Loss:	1.9160575866699219

training epoch 118 / 500, batch #450 / 625
Loss:	2.00199818611145

training epoch 118 / 500, batch #475 / 625
Loss:	1.8960176706314087

training epoch 118 / 500, batch #500 / 625
Loss:	1.7981703281402588

training epoch 118 / 500, batch #525 / 625
Loss:	1.723142385482788

training epoch 118 / 500, batch #550 / 625
Loss:	1.8215210437774658

training epoch 118 / 500, batch #575 / 625
Loss:	1.8744142055511475

training epoch 118 / 500, batch #600 / 625
Loss:	1.9049098491668701

training epoch 119 / 500, batch #0 / 625
Loss:	1.6631574630737305

training epoch 119 / 500, batch #25 / 625
Loss:	1.716910481452942

training epoch 119 / 500, batch #50 / 625
Loss:	1.8520678281784058

training epoch 119 / 500, batch #75 / 625
Loss:	1.9285502433776855

training epoch 119 / 500, batch #100 / 625
Loss:	1.8230736255645752

training epoch 119 / 500, batch #125 / 625
Loss:	1.707175374031067

training epoch 119 / 500, batch #150 / 625
Loss:	1.6749969720840454

training epoch 119 / 500, batch #175 / 625
Loss:	1.883628487586975

training epoch 119 / 500, batch #200 / 625
Loss:	1.7655373811721802

training epoch 119 / 500, batch #225 / 625
Loss:	1.689746618270874

training epoch 119 / 500, batch #250 / 625
Loss:	1.9078408479690552

training epoch 119 / 500, batch #275 / 625
Loss:	1.9437828063964844

training epoch 119 / 500, batch #300 / 625
Loss:	1.941031813621521

training epoch 119 / 500, batch #325 / 625
Loss:	1.9295499324798584

training epoch 119 / 500, batch #350 / 625
Loss:	1.7099919319152832

training epoch 119 / 500, batch #375 / 625
Loss:	1.5530970096588135

training epoch 119 / 500, batch #400 / 625
Loss:	1.9765914678573608

training epoch 119 / 500, batch #425 / 625
Loss:	1.9968115091323853

training epoch 119 / 500, batch #450 / 625
Loss:	1.966823935508728

training epoch 119 / 500, batch #475 / 625
Loss:	1.967278242111206

training epoch 119 / 500, batch #500 / 625
Loss:	1.8269891738891602

training epoch 119 / 500, batch #525 / 625
Loss:	1.877741813659668

training epoch 119 / 500, batch #550 / 625
Loss:	1.6812715530395508

training epoch 119 / 500, batch #575 / 625
Loss:	1.7726298570632935

training epoch 119 / 500, batch #600 / 625
Loss:	1.8088136911392212

training epoch 120 / 500, batch #0 / 625
Loss:	1.7928069829940796

training epoch 120 / 500, batch #25 / 625
Loss:	1.7083677053451538

training epoch 120 / 500, batch #50 / 625
Loss:	1.846988558769226

training epoch 120 / 500, batch #75 / 625
Loss:	1.6319457292556763

training epoch 120 / 500, batch #100 / 625
Loss:	1.8772269487380981

training epoch 120 / 500, batch #125 / 625
Loss:	1.8840420246124268

training epoch 120 / 500, batch #150 / 625
Loss:	1.9295560121536255

training epoch 120 / 500, batch #175 / 625
Loss:	1.5693480968475342

training epoch 120 / 500, batch #200 / 625
Loss:	1.8024475574493408

training epoch 120 / 500, batch #225 / 625
Loss:	1.8811578750610352

training epoch 120 / 500, batch #250 / 625
Loss:	1.708949089050293

training epoch 120 / 500, batch #275 / 625
Loss:	1.6919684410095215

training epoch 120 / 500, batch #300 / 625
Loss:	1.5887162685394287

training epoch 120 / 500, batch #325 / 625
Loss:	1.69387948513031

training epoch 120 / 500, batch #350 / 625
Loss:	1.7935287952423096

training epoch 120 / 500, batch #375 / 625
Loss:	1.7380057573318481

training epoch 120 / 500, batch #400 / 625
Loss:	1.6844061613082886

training epoch 120 / 500, batch #425 / 625
Loss:	1.8260806798934937

training epoch 120 / 500, batch #450 / 625
Loss:	1.7120004892349243

training epoch 120 / 500, batch #475 / 625
Loss:	2.0656867027282715

training epoch 120 / 500, batch #500 / 625
Loss:	1.8211021423339844

training epoch 120 / 500, batch #525 / 625
Loss:	1.8239926099777222

training epoch 120 / 500, batch #550 / 625
Loss:	1.8119337558746338

training epoch 120 / 500, batch #575 / 625
Loss:	1.9495337009429932

training epoch 120 / 500, batch #600 / 625
Loss:	1.9745540618896484

training epoch 121 / 500, batch #0 / 625
Loss:	1.8662562370300293

training epoch 121 / 500, batch #25 / 625
Loss:	2.0022881031036377

training epoch 121 / 500, batch #50 / 625
Loss:	1.8278563022613525

training epoch 121 / 500, batch #75 / 625
Loss:	1.7540388107299805

training epoch 121 / 500, batch #100 / 625
Loss:	1.7416601181030273

training epoch 121 / 500, batch #125 / 625
Loss:	1.7362420558929443

training epoch 121 / 500, batch #150 / 625
Loss:	1.8567795753479004

training epoch 121 / 500, batch #175 / 625
Loss:	1.8751487731933594

training epoch 121 / 500, batch #200 / 625
Loss:	1.6366336345672607

training epoch 121 / 500, batch #225 / 625
Loss:	2.02095890045166

training epoch 121 / 500, batch #250 / 625
Loss:	1.8434513807296753

training epoch 121 / 500, batch #275 / 625
Loss:	1.8550324440002441

training epoch 121 / 500, batch #300 / 625
Loss:	1.8576438426971436

training epoch 121 / 500, batch #325 / 625
Loss:	1.7362124919891357

training epoch 121 / 500, batch #350 / 625
Loss:	1.8190442323684692

training epoch 121 / 500, batch #375 / 625
Loss:	1.916754126548767

training epoch 121 / 500, batch #400 / 625
Loss:	1.7514116764068604

training epoch 121 / 500, batch #425 / 625
Loss:	1.9672234058380127

training epoch 121 / 500, batch #450 / 625
Loss:	1.8323719501495361

training epoch 121 / 500, batch #475 / 625
Loss:	1.8328579664230347

training epoch 121 / 500, batch #500 / 625
Loss:	1.541263222694397

training epoch 121 / 500, batch #525 / 625
Loss:	1.655895709991455

training epoch 121 / 500, batch #550 / 625
Loss:	1.8382991552352905

training epoch 121 / 500, batch #575 / 625
Loss:	1.7744076251983643

training epoch 121 / 500, batch #600 / 625
Loss:	2.0415499210357666

training epoch 122 / 500, batch #0 / 625
Loss:	1.8878200054168701

training epoch 122 / 500, batch #25 / 625
Loss:	1.9136472940444946

training epoch 122 / 500, batch #50 / 625
Loss:	2.1119349002838135

training epoch 122 / 500, batch #75 / 625
Loss:	1.7796095609664917

training epoch 122 / 500, batch #100 / 625
Loss:	1.866082787513733

training epoch 122 / 500, batch #125 / 625
Loss:	1.963674545288086

training epoch 122 / 500, batch #150 / 625
Loss:	1.6932001113891602

training epoch 122 / 500, batch #175 / 625
Loss:	1.7264140844345093

training epoch 122 / 500, batch #200 / 625
Loss:	1.8918637037277222

training epoch 122 / 500, batch #225 / 625
Loss:	2.059418201446533

training epoch 122 / 500, batch #250 / 625
Loss:	1.742130994796753

training epoch 122 / 500, batch #275 / 625
Loss:	1.9342796802520752

training epoch 122 / 500, batch #300 / 625
Loss:	1.6514527797698975

training epoch 122 / 500, batch #325 / 625
Loss:	1.8053773641586304

training epoch 122 / 500, batch #350 / 625
Loss:	1.820981740951538

training epoch 122 / 500, batch #375 / 625
Loss:	1.5790923833847046

training epoch 122 / 500, batch #400 / 625
Loss:	1.8419846296310425

training epoch 122 / 500, batch #425 / 625
Loss:	1.7633678913116455

training epoch 122 / 500, batch #450 / 625
Loss:	1.8236875534057617

training epoch 122 / 500, batch #475 / 625
Loss:	1.846928358078003

training epoch 122 / 500, batch #500 / 625
Loss:	2.1750905513763428

training epoch 122 / 500, batch #525 / 625
Loss:	1.7599997520446777

training epoch 122 / 500, batch #550 / 625
Loss:	1.8004108667373657

training epoch 122 / 500, batch #575 / 625
Loss:	1.8401011228561401

training epoch 122 / 500, batch #600 / 625
Loss:	1.8515145778656006

training epoch 123 / 500, batch #0 / 625
Loss:	1.8825137615203857

training epoch 123 / 500, batch #25 / 625
Loss:	1.6691454648971558

training epoch 123 / 500, batch #50 / 625
Loss:	1.7959420680999756

training epoch 123 / 500, batch #75 / 625
Loss:	1.9340441226959229

training epoch 123 / 500, batch #100 / 625
Loss:	1.772518515586853

training epoch 123 / 500, batch #125 / 625
Loss:	1.7203437089920044

training epoch 123 / 500, batch #150 / 625
Loss:	1.662578821182251

training epoch 123 / 500, batch #175 / 625
Loss:	1.8275535106658936

training epoch 123 / 500, batch #200 / 625
Loss:	1.7698776721954346

training epoch 123 / 500, batch #225 / 625
Loss:	1.9102716445922852

training epoch 123 / 500, batch #250 / 625
Loss:	1.7554068565368652

training epoch 123 / 500, batch #275 / 625
Loss:	2.026705741882324

training epoch 123 / 500, batch #300 / 625
Loss:	1.9331984519958496

training epoch 123 / 500, batch #325 / 625
Loss:	1.7522363662719727

training epoch 123 / 500, batch #350 / 625
Loss:	1.8376749753952026

training epoch 123 / 500, batch #375 / 625
Loss:	1.9598664045333862

training epoch 123 / 500, batch #400 / 625
Loss:	1.7424055337905884

training epoch 123 / 500, batch #425 / 625
Loss:	1.7614820003509521

training epoch 123 / 500, batch #450 / 625
Loss:	2.0282866954803467

training epoch 123 / 500, batch #475 / 625
Loss:	1.521223783493042

training epoch 123 / 500, batch #500 / 625
Loss:	2.027996778488159

training epoch 123 / 500, batch #525 / 625
Loss:	1.8348954916000366

training epoch 123 / 500, batch #550 / 625
Loss:	1.933275818824768

training epoch 123 / 500, batch #575 / 625
Loss:	1.8366414308547974

training epoch 123 / 500, batch #600 / 625
Loss:	1.8937230110168457

training epoch 124 / 500, batch #0 / 625
Loss:	1.8831230401992798

training epoch 124 / 500, batch #25 / 625
Loss:	1.609938621520996

training epoch 124 / 500, batch #50 / 625
Loss:	1.7033168077468872

training epoch 124 / 500, batch #75 / 625
Loss:	1.8997509479522705

training epoch 124 / 500, batch #100 / 625
Loss:	1.8986917734146118

training epoch 124 / 500, batch #125 / 625
Loss:	1.8053621053695679

training epoch 124 / 500, batch #150 / 625
Loss:	1.7519611120224

training epoch 124 / 500, batch #175 / 625
Loss:	1.887884497642517

training epoch 124 / 500, batch #200 / 625
Loss:	1.953644037246704

training epoch 124 / 500, batch #225 / 625
Loss:	1.8381123542785645

training epoch 124 / 500, batch #250 / 625
Loss:	1.770913004875183

training epoch 124 / 500, batch #275 / 625
Loss:	1.7525745630264282

training epoch 124 / 500, batch #300 / 625
Loss:	1.856768012046814

training epoch 124 / 500, batch #325 / 625
Loss:	2.057427167892456

training epoch 124 / 500, batch #350 / 625
Loss:	1.9389803409576416

training epoch 124 / 500, batch #375 / 625
Loss:	2.02773118019104

training epoch 124 / 500, batch #400 / 625
Loss:	1.9840736389160156

training epoch 124 / 500, batch #425 / 625
Loss:	1.6512867212295532

training epoch 124 / 500, batch #450 / 625
Loss:	1.982983112335205

training epoch 124 / 500, batch #475 / 625
Loss:	1.773481011390686

training epoch 124 / 500, batch #500 / 625
Loss:	1.8021632432937622

training epoch 124 / 500, batch #525 / 625
Loss:	1.9753578901290894

training epoch 124 / 500, batch #550 / 625
Loss:	1.9395861625671387

training epoch 124 / 500, batch #575 / 625
Loss:	2.082876443862915

training epoch 124 / 500, batch #600 / 625
Loss:	1.6726927757263184

training epoch 125 / 500, batch #0 / 625
Loss:	1.7925777435302734

training epoch 125 / 500, batch #25 / 625
Loss:	1.8943384885787964

training epoch 125 / 500, batch #50 / 625
Loss:	1.63222336769104

training epoch 125 / 500, batch #75 / 625
Loss:	1.752488613128662

training epoch 125 / 500, batch #100 / 625
Loss:	1.5906344652175903

training epoch 125 / 500, batch #125 / 625
Loss:	1.9946539402008057

training epoch 125 / 500, batch #150 / 625
Loss:	1.7104002237319946

training epoch 125 / 500, batch #175 / 625
Loss:	1.8093595504760742

training epoch 125 / 500, batch #200 / 625
Loss:	1.690769076347351

training epoch 125 / 500, batch #225 / 625
Loss:	1.957598090171814

training epoch 125 / 500, batch #250 / 625
Loss:	1.7927266359329224

training epoch 125 / 500, batch #275 / 625
Loss:	1.6976407766342163

training epoch 125 / 500, batch #300 / 625
Loss:	1.664543628692627

training epoch 125 / 500, batch #325 / 625
Loss:	1.6999727487564087

training epoch 125 / 500, batch #350 / 625
Loss:	1.633193016052246

training epoch 125 / 500, batch #375 / 625
Loss:	2.0047755241394043

training epoch 125 / 500, batch #400 / 625
Loss:	1.8565003871917725

training epoch 125 / 500, batch #425 / 625
Loss:	1.8337247371673584

training epoch 125 / 500, batch #450 / 625
Loss:	1.7809525728225708

training epoch 125 / 500, batch #475 / 625
Loss:	1.7152925729751587

training epoch 125 / 500, batch #500 / 625
Loss:	1.9104665517807007

training epoch 125 / 500, batch #525 / 625
Loss:	2.111570119857788

training epoch 125 / 500, batch #550 / 625
Loss:	1.7846312522888184

training epoch 125 / 500, batch #575 / 625
Loss:	1.576194167137146

training epoch 125 / 500, batch #600 / 625
Loss:	1.8119394779205322

training epoch 126 / 500, batch #0 / 625
Loss:	1.8971415758132935

training epoch 126 / 500, batch #25 / 625
Loss:	1.9357216358184814

training epoch 126 / 500, batch #50 / 625
Loss:	1.695417046546936

training epoch 126 / 500, batch #75 / 625
Loss:	1.854471206665039

training epoch 126 / 500, batch #100 / 625
Loss:	1.8012162446975708

training epoch 126 / 500, batch #125 / 625
Loss:	1.7743088006973267

training epoch 126 / 500, batch #150 / 625
Loss:	1.8620061874389648

training epoch 126 / 500, batch #175 / 625
Loss:	1.418860912322998

training epoch 126 / 500, batch #200 / 625
Loss:	1.9368458986282349

training epoch 126 / 500, batch #225 / 625
Loss:	1.7947944402694702

training epoch 126 / 500, batch #250 / 625
Loss:	1.6872310638427734

training epoch 126 / 500, batch #275 / 625
Loss:	1.8941779136657715

training epoch 126 / 500, batch #300 / 625
Loss:	1.8541539907455444

training epoch 126 / 500, batch #325 / 625
Loss:	1.875058889389038

training epoch 126 / 500, batch #350 / 625
Loss:	1.6527299880981445

training epoch 126 / 500, batch #375 / 625
Loss:	1.7616742849349976

training epoch 126 / 500, batch #400 / 625
Loss:	1.802533507347107

training epoch 126 / 500, batch #425 / 625
Loss:	1.8263746500015259

training epoch 126 / 500, batch #450 / 625
Loss:	1.860926866531372

training epoch 126 / 500, batch #475 / 625
Loss:	1.7682100534439087

training epoch 126 / 500, batch #500 / 625
Loss:	1.758351445198059

training epoch 126 / 500, batch #525 / 625
Loss:	2.017672300338745

training epoch 126 / 500, batch #550 / 625
Loss:	1.6472381353378296

training epoch 126 / 500, batch #575 / 625
Loss:	2.064283609390259

training epoch 126 / 500, batch #600 / 625
Loss:	1.9257510900497437

training epoch 127 / 500, batch #0 / 625
Loss:	1.639677882194519

training epoch 127 / 500, batch #25 / 625
Loss:	1.9347403049468994

training epoch 127 / 500, batch #50 / 625
Loss:	1.8275001049041748

training epoch 127 / 500, batch #75 / 625
Loss:	1.671848177909851

training epoch 127 / 500, batch #100 / 625
Loss:	1.9601978063583374

training epoch 127 / 500, batch #125 / 625
Loss:	1.7274783849716187

training epoch 127 / 500, batch #150 / 625
Loss:	1.9134325981140137

training epoch 127 / 500, batch #175 / 625
Loss:	1.8550032377243042

training epoch 127 / 500, batch #200 / 625
Loss:	1.7877895832061768

training epoch 127 / 500, batch #225 / 625
Loss:	1.8806334733963013

training epoch 127 / 500, batch #250 / 625
Loss:	1.8563731908798218

training epoch 127 / 500, batch #275 / 625
Loss:	1.840312123298645

training epoch 127 / 500, batch #300 / 625
Loss:	2.051079750061035

training epoch 127 / 500, batch #325 / 625
Loss:	1.6692299842834473

training epoch 127 / 500, batch #350 / 625
Loss:	2.0217156410217285

training epoch 127 / 500, batch #375 / 625
Loss:	1.6777406930923462

training epoch 127 / 500, batch #400 / 625
Loss:	1.8203721046447754

training epoch 127 / 500, batch #425 / 625
Loss:	1.8440452814102173

training epoch 127 / 500, batch #450 / 625
Loss:	1.943280577659607

training epoch 127 / 500, batch #475 / 625
Loss:	1.8767842054367065

training epoch 127 / 500, batch #500 / 625
Loss:	1.8907461166381836

training epoch 127 / 500, batch #525 / 625
Loss:	1.9881027936935425

training epoch 127 / 500, batch #550 / 625
Loss:	1.9221566915512085

training epoch 127 / 500, batch #575 / 625
Loss:	1.8660705089569092

training epoch 127 / 500, batch #600 / 625
Loss:	1.758625864982605

training epoch 128 / 500, batch #0 / 625
Loss:	1.8467851877212524

training epoch 128 / 500, batch #25 / 625
Loss:	1.7150700092315674

training epoch 128 / 500, batch #50 / 625
Loss:	1.654296636581421

training epoch 128 / 500, batch #75 / 625
Loss:	1.5277305841445923

training epoch 128 / 500, batch #100 / 625
Loss:	1.8730919361114502

training epoch 128 / 500, batch #125 / 625
Loss:	1.4606802463531494

training epoch 128 / 500, batch #150 / 625
Loss:	2.075329542160034

training epoch 128 / 500, batch #175 / 625
Loss:	1.5928364992141724

training epoch 128 / 500, batch #200 / 625
Loss:	1.6195251941680908

training epoch 128 / 500, batch #225 / 625
Loss:	1.6120706796646118

training epoch 128 / 500, batch #250 / 625
Loss:	1.8671350479125977

training epoch 128 / 500, batch #275 / 625
Loss:	2.0064854621887207

training epoch 128 / 500, batch #300 / 625
Loss:	1.7204195261001587

training epoch 128 / 500, batch #325 / 625
Loss:	1.8542040586471558

training epoch 128 / 500, batch #350 / 625
Loss:	1.7687065601348877

training epoch 128 / 500, batch #375 / 625
Loss:	1.7540035247802734

training epoch 128 / 500, batch #400 / 625
Loss:	1.7683746814727783

training epoch 128 / 500, batch #425 / 625
Loss:	1.8893588781356812

training epoch 128 / 500, batch #450 / 625
Loss:	1.8647328615188599

training epoch 128 / 500, batch #475 / 625
Loss:	1.7560019493103027

training epoch 128 / 500, batch #500 / 625
Loss:	1.8983328342437744

training epoch 128 / 500, batch #525 / 625
Loss:	1.9610321521759033

training epoch 128 / 500, batch #550 / 625
Loss:	1.727155327796936

training epoch 128 / 500, batch #575 / 625
Loss:	1.9380439519882202

training epoch 128 / 500, batch #600 / 625
Loss:	1.9623026847839355

training epoch 129 / 500, batch #0 / 625
Loss:	1.750466227531433

training epoch 129 / 500, batch #25 / 625
Loss:	1.9674829244613647

training epoch 129 / 500, batch #50 / 625
Loss:	1.664218783378601

training epoch 129 / 500, batch #75 / 625
Loss:	1.681473731994629

training epoch 129 / 500, batch #100 / 625
Loss:	1.886246919631958

training epoch 129 / 500, batch #125 / 625
Loss:	1.7528373003005981

training epoch 129 / 500, batch #150 / 625
Loss:	1.6279696226119995

training epoch 129 / 500, batch #175 / 625
Loss:	1.7505079507827759

training epoch 129 / 500, batch #200 / 625
Loss:	1.8322995901107788

training epoch 129 / 500, batch #225 / 625
Loss:	1.9071238040924072

training epoch 129 / 500, batch #250 / 625
Loss:	1.9210436344146729

training epoch 129 / 500, batch #275 / 625
Loss:	2.0297164916992188

training epoch 129 / 500, batch #300 / 625
Loss:	1.9746404886245728

training epoch 129 / 500, batch #325 / 625
Loss:	1.7132782936096191

training epoch 129 / 500, batch #350 / 625
Loss:	1.9053750038146973

training epoch 129 / 500, batch #375 / 625
Loss:	1.9544944763183594

training epoch 129 / 500, batch #400 / 625
Loss:	1.850728988647461

training epoch 129 / 500, batch #425 / 625
Loss:	1.71285080909729

training epoch 129 / 500, batch #450 / 625
Loss:	1.7664680480957031

training epoch 129 / 500, batch #475 / 625
Loss:	2.1106362342834473

training epoch 129 / 500, batch #500 / 625
Loss:	1.7081694602966309

training epoch 129 / 500, batch #525 / 625
Loss:	1.796877145767212

training epoch 129 / 500, batch #550 / 625
Loss:	2.0319135189056396

training epoch 129 / 500, batch #575 / 625
Loss:	1.9809455871582031

training epoch 129 / 500, batch #600 / 625
Loss:	1.856895089149475

training epoch 130 / 500, batch #0 / 625
Loss:	1.6918659210205078

training epoch 130 / 500, batch #25 / 625
Loss:	1.7129584550857544

training epoch 130 / 500, batch #50 / 625
Loss:	1.8967634439468384

training epoch 130 / 500, batch #75 / 625
Loss:	1.9236445426940918

training epoch 130 / 500, batch #100 / 625
Loss:	1.7450532913208008

training epoch 130 / 500, batch #125 / 625
Loss:	1.736182451248169

training epoch 130 / 500, batch #150 / 625
Loss:	1.801369309425354

training epoch 130 / 500, batch #175 / 625
Loss:	1.636710286140442

training epoch 130 / 500, batch #200 / 625
Loss:	1.7554208040237427

training epoch 130 / 500, batch #225 / 625
Loss:	1.6089845895767212

training epoch 130 / 500, batch #250 / 625
Loss:	1.9512790441513062

training epoch 130 / 500, batch #275 / 625
Loss:	1.822867512702942

training epoch 130 / 500, batch #300 / 625
Loss:	1.7008624076843262

training epoch 130 / 500, batch #325 / 625
Loss:	1.9104057550430298

training epoch 130 / 500, batch #350 / 625
Loss:	2.2434346675872803

training epoch 130 / 500, batch #375 / 625
Loss:	1.7450971603393555

training epoch 130 / 500, batch #400 / 625
Loss:	1.825484037399292

training epoch 130 / 500, batch #425 / 625
Loss:	1.8956243991851807

training epoch 130 / 500, batch #450 / 625
Loss:	1.8333587646484375

training epoch 130 / 500, batch #475 / 625
Loss:	1.6928143501281738

training epoch 130 / 500, batch #500 / 625
Loss:	1.6616137027740479

training epoch 130 / 500, batch #525 / 625
Loss:	1.7910761833190918

training epoch 130 / 500, batch #550 / 625
Loss:	1.578704833984375

training epoch 130 / 500, batch #575 / 625
Loss:	1.799605131149292

training epoch 130 / 500, batch #600 / 625
Loss:	1.7144817113876343

training epoch 131 / 500, batch #0 / 625
Loss:	1.89743971824646

training epoch 131 / 500, batch #25 / 625
Loss:	1.6438695192337036

training epoch 131 / 500, batch #50 / 625
Loss:	1.88516104221344

training epoch 131 / 500, batch #75 / 625
Loss:	1.7580856084823608

training epoch 131 / 500, batch #100 / 625
Loss:	1.9155240058898926

training epoch 131 / 500, batch #125 / 625
Loss:	1.5699806213378906

training epoch 131 / 500, batch #150 / 625
Loss:	1.7722582817077637

training epoch 131 / 500, batch #175 / 625
Loss:	2.026660680770874

training epoch 131 / 500, batch #200 / 625
Loss:	1.5881450176239014

training epoch 131 / 500, batch #225 / 625
Loss:	1.9139766693115234

training epoch 131 / 500, batch #250 / 625
Loss:	1.8491367101669312

training epoch 131 / 500, batch #275 / 625
Loss:	1.905795693397522

training epoch 131 / 500, batch #300 / 625
Loss:	1.792142391204834

training epoch 131 / 500, batch #325 / 625
Loss:	1.8290640115737915

training epoch 131 / 500, batch #350 / 625
Loss:	1.7009369134902954

training epoch 131 / 500, batch #375 / 625
Loss:	1.8082082271575928

training epoch 131 / 500, batch #400 / 625
Loss:	1.5806481838226318

training epoch 131 / 500, batch #425 / 625
Loss:	1.7263293266296387

training epoch 131 / 500, batch #450 / 625
Loss:	1.750380277633667

training epoch 131 / 500, batch #475 / 625
Loss:	1.701396107673645

training epoch 131 / 500, batch #500 / 625
Loss:	1.8922793865203857

training epoch 131 / 500, batch #525 / 625
Loss:	1.8780345916748047

training epoch 131 / 500, batch #550 / 625
Loss:	1.8306398391723633

training epoch 131 / 500, batch #575 / 625
Loss:	1.8291139602661133

training epoch 131 / 500, batch #600 / 625
Loss:	1.8317147493362427

training epoch 132 / 500, batch #0 / 625
Loss:	1.802577018737793

training epoch 132 / 500, batch #25 / 625
Loss:	1.8734238147735596

training epoch 132 / 500, batch #50 / 625
Loss:	1.9139541387557983

training epoch 132 / 500, batch #75 / 625
Loss:	1.7814594507217407

training epoch 132 / 500, batch #100 / 625
Loss:	1.701147437095642

training epoch 132 / 500, batch #125 / 625
Loss:	1.7573740482330322

training epoch 132 / 500, batch #150 / 625
Loss:	1.6805375814437866

training epoch 132 / 500, batch #175 / 625
Loss:	1.984065294265747

training epoch 132 / 500, batch #200 / 625
Loss:	1.7053256034851074

training epoch 132 / 500, batch #225 / 625
Loss:	1.7927160263061523

training epoch 132 / 500, batch #250 / 625
Loss:	1.841944694519043

training epoch 132 / 500, batch #275 / 625
Loss:	1.6796070337295532

training epoch 132 / 500, batch #300 / 625
Loss:	1.8304920196533203

training epoch 132 / 500, batch #325 / 625
Loss:	1.6898993253707886

training epoch 132 / 500, batch #350 / 625
Loss:	1.6220991611480713

training epoch 132 / 500, batch #375 / 625
Loss:	1.7742300033569336

training epoch 132 / 500, batch #400 / 625
Loss:	1.772328495979309

training epoch 132 / 500, batch #425 / 625
Loss:	1.8382774591445923

training epoch 132 / 500, batch #450 / 625
Loss:	1.777946949005127

training epoch 132 / 500, batch #475 / 625
Loss:	1.907392144203186

training epoch 132 / 500, batch #500 / 625
Loss:	1.853066086769104

training epoch 132 / 500, batch #525 / 625
Loss:	1.8218340873718262

training epoch 132 / 500, batch #550 / 625
Loss:	1.7304370403289795

training epoch 132 / 500, batch #575 / 625
Loss:	1.7756868600845337

training epoch 132 / 500, batch #600 / 625
Loss:	1.8992894887924194

training epoch 133 / 500, batch #0 / 625
Loss:	1.8681368827819824

training epoch 133 / 500, batch #25 / 625
Loss:	1.8471680879592896

training epoch 133 / 500, batch #50 / 625
Loss:	1.9342797994613647

training epoch 133 / 500, batch #75 / 625
Loss:	1.9826016426086426

training epoch 133 / 500, batch #100 / 625
Loss:	1.7808517217636108

training epoch 133 / 500, batch #125 / 625
Loss:	1.9629939794540405

training epoch 133 / 500, batch #150 / 625
Loss:	1.6119905710220337

training epoch 133 / 500, batch #175 / 625
Loss:	2.0439133644104004

training epoch 133 / 500, batch #200 / 625
Loss:	1.7382769584655762

training epoch 133 / 500, batch #225 / 625
Loss:	1.8765904903411865

training epoch 133 / 500, batch #250 / 625
Loss:	1.4887949228286743

training epoch 133 / 500, batch #275 / 625
Loss:	1.893700361251831

training epoch 133 / 500, batch #300 / 625
Loss:	1.698561668395996

training epoch 133 / 500, batch #325 / 625
Loss:	1.8684914112091064

training epoch 133 / 500, batch #350 / 625
Loss:	1.6906635761260986

training epoch 133 / 500, batch #375 / 625
Loss:	1.8362802267074585

training epoch 133 / 500, batch #400 / 625
Loss:	1.7405059337615967

training epoch 133 / 500, batch #425 / 625
Loss:	1.81699538230896

training epoch 133 / 500, batch #450 / 625
Loss:	2.0645530223846436

training epoch 133 / 500, batch #475 / 625
Loss:	1.6549454927444458

training epoch 133 / 500, batch #500 / 625
Loss:	2.0071494579315186

training epoch 133 / 500, batch #525 / 625
Loss:	1.7661421298980713

training epoch 133 / 500, batch #550 / 625
Loss:	1.658461093902588

training epoch 133 / 500, batch #575 / 625
Loss:	1.8696812391281128

training epoch 133 / 500, batch #600 / 625
Loss:	1.9883936643600464

training epoch 134 / 500, batch #0 / 625
Loss:	1.9386076927185059

training epoch 134 / 500, batch #25 / 625
Loss:	1.7090550661087036

training epoch 134 / 500, batch #50 / 625
Loss:	2.019749879837036

training epoch 134 / 500, batch #75 / 625
Loss:	1.826521396636963

training epoch 134 / 500, batch #100 / 625
Loss:	1.8304601907730103

training epoch 134 / 500, batch #125 / 625
Loss:	1.845442295074463

training epoch 134 / 500, batch #150 / 625
Loss:	1.875653624534607

training epoch 134 / 500, batch #175 / 625
Loss:	1.8498938083648682

training epoch 134 / 500, batch #200 / 625
Loss:	1.9226853847503662

training epoch 134 / 500, batch #225 / 625
Loss:	1.5838936567306519

training epoch 134 / 500, batch #250 / 625
Loss:	1.7790608406066895

training epoch 134 / 500, batch #275 / 625
Loss:	1.9475665092468262

training epoch 134 / 500, batch #300 / 625
Loss:	1.8880311250686646

training epoch 134 / 500, batch #325 / 625
Loss:	1.6958800554275513

training epoch 134 / 500, batch #350 / 625
Loss:	1.5877714157104492

training epoch 134 / 500, batch #375 / 625
Loss:	1.8595924377441406

training epoch 134 / 500, batch #400 / 625
Loss:	1.683034062385559

training epoch 134 / 500, batch #425 / 625
Loss:	1.9382681846618652

training epoch 134 / 500, batch #450 / 625
Loss:	1.8515808582305908

training epoch 134 / 500, batch #475 / 625
Loss:	1.748126745223999

training epoch 134 / 500, batch #500 / 625
Loss:	1.7053393125534058

training epoch 134 / 500, batch #525 / 625
Loss:	1.6918041706085205

training epoch 134 / 500, batch #550 / 625
Loss:	1.6639583110809326

training epoch 134 / 500, batch #575 / 625
Loss:	1.8183332681655884

training epoch 134 / 500, batch #600 / 625
Loss:	1.9175643920898438

training epoch 135 / 500, batch #0 / 625
Loss:	1.9618659019470215

training epoch 135 / 500, batch #25 / 625
Loss:	1.6301614046096802

training epoch 135 / 500, batch #50 / 625
Loss:	1.6885442733764648

training epoch 135 / 500, batch #75 / 625
Loss:	2.085559368133545

training epoch 135 / 500, batch #100 / 625
Loss:	1.8840184211730957

training epoch 135 / 500, batch #125 / 625
Loss:	1.8722461462020874

training epoch 135 / 500, batch #150 / 625
Loss:	1.915752649307251

training epoch 135 / 500, batch #175 / 625
Loss:	1.8749682903289795

training epoch 135 / 500, batch #200 / 625
Loss:	2.000072717666626

training epoch 135 / 500, batch #225 / 625
Loss:	1.8166871070861816

training epoch 135 / 500, batch #250 / 625
Loss:	1.6779544353485107

training epoch 135 / 500, batch #275 / 625
Loss:	1.8835670948028564

training epoch 135 / 500, batch #300 / 625
Loss:	1.5686267614364624

training epoch 135 / 500, batch #325 / 625
Loss:	1.9108359813690186

training epoch 135 / 500, batch #350 / 625
Loss:	1.689940094947815

training epoch 135 / 500, batch #375 / 625
Loss:	1.8888332843780518

training epoch 135 / 500, batch #400 / 625
Loss:	1.7584539651870728

training epoch 135 / 500, batch #425 / 625
Loss:	1.879993200302124

training epoch 135 / 500, batch #450 / 625
Loss:	1.861768126487732

training epoch 135 / 500, batch #475 / 625
Loss:	1.756558895111084

training epoch 135 / 500, batch #500 / 625
Loss:	1.649330735206604

training epoch 135 / 500, batch #525 / 625
Loss:	1.8707871437072754

training epoch 135 / 500, batch #550 / 625
Loss:	1.8525965213775635

training epoch 135 / 500, batch #575 / 625
Loss:	1.5623667240142822

training epoch 135 / 500, batch #600 / 625
Loss:	1.6827163696289062

training epoch 136 / 500, batch #0 / 625
Loss:	1.724243402481079

training epoch 136 / 500, batch #25 / 625
Loss:	1.5131114721298218

training epoch 136 / 500, batch #50 / 625
Loss:	1.82893967628479

training epoch 136 / 500, batch #75 / 625
Loss:	1.6522963047027588

training epoch 136 / 500, batch #100 / 625
Loss:	1.7465813159942627

training epoch 136 / 500, batch #125 / 625
Loss:	2.037008047103882

training epoch 136 / 500, batch #150 / 625
Loss:	1.8157957792282104

training epoch 136 / 500, batch #175 / 625
Loss:	1.982992172241211

training epoch 136 / 500, batch #200 / 625
Loss:	1.9255329370498657

training epoch 136 / 500, batch #225 / 625
Loss:	1.9735537767410278

training epoch 136 / 500, batch #250 / 625
Loss:	1.957785725593567

training epoch 136 / 500, batch #275 / 625
Loss:	1.8051494359970093

training epoch 136 / 500, batch #300 / 625
Loss:	1.6533912420272827

training epoch 136 / 500, batch #325 / 625
Loss:	1.8376407623291016

training epoch 136 / 500, batch #350 / 625
Loss:	1.811006784439087

training epoch 136 / 500, batch #375 / 625
Loss:	1.7734957933425903

training epoch 136 / 500, batch #400 / 625
Loss:	1.611844539642334

training epoch 136 / 500, batch #425 / 625
Loss:	1.7346889972686768

training epoch 136 / 500, batch #450 / 625
Loss:	1.8447957038879395

training epoch 136 / 500, batch #475 / 625
Loss:	1.9769648313522339

training epoch 136 / 500, batch #500 / 625
Loss:	1.7542626857757568

training epoch 136 / 500, batch #525 / 625
Loss:	1.5517534017562866

training epoch 136 / 500, batch #550 / 625
Loss:	1.619962453842163

training epoch 136 / 500, batch #575 / 625
Loss:	1.576522946357727

training epoch 136 / 500, batch #600 / 625
Loss:	1.8663970232009888

training epoch 137 / 500, batch #0 / 625
Loss:	1.7122585773468018

training epoch 137 / 500, batch #25 / 625
Loss:	1.6941155195236206

training epoch 137 / 500, batch #50 / 625
Loss:	1.5928494930267334

training epoch 137 / 500, batch #75 / 625
Loss:	1.8626794815063477

training epoch 137 / 500, batch #100 / 625
Loss:	1.9198625087738037

training epoch 137 / 500, batch #125 / 625
Loss:	1.4539744853973389

training epoch 137 / 500, batch #150 / 625
Loss:	1.7875585556030273

training epoch 137 / 500, batch #175 / 625
Loss:	1.784017562866211

training epoch 137 / 500, batch #200 / 625
Loss:	1.8981822729110718

training epoch 137 / 500, batch #225 / 625
Loss:	1.8320258855819702

training epoch 137 / 500, batch #250 / 625
Loss:	1.5947670936584473

training epoch 137 / 500, batch #275 / 625
Loss:	1.8774232864379883

training epoch 137 / 500, batch #300 / 625
Loss:	1.5382672548294067

training epoch 137 / 500, batch #325 / 625
Loss:	1.703597903251648

training epoch 137 / 500, batch #350 / 625
Loss:	1.7960172891616821

training epoch 137 / 500, batch #375 / 625
Loss:	1.7752923965454102

training epoch 137 / 500, batch #400 / 625
Loss:	2.1080644130706787

training epoch 137 / 500, batch #425 / 625
Loss:	1.9785221815109253

training epoch 137 / 500, batch #450 / 625
Loss:	1.916221261024475

training epoch 137 / 500, batch #475 / 625
Loss:	1.8343303203582764

training epoch 137 / 500, batch #500 / 625
Loss:	1.772384524345398

training epoch 137 / 500, batch #525 / 625
Loss:	1.6555290222167969

training epoch 137 / 500, batch #550 / 625
Loss:	1.692607045173645

training epoch 137 / 500, batch #575 / 625
Loss:	1.7401771545410156

training epoch 137 / 500, batch #600 / 625
Loss:	1.8275330066680908

training epoch 138 / 500, batch #0 / 625
Loss:	1.8509719371795654

training epoch 138 / 500, batch #25 / 625
Loss:	1.5812911987304688

training epoch 138 / 500, batch #50 / 625
Loss:	1.7977021932601929

training epoch 138 / 500, batch #75 / 625
Loss:	1.921888828277588

training epoch 138 / 500, batch #100 / 625
Loss:	1.821778416633606

training epoch 138 / 500, batch #125 / 625
Loss:	1.6486561298370361

training epoch 138 / 500, batch #150 / 625
Loss:	1.7039799690246582

training epoch 138 / 500, batch #175 / 625
Loss:	1.9388378858566284

training epoch 138 / 500, batch #200 / 625
Loss:	1.8535404205322266

training epoch 138 / 500, batch #225 / 625
Loss:	1.66122305393219

training epoch 138 / 500, batch #250 / 625
Loss:	2.0120768547058105

training epoch 138 / 500, batch #275 / 625
Loss:	1.7488787174224854

training epoch 138 / 500, batch #300 / 625
Loss:	1.8498377799987793

training epoch 138 / 500, batch #325 / 625
Loss:	1.6577527523040771

training epoch 138 / 500, batch #350 / 625
Loss:	1.6110066175460815

training epoch 138 / 500, batch #375 / 625
Loss:	2.016584873199463

training epoch 138 / 500, batch #400 / 625
Loss:	1.6838936805725098

training epoch 138 / 500, batch #425 / 625
Loss:	1.715175747871399

training epoch 138 / 500, batch #450 / 625
Loss:	1.7213197946548462

training epoch 138 / 500, batch #475 / 625
Loss:	1.7103114128112793

training epoch 138 / 500, batch #500 / 625
Loss:	1.7287999391555786

training epoch 138 / 500, batch #525 / 625
Loss:	1.694784164428711

training epoch 138 / 500, batch #550 / 625
Loss:	1.9788249731063843

training epoch 138 / 500, batch #575 / 625
Loss:	1.8080297708511353

training epoch 138 / 500, batch #600 / 625
Loss:	1.7714130878448486

training epoch 139 / 500, batch #0 / 625
Loss:	1.7617584466934204

training epoch 139 / 500, batch #25 / 625
Loss:	1.8136672973632812

training epoch 139 / 500, batch #50 / 625
Loss:	1.678225040435791

training epoch 139 / 500, batch #75 / 625
Loss:	1.8938339948654175

training epoch 139 / 500, batch #100 / 625
Loss:	1.9050980806350708

training epoch 139 / 500, batch #125 / 625
Loss:	1.8081454038619995

training epoch 139 / 500, batch #150 / 625
Loss:	1.6644090414047241

training epoch 139 / 500, batch #175 / 625
Loss:	1.752158284187317

training epoch 139 / 500, batch #200 / 625
Loss:	1.6215094327926636

training epoch 139 / 500, batch #225 / 625
Loss:	1.821915626525879

training epoch 139 / 500, batch #250 / 625
Loss:	1.7119613885879517

training epoch 139 / 500, batch #275 / 625
Loss:	1.6092458963394165

training epoch 139 / 500, batch #300 / 625
Loss:	1.8166621923446655

training epoch 139 / 500, batch #325 / 625
Loss:	1.8072805404663086

training epoch 139 / 500, batch #350 / 625
Loss:	1.8812452554702759

training epoch 139 / 500, batch #375 / 625
Loss:	1.8818556070327759

training epoch 139 / 500, batch #400 / 625
Loss:	1.8293397426605225

training epoch 139 / 500, batch #425 / 625
Loss:	1.5859074592590332

training epoch 139 / 500, batch #450 / 625
Loss:	2.185901403427124

training epoch 139 / 500, batch #475 / 625
Loss:	1.7721123695373535

training epoch 139 / 500, batch #500 / 625
Loss:	1.9557251930236816

training epoch 139 / 500, batch #525 / 625
Loss:	1.8952531814575195

training epoch 139 / 500, batch #550 / 625
Loss:	1.7176234722137451

training epoch 139 / 500, batch #575 / 625
Loss:	1.7254973649978638

training epoch 139 / 500, batch #600 / 625
Loss:	1.8553624153137207

training epoch 140 / 500, batch #0 / 625
Loss:	1.8039144277572632

training epoch 140 / 500, batch #25 / 625
Loss:	1.6941916942596436

training epoch 140 / 500, batch #50 / 625
Loss:	1.7827391624450684

training epoch 140 / 500, batch #75 / 625
Loss:	1.7285975217819214

training epoch 140 / 500, batch #100 / 625
Loss:	1.5948436260223389

training epoch 140 / 500, batch #125 / 625
Loss:	1.9047412872314453

training epoch 140 / 500, batch #150 / 625
Loss:	1.7386693954467773

training epoch 140 / 500, batch #175 / 625
Loss:	1.7273738384246826

training epoch 140 / 500, batch #200 / 625
Loss:	1.7407153844833374

training epoch 140 / 500, batch #225 / 625
Loss:	1.6940386295318604

training epoch 140 / 500, batch #250 / 625
Loss:	1.744814157485962

training epoch 140 / 500, batch #275 / 625
Loss:	1.8315129280090332

training epoch 140 / 500, batch #300 / 625
Loss:	1.9370765686035156

training epoch 140 / 500, batch #325 / 625
Loss:	1.8653587102890015

training epoch 140 / 500, batch #350 / 625
Loss:	1.7818266153335571

training epoch 140 / 500, batch #375 / 625
Loss:	1.7925283908843994

training epoch 140 / 500, batch #400 / 625
Loss:	1.911116123199463

training epoch 140 / 500, batch #425 / 625
Loss:	1.9938336610794067

training epoch 140 / 500, batch #450 / 625
Loss:	1.9517476558685303

training epoch 140 / 500, batch #475 / 625
Loss:	1.9213738441467285

training epoch 140 / 500, batch #500 / 625
Loss:	1.6819422245025635

training epoch 140 / 500, batch #525 / 625
Loss:	1.5982623100280762

training epoch 140 / 500, batch #550 / 625
Loss:	1.736488938331604

training epoch 140 / 500, batch #575 / 625
Loss:	1.8794472217559814

training epoch 140 / 500, batch #600 / 625
Loss:	1.5761191844940186

training epoch 141 / 500, batch #0 / 625
Loss:	2.008241891860962

training epoch 141 / 500, batch #25 / 625
Loss:	1.8243465423583984

training epoch 141 / 500, batch #50 / 625
Loss:	1.6087430715560913

training epoch 141 / 500, batch #75 / 625
Loss:	1.685707449913025

training epoch 141 / 500, batch #100 / 625
Loss:	1.8070977926254272

training epoch 141 / 500, batch #125 / 625
Loss:	1.8843913078308105

training epoch 141 / 500, batch #150 / 625
Loss:	1.8980672359466553

training epoch 141 / 500, batch #175 / 625
Loss:	1.9970643520355225

training epoch 141 / 500, batch #200 / 625
Loss:	2.0557587146759033

training epoch 141 / 500, batch #225 / 625
Loss:	1.8083401918411255

training epoch 141 / 500, batch #250 / 625
Loss:	1.6691322326660156

training epoch 141 / 500, batch #275 / 625
Loss:	1.9508877992630005

training epoch 141 / 500, batch #300 / 625
Loss:	2.0209076404571533

training epoch 141 / 500, batch #325 / 625
Loss:	1.8216371536254883

training epoch 141 / 500, batch #350 / 625
Loss:	2.037705898284912

training epoch 141 / 500, batch #375 / 625
Loss:	1.5232347249984741

training epoch 141 / 500, batch #400 / 625
Loss:	1.6829450130462646

training epoch 141 / 500, batch #425 / 625
Loss:	1.7519079446792603

training epoch 141 / 500, batch #450 / 625
Loss:	1.8092389106750488

training epoch 141 / 500, batch #475 / 625
Loss:	1.7495179176330566

training epoch 141 / 500, batch #500 / 625
Loss:	1.6323472261428833

training epoch 141 / 500, batch #525 / 625
Loss:	1.8988662958145142

training epoch 141 / 500, batch #550 / 625
Loss:	1.8283957242965698

training epoch 141 / 500, batch #575 / 625
Loss:	1.5030767917633057

training epoch 141 / 500, batch #600 / 625
Loss:	1.873881220817566

training epoch 142 / 500, batch #0 / 625
Loss:	2.0151281356811523

training epoch 142 / 500, batch #25 / 625
Loss:	2.1010055541992188

training epoch 142 / 500, batch #50 / 625
Loss:	1.6992965936660767

training epoch 142 / 500, batch #75 / 625
Loss:	1.8822354078292847

training epoch 142 / 500, batch #100 / 625
Loss:	1.5777757167816162

training epoch 142 / 500, batch #125 / 625
Loss:	1.6813163757324219

training epoch 142 / 500, batch #150 / 625
Loss:	1.759961724281311

training epoch 142 / 500, batch #175 / 625
Loss:	1.7494375705718994

training epoch 142 / 500, batch #200 / 625
Loss:	1.723349690437317

training epoch 142 / 500, batch #225 / 625
Loss:	1.9054529666900635

training epoch 142 / 500, batch #250 / 625
Loss:	1.6044875383377075

training epoch 142 / 500, batch #275 / 625
Loss:	1.943935751914978

training epoch 142 / 500, batch #300 / 625
Loss:	1.6429247856140137

training epoch 142 / 500, batch #325 / 625
Loss:	1.8251811265945435

training epoch 142 / 500, batch #350 / 625
Loss:	1.9536113739013672

training epoch 142 / 500, batch #375 / 625
Loss:	1.9813792705535889

training epoch 142 / 500, batch #400 / 625
Loss:	1.7414623498916626

training epoch 142 / 500, batch #425 / 625
Loss:	1.8743139505386353

training epoch 142 / 500, batch #450 / 625
Loss:	1.8501187562942505

training epoch 142 / 500, batch #475 / 625
Loss:	1.870120644569397

training epoch 142 / 500, batch #500 / 625
Loss:	1.832120418548584

training epoch 142 / 500, batch #525 / 625
Loss:	1.7724238634109497

training epoch 142 / 500, batch #550 / 625
Loss:	1.9779309034347534

training epoch 142 / 500, batch #575 / 625
Loss:	1.9296448230743408

training epoch 142 / 500, batch #600 / 625
Loss:	1.8693881034851074

training epoch 143 / 500, batch #0 / 625
Loss:	1.7721190452575684

training epoch 143 / 500, batch #25 / 625
Loss:	1.6619973182678223

training epoch 143 / 500, batch #50 / 625
Loss:	1.9094310998916626

training epoch 143 / 500, batch #75 / 625
Loss:	1.8678456544876099

training epoch 143 / 500, batch #100 / 625
Loss:	2.0334343910217285

training epoch 143 / 500, batch #125 / 625
Loss:	1.809949278831482

training epoch 143 / 500, batch #150 / 625
Loss:	1.8289759159088135

training epoch 143 / 500, batch #175 / 625
Loss:	1.7182258367538452

training epoch 143 / 500, batch #200 / 625
Loss:	1.7608603239059448

training epoch 143 / 500, batch #225 / 625
Loss:	1.6875882148742676

training epoch 143 / 500, batch #250 / 625
Loss:	1.8365329504013062

training epoch 143 / 500, batch #275 / 625
Loss:	1.7612611055374146

training epoch 143 / 500, batch #300 / 625
Loss:	1.7032543420791626

training epoch 143 / 500, batch #325 / 625
Loss:	1.9143368005752563

training epoch 143 / 500, batch #350 / 625
Loss:	2.039851665496826

training epoch 143 / 500, batch #375 / 625
Loss:	1.895186185836792

training epoch 143 / 500, batch #400 / 625
Loss:	1.9060083627700806

training epoch 143 / 500, batch #425 / 625
Loss:	1.8232035636901855

training epoch 143 / 500, batch #450 / 625
Loss:	1.7335165739059448

training epoch 143 / 500, batch #475 / 625
Loss:	1.7969928979873657

training epoch 143 / 500, batch #500 / 625
Loss:	1.7012397050857544

training epoch 143 / 500, batch #525 / 625
Loss:	1.7185349464416504

training epoch 143 / 500, batch #550 / 625
Loss:	1.7780041694641113

training epoch 143 / 500, batch #575 / 625
Loss:	1.9822769165039062

training epoch 143 / 500, batch #600 / 625
Loss:	1.8751680850982666

training epoch 144 / 500, batch #0 / 625
Loss:	1.9187918901443481

training epoch 144 / 500, batch #25 / 625
Loss:	1.8998568058013916

training epoch 144 / 500, batch #50 / 625
Loss:	1.953269124031067

training epoch 144 / 500, batch #75 / 625
Loss:	1.8654167652130127

training epoch 144 / 500, batch #100 / 625
Loss:	1.5930143594741821

training epoch 144 / 500, batch #125 / 625
Loss:	1.8021280765533447

training epoch 144 / 500, batch #150 / 625
Loss:	1.7933772802352905

training epoch 144 / 500, batch #175 / 625
Loss:	1.878846526145935

training epoch 144 / 500, batch #200 / 625
Loss:	1.8158366680145264

training epoch 144 / 500, batch #225 / 625
Loss:	2.0303311347961426

training epoch 144 / 500, batch #250 / 625
Loss:	1.7261542081832886

training epoch 144 / 500, batch #275 / 625
Loss:	1.8523980379104614

training epoch 144 / 500, batch #300 / 625
Loss:	1.8551852703094482

training epoch 144 / 500, batch #325 / 625
Loss:	1.8664636611938477

training epoch 144 / 500, batch #350 / 625
Loss:	1.655362606048584

training epoch 144 / 500, batch #375 / 625
Loss:	1.7779974937438965

training epoch 144 / 500, batch #400 / 625
Loss:	1.6722739934921265

training epoch 144 / 500, batch #425 / 625
Loss:	1.5380735397338867

training epoch 144 / 500, batch #450 / 625
Loss:	1.917436122894287

training epoch 144 / 500, batch #475 / 625
Loss:	1.8539934158325195

training epoch 144 / 500, batch #500 / 625
Loss:	1.9751300811767578

training epoch 144 / 500, batch #525 / 625
Loss:	1.6173640489578247

training epoch 144 / 500, batch #550 / 625
Loss:	1.70864999294281

training epoch 144 / 500, batch #575 / 625
Loss:	1.7087295055389404

training epoch 144 / 500, batch #600 / 625
Loss:	1.6973841190338135

training epoch 145 / 500, batch #0 / 625
Loss:	1.7960436344146729

training epoch 145 / 500, batch #25 / 625
Loss:	1.8695766925811768

training epoch 145 / 500, batch #50 / 625
Loss:	1.7611770629882812

training epoch 145 / 500, batch #75 / 625
Loss:	1.6572941541671753

training epoch 145 / 500, batch #100 / 625
Loss:	2.006824493408203

training epoch 145 / 500, batch #125 / 625
Loss:	1.7471040487289429

training epoch 145 / 500, batch #150 / 625
Loss:	1.9490512609481812

training epoch 145 / 500, batch #175 / 625
Loss:	1.8719946146011353

training epoch 145 / 500, batch #200 / 625
Loss:	1.802438497543335

training epoch 145 / 500, batch #225 / 625
Loss:	1.740190029144287

training epoch 145 / 500, batch #250 / 625
Loss:	1.864567756652832

training epoch 145 / 500, batch #275 / 625
Loss:	2.053037643432617

training epoch 145 / 500, batch #300 / 625
Loss:	1.870249629020691

training epoch 145 / 500, batch #325 / 625
Loss:	1.7753762006759644

training epoch 145 / 500, batch #350 / 625
Loss:	1.765208125114441

training epoch 145 / 500, batch #375 / 625
Loss:	1.6971980333328247

training epoch 145 / 500, batch #400 / 625
Loss:	1.616722822189331

training epoch 145 / 500, batch #425 / 625
Loss:	1.6874186992645264

training epoch 145 / 500, batch #450 / 625
Loss:	1.7471281290054321

training epoch 145 / 500, batch #475 / 625
Loss:	1.940583348274231

training epoch 145 / 500, batch #500 / 625
Loss:	2.101620674133301

training epoch 145 / 500, batch #525 / 625
Loss:	1.6745749711990356

training epoch 145 / 500, batch #550 / 625
Loss:	1.877610206604004

training epoch 145 / 500, batch #575 / 625
Loss:	1.8601866960525513

training epoch 145 / 500, batch #600 / 625
Loss:	1.6917088031768799

training epoch 146 / 500, batch #0 / 625
Loss:	1.751693844795227

training epoch 146 / 500, batch #25 / 625
Loss:	1.7601845264434814

training epoch 146 / 500, batch #50 / 625
Loss:	1.5791308879852295

training epoch 146 / 500, batch #75 / 625
Loss:	1.818131923675537

training epoch 146 / 500, batch #100 / 625
Loss:	1.8620649576187134

training epoch 146 / 500, batch #125 / 625
Loss:	1.783359408378601

training epoch 146 / 500, batch #150 / 625
Loss:	1.945630669593811

training epoch 146 / 500, batch #175 / 625
Loss:	1.7563878297805786

training epoch 146 / 500, batch #200 / 625
Loss:	1.8322408199310303

training epoch 146 / 500, batch #225 / 625
Loss:	1.691608190536499

training epoch 146 / 500, batch #250 / 625
Loss:	1.7977681159973145

training epoch 146 / 500, batch #275 / 625
Loss:	1.6866458654403687

training epoch 146 / 500, batch #300 / 625
Loss:	1.84829580783844

training epoch 146 / 500, batch #325 / 625
Loss:	1.5443910360336304

training epoch 146 / 500, batch #350 / 625
Loss:	1.7397489547729492

training epoch 146 / 500, batch #375 / 625
Loss:	1.8503913879394531

training epoch 146 / 500, batch #400 / 625
Loss:	1.8508614301681519

training epoch 146 / 500, batch #425 / 625
Loss:	1.8175811767578125

training epoch 146 / 500, batch #450 / 625
Loss:	1.567919373512268

training epoch 146 / 500, batch #475 / 625
Loss:	1.8364217281341553

training epoch 146 / 500, batch #500 / 625
Loss:	1.824864149093628

training epoch 146 / 500, batch #525 / 625
Loss:	1.8712033033370972

training epoch 146 / 500, batch #550 / 625
Loss:	1.9267972707748413

training epoch 146 / 500, batch #575 / 625
Loss:	1.707390308380127

training epoch 146 / 500, batch #600 / 625
Loss:	1.7861021757125854

training epoch 147 / 500, batch #0 / 625
Loss:	1.8158259391784668

training epoch 147 / 500, batch #25 / 625
Loss:	1.6429376602172852

training epoch 147 / 500, batch #50 / 625
Loss:	1.8333667516708374

training epoch 147 / 500, batch #75 / 625
Loss:	1.7390912771224976

training epoch 147 / 500, batch #100 / 625
Loss:	1.8167147636413574

training epoch 147 / 500, batch #125 / 625
Loss:	1.8160394430160522

training epoch 147 / 500, batch #150 / 625
Loss:	1.8565151691436768

training epoch 147 / 500, batch #175 / 625
Loss:	1.9141710996627808

training epoch 147 / 500, batch #200 / 625
Loss:	1.758811593055725

training epoch 147 / 500, batch #225 / 625
Loss:	1.728161334991455

training epoch 147 / 500, batch #250 / 625
Loss:	1.665035367012024

training epoch 147 / 500, batch #275 / 625
Loss:	1.8030248880386353

training epoch 147 / 500, batch #300 / 625
Loss:	1.8587310314178467

training epoch 147 / 500, batch #325 / 625
Loss:	1.4854650497436523

training epoch 147 / 500, batch #350 / 625
Loss:	1.7758746147155762

training epoch 147 / 500, batch #375 / 625
Loss:	1.6549640893936157

training epoch 147 / 500, batch #400 / 625
Loss:	1.6697007417678833

training epoch 147 / 500, batch #425 / 625
Loss:	1.78875732421875

training epoch 147 / 500, batch #450 / 625
Loss:	2.2872374057769775

training epoch 147 / 500, batch #475 / 625
Loss:	2.251812219619751

training epoch 147 / 500, batch #500 / 625
Loss:	1.6298387050628662

training epoch 147 / 500, batch #525 / 625
Loss:	1.6937644481658936

training epoch 147 / 500, batch #550 / 625
Loss:	1.683040976524353

training epoch 147 / 500, batch #575 / 625
Loss:	1.7861639261245728

training epoch 147 / 500, batch #600 / 625
Loss:	1.7402865886688232

training epoch 148 / 500, batch #0 / 625
Loss:	1.7768503427505493

training epoch 148 / 500, batch #25 / 625
Loss:	1.6705341339111328

training epoch 148 / 500, batch #50 / 625
Loss:	1.5314754247665405

training epoch 148 / 500, batch #75 / 625
Loss:	1.7212538719177246

training epoch 148 / 500, batch #100 / 625
Loss:	1.6479634046554565

training epoch 148 / 500, batch #125 / 625
Loss:	1.9922477006912231

training epoch 148 / 500, batch #150 / 625
Loss:	2.0800094604492188

training epoch 148 / 500, batch #175 / 625
Loss:	1.673161268234253

training epoch 148 / 500, batch #200 / 625
Loss:	1.6058735847473145

training epoch 148 / 500, batch #225 / 625
Loss:	1.997678518295288

training epoch 148 / 500, batch #250 / 625
Loss:	1.733723759651184

training epoch 148 / 500, batch #275 / 625
Loss:	1.8080155849456787

training epoch 148 / 500, batch #300 / 625
Loss:	2.0037543773651123

training epoch 148 / 500, batch #325 / 625
Loss:	2.0756282806396484

training epoch 148 / 500, batch #350 / 625
Loss:	1.8282018899917603

training epoch 148 / 500, batch #375 / 625
Loss:	1.9535216093063354

training epoch 148 / 500, batch #400 / 625
Loss:	1.5355284214019775

training epoch 148 / 500, batch #425 / 625
Loss:	1.752009630203247

training epoch 148 / 500, batch #450 / 625
Loss:	1.6250391006469727

training epoch 148 / 500, batch #475 / 625
Loss:	1.6188385486602783

training epoch 148 / 500, batch #500 / 625
Loss:	2.040605306625366

training epoch 148 / 500, batch #525 / 625
Loss:	1.764855980873108

training epoch 148 / 500, batch #550 / 625
Loss:	1.9094486236572266

training epoch 148 / 500, batch #575 / 625
Loss:	1.7945754528045654

training epoch 148 / 500, batch #600 / 625
Loss:	1.600379228591919

training epoch 149 / 500, batch #0 / 625
Loss:	1.6539393663406372

training epoch 149 / 500, batch #25 / 625
Loss:	1.8004982471466064

training epoch 149 / 500, batch #50 / 625
Loss:	1.719782829284668

training epoch 149 / 500, batch #75 / 625
Loss:	1.681021809577942

training epoch 149 / 500, batch #100 / 625
Loss:	1.9812304973602295

training epoch 149 / 500, batch #125 / 625
Loss:	1.832727313041687

training epoch 149 / 500, batch #150 / 625
Loss:	1.828112006187439

training epoch 149 / 500, batch #175 / 625
Loss:	1.695533037185669

training epoch 149 / 500, batch #200 / 625
Loss:	1.8256120681762695

training epoch 149 / 500, batch #225 / 625
Loss:	2.0292670726776123

training epoch 149 / 500, batch #250 / 625
Loss:	1.997689962387085

training epoch 149 / 500, batch #275 / 625
Loss:	1.7087043523788452

training epoch 149 / 500, batch #300 / 625
Loss:	1.9999381303787231

training epoch 149 / 500, batch #325 / 625
Loss:	1.8910555839538574

training epoch 149 / 500, batch #350 / 625
Loss:	1.9733476638793945

training epoch 149 / 500, batch #375 / 625
Loss:	1.6388493776321411

training epoch 149 / 500, batch #400 / 625
Loss:	1.9110852479934692

training epoch 149 / 500, batch #425 / 625
Loss:	1.7753021717071533

training epoch 149 / 500, batch #450 / 625
Loss:	1.8357219696044922

training epoch 149 / 500, batch #475 / 625
Loss:	1.8597941398620605

training epoch 149 / 500, batch #500 / 625
Loss:	1.7069319486618042

training epoch 149 / 500, batch #525 / 625
Loss:	1.887410283088684

training epoch 149 / 500, batch #550 / 625
Loss:	1.8406039476394653

training epoch 149 / 500, batch #575 / 625
Loss:	1.7277991771697998

training epoch 149 / 500, batch #600 / 625
Loss:	1.835148811340332

training epoch 150 / 500, batch #0 / 625
Loss:	1.6483861207962036

training epoch 150 / 500, batch #25 / 625
Loss:	1.7126673460006714

training epoch 150 / 500, batch #50 / 625
Loss:	1.7783501148223877

training epoch 150 / 500, batch #75 / 625
Loss:	1.861725926399231

training epoch 150 / 500, batch #100 / 625
Loss:	1.8625744581222534

training epoch 150 / 500, batch #125 / 625
Loss:	1.9626617431640625

training epoch 150 / 500, batch #150 / 625
Loss:	1.9662686586380005

training epoch 150 / 500, batch #175 / 625
Loss:	1.74799382686615

training epoch 150 / 500, batch #200 / 625
Loss:	1.7027000188827515

training epoch 150 / 500, batch #225 / 625
Loss:	1.8387938737869263

training epoch 150 / 500, batch #250 / 625
Loss:	1.8834705352783203

training epoch 150 / 500, batch #275 / 625
Loss:	2.04002046585083

training epoch 150 / 500, batch #300 / 625
Loss:	1.7262482643127441

training epoch 150 / 500, batch #325 / 625
Loss:	1.5799169540405273

training epoch 150 / 500, batch #350 / 625
Loss:	1.5252418518066406

training epoch 150 / 500, batch #375 / 625
Loss:	1.7724740505218506

training epoch 150 / 500, batch #400 / 625
Loss:	1.6622369289398193

training epoch 150 / 500, batch #425 / 625
Loss:	1.9343851804733276

training epoch 150 / 500, batch #450 / 625
Loss:	2.175119400024414

training epoch 150 / 500, batch #475 / 625
Loss:	1.8827638626098633

training epoch 150 / 500, batch #500 / 625
Loss:	2.1709554195404053

training epoch 150 / 500, batch #525 / 625
Loss:	1.6010528802871704

training epoch 150 / 500, batch #550 / 625
Loss:	1.9554611444473267

training epoch 150 / 500, batch #575 / 625
Loss:	1.6629269123077393

training epoch 150 / 500, batch #600 / 625
Loss:	1.7612334489822388

training epoch 151 / 500, batch #0 / 625
Loss:	1.8430203199386597

training epoch 151 / 500, batch #25 / 625
Loss:	1.964543342590332

training epoch 151 / 500, batch #50 / 625
Loss:	1.6180295944213867

training epoch 151 / 500, batch #75 / 625
Loss:	1.7019238471984863

training epoch 151 / 500, batch #100 / 625
Loss:	1.8074432611465454

training epoch 151 / 500, batch #125 / 625
Loss:	1.757556438446045

training epoch 151 / 500, batch #150 / 625
Loss:	1.8708431720733643

training epoch 151 / 500, batch #175 / 625
Loss:	1.6587982177734375

training epoch 151 / 500, batch #200 / 625
Loss:	1.8470109701156616

training epoch 151 / 500, batch #225 / 625
Loss:	1.835498571395874

training epoch 151 / 500, batch #250 / 625
Loss:	1.8254594802856445

training epoch 151 / 500, batch #275 / 625
Loss:	1.7436723709106445

training epoch 151 / 500, batch #300 / 625
Loss:	1.8903578519821167

training epoch 151 / 500, batch #325 / 625
Loss:	1.7714359760284424

training epoch 151 / 500, batch #350 / 625
Loss:	1.7175980806350708

training epoch 151 / 500, batch #375 / 625
Loss:	1.91944420337677

training epoch 151 / 500, batch #400 / 625
Loss:	1.6386302709579468

training epoch 151 / 500, batch #425 / 625
Loss:	1.7760752439498901

training epoch 151 / 500, batch #450 / 625
Loss:	1.8199312686920166

training epoch 151 / 500, batch #475 / 625
Loss:	1.4158315658569336

training epoch 151 / 500, batch #500 / 625
Loss:	1.8702223300933838

training epoch 151 / 500, batch #525 / 625
Loss:	1.9572718143463135

training epoch 151 / 500, batch #550 / 625
Loss:	1.7393089532852173

training epoch 151 / 500, batch #575 / 625
Loss:	1.688528299331665

training epoch 151 / 500, batch #600 / 625
Loss:	1.8181461095809937

training epoch 152 / 500, batch #0 / 625
Loss:	1.6454819440841675

training epoch 152 / 500, batch #25 / 625
Loss:	1.9787945747375488

training epoch 152 / 500, batch #50 / 625
Loss:	1.704023838043213

training epoch 152 / 500, batch #75 / 625
Loss:	1.9806965589523315

training epoch 152 / 500, batch #100 / 625
Loss:	2.02586030960083

training epoch 152 / 500, batch #125 / 625
Loss:	1.9235565662384033

training epoch 152 / 500, batch #150 / 625
Loss:	1.7147021293640137

training epoch 152 / 500, batch #175 / 625
Loss:	1.9478747844696045

training epoch 152 / 500, batch #200 / 625
Loss:	1.5780506134033203

training epoch 152 / 500, batch #225 / 625
Loss:	1.7293665409088135

training epoch 152 / 500, batch #250 / 625
Loss:	1.730958342552185

training epoch 152 / 500, batch #275 / 625
Loss:	1.8208057880401611

training epoch 152 / 500, batch #300 / 625
Loss:	1.7593607902526855

training epoch 152 / 500, batch #325 / 625
Loss:	1.4871418476104736

training epoch 152 / 500, batch #350 / 625
Loss:	1.8097931146621704

training epoch 152 / 500, batch #375 / 625
Loss:	2.029412269592285

training epoch 152 / 500, batch #400 / 625
Loss:	1.8023111820220947

training epoch 152 / 500, batch #425 / 625
Loss:	1.7339733839035034

training epoch 152 / 500, batch #450 / 625
Loss:	1.8443816900253296

training epoch 152 / 500, batch #475 / 625
Loss:	1.9562888145446777

training epoch 152 / 500, batch #500 / 625
Loss:	1.7342431545257568

training epoch 152 / 500, batch #525 / 625
Loss:	1.8275655508041382

training epoch 152 / 500, batch #550 / 625
Loss:	1.5924487113952637

training epoch 152 / 500, batch #575 / 625
Loss:	1.9795986413955688

training epoch 152 / 500, batch #600 / 625
Loss:	1.8881959915161133

training epoch 153 / 500, batch #0 / 625
Loss:	1.6819230318069458

training epoch 153 / 500, batch #25 / 625
Loss:	1.6187598705291748

training epoch 153 / 500, batch #50 / 625
Loss:	1.73106849193573

training epoch 153 / 500, batch #75 / 625
Loss:	1.8321146965026855

training epoch 153 / 500, batch #100 / 625
Loss:	1.8001987934112549

training epoch 153 / 500, batch #125 / 625
Loss:	1.6372251510620117

training epoch 153 / 500, batch #150 / 625
Loss:	1.6762919425964355

training epoch 153 / 500, batch #175 / 625
Loss:	1.7830549478530884

training epoch 153 / 500, batch #200 / 625
Loss:	1.5822176933288574

training epoch 153 / 500, batch #225 / 625
Loss:	2.0328078269958496

training epoch 153 / 500, batch #250 / 625
Loss:	1.6098175048828125

training epoch 153 / 500, batch #275 / 625
Loss:	1.8837521076202393

training epoch 153 / 500, batch #300 / 625
Loss:	1.8608925342559814

training epoch 153 / 500, batch #325 / 625
Loss:	1.9847466945648193

training epoch 153 / 500, batch #350 / 625
Loss:	1.7332358360290527

training epoch 153 / 500, batch #375 / 625
Loss:	1.5862197875976562

training epoch 153 / 500, batch #400 / 625
Loss:	1.7469873428344727

training epoch 153 / 500, batch #425 / 625
Loss:	1.8127108812332153

training epoch 153 / 500, batch #450 / 625
Loss:	1.7485793828964233

training epoch 153 / 500, batch #475 / 625
Loss:	2.0762007236480713

training epoch 153 / 500, batch #500 / 625
Loss:	1.9519078731536865

training epoch 153 / 500, batch #525 / 625
Loss:	1.772474765777588

training epoch 153 / 500, batch #550 / 625
Loss:	1.6640830039978027

training epoch 153 / 500, batch #575 / 625
Loss:	1.7886428833007812

training epoch 153 / 500, batch #600 / 625
Loss:	1.9363713264465332

training epoch 154 / 500, batch #0 / 625
Loss:	1.9788320064544678

training epoch 154 / 500, batch #25 / 625
Loss:	1.88869309425354

training epoch 154 / 500, batch #50 / 625
Loss:	2.237037181854248

training epoch 154 / 500, batch #75 / 625
Loss:	1.5847245454788208

training epoch 154 / 500, batch #100 / 625
Loss:	1.7887709140777588

training epoch 154 / 500, batch #125 / 625
Loss:	1.3968909978866577

training epoch 154 / 500, batch #150 / 625
Loss:	1.6840901374816895

training epoch 154 / 500, batch #175 / 625
Loss:	1.580146074295044

training epoch 154 / 500, batch #200 / 625
Loss:	1.8215762376785278

training epoch 154 / 500, batch #225 / 625
Loss:	1.682206630706787

training epoch 154 / 500, batch #250 / 625
Loss:	1.8673145771026611

training epoch 154 / 500, batch #275 / 625
Loss:	1.7613024711608887

training epoch 154 / 500, batch #300 / 625
Loss:	1.5393716096878052

training epoch 154 / 500, batch #325 / 625
Loss:	1.585679292678833

training epoch 154 / 500, batch #350 / 625
Loss:	1.759026288986206

training epoch 154 / 500, batch #375 / 625
Loss:	1.8766976594924927

training epoch 154 / 500, batch #400 / 625
Loss:	1.939517855644226

training epoch 154 / 500, batch #425 / 625
Loss:	1.8994781970977783

training epoch 154 / 500, batch #450 / 625
Loss:	1.6751145124435425

training epoch 154 / 500, batch #475 / 625
Loss:	1.8343669176101685

training epoch 154 / 500, batch #500 / 625
Loss:	1.8159773349761963

training epoch 154 / 500, batch #525 / 625
Loss:	1.8346176147460938

training epoch 154 / 500, batch #550 / 625
Loss:	2.084881544113159

training epoch 154 / 500, batch #575 / 625
Loss:	1.8797129392623901

training epoch 154 / 500, batch #600 / 625
Loss:	1.8324278593063354

training epoch 155 / 500, batch #0 / 625
Loss:	1.7268141508102417

training epoch 155 / 500, batch #25 / 625
Loss:	1.9282516241073608

training epoch 155 / 500, batch #50 / 625
Loss:	1.7409108877182007

training epoch 155 / 500, batch #75 / 625
Loss:	1.620383620262146

training epoch 155 / 500, batch #100 / 625
Loss:	1.5290000438690186

training epoch 155 / 500, batch #125 / 625
Loss:	1.7523983716964722

training epoch 155 / 500, batch #150 / 625
Loss:	1.6529909372329712

training epoch 155 / 500, batch #175 / 625
Loss:	1.8439130783081055

training epoch 155 / 500, batch #200 / 625
Loss:	1.751392126083374

training epoch 155 / 500, batch #225 / 625
Loss:	1.6856341361999512

training epoch 155 / 500, batch #250 / 625
Loss:	1.7693887948989868

training epoch 155 / 500, batch #275 / 625
Loss:	1.6360670328140259

training epoch 155 / 500, batch #300 / 625
Loss:	2.007305145263672

training epoch 155 / 500, batch #325 / 625
Loss:	1.8286970853805542

training epoch 155 / 500, batch #350 / 625
Loss:	1.885399580001831

training epoch 155 / 500, batch #375 / 625
Loss:	1.9190354347229004

training epoch 155 / 500, batch #400 / 625
Loss:	1.768886923789978

training epoch 155 / 500, batch #425 / 625
Loss:	1.765836477279663

training epoch 155 / 500, batch #450 / 625
Loss:	1.688497543334961

training epoch 155 / 500, batch #475 / 625
Loss:	1.760990858078003

training epoch 155 / 500, batch #500 / 625
Loss:	1.6417688131332397

training epoch 155 / 500, batch #525 / 625
Loss:	1.6268575191497803

training epoch 155 / 500, batch #550 / 625
Loss:	1.4136552810668945

training epoch 155 / 500, batch #575 / 625
Loss:	1.7651563882827759

training epoch 155 / 500, batch #600 / 625
Loss:	1.8039577007293701

training epoch 156 / 500, batch #0 / 625
Loss:	1.929934024810791

training epoch 156 / 500, batch #25 / 625
Loss:	1.670013666152954

training epoch 156 / 500, batch #50 / 625
Loss:	1.8466777801513672

training epoch 156 / 500, batch #75 / 625
Loss:	1.9846230745315552

training epoch 156 / 500, batch #100 / 625
Loss:	1.527405023574829

training epoch 156 / 500, batch #125 / 625
Loss:	1.676714301109314

training epoch 156 / 500, batch #150 / 625
Loss:	1.955044150352478

training epoch 156 / 500, batch #175 / 625
Loss:	1.9678527116775513

training epoch 156 / 500, batch #200 / 625
Loss:	1.6588366031646729

training epoch 156 / 500, batch #225 / 625
Loss:	1.8362772464752197

training epoch 156 / 500, batch #250 / 625
Loss:	1.8839449882507324

training epoch 156 / 500, batch #275 / 625
Loss:	1.515026569366455

training epoch 156 / 500, batch #300 / 625
Loss:	1.67153000831604

training epoch 156 / 500, batch #325 / 625
Loss:	1.8440446853637695

training epoch 156 / 500, batch #350 / 625
Loss:	1.7522474527359009

training epoch 156 / 500, batch #375 / 625
Loss:	1.6465330123901367

training epoch 156 / 500, batch #400 / 625
Loss:	1.718017339706421

training epoch 156 / 500, batch #425 / 625
Loss:	1.8015000820159912

training epoch 156 / 500, batch #450 / 625
Loss:	1.927678108215332

training epoch 156 / 500, batch #475 / 625
Loss:	1.69678795337677

training epoch 156 / 500, batch #500 / 625
Loss:	1.625685453414917

training epoch 156 / 500, batch #525 / 625
Loss:	1.8381539583206177

training epoch 156 / 500, batch #550 / 625
Loss:	2.0198252201080322

training epoch 156 / 500, batch #575 / 625
Loss:	1.7856446504592896

training epoch 156 / 500, batch #600 / 625
Loss:	1.7634687423706055

training epoch 157 / 500, batch #0 / 625
Loss:	1.8437559604644775

training epoch 157 / 500, batch #25 / 625
Loss:	1.8852097988128662

training epoch 157 / 500, batch #50 / 625
Loss:	1.8511713743209839

training epoch 157 / 500, batch #75 / 625
Loss:	1.706654667854309

training epoch 157 / 500, batch #100 / 625
Loss:	1.5879782438278198

training epoch 157 / 500, batch #125 / 625
Loss:	1.826836109161377

training epoch 157 / 500, batch #150 / 625
Loss:	1.748234510421753

training epoch 157 / 500, batch #175 / 625
Loss:	1.759399175643921

training epoch 157 / 500, batch #200 / 625
Loss:	1.7756656408309937

training epoch 157 / 500, batch #225 / 625
Loss:	1.8183153867721558

training epoch 157 / 500, batch #250 / 625
Loss:	1.73732590675354

training epoch 157 / 500, batch #275 / 625
Loss:	1.6537128686904907

training epoch 157 / 500, batch #300 / 625
Loss:	1.8733484745025635

training epoch 157 / 500, batch #325 / 625
Loss:	1.7526222467422485

training epoch 157 / 500, batch #350 / 625
Loss:	1.6460106372833252

training epoch 157 / 500, batch #375 / 625
Loss:	2.069573402404785

training epoch 157 / 500, batch #400 / 625
Loss:	1.8778780698776245

training epoch 157 / 500, batch #425 / 625
Loss:	1.813206672668457

training epoch 157 / 500, batch #450 / 625
Loss:	1.5870224237442017

training epoch 157 / 500, batch #475 / 625
Loss:	1.72234308719635

training epoch 157 / 500, batch #500 / 625
Loss:	2.029893159866333

training epoch 157 / 500, batch #525 / 625
Loss:	1.8236106634140015

training epoch 157 / 500, batch #550 / 625
Loss:	1.681260108947754

training epoch 157 / 500, batch #575 / 625
Loss:	1.914087176322937

training epoch 157 / 500, batch #600 / 625
Loss:	1.6932927370071411

training epoch 158 / 500, batch #0 / 625
Loss:	1.645237922668457

training epoch 158 / 500, batch #25 / 625
Loss:	1.8865211009979248

training epoch 158 / 500, batch #50 / 625
Loss:	1.796811580657959

training epoch 158 / 500, batch #75 / 625
Loss:	1.9517065286636353

training epoch 158 / 500, batch #100 / 625
Loss:	1.7538753747940063

training epoch 158 / 500, batch #125 / 625
Loss:	1.7032618522644043

training epoch 158 / 500, batch #150 / 625
Loss:	1.7110761404037476

training epoch 158 / 500, batch #175 / 625
Loss:	1.843631386756897

training epoch 158 / 500, batch #200 / 625
Loss:	1.7907181978225708

training epoch 158 / 500, batch #225 / 625
Loss:	1.933158040046692

training epoch 158 / 500, batch #250 / 625
Loss:	1.7313616275787354

training epoch 158 / 500, batch #275 / 625
Loss:	1.5233979225158691

training epoch 158 / 500, batch #300 / 625
Loss:	1.8259258270263672

training epoch 158 / 500, batch #325 / 625
Loss:	1.6520565748214722

training epoch 158 / 500, batch #350 / 625
Loss:	1.92268705368042

training epoch 158 / 500, batch #375 / 625
Loss:	1.7448333501815796

training epoch 158 / 500, batch #400 / 625
Loss:	1.7333524227142334

training epoch 158 / 500, batch #425 / 625
Loss:	1.5656300783157349

training epoch 158 / 500, batch #450 / 625
Loss:	1.6741907596588135

training epoch 158 / 500, batch #475 / 625
Loss:	1.7827725410461426

training epoch 158 / 500, batch #500 / 625
Loss:	1.5849590301513672

training epoch 158 / 500, batch #525 / 625
Loss:	1.581567406654358

training epoch 158 / 500, batch #550 / 625
Loss:	1.758924961090088

training epoch 158 / 500, batch #575 / 625
Loss:	1.9726462364196777

training epoch 158 / 500, batch #600 / 625
Loss:	1.6371108293533325

training epoch 159 / 500, batch #0 / 625
Loss:	1.8670135736465454

training epoch 159 / 500, batch #25 / 625
Loss:	1.7637380361557007

training epoch 159 / 500, batch #50 / 625
Loss:	1.6631548404693604

training epoch 159 / 500, batch #75 / 625
Loss:	1.4902629852294922

training epoch 159 / 500, batch #100 / 625
Loss:	1.7555267810821533

training epoch 159 / 500, batch #125 / 625
Loss:	1.723667025566101

training epoch 159 / 500, batch #150 / 625
Loss:	1.7548388242721558

training epoch 159 / 500, batch #175 / 625
Loss:	1.5795294046401978

training epoch 159 / 500, batch #200 / 625
Loss:	1.9648569822311401

training epoch 159 / 500, batch #225 / 625
Loss:	1.8046009540557861

training epoch 159 / 500, batch #250 / 625
Loss:	1.7738481760025024

training epoch 159 / 500, batch #275 / 625
Loss:	1.68155038356781

training epoch 159 / 500, batch #300 / 625
Loss:	1.8794264793395996

training epoch 159 / 500, batch #325 / 625
Loss:	1.8291274309158325

training epoch 159 / 500, batch #350 / 625
Loss:	1.9419225454330444

training epoch 159 / 500, batch #375 / 625
Loss:	1.858401894569397

training epoch 159 / 500, batch #400 / 625
Loss:	1.772797703742981

training epoch 159 / 500, batch #425 / 625
Loss:	1.756962537765503

training epoch 159 / 500, batch #450 / 625
Loss:	1.786598563194275

training epoch 159 / 500, batch #475 / 625
Loss:	1.5080870389938354

training epoch 159 / 500, batch #500 / 625
Loss:	1.7412880659103394

training epoch 159 / 500, batch #525 / 625
Loss:	1.8089957237243652

training epoch 159 / 500, batch #550 / 625
Loss:	1.7835854291915894

training epoch 159 / 500, batch #575 / 625
Loss:	1.776893138885498

training epoch 159 / 500, batch #600 / 625
Loss:	1.9230941534042358

training epoch 160 / 500, batch #0 / 625
Loss:	1.5946214199066162

training epoch 160 / 500, batch #25 / 625
Loss:	1.7357019186019897

training epoch 160 / 500, batch #50 / 625
Loss:	1.8917208909988403

training epoch 160 / 500, batch #75 / 625
Loss:	1.6208494901657104

training epoch 160 / 500, batch #100 / 625
Loss:	1.6189879179000854

training epoch 160 / 500, batch #125 / 625
Loss:	1.9599788188934326

training epoch 160 / 500, batch #150 / 625
Loss:	1.68677818775177

training epoch 160 / 500, batch #175 / 625
Loss:	1.434821605682373

training epoch 160 / 500, batch #200 / 625
Loss:	1.6802926063537598

training epoch 160 / 500, batch #225 / 625
Loss:	1.7514846324920654

training epoch 160 / 500, batch #250 / 625
Loss:	1.6545037031173706

training epoch 160 / 500, batch #275 / 625
Loss:	1.7983824014663696

training epoch 160 / 500, batch #300 / 625
Loss:	1.8017245531082153

training epoch 160 / 500, batch #325 / 625
Loss:	1.7248083353042603

training epoch 160 / 500, batch #350 / 625
Loss:	1.5856508016586304

training epoch 160 / 500, batch #375 / 625
Loss:	1.6232603788375854

training epoch 160 / 500, batch #400 / 625
Loss:	1.8342150449752808

training epoch 160 / 500, batch #425 / 625
Loss:	1.9316368103027344

training epoch 160 / 500, batch #450 / 625
Loss:	1.608034610748291

training epoch 160 / 500, batch #475 / 625
Loss:	1.743543267250061

training epoch 160 / 500, batch #500 / 625
Loss:	1.647118330001831

training epoch 160 / 500, batch #525 / 625
Loss:	1.76383376121521

training epoch 160 / 500, batch #550 / 625
Loss:	1.7251650094985962

training epoch 160 / 500, batch #575 / 625
Loss:	1.7366409301757812

training epoch 160 / 500, batch #600 / 625
Loss:	1.781368374824524

training epoch 161 / 500, batch #0 / 625
Loss:	1.813541054725647

training epoch 161 / 500, batch #25 / 625
Loss:	1.850543737411499

training epoch 161 / 500, batch #50 / 625
Loss:	1.8946952819824219

training epoch 161 / 500, batch #75 / 625
Loss:	1.7842167615890503

training epoch 161 / 500, batch #100 / 625
Loss:	1.912926197052002

training epoch 161 / 500, batch #125 / 625
Loss:	1.6182442903518677

training epoch 161 / 500, batch #150 / 625
Loss:	1.7400058507919312

training epoch 161 / 500, batch #175 / 625
Loss:	1.6692471504211426

training epoch 161 / 500, batch #200 / 625
Loss:	1.6332573890686035

training epoch 161 / 500, batch #225 / 625
Loss:	1.9575660228729248

training epoch 161 / 500, batch #250 / 625
Loss:	1.8980352878570557

training epoch 161 / 500, batch #275 / 625
Loss:	1.722738265991211

training epoch 161 / 500, batch #300 / 625
Loss:	1.9687275886535645

training epoch 161 / 500, batch #325 / 625
Loss:	1.7469768524169922

training epoch 161 / 500, batch #350 / 625
Loss:	1.8833810091018677

training epoch 161 / 500, batch #375 / 625
Loss:	1.7252602577209473

training epoch 161 / 500, batch #400 / 625
Loss:	1.7908049821853638

training epoch 161 / 500, batch #425 / 625
Loss:	1.7240817546844482

training epoch 161 / 500, batch #450 / 625
Loss:	1.6183888912200928

training epoch 161 / 500, batch #475 / 625
Loss:	1.9135557413101196

training epoch 161 / 500, batch #500 / 625
Loss:	1.8112528324127197

training epoch 161 / 500, batch #525 / 625
Loss:	1.7428699731826782

training epoch 161 / 500, batch #550 / 625
Loss:	1.776497721672058

training epoch 161 / 500, batch #575 / 625
Loss:	1.9787263870239258

training epoch 161 / 500, batch #600 / 625
Loss:	1.809685230255127

training epoch 162 / 500, batch #0 / 625
Loss:	1.87616765499115

training epoch 162 / 500, batch #25 / 625
Loss:	1.6719919443130493

training epoch 162 / 500, batch #50 / 625
Loss:	1.6185604333877563

training epoch 162 / 500, batch #75 / 625
Loss:	1.6277916431427002

training epoch 162 / 500, batch #100 / 625
Loss:	1.6759536266326904

training epoch 162 / 500, batch #125 / 625
Loss:	1.8010592460632324

training epoch 162 / 500, batch #150 / 625
Loss:	1.5472029447555542

training epoch 162 / 500, batch #175 / 625
Loss:	1.674697756767273

training epoch 162 / 500, batch #200 / 625
Loss:	1.8247257471084595

training epoch 162 / 500, batch #225 / 625
Loss:	1.75619375705719

training epoch 162 / 500, batch #250 / 625
Loss:	1.591814398765564

training epoch 162 / 500, batch #275 / 625
Loss:	1.6732466220855713

training epoch 162 / 500, batch #300 / 625
Loss:	1.5494612455368042

training epoch 162 / 500, batch #325 / 625
Loss:	1.764554738998413

training epoch 162 / 500, batch #350 / 625
Loss:	1.729909896850586

training epoch 162 / 500, batch #375 / 625
Loss:	1.9238313436508179

training epoch 162 / 500, batch #400 / 625
Loss:	1.7089931964874268

training epoch 162 / 500, batch #425 / 625
Loss:	1.566644549369812

training epoch 162 / 500, batch #450 / 625
Loss:	1.7826988697052002

training epoch 162 / 500, batch #475 / 625
Loss:	2.0082995891571045

training epoch 162 / 500, batch #500 / 625
Loss:	1.6777044534683228

training epoch 162 / 500, batch #525 / 625
Loss:	1.6682202816009521

training epoch 162 / 500, batch #550 / 625
Loss:	1.6899504661560059

training epoch 162 / 500, batch #575 / 625
Loss:	1.6727837324142456

training epoch 162 / 500, batch #600 / 625
Loss:	1.8118948936462402

training epoch 163 / 500, batch #0 / 625
Loss:	1.4991854429244995

training epoch 163 / 500, batch #25 / 625
Loss:	1.7920187711715698

training epoch 163 / 500, batch #50 / 625
Loss:	1.8771166801452637

training epoch 163 / 500, batch #75 / 625
Loss:	1.7388395071029663

training epoch 163 / 500, batch #100 / 625
Loss:	1.7890492677688599

training epoch 163 / 500, batch #125 / 625
Loss:	2.0448479652404785

training epoch 163 / 500, batch #150 / 625
Loss:	1.582629680633545

training epoch 163 / 500, batch #175 / 625
Loss:	1.7590562105178833

training epoch 163 / 500, batch #200 / 625
Loss:	1.6926981210708618

training epoch 163 / 500, batch #225 / 625
Loss:	2.0909790992736816

training epoch 163 / 500, batch #250 / 625
Loss:	1.9166531562805176

training epoch 163 / 500, batch #275 / 625
Loss:	1.735215663909912

training epoch 163 / 500, batch #300 / 625
Loss:	1.8657169342041016

training epoch 163 / 500, batch #325 / 625
Loss:	1.7684266567230225

training epoch 163 / 500, batch #350 / 625
Loss:	1.9021610021591187

training epoch 163 / 500, batch #375 / 625
Loss:	1.6187081336975098

training epoch 163 / 500, batch #400 / 625
Loss:	1.7713814973831177

training epoch 163 / 500, batch #425 / 625
Loss:	1.7600840330123901

training epoch 163 / 500, batch #450 / 625
Loss:	1.7205904722213745

training epoch 163 / 500, batch #475 / 625
Loss:	1.8566992282867432

training epoch 163 / 500, batch #500 / 625
Loss:	1.910092830657959

training epoch 163 / 500, batch #525 / 625
Loss:	1.5837565660476685

training epoch 163 / 500, batch #550 / 625
Loss:	1.7427072525024414

training epoch 163 / 500, batch #575 / 625
Loss:	1.6900721788406372

training epoch 163 / 500, batch #600 / 625
Loss:	1.6167131662368774

training epoch 164 / 500, batch #0 / 625
Loss:	1.8549492359161377

training epoch 164 / 500, batch #25 / 625
Loss:	1.6586905717849731

training epoch 164 / 500, batch #50 / 625
Loss:	1.8931608200073242

training epoch 164 / 500, batch #75 / 625
Loss:	1.6585644483566284

training epoch 164 / 500, batch #100 / 625
Loss:	1.8848974704742432

training epoch 164 / 500, batch #125 / 625
Loss:	1.3135032653808594

training epoch 164 / 500, batch #150 / 625
Loss:	1.8821630477905273

training epoch 164 / 500, batch #175 / 625
Loss:	1.9499146938323975

training epoch 164 / 500, batch #200 / 625
Loss:	1.6827471256256104

training epoch 164 / 500, batch #225 / 625
Loss:	1.7074631452560425

training epoch 164 / 500, batch #250 / 625
Loss:	1.7548775672912598

training epoch 164 / 500, batch #275 / 625
Loss:	1.8708587884902954

training epoch 164 / 500, batch #300 / 625
Loss:	1.940985083580017

training epoch 164 / 500, batch #325 / 625
Loss:	1.6262335777282715

training epoch 164 / 500, batch #350 / 625
Loss:	1.7816506624221802

training epoch 164 / 500, batch #375 / 625
Loss:	1.9084199666976929

training epoch 164 / 500, batch #400 / 625
Loss:	1.9720118045806885

training epoch 164 / 500, batch #425 / 625
Loss:	1.6546788215637207

training epoch 164 / 500, batch #450 / 625
Loss:	2.075514793395996

training epoch 164 / 500, batch #475 / 625
Loss:	1.526615023612976

training epoch 164 / 500, batch #500 / 625
Loss:	1.5663787126541138

training epoch 164 / 500, batch #525 / 625
Loss:	1.7344876527786255

training epoch 164 / 500, batch #550 / 625
Loss:	1.9584788084030151

training epoch 164 / 500, batch #575 / 625
Loss:	1.8187731504440308

training epoch 164 / 500, batch #600 / 625
Loss:	1.6921864748001099

training epoch 165 / 500, batch #0 / 625
Loss:	1.9013686180114746

training epoch 165 / 500, batch #25 / 625
Loss:	1.6505863666534424

training epoch 165 / 500, batch #50 / 625
Loss:	1.810559630393982

training epoch 165 / 500, batch #75 / 625
Loss:	1.7817156314849854

training epoch 165 / 500, batch #100 / 625
Loss:	1.638231873512268

training epoch 165 / 500, batch #125 / 625
Loss:	1.9043734073638916

training epoch 165 / 500, batch #150 / 625
Loss:	1.9103150367736816

training epoch 165 / 500, batch #175 / 625
Loss:	1.978891134262085

training epoch 165 / 500, batch #200 / 625
Loss:	1.9003617763519287

training epoch 165 / 500, batch #225 / 625
Loss:	1.8633296489715576

training epoch 165 / 500, batch #250 / 625
Loss:	1.863909125328064

training epoch 165 / 500, batch #275 / 625
Loss:	1.9645737409591675

training epoch 165 / 500, batch #300 / 625
Loss:	1.8091025352478027

training epoch 165 / 500, batch #325 / 625
Loss:	1.5930287837982178

training epoch 165 / 500, batch #350 / 625
Loss:	1.5623292922973633

training epoch 165 / 500, batch #375 / 625
Loss:	1.9957594871520996

training epoch 165 / 500, batch #400 / 625
Loss:	2.026841163635254

training epoch 165 / 500, batch #425 / 625
Loss:	1.722774624824524

training epoch 165 / 500, batch #450 / 625
Loss:	1.8047946691513062

training epoch 165 / 500, batch #475 / 625
Loss:	1.32181978225708

training epoch 165 / 500, batch #500 / 625
Loss:	1.7711375951766968

training epoch 165 / 500, batch #525 / 625
Loss:	1.8832859992980957

training epoch 165 / 500, batch #550 / 625
Loss:	1.6176892518997192

training epoch 165 / 500, batch #575 / 625
Loss:	1.8885642290115356

training epoch 165 / 500, batch #600 / 625
Loss:	1.7843801975250244

training epoch 166 / 500, batch #0 / 625
Loss:	1.553479552268982

training epoch 166 / 500, batch #25 / 625
Loss:	1.5698878765106201

training epoch 166 / 500, batch #50 / 625
Loss:	1.4598430395126343

training epoch 166 / 500, batch #75 / 625
Loss:	1.5729156732559204

training epoch 166 / 500, batch #100 / 625
Loss:	1.734503149986267

training epoch 166 / 500, batch #125 / 625
Loss:	1.992095708847046

training epoch 166 / 500, batch #150 / 625
Loss:	1.7543354034423828

training epoch 166 / 500, batch #175 / 625
Loss:	1.6127198934555054

training epoch 166 / 500, batch #200 / 625
Loss:	1.7122009992599487

training epoch 166 / 500, batch #225 / 625
Loss:	1.562466025352478

training epoch 166 / 500, batch #250 / 625
Loss:	1.6691114902496338

training epoch 166 / 500, batch #275 / 625
Loss:	1.801428198814392

training epoch 166 / 500, batch #300 / 625
Loss:	1.6829450130462646

training epoch 166 / 500, batch #325 / 625
Loss:	1.7179059982299805

training epoch 166 / 500, batch #350 / 625
Loss:	1.9276585578918457

training epoch 166 / 500, batch #375 / 625
Loss:	1.6550956964492798

training epoch 166 / 500, batch #400 / 625
Loss:	1.7854458093643188

training epoch 166 / 500, batch #425 / 625
Loss:	1.5749784708023071

training epoch 166 / 500, batch #450 / 625
Loss:	1.899816632270813

training epoch 166 / 500, batch #475 / 625
Loss:	1.75407075881958

training epoch 166 / 500, batch #500 / 625
Loss:	1.6650522947311401

training epoch 166 / 500, batch #525 / 625
Loss:	1.8944058418273926

training epoch 166 / 500, batch #550 / 625
Loss:	1.9286106824874878

training epoch 166 / 500, batch #575 / 625
Loss:	1.966261625289917

training epoch 166 / 500, batch #600 / 625
Loss:	1.8137248754501343

training epoch 167 / 500, batch #0 / 625
Loss:	1.783327579498291

training epoch 167 / 500, batch #25 / 625
Loss:	1.8069381713867188

training epoch 167 / 500, batch #50 / 625
Loss:	1.7405675649642944

training epoch 167 / 500, batch #75 / 625
Loss:	1.6374486684799194

training epoch 167 / 500, batch #100 / 625
Loss:	1.9298101663589478

training epoch 167 / 500, batch #125 / 625
Loss:	1.8431557416915894

training epoch 167 / 500, batch #150 / 625
Loss:	1.620047926902771

training epoch 167 / 500, batch #175 / 625
Loss:	1.6423826217651367

training epoch 167 / 500, batch #200 / 625
Loss:	1.8153455257415771

training epoch 167 / 500, batch #225 / 625
Loss:	1.706846833229065

training epoch 167 / 500, batch #250 / 625
Loss:	1.8313621282577515

training epoch 167 / 500, batch #275 / 625
Loss:	1.802064061164856

training epoch 167 / 500, batch #300 / 625
Loss:	1.801754117012024

training epoch 167 / 500, batch #325 / 625
Loss:	1.9111419916152954

training epoch 167 / 500, batch #350 / 625
Loss:	1.9735418558120728

training epoch 167 / 500, batch #375 / 625
Loss:	1.8462222814559937

training epoch 167 / 500, batch #400 / 625
Loss:	1.8006958961486816

training epoch 167 / 500, batch #425 / 625
Loss:	1.8146387338638306

training epoch 167 / 500, batch #450 / 625
Loss:	1.8705381155014038

training epoch 167 / 500, batch #475 / 625
Loss:	1.5865931510925293

training epoch 167 / 500, batch #500 / 625
Loss:	2.076188087463379

training epoch 167 / 500, batch #525 / 625
Loss:	1.8708666563034058

training epoch 167 / 500, batch #550 / 625
Loss:	1.9395413398742676

training epoch 167 / 500, batch #575 / 625
Loss:	1.5532770156860352

training epoch 167 / 500, batch #600 / 625
Loss:	1.6007108688354492

training epoch 168 / 500, batch #0 / 625
Loss:	1.7839136123657227

training epoch 168 / 500, batch #25 / 625
Loss:	1.6019012928009033

training epoch 168 / 500, batch #50 / 625
Loss:	1.6078611612319946

training epoch 168 / 500, batch #75 / 625
Loss:	1.7771177291870117

training epoch 168 / 500, batch #100 / 625
Loss:	1.8267180919647217

training epoch 168 / 500, batch #125 / 625
Loss:	1.8016955852508545

training epoch 168 / 500, batch #150 / 625
Loss:	1.6353569030761719

training epoch 168 / 500, batch #175 / 625
Loss:	2.016787052154541

training epoch 168 / 500, batch #200 / 625
Loss:	1.760434627532959

training epoch 168 / 500, batch #225 / 625
Loss:	1.6160402297973633

training epoch 168 / 500, batch #250 / 625
Loss:	1.7388609647750854

training epoch 168 / 500, batch #275 / 625
Loss:	1.7501094341278076

training epoch 168 / 500, batch #300 / 625
Loss:	1.7365450859069824

training epoch 168 / 500, batch #325 / 625
Loss:	1.9685949087142944

training epoch 168 / 500, batch #350 / 625
Loss:	1.634330153465271

training epoch 168 / 500, batch #375 / 625
Loss:	1.5471745729446411

training epoch 168 / 500, batch #400 / 625
Loss:	1.7839385271072388

training epoch 168 / 500, batch #425 / 625
Loss:	1.7489477396011353

training epoch 168 / 500, batch #450 / 625
Loss:	1.6598618030548096

training epoch 168 / 500, batch #475 / 625
Loss:	1.7644072771072388

training epoch 168 / 500, batch #500 / 625
Loss:	1.7730671167373657

training epoch 168 / 500, batch #525 / 625
Loss:	1.7974119186401367

training epoch 168 / 500, batch #550 / 625
Loss:	1.9390422105789185

training epoch 168 / 500, batch #575 / 625
Loss:	1.8132848739624023

training epoch 168 / 500, batch #600 / 625
Loss:	1.9263886213302612

training epoch 169 / 500, batch #0 / 625
Loss:	1.8577243089675903

training epoch 169 / 500, batch #25 / 625
Loss:	1.6602449417114258

training epoch 169 / 500, batch #50 / 625
Loss:	1.8838720321655273

training epoch 169 / 500, batch #75 / 625
Loss:	1.5091454982757568

training epoch 169 / 500, batch #100 / 625
Loss:	1.9102164506912231

training epoch 169 / 500, batch #125 / 625
Loss:	1.6515443325042725

training epoch 169 / 500, batch #150 / 625
Loss:	1.8038231134414673

training epoch 169 / 500, batch #175 / 625
Loss:	2.0214171409606934

training epoch 169 / 500, batch #200 / 625
Loss:	1.7153782844543457

training epoch 169 / 500, batch #225 / 625
Loss:	1.6993671655654907

training epoch 169 / 500, batch #250 / 625
Loss:	1.6218096017837524

training epoch 169 / 500, batch #275 / 625
Loss:	1.5347946882247925

training epoch 169 / 500, batch #300 / 625
Loss:	1.818170189857483

training epoch 169 / 500, batch #325 / 625
Loss:	1.6890994310379028

training epoch 169 / 500, batch #350 / 625
Loss:	1.7786343097686768

training epoch 169 / 500, batch #375 / 625
Loss:	1.781933307647705

training epoch 169 / 500, batch #400 / 625
Loss:	1.6429890394210815

training epoch 169 / 500, batch #425 / 625
Loss:	1.8462588787078857

training epoch 169 / 500, batch #450 / 625
Loss:	1.7885628938674927

training epoch 169 / 500, batch #475 / 625
Loss:	1.7088602781295776

training epoch 169 / 500, batch #500 / 625
Loss:	1.7011096477508545

training epoch 169 / 500, batch #525 / 625
Loss:	1.7533588409423828

training epoch 169 / 500, batch #550 / 625
Loss:	1.8187286853790283

training epoch 169 / 500, batch #575 / 625
Loss:	1.7817156314849854

training epoch 169 / 500, batch #600 / 625
Loss:	1.5270684957504272

training epoch 170 / 500, batch #0 / 625
Loss:	1.7763344049453735

training epoch 170 / 500, batch #25 / 625
Loss:	2.1023175716400146

training epoch 170 / 500, batch #50 / 625
Loss:	1.6142289638519287

training epoch 170 / 500, batch #75 / 625
Loss:	1.5989415645599365

training epoch 170 / 500, batch #100 / 625
Loss:	1.6932543516159058

training epoch 170 / 500, batch #125 / 625
Loss:	1.8583104610443115

training epoch 170 / 500, batch #150 / 625
Loss:	1.8383115530014038

training epoch 170 / 500, batch #175 / 625
Loss:	1.565954327583313

training epoch 170 / 500, batch #200 / 625
Loss:	1.6032084226608276

training epoch 170 / 500, batch #225 / 625
Loss:	1.8929386138916016

training epoch 170 / 500, batch #250 / 625
Loss:	1.633115530014038

training epoch 170 / 500, batch #275 / 625
Loss:	1.713466763496399

training epoch 170 / 500, batch #300 / 625
Loss:	1.8694664239883423

training epoch 170 / 500, batch #325 / 625
Loss:	1.691054105758667

training epoch 170 / 500, batch #350 / 625
Loss:	1.7148573398590088

training epoch 170 / 500, batch #375 / 625
Loss:	1.7128047943115234

training epoch 170 / 500, batch #400 / 625
Loss:	1.9019701480865479

training epoch 170 / 500, batch #425 / 625
Loss:	1.782037615776062

training epoch 170 / 500, batch #450 / 625
Loss:	1.8801227807998657

training epoch 170 / 500, batch #475 / 625
Loss:	1.710755705833435

training epoch 170 / 500, batch #500 / 625
Loss:	1.8381017446517944

training epoch 170 / 500, batch #525 / 625
Loss:	1.7201424837112427

training epoch 170 / 500, batch #550 / 625
Loss:	2.099898099899292

training epoch 170 / 500, batch #575 / 625
Loss:	1.7005492448806763

training epoch 170 / 500, batch #600 / 625
Loss:	1.6351631879806519

training epoch 171 / 500, batch #0 / 625
Loss:	1.5404679775238037

training epoch 171 / 500, batch #25 / 625
Loss:	1.820504903793335

training epoch 171 / 500, batch #50 / 625
Loss:	1.8265376091003418

training epoch 171 / 500, batch #75 / 625
Loss:	2.026854991912842

training epoch 171 / 500, batch #100 / 625
Loss:	1.6477320194244385

training epoch 171 / 500, batch #125 / 625
Loss:	1.59769606590271

training epoch 171 / 500, batch #150 / 625
Loss:	1.7629107236862183

training epoch 171 / 500, batch #175 / 625
Loss:	1.7460477352142334

training epoch 171 / 500, batch #200 / 625
Loss:	2.1382644176483154

training epoch 171 / 500, batch #225 / 625
Loss:	1.7895431518554688

training epoch 171 / 500, batch #250 / 625
Loss:	1.6434544324874878

training epoch 171 / 500, batch #275 / 625
Loss:	1.8284333944320679

training epoch 171 / 500, batch #300 / 625
Loss:	1.7283637523651123

training epoch 171 / 500, batch #325 / 625
Loss:	1.6790149211883545

training epoch 171 / 500, batch #350 / 625
Loss:	2.1010189056396484

training epoch 171 / 500, batch #375 / 625
Loss:	1.5458098649978638

training epoch 171 / 500, batch #400 / 625
Loss:	1.8578768968582153

training epoch 171 / 500, batch #425 / 625
Loss:	1.6897683143615723

training epoch 171 / 500, batch #450 / 625
Loss:	1.8475844860076904

training epoch 171 / 500, batch #475 / 625
Loss:	1.7589906454086304

training epoch 171 / 500, batch #500 / 625
Loss:	1.9180781841278076

training epoch 171 / 500, batch #525 / 625
Loss:	1.5697853565216064

training epoch 171 / 500, batch #550 / 625
Loss:	1.8655966520309448

training epoch 171 / 500, batch #575 / 625
Loss:	1.6968141794204712

training epoch 171 / 500, batch #600 / 625
Loss:	1.891251564025879

training epoch 172 / 500, batch #0 / 625
Loss:	2.035170316696167

training epoch 172 / 500, batch #25 / 625
Loss:	1.764148235321045

training epoch 172 / 500, batch #50 / 625
Loss:	1.965693473815918

training epoch 172 / 500, batch #75 / 625
Loss:	1.895190954208374

training epoch 172 / 500, batch #100 / 625
Loss:	1.7276397943496704

training epoch 172 / 500, batch #125 / 625
Loss:	1.7083220481872559

training epoch 172 / 500, batch #150 / 625
Loss:	1.8245495557785034

training epoch 172 / 500, batch #175 / 625
Loss:	1.8276952505111694

training epoch 172 / 500, batch #200 / 625
Loss:	1.7604743242263794

training epoch 172 / 500, batch #225 / 625
Loss:	1.7304362058639526

training epoch 172 / 500, batch #250 / 625
Loss:	1.7842395305633545

training epoch 172 / 500, batch #275 / 625
Loss:	1.616376280784607

training epoch 172 / 500, batch #300 / 625
Loss:	1.6131985187530518

training epoch 172 / 500, batch #325 / 625
Loss:	1.8271570205688477

training epoch 172 / 500, batch #350 / 625
Loss:	1.8431659936904907

training epoch 172 / 500, batch #375 / 625
Loss:	1.7202489376068115

training epoch 172 / 500, batch #400 / 625
Loss:	1.7000930309295654

training epoch 172 / 500, batch #425 / 625
Loss:	1.8680473566055298

training epoch 172 / 500, batch #450 / 625
Loss:	2.094972610473633

training epoch 172 / 500, batch #475 / 625
Loss:	1.575559139251709

training epoch 172 / 500, batch #500 / 625
Loss:	1.7485482692718506

training epoch 172 / 500, batch #525 / 625
Loss:	1.6362721920013428

training epoch 172 / 500, batch #550 / 625
Loss:	1.7274601459503174

training epoch 172 / 500, batch #575 / 625
Loss:	1.8004090785980225

training epoch 172 / 500, batch #600 / 625
Loss:	1.7241652011871338

training epoch 173 / 500, batch #0 / 625
Loss:	1.9390392303466797

training epoch 173 / 500, batch #25 / 625
Loss:	1.71942138671875

training epoch 173 / 500, batch #50 / 625
Loss:	1.7599022388458252

training epoch 173 / 500, batch #75 / 625
Loss:	1.7442823648452759

training epoch 173 / 500, batch #100 / 625
Loss:	1.8772156238555908

training epoch 173 / 500, batch #125 / 625
Loss:	1.8228918313980103

training epoch 173 / 500, batch #150 / 625
Loss:	1.5892332792282104

training epoch 173 / 500, batch #175 / 625
Loss:	1.6993777751922607

training epoch 173 / 500, batch #200 / 625
Loss:	1.6410737037658691

training epoch 173 / 500, batch #225 / 625
Loss:	1.8815675973892212

training epoch 173 / 500, batch #250 / 625
Loss:	1.7565367221832275

training epoch 173 / 500, batch #275 / 625
Loss:	1.9127802848815918

training epoch 173 / 500, batch #300 / 625
Loss:	1.5954147577285767

training epoch 173 / 500, batch #325 / 625
Loss:	1.8624430894851685

training epoch 173 / 500, batch #350 / 625
Loss:	1.7637463808059692

training epoch 173 / 500, batch #375 / 625
Loss:	1.829728126525879

training epoch 173 / 500, batch #400 / 625
Loss:	1.9092764854431152

training epoch 173 / 500, batch #425 / 625
Loss:	1.7685778141021729

training epoch 173 / 500, batch #450 / 625
Loss:	1.7625725269317627

training epoch 173 / 500, batch #475 / 625
Loss:	1.8572556972503662

training epoch 173 / 500, batch #500 / 625
Loss:	1.7554997205734253

training epoch 173 / 500, batch #525 / 625
Loss:	1.6959441900253296

training epoch 173 / 500, batch #550 / 625
Loss:	1.6822123527526855

training epoch 173 / 500, batch #575 / 625
Loss:	1.6545023918151855

training epoch 173 / 500, batch #600 / 625
Loss:	1.7184231281280518

training epoch 174 / 500, batch #0 / 625
Loss:	1.6940544843673706

training epoch 174 / 500, batch #25 / 625
Loss:	1.8161698579788208

training epoch 174 / 500, batch #50 / 625
Loss:	1.7999811172485352

training epoch 174 / 500, batch #75 / 625
Loss:	1.6775858402252197

training epoch 174 / 500, batch #100 / 625
Loss:	1.5358870029449463

training epoch 174 / 500, batch #125 / 625
Loss:	1.9952199459075928

training epoch 174 / 500, batch #150 / 625
Loss:	1.69319486618042

training epoch 174 / 500, batch #175 / 625
Loss:	1.5717716217041016

training epoch 174 / 500, batch #200 / 625
Loss:	1.6303672790527344

training epoch 174 / 500, batch #225 / 625
Loss:	1.7687212228775024

training epoch 174 / 500, batch #250 / 625
Loss:	1.9782931804656982

training epoch 174 / 500, batch #275 / 625
Loss:	1.8052353858947754

training epoch 174 / 500, batch #300 / 625
Loss:	1.6231087446212769

training epoch 174 / 500, batch #325 / 625
Loss:	1.872765064239502

training epoch 174 / 500, batch #350 / 625
Loss:	1.4824059009552002

training epoch 174 / 500, batch #375 / 625
Loss:	1.8693103790283203

training epoch 174 / 500, batch #400 / 625
Loss:	2.072019577026367

training epoch 174 / 500, batch #425 / 625
Loss:	1.5263820886611938

training epoch 174 / 500, batch #450 / 625
Loss:	1.7554250955581665

training epoch 174 / 500, batch #475 / 625
Loss:	1.8520283699035645

training epoch 174 / 500, batch #500 / 625
Loss:	1.8156013488769531

training epoch 174 / 500, batch #525 / 625
Loss:	1.7024638652801514

training epoch 174 / 500, batch #550 / 625
Loss:	1.7940939664840698

training epoch 174 / 500, batch #575 / 625
Loss:	1.8919788599014282

training epoch 174 / 500, batch #600 / 625
Loss:	2.1167333126068115

training epoch 175 / 500, batch #0 / 625
Loss:	1.790112853050232

training epoch 175 / 500, batch #25 / 625
Loss:	1.7930235862731934

training epoch 175 / 500, batch #50 / 625
Loss:	1.7759116888046265

training epoch 175 / 500, batch #75 / 625
Loss:	1.7523173093795776

training epoch 175 / 500, batch #100 / 625
Loss:	1.5271669626235962

training epoch 175 / 500, batch #125 / 625
Loss:	2.062544107437134

training epoch 175 / 500, batch #150 / 625
Loss:	1.8827999830245972

training epoch 175 / 500, batch #175 / 625
Loss:	1.7303762435913086

training epoch 175 / 500, batch #200 / 625
Loss:	1.7015101909637451

training epoch 175 / 500, batch #225 / 625
Loss:	1.836920142173767

training epoch 175 / 500, batch #250 / 625
Loss:	1.6623188257217407

training epoch 175 / 500, batch #275 / 625
Loss:	1.8721320629119873

training epoch 175 / 500, batch #300 / 625
Loss:	1.8842469453811646

training epoch 175 / 500, batch #325 / 625
Loss:	1.7711378335952759

training epoch 175 / 500, batch #350 / 625
Loss:	1.7577992677688599

training epoch 175 / 500, batch #375 / 625
Loss:	1.8640216588974

training epoch 175 / 500, batch #400 / 625
Loss:	1.724021553993225

training epoch 175 / 500, batch #425 / 625
Loss:	1.7073919773101807

training epoch 175 / 500, batch #450 / 625
Loss:	1.545242428779602

training epoch 175 / 500, batch #475 / 625
Loss:	1.7907973527908325

training epoch 175 / 500, batch #500 / 625
Loss:	1.9204972982406616

training epoch 175 / 500, batch #525 / 625
Loss:	1.775489330291748

training epoch 175 / 500, batch #550 / 625
Loss:	1.8324674367904663

training epoch 175 / 500, batch #575 / 625
Loss:	1.97158944606781

training epoch 175 / 500, batch #600 / 625
Loss:	1.8768134117126465

training epoch 176 / 500, batch #0 / 625
Loss:	1.5110371112823486

training epoch 176 / 500, batch #25 / 625
Loss:	1.8113468885421753

training epoch 176 / 500, batch #50 / 625
Loss:	1.9158705472946167

training epoch 176 / 500, batch #75 / 625
Loss:	1.7396533489227295

training epoch 176 / 500, batch #100 / 625
Loss:	1.8565495014190674

training epoch 176 / 500, batch #125 / 625
Loss:	1.8284391164779663

training epoch 176 / 500, batch #150 / 625
Loss:	1.7750734090805054

training epoch 176 / 500, batch #175 / 625
Loss:	1.9113545417785645

training epoch 176 / 500, batch #200 / 625
Loss:	1.6084307432174683

training epoch 176 / 500, batch #225 / 625
Loss:	1.9980778694152832

training epoch 176 / 500, batch #250 / 625
Loss:	2.009369134902954

training epoch 176 / 500, batch #275 / 625
Loss:	1.825616478919983

training epoch 176 / 500, batch #300 / 625
Loss:	1.6634122133255005

training epoch 176 / 500, batch #325 / 625
Loss:	1.6293466091156006

training epoch 176 / 500, batch #350 / 625
Loss:	1.8915282487869263

training epoch 176 / 500, batch #375 / 625
Loss:	1.5517243146896362

training epoch 176 / 500, batch #400 / 625
Loss:	1.7276768684387207

training epoch 176 / 500, batch #425 / 625
Loss:	1.7098875045776367

training epoch 176 / 500, batch #450 / 625
Loss:	1.846682071685791

training epoch 176 / 500, batch #475 / 625
Loss:	1.7585691213607788

training epoch 176 / 500, batch #500 / 625
Loss:	1.7138899564743042

training epoch 176 / 500, batch #525 / 625
Loss:	1.9589698314666748

training epoch 176 / 500, batch #550 / 625
Loss:	1.9970301389694214

training epoch 176 / 500, batch #575 / 625
Loss:	1.8197929859161377

training epoch 176 / 500, batch #600 / 625
Loss:	1.3984310626983643

training epoch 177 / 500, batch #0 / 625
Loss:	1.883663535118103

training epoch 177 / 500, batch #25 / 625
Loss:	1.8768757581710815

training epoch 177 / 500, batch #50 / 625
Loss:	1.831100344657898

training epoch 177 / 500, batch #75 / 625
Loss:	2.009229898452759

training epoch 177 / 500, batch #100 / 625
Loss:	1.7922152280807495

training epoch 177 / 500, batch #125 / 625
Loss:	1.70322585105896

training epoch 177 / 500, batch #150 / 625
Loss:	1.8359636068344116

training epoch 177 / 500, batch #175 / 625
Loss:	1.5934888124465942

training epoch 177 / 500, batch #200 / 625
Loss:	1.9358981847763062

training epoch 177 / 500, batch #225 / 625
Loss:	1.5049155950546265

training epoch 177 / 500, batch #250 / 625
Loss:	1.9185842275619507

training epoch 177 / 500, batch #275 / 625
Loss:	1.6987577676773071

training epoch 177 / 500, batch #300 / 625
Loss:	1.6470892429351807

training epoch 177 / 500, batch #325 / 625
Loss:	1.6919293403625488

training epoch 177 / 500, batch #350 / 625
Loss:	1.8127938508987427

training epoch 177 / 500, batch #375 / 625
Loss:	2.026054859161377

training epoch 177 / 500, batch #400 / 625
Loss:	1.9748914241790771

training epoch 177 / 500, batch #425 / 625
Loss:	1.5904039144515991

training epoch 177 / 500, batch #450 / 625
Loss:	1.857444405555725

training epoch 177 / 500, batch #475 / 625
Loss:	1.6377304792404175

training epoch 177 / 500, batch #500 / 625
Loss:	1.6893486976623535

training epoch 177 / 500, batch #525 / 625
Loss:	1.742243766784668

training epoch 177 / 500, batch #550 / 625
Loss:	1.8115242719650269

training epoch 177 / 500, batch #575 / 625
Loss:	1.971651554107666

training epoch 177 / 500, batch #600 / 625
Loss:	1.5797865390777588

training epoch 178 / 500, batch #0 / 625
Loss:	1.6520556211471558

training epoch 178 / 500, batch #25 / 625
Loss:	1.8142911195755005

training epoch 178 / 500, batch #50 / 625
Loss:	1.939939022064209

training epoch 178 / 500, batch #75 / 625
Loss:	1.9498604536056519

training epoch 178 / 500, batch #100 / 625
Loss:	1.9330291748046875

training epoch 178 / 500, batch #125 / 625
Loss:	1.8684130907058716

training epoch 178 / 500, batch #150 / 625
Loss:	1.811623454093933

training epoch 178 / 500, batch #175 / 625
Loss:	1.6163058280944824

training epoch 178 / 500, batch #200 / 625
Loss:	1.860094428062439

training epoch 178 / 500, batch #225 / 625
Loss:	1.801438331604004

training epoch 178 / 500, batch #250 / 625
Loss:	1.7297321557998657

training epoch 178 / 500, batch #275 / 625
Loss:	1.683436632156372

training epoch 178 / 500, batch #300 / 625
Loss:	1.6238152980804443

training epoch 178 / 500, batch #325 / 625
Loss:	1.5366328954696655

training epoch 178 / 500, batch #350 / 625
Loss:	1.7591590881347656

training epoch 178 / 500, batch #375 / 625
Loss:	1.7119214534759521

training epoch 178 / 500, batch #400 / 625
Loss:	1.5146890878677368

training epoch 178 / 500, batch #425 / 625
Loss:	1.9378626346588135

training epoch 178 / 500, batch #450 / 625
Loss:	1.9880486726760864

training epoch 178 / 500, batch #475 / 625
Loss:	1.8444128036499023

training epoch 178 / 500, batch #500 / 625
Loss:	1.5860662460327148

training epoch 178 / 500, batch #525 / 625
Loss:	1.6146454811096191

training epoch 178 / 500, batch #550 / 625
Loss:	1.8658970594406128

training epoch 178 / 500, batch #575 / 625
Loss:	1.592394232749939

training epoch 178 / 500, batch #600 / 625
Loss:	1.6130306720733643

training epoch 179 / 500, batch #0 / 625
Loss:	1.6672422885894775

training epoch 179 / 500, batch #25 / 625
Loss:	1.5431345701217651

training epoch 179 / 500, batch #50 / 625
Loss:	1.7009674310684204

training epoch 179 / 500, batch #75 / 625
Loss:	1.7815477848052979

training epoch 179 / 500, batch #100 / 625
Loss:	1.924060583114624

training epoch 179 / 500, batch #125 / 625
Loss:	1.6737558841705322

training epoch 179 / 500, batch #150 / 625
Loss:	1.4572908878326416

training epoch 179 / 500, batch #175 / 625
Loss:	1.8859304189682007

training epoch 179 / 500, batch #200 / 625
Loss:	1.8699979782104492

training epoch 179 / 500, batch #225 / 625
Loss:	1.7068243026733398

training epoch 179 / 500, batch #250 / 625
Loss:	1.6989827156066895

training epoch 179 / 500, batch #275 / 625
Loss:	1.686699628829956

training epoch 179 / 500, batch #300 / 625
Loss:	1.7910791635513306

training epoch 179 / 500, batch #325 / 625
Loss:	1.8733261823654175

training epoch 179 / 500, batch #350 / 625
Loss:	1.6975376605987549

training epoch 179 / 500, batch #375 / 625
Loss:	1.8067619800567627

training epoch 179 / 500, batch #400 / 625
Loss:	1.995539903640747

training epoch 179 / 500, batch #425 / 625
Loss:	1.7342365980148315

training epoch 179 / 500, batch #450 / 625
Loss:	1.8052154779434204

training epoch 179 / 500, batch #475 / 625
Loss:	1.722985029220581

training epoch 179 / 500, batch #500 / 625
Loss:	1.8677332401275635

training epoch 179 / 500, batch #525 / 625
Loss:	2.073065757751465

training epoch 179 / 500, batch #550 / 625
Loss:	1.8162177801132202

training epoch 179 / 500, batch #575 / 625
Loss:	1.6106547117233276

training epoch 179 / 500, batch #600 / 625
Loss:	1.682059645652771

training epoch 180 / 500, batch #0 / 625
Loss:	1.5515443086624146

training epoch 180 / 500, batch #25 / 625
Loss:	1.4983631372451782

training epoch 180 / 500, batch #50 / 625
Loss:	1.735222578048706

training epoch 180 / 500, batch #75 / 625
Loss:	1.62069571018219

training epoch 180 / 500, batch #100 / 625
Loss:	1.8119630813598633

training epoch 180 / 500, batch #125 / 625
Loss:	1.9998266696929932

training epoch 180 / 500, batch #150 / 625
Loss:	1.8098366260528564

training epoch 180 / 500, batch #175 / 625
Loss:	1.5137683153152466

training epoch 180 / 500, batch #200 / 625
Loss:	1.7256014347076416

training epoch 180 / 500, batch #225 / 625
Loss:	1.7897512912750244

training epoch 180 / 500, batch #250 / 625
Loss:	1.895542025566101

training epoch 180 / 500, batch #275 / 625
Loss:	1.9335598945617676

training epoch 180 / 500, batch #300 / 625
Loss:	1.816388726234436

training epoch 180 / 500, batch #325 / 625
Loss:	1.8203449249267578

training epoch 180 / 500, batch #350 / 625
Loss:	1.9005907773971558

training epoch 180 / 500, batch #375 / 625
Loss:	1.575850486755371

training epoch 180 / 500, batch #400 / 625
Loss:	1.7572110891342163

training epoch 180 / 500, batch #425 / 625
Loss:	1.7286978960037231

training epoch 180 / 500, batch #450 / 625
Loss:	1.764668583869934

training epoch 180 / 500, batch #475 / 625
Loss:	1.8099135160446167

training epoch 180 / 500, batch #500 / 625
Loss:	1.6936655044555664

training epoch 180 / 500, batch #525 / 625
Loss:	1.7895272970199585

training epoch 180 / 500, batch #550 / 625
Loss:	1.411697268486023

training epoch 180 / 500, batch #575 / 625
Loss:	1.9249119758605957

training epoch 180 / 500, batch #600 / 625
Loss:	1.783355474472046

training epoch 181 / 500, batch #0 / 625
Loss:	1.8239675760269165

training epoch 181 / 500, batch #25 / 625
Loss:	1.7393932342529297

training epoch 181 / 500, batch #50 / 625
Loss:	1.7603164911270142

training epoch 181 / 500, batch #75 / 625
Loss:	1.7771412134170532

training epoch 181 / 500, batch #100 / 625
Loss:	2.0598886013031006

training epoch 181 / 500, batch #125 / 625
Loss:	1.7663575410842896

training epoch 181 / 500, batch #150 / 625
Loss:	1.8079938888549805

training epoch 181 / 500, batch #175 / 625
Loss:	1.8204305171966553

training epoch 181 / 500, batch #200 / 625
Loss:	1.7468162775039673

training epoch 181 / 500, batch #225 / 625
Loss:	1.7817604541778564

training epoch 181 / 500, batch #250 / 625
Loss:	1.827027440071106

training epoch 181 / 500, batch #275 / 625
Loss:	1.7558770179748535

training epoch 181 / 500, batch #300 / 625
Loss:	1.7796167135238647

training epoch 181 / 500, batch #325 / 625
Loss:	1.6966071128845215

training epoch 181 / 500, batch #350 / 625
Loss:	1.5537099838256836

training epoch 181 / 500, batch #375 / 625
Loss:	1.786888837814331

training epoch 181 / 500, batch #400 / 625
Loss:	2.0618197917938232

training epoch 181 / 500, batch #425 / 625
Loss:	1.4134955406188965

training epoch 181 / 500, batch #450 / 625
Loss:	1.91264808177948

training epoch 181 / 500, batch #475 / 625
Loss:	1.9242607355117798

training epoch 181 / 500, batch #500 / 625
Loss:	1.7731572389602661

training epoch 181 / 500, batch #525 / 625
Loss:	1.8586180210113525

training epoch 181 / 500, batch #550 / 625
Loss:	1.6397573947906494

training epoch 181 / 500, batch #575 / 625
Loss:	1.8409966230392456

training epoch 181 / 500, batch #600 / 625
Loss:	1.6328585147857666

training epoch 182 / 500, batch #0 / 625
Loss:	1.7417601346969604

training epoch 182 / 500, batch #25 / 625
Loss:	1.5845354795455933

training epoch 182 / 500, batch #50 / 625
Loss:	1.9697057008743286

training epoch 182 / 500, batch #75 / 625
Loss:	1.8369084596633911

training epoch 182 / 500, batch #100 / 625
Loss:	1.9182558059692383

training epoch 182 / 500, batch #125 / 625
Loss:	1.8263577222824097

training epoch 182 / 500, batch #150 / 625
Loss:	1.4979405403137207

training epoch 182 / 500, batch #175 / 625
Loss:	1.5520561933517456

training epoch 182 / 500, batch #200 / 625
Loss:	1.7760696411132812

training epoch 182 / 500, batch #225 / 625
Loss:	1.8201912641525269

training epoch 182 / 500, batch #250 / 625
Loss:	1.6727981567382812

training epoch 182 / 500, batch #275 / 625
Loss:	1.778618574142456

training epoch 182 / 500, batch #300 / 625
Loss:	1.7551192045211792

training epoch 182 / 500, batch #325 / 625
Loss:	1.5659312009811401

training epoch 182 / 500, batch #350 / 625
Loss:	1.6411364078521729

training epoch 182 / 500, batch #375 / 625
Loss:	1.790142297744751

training epoch 182 / 500, batch #400 / 625
Loss:	1.5995837450027466

training epoch 182 / 500, batch #425 / 625
Loss:	1.7080525159835815

training epoch 182 / 500, batch #450 / 625
Loss:	1.6771163940429688

training epoch 182 / 500, batch #475 / 625
Loss:	1.7263275384902954

training epoch 182 / 500, batch #500 / 625
Loss:	1.7431843280792236

training epoch 182 / 500, batch #525 / 625
Loss:	1.8408153057098389

training epoch 182 / 500, batch #550 / 625
Loss:	1.7888355255126953

training epoch 182 / 500, batch #575 / 625
Loss:	1.768815040588379

training epoch 182 / 500, batch #600 / 625
Loss:	1.8596535921096802

training epoch 183 / 500, batch #0 / 625
Loss:	1.6255041360855103

training epoch 183 / 500, batch #25 / 625
Loss:	1.588639259338379

training epoch 183 / 500, batch #50 / 625
Loss:	1.5091350078582764

training epoch 183 / 500, batch #75 / 625
Loss:	1.6435496807098389

training epoch 183 / 500, batch #100 / 625
Loss:	1.9204407930374146

training epoch 183 / 500, batch #125 / 625
Loss:	1.6662777662277222

training epoch 183 / 500, batch #150 / 625
Loss:	1.6298959255218506

training epoch 183 / 500, batch #175 / 625
Loss:	1.6092453002929688

training epoch 183 / 500, batch #200 / 625
Loss:	1.8203089237213135

training epoch 183 / 500, batch #225 / 625
Loss:	1.7928811311721802

training epoch 183 / 500, batch #250 / 625
Loss:	1.523768424987793

training epoch 183 / 500, batch #275 / 625
Loss:	1.517012357711792

training epoch 183 / 500, batch #300 / 625
Loss:	2.0157346725463867

training epoch 183 / 500, batch #325 / 625
Loss:	1.9447983503341675

training epoch 183 / 500, batch #350 / 625
Loss:	2.0299034118652344

training epoch 183 / 500, batch #375 / 625
Loss:	1.6956684589385986

training epoch 183 / 500, batch #400 / 625
Loss:	1.7255098819732666

training epoch 183 / 500, batch #425 / 625
Loss:	1.7349333763122559

training epoch 183 / 500, batch #450 / 625
Loss:	1.6404643058776855

training epoch 183 / 500, batch #475 / 625
Loss:	2.0323498249053955

training epoch 183 / 500, batch #500 / 625
Loss:	1.6000975370407104

training epoch 183 / 500, batch #525 / 625
Loss:	1.742184042930603

training epoch 183 / 500, batch #550 / 625
Loss:	1.4012651443481445

training epoch 183 / 500, batch #575 / 625
Loss:	1.8209344148635864

training epoch 183 / 500, batch #600 / 625
Loss:	1.829089879989624

training epoch 184 / 500, batch #0 / 625
Loss:	1.5303343534469604

training epoch 184 / 500, batch #25 / 625
Loss:	1.7445757389068604

training epoch 184 / 500, batch #50 / 625
Loss:	1.713865041732788

training epoch 184 / 500, batch #75 / 625
Loss:	1.706971287727356

training epoch 184 / 500, batch #100 / 625
Loss:	1.5802273750305176

training epoch 184 / 500, batch #125 / 625
Loss:	2.0656368732452393

training epoch 184 / 500, batch #150 / 625
Loss:	1.7153775691986084

training epoch 184 / 500, batch #175 / 625
Loss:	1.6847479343414307

training epoch 184 / 500, batch #200 / 625
Loss:	1.727716088294983

training epoch 184 / 500, batch #225 / 625
Loss:	1.906105637550354

training epoch 184 / 500, batch #250 / 625
Loss:	1.93994140625

training epoch 184 / 500, batch #275 / 625
Loss:	1.7950751781463623

training epoch 184 / 500, batch #300 / 625
Loss:	1.843416690826416

training epoch 184 / 500, batch #325 / 625
Loss:	1.794220209121704

training epoch 184 / 500, batch #350 / 625
Loss:	1.7953462600708008

training epoch 184 / 500, batch #375 / 625
Loss:	1.7953640222549438

training epoch 184 / 500, batch #400 / 625
Loss:	1.8692072629928589

training epoch 184 / 500, batch #425 / 625
Loss:	1.8377230167388916

training epoch 184 / 500, batch #450 / 625
Loss:	1.7882508039474487

training epoch 184 / 500, batch #475 / 625
Loss:	1.8595025539398193

training epoch 184 / 500, batch #500 / 625
Loss:	1.7057971954345703

training epoch 184 / 500, batch #525 / 625
Loss:	1.8312313556671143

training epoch 184 / 500, batch #550 / 625
Loss:	1.7241086959838867

training epoch 184 / 500, batch #575 / 625
Loss:	1.550358772277832

training epoch 184 / 500, batch #600 / 625
Loss:	1.7632652521133423

training epoch 185 / 500, batch #0 / 625
Loss:	1.834717035293579

training epoch 185 / 500, batch #25 / 625
Loss:	1.7781673669815063

training epoch 185 / 500, batch #50 / 625
Loss:	1.692946195602417

training epoch 185 / 500, batch #75 / 625
Loss:	1.6465383768081665

training epoch 185 / 500, batch #100 / 625
Loss:	1.7954834699630737

training epoch 185 / 500, batch #125 / 625
Loss:	1.8653442859649658

training epoch 185 / 500, batch #150 / 625
Loss:	1.7701725959777832

training epoch 185 / 500, batch #175 / 625
Loss:	1.8106615543365479

training epoch 185 / 500, batch #200 / 625
Loss:	1.7798393964767456

training epoch 185 / 500, batch #225 / 625
Loss:	1.662392020225525

training epoch 185 / 500, batch #250 / 625
Loss:	1.5817526578903198

training epoch 185 / 500, batch #275 / 625
Loss:	1.8160362243652344

training epoch 185 / 500, batch #300 / 625
Loss:	1.9540115594863892

training epoch 185 / 500, batch #325 / 625
Loss:	1.5954928398132324

training epoch 185 / 500, batch #350 / 625
Loss:	1.8491902351379395

training epoch 185 / 500, batch #375 / 625
Loss:	1.543379545211792

training epoch 185 / 500, batch #400 / 625
Loss:	1.7129226922988892

training epoch 185 / 500, batch #425 / 625
Loss:	1.4696520566940308

training epoch 185 / 500, batch #450 / 625
Loss:	1.8204765319824219

training epoch 185 / 500, batch #475 / 625
Loss:	1.6692938804626465

training epoch 185 / 500, batch #500 / 625
Loss:	1.76499605178833

training epoch 185 / 500, batch #525 / 625
Loss:	1.5732295513153076

training epoch 185 / 500, batch #550 / 625
Loss:	1.7144391536712646

training epoch 185 / 500, batch #575 / 625
Loss:	1.6300188302993774

training epoch 185 / 500, batch #600 / 625
Loss:	1.9073593616485596

training epoch 186 / 500, batch #0 / 625
Loss:	1.6097959280014038

training epoch 186 / 500, batch #25 / 625
Loss:	1.6331236362457275

training epoch 186 / 500, batch #50 / 625
Loss:	1.7493492364883423

training epoch 186 / 500, batch #75 / 625
Loss:	1.8335455656051636

training epoch 186 / 500, batch #100 / 625
Loss:	1.9289398193359375

training epoch 186 / 500, batch #125 / 625
Loss:	1.6778533458709717

training epoch 186 / 500, batch #150 / 625
Loss:	1.59821355342865

training epoch 186 / 500, batch #175 / 625
Loss:	1.747994303703308

training epoch 186 / 500, batch #200 / 625
Loss:	1.9013612270355225

training epoch 186 / 500, batch #225 / 625
Loss:	1.8238469362258911

training epoch 186 / 500, batch #250 / 625
Loss:	1.6990128755569458

training epoch 186 / 500, batch #275 / 625
Loss:	1.7366796731948853

training epoch 186 / 500, batch #300 / 625
Loss:	1.8664286136627197

training epoch 186 / 500, batch #325 / 625
Loss:	1.8704508543014526

training epoch 186 / 500, batch #350 / 625
Loss:	1.6947070360183716

training epoch 186 / 500, batch #375 / 625
Loss:	1.566557765007019

training epoch 186 / 500, batch #400 / 625
Loss:	1.7518082857131958

training epoch 186 / 500, batch #425 / 625
Loss:	1.8861947059631348

training epoch 186 / 500, batch #450 / 625
Loss:	1.6395647525787354

training epoch 186 / 500, batch #475 / 625
Loss:	1.8111308813095093

training epoch 186 / 500, batch #500 / 625
Loss:	1.754426121711731

training epoch 186 / 500, batch #525 / 625
Loss:	1.8802566528320312

training epoch 186 / 500, batch #550 / 625
Loss:	1.898603916168213

training epoch 186 / 500, batch #575 / 625
Loss:	1.5293102264404297

training epoch 186 / 500, batch #600 / 625
Loss:	1.6628423929214478

training epoch 187 / 500, batch #0 / 625
Loss:	1.7405192852020264

training epoch 187 / 500, batch #25 / 625
Loss:	1.80143141746521

training epoch 187 / 500, batch #50 / 625
Loss:	1.860365867614746

training epoch 187 / 500, batch #75 / 625
Loss:	1.8017749786376953

training epoch 187 / 500, batch #100 / 625
Loss:	1.5376192331314087

training epoch 187 / 500, batch #125 / 625
Loss:	1.9289900064468384

training epoch 187 / 500, batch #150 / 625
Loss:	1.8521150350570679

training epoch 187 / 500, batch #175 / 625
Loss:	1.7128779888153076

training epoch 187 / 500, batch #200 / 625
Loss:	2.1097047328948975

training epoch 187 / 500, batch #225 / 625
Loss:	1.651015281677246

training epoch 187 / 500, batch #250 / 625
Loss:	1.6209746599197388

training epoch 187 / 500, batch #275 / 625
Loss:	1.803200125694275

training epoch 187 / 500, batch #300 / 625
Loss:	1.697790503501892

training epoch 187 / 500, batch #325 / 625
Loss:	1.8570903539657593

training epoch 187 / 500, batch #350 / 625
Loss:	1.7786259651184082

training epoch 187 / 500, batch #375 / 625
Loss:	1.9456672668457031

training epoch 187 / 500, batch #400 / 625
Loss:	1.8228530883789062

training epoch 187 / 500, batch #425 / 625
Loss:	1.5868903398513794

training epoch 187 / 500, batch #450 / 625
Loss:	1.7544611692428589

training epoch 187 / 500, batch #475 / 625
Loss:	1.8178980350494385

training epoch 187 / 500, batch #500 / 625
Loss:	1.8451573848724365

training epoch 187 / 500, batch #525 / 625
Loss:	1.672452688217163

training epoch 187 / 500, batch #550 / 625
Loss:	1.5836833715438843

training epoch 187 / 500, batch #575 / 625
Loss:	1.652076005935669

training epoch 187 / 500, batch #600 / 625
Loss:	1.8082332611083984

training epoch 188 / 500, batch #0 / 625
Loss:	1.8828730583190918

training epoch 188 / 500, batch #25 / 625
Loss:	1.5118306875228882

training epoch 188 / 500, batch #50 / 625
Loss:	1.8750550746917725

training epoch 188 / 500, batch #75 / 625
Loss:	1.8108996152877808

training epoch 188 / 500, batch #100 / 625
Loss:	1.6976662874221802

training epoch 188 / 500, batch #125 / 625
Loss:	1.5835195779800415

training epoch 188 / 500, batch #150 / 625
Loss:	1.511534571647644

training epoch 188 / 500, batch #175 / 625
Loss:	1.9012997150421143

training epoch 188 / 500, batch #200 / 625
Loss:	1.6308727264404297

training epoch 188 / 500, batch #225 / 625
Loss:	1.8034729957580566

training epoch 188 / 500, batch #250 / 625
Loss:	1.8023537397384644

training epoch 188 / 500, batch #275 / 625
Loss:	1.7650033235549927

training epoch 188 / 500, batch #300 / 625
Loss:	1.6543828248977661

training epoch 188 / 500, batch #325 / 625
Loss:	1.5868656635284424

training epoch 188 / 500, batch #350 / 625
Loss:	1.8717679977416992

training epoch 188 / 500, batch #375 / 625
Loss:	1.6244463920593262

training epoch 188 / 500, batch #400 / 625
Loss:	1.646701455116272

training epoch 188 / 500, batch #425 / 625
Loss:	1.726935863494873

training epoch 188 / 500, batch #450 / 625
Loss:	1.9149891138076782

training epoch 188 / 500, batch #475 / 625
Loss:	1.7644494771957397

training epoch 188 / 500, batch #500 / 625
Loss:	1.7324635982513428

training epoch 188 / 500, batch #525 / 625
Loss:	1.926536202430725

training epoch 188 / 500, batch #550 / 625
Loss:	1.7042863368988037

training epoch 188 / 500, batch #575 / 625
Loss:	1.9032219648361206

training epoch 188 / 500, batch #600 / 625
Loss:	2.123222827911377

training epoch 189 / 500, batch #0 / 625
Loss:	1.6477277278900146

training epoch 189 / 500, batch #25 / 625
Loss:	1.6942050457000732

training epoch 189 / 500, batch #50 / 625
Loss:	1.71645188331604

training epoch 189 / 500, batch #75 / 625
Loss:	1.702297568321228

training epoch 189 / 500, batch #100 / 625
Loss:	1.6926383972167969

training epoch 189 / 500, batch #125 / 625
Loss:	1.7918989658355713

training epoch 189 / 500, batch #150 / 625
Loss:	1.8567488193511963

training epoch 189 / 500, batch #175 / 625
Loss:	1.9110358953475952

training epoch 189 / 500, batch #200 / 625
Loss:	1.7181097269058228

training epoch 189 / 500, batch #225 / 625
Loss:	1.7497227191925049

training epoch 189 / 500, batch #250 / 625
Loss:	1.5103603601455688

training epoch 189 / 500, batch #275 / 625
Loss:	1.842453956604004

training epoch 189 / 500, batch #300 / 625
Loss:	1.832120418548584

training epoch 189 / 500, batch #325 / 625
Loss:	1.9413182735443115

training epoch 189 / 500, batch #350 / 625
Loss:	1.8974783420562744

training epoch 189 / 500, batch #375 / 625
Loss:	1.6493991613388062

training epoch 189 / 500, batch #400 / 625
Loss:	1.6833910942077637

training epoch 189 / 500, batch #425 / 625
Loss:	1.6933408975601196

training epoch 189 / 500, batch #450 / 625
Loss:	2.029755115509033

training epoch 189 / 500, batch #475 / 625
Loss:	1.69696044921875

training epoch 189 / 500, batch #500 / 625
Loss:	1.9128050804138184

training epoch 189 / 500, batch #525 / 625
Loss:	1.6469537019729614

training epoch 189 / 500, batch #550 / 625
Loss:	1.8642371892929077

training epoch 189 / 500, batch #575 / 625
Loss:	1.7114779949188232

training epoch 189 / 500, batch #600 / 625
Loss:	1.9408506155014038

training epoch 190 / 500, batch #0 / 625
Loss:	1.7637031078338623

training epoch 190 / 500, batch #25 / 625
Loss:	1.7862226963043213

training epoch 190 / 500, batch #50 / 625
Loss:	1.7725498676300049

training epoch 190 / 500, batch #75 / 625
Loss:	1.607487678527832

training epoch 190 / 500, batch #100 / 625
Loss:	1.6335394382476807

training epoch 190 / 500, batch #125 / 625
Loss:	1.892647385597229

training epoch 190 / 500, batch #150 / 625
Loss:	1.5817047357559204

training epoch 190 / 500, batch #175 / 625
Loss:	1.66775381565094

training epoch 190 / 500, batch #200 / 625
Loss:	1.707597255706787

training epoch 190 / 500, batch #225 / 625
Loss:	1.7442739009857178

training epoch 190 / 500, batch #250 / 625
Loss:	1.7271243333816528

training epoch 190 / 500, batch #275 / 625
Loss:	1.5886319875717163

training epoch 190 / 500, batch #300 / 625
Loss:	1.6105906963348389

training epoch 190 / 500, batch #325 / 625
Loss:	1.6727879047393799

training epoch 190 / 500, batch #350 / 625
Loss:	1.7369751930236816

training epoch 190 / 500, batch #375 / 625
Loss:	1.81232750415802

training epoch 190 / 500, batch #400 / 625
Loss:	1.8591864109039307

training epoch 190 / 500, batch #425 / 625
Loss:	1.7064465284347534

training epoch 190 / 500, batch #450 / 625
Loss:	1.7084053754806519

training epoch 190 / 500, batch #475 / 625
Loss:	1.6986544132232666

training epoch 190 / 500, batch #500 / 625
Loss:	1.8077081441879272

training epoch 190 / 500, batch #525 / 625
Loss:	1.8128923177719116

training epoch 190 / 500, batch #550 / 625
Loss:	1.9606986045837402

training epoch 190 / 500, batch #575 / 625
Loss:	1.7958379983901978

training epoch 190 / 500, batch #600 / 625
Loss:	1.548592209815979

training epoch 191 / 500, batch #0 / 625
Loss:	1.6617076396942139

training epoch 191 / 500, batch #25 / 625
Loss:	1.7451837062835693

training epoch 191 / 500, batch #50 / 625
Loss:	1.806275486946106

training epoch 191 / 500, batch #75 / 625
Loss:	1.8311567306518555

training epoch 191 / 500, batch #100 / 625
Loss:	1.8235245943069458

training epoch 191 / 500, batch #125 / 625
Loss:	2.149521589279175

training epoch 191 / 500, batch #150 / 625
Loss:	1.8259437084197998

training epoch 191 / 500, batch #175 / 625
Loss:	1.7000657320022583

training epoch 191 / 500, batch #200 / 625
Loss:	1.818527102470398

training epoch 191 / 500, batch #225 / 625
Loss:	1.57349693775177

training epoch 191 / 500, batch #250 / 625
Loss:	1.641823649406433

training epoch 191 / 500, batch #275 / 625
Loss:	1.6925458908081055

training epoch 191 / 500, batch #300 / 625
Loss:	1.75807785987854

training epoch 191 / 500, batch #325 / 625
Loss:	1.7807329893112183

training epoch 191 / 500, batch #350 / 625
Loss:	1.7186886072158813

training epoch 191 / 500, batch #375 / 625
Loss:	1.6468662023544312

training epoch 191 / 500, batch #400 / 625
Loss:	1.5733916759490967

training epoch 191 / 500, batch #425 / 625
Loss:	1.877244234085083

training epoch 191 / 500, batch #450 / 625
Loss:	1.6069426536560059

training epoch 191 / 500, batch #475 / 625
Loss:	1.719942569732666

training epoch 191 / 500, batch #500 / 625
Loss:	1.983746886253357

training epoch 191 / 500, batch #525 / 625
Loss:	1.825355887413025

training epoch 191 / 500, batch #550 / 625
Loss:	1.732414722442627

training epoch 191 / 500, batch #575 / 625
Loss:	1.7432496547698975

training epoch 191 / 500, batch #600 / 625
Loss:	1.8802863359451294

training epoch 192 / 500, batch #0 / 625
Loss:	1.6653330326080322

training epoch 192 / 500, batch #25 / 625
Loss:	1.4521948099136353

training epoch 192 / 500, batch #50 / 625
Loss:	1.6687960624694824

training epoch 192 / 500, batch #75 / 625
Loss:	1.8291778564453125

training epoch 192 / 500, batch #100 / 625
Loss:	1.8931783437728882

training epoch 192 / 500, batch #125 / 625
Loss:	1.804044485092163

training epoch 192 / 500, batch #150 / 625
Loss:	1.770822525024414

training epoch 192 / 500, batch #175 / 625
Loss:	1.759665608406067

training epoch 192 / 500, batch #200 / 625
Loss:	1.691706657409668

training epoch 192 / 500, batch #225 / 625
Loss:	1.7419227361679077

training epoch 192 / 500, batch #250 / 625
Loss:	1.728872299194336

training epoch 192 / 500, batch #275 / 625
Loss:	1.7797770500183105

training epoch 192 / 500, batch #300 / 625
Loss:	1.6269222497940063

training epoch 192 / 500, batch #325 / 625
Loss:	1.6776113510131836

training epoch 192 / 500, batch #350 / 625
Loss:	1.8696602582931519

training epoch 192 / 500, batch #375 / 625
Loss:	1.721034049987793

training epoch 192 / 500, batch #400 / 625
Loss:	1.9639467000961304

training epoch 192 / 500, batch #425 / 625
Loss:	1.8857405185699463

training epoch 192 / 500, batch #450 / 625
Loss:	1.7828668355941772

training epoch 192 / 500, batch #475 / 625
Loss:	1.6801098585128784

training epoch 192 / 500, batch #500 / 625
Loss:	1.7265535593032837

training epoch 192 / 500, batch #525 / 625
Loss:	1.8678277730941772

training epoch 192 / 500, batch #550 / 625
Loss:	1.6883947849273682

training epoch 192 / 500, batch #575 / 625
Loss:	1.6969672441482544

training epoch 192 / 500, batch #600 / 625
Loss:	1.9824804067611694

training epoch 193 / 500, batch #0 / 625
Loss:	1.6767135858535767

training epoch 193 / 500, batch #25 / 625
Loss:	1.7825653553009033

training epoch 193 / 500, batch #50 / 625
Loss:	1.832431674003601

training epoch 193 / 500, batch #75 / 625
Loss:	1.7107707262039185

training epoch 193 / 500, batch #100 / 625
Loss:	1.899347186088562

training epoch 193 / 500, batch #125 / 625
Loss:	1.8492056131362915

training epoch 193 / 500, batch #150 / 625
Loss:	1.5080941915512085

training epoch 193 / 500, batch #175 / 625
Loss:	1.8070597648620605

training epoch 193 / 500, batch #200 / 625
Loss:	1.6259044408798218

training epoch 193 / 500, batch #225 / 625
Loss:	1.8318071365356445

training epoch 193 / 500, batch #250 / 625
Loss:	1.7185431718826294

training epoch 193 / 500, batch #275 / 625
Loss:	1.9434131383895874

training epoch 193 / 500, batch #300 / 625
Loss:	1.5137948989868164

training epoch 193 / 500, batch #325 / 625
Loss:	1.6779857873916626

training epoch 193 / 500, batch #350 / 625
Loss:	1.7273815870285034

training epoch 193 / 500, batch #375 / 625
Loss:	1.543977975845337

training epoch 193 / 500, batch #400 / 625
Loss:	2.0061094760894775

training epoch 193 / 500, batch #425 / 625
Loss:	1.8241935968399048

training epoch 193 / 500, batch #450 / 625
Loss:	1.7268197536468506

training epoch 193 / 500, batch #475 / 625
Loss:	1.7483373880386353

training epoch 193 / 500, batch #500 / 625
Loss:	1.4081617593765259

training epoch 193 / 500, batch #525 / 625
Loss:	1.923378348350525

training epoch 193 / 500, batch #550 / 625
Loss:	1.9211952686309814

training epoch 193 / 500, batch #575 / 625
Loss:	1.754772663116455

training epoch 193 / 500, batch #600 / 625
Loss:	1.729203224182129

training epoch 194 / 500, batch #0 / 625
Loss:	1.6135380268096924

training epoch 194 / 500, batch #25 / 625
Loss:	1.870556354522705

training epoch 194 / 500, batch #50 / 625
Loss:	1.6469550132751465

training epoch 194 / 500, batch #75 / 625
Loss:	1.7003577947616577

training epoch 194 / 500, batch #100 / 625
Loss:	1.5776551961898804

training epoch 194 / 500, batch #125 / 625
Loss:	1.7944523096084595

training epoch 194 / 500, batch #150 / 625
Loss:	1.8331549167633057

training epoch 194 / 500, batch #175 / 625
Loss:	1.7123422622680664

training epoch 194 / 500, batch #200 / 625
Loss:	1.8303451538085938

training epoch 194 / 500, batch #225 / 625
Loss:	1.7802366018295288

training epoch 194 / 500, batch #250 / 625
Loss:	1.658413290977478

training epoch 194 / 500, batch #275 / 625
Loss:	1.9723538160324097

training epoch 194 / 500, batch #300 / 625
Loss:	1.585947871208191

training epoch 194 / 500, batch #325 / 625
Loss:	1.5951075553894043

training epoch 194 / 500, batch #350 / 625
Loss:	1.821305274963379

training epoch 194 / 500, batch #375 / 625
Loss:	1.991129755973816

training epoch 194 / 500, batch #400 / 625
Loss:	1.5578495264053345

training epoch 194 / 500, batch #425 / 625
Loss:	1.4628757238388062

training epoch 194 / 500, batch #450 / 625
Loss:	1.8029608726501465

training epoch 194 / 500, batch #475 / 625
Loss:	1.7267073392868042

training epoch 194 / 500, batch #500 / 625
Loss:	1.808830738067627

training epoch 194 / 500, batch #525 / 625
Loss:	1.5296053886413574

training epoch 194 / 500, batch #550 / 625
Loss:	1.7248163223266602

training epoch 194 / 500, batch #575 / 625
Loss:	1.8469244241714478

training epoch 194 / 500, batch #600 / 625
Loss:	1.552564024925232

training epoch 195 / 500, batch #0 / 625
Loss:	1.800366759300232

training epoch 195 / 500, batch #25 / 625
Loss:	1.8722162246704102

training epoch 195 / 500, batch #50 / 625
Loss:	1.7841029167175293

training epoch 195 / 500, batch #75 / 625
Loss:	1.8118327856063843

training epoch 195 / 500, batch #100 / 625
Loss:	1.643464207649231

training epoch 195 / 500, batch #125 / 625
Loss:	1.6890689134597778

training epoch 195 / 500, batch #150 / 625
Loss:	1.7040654420852661

training epoch 195 / 500, batch #175 / 625
Loss:	1.494640588760376

training epoch 195 / 500, batch #200 / 625
Loss:	1.7990756034851074

training epoch 195 / 500, batch #225 / 625
Loss:	2.0077567100524902

training epoch 195 / 500, batch #250 / 625
Loss:	1.5813440084457397

training epoch 195 / 500, batch #275 / 625
Loss:	1.9061592817306519

training epoch 195 / 500, batch #300 / 625
Loss:	1.53224515914917

training epoch 195 / 500, batch #325 / 625
Loss:	1.4842753410339355

training epoch 195 / 500, batch #350 / 625
Loss:	1.6975769996643066

training epoch 195 / 500, batch #375 / 625
Loss:	1.6139332056045532

training epoch 195 / 500, batch #400 / 625
Loss:	1.7073626518249512

training epoch 195 / 500, batch #425 / 625
Loss:	1.680876612663269

training epoch 195 / 500, batch #450 / 625
Loss:	1.7608797550201416

training epoch 195 / 500, batch #475 / 625
Loss:	1.7036628723144531

training epoch 195 / 500, batch #500 / 625
Loss:	1.8049192428588867

training epoch 195 / 500, batch #525 / 625
Loss:	1.7550004720687866

training epoch 195 / 500, batch #550 / 625
Loss:	1.9021859169006348

training epoch 195 / 500, batch #575 / 625
Loss:	1.863067626953125

training epoch 195 / 500, batch #600 / 625
Loss:	1.6927834749221802

training epoch 196 / 500, batch #0 / 625
Loss:	1.8010358810424805

training epoch 196 / 500, batch #25 / 625
Loss:	1.7617601156234741

training epoch 196 / 500, batch #50 / 625
Loss:	1.7741258144378662

training epoch 196 / 500, batch #75 / 625
Loss:	1.7533929347991943

training epoch 196 / 500, batch #100 / 625
Loss:	1.572949767112732

training epoch 196 / 500, batch #125 / 625
Loss:	1.9099574089050293

training epoch 196 / 500, batch #150 / 625
Loss:	1.6182101964950562

training epoch 196 / 500, batch #175 / 625
Loss:	1.9027624130249023

training epoch 196 / 500, batch #200 / 625
Loss:	1.6839733123779297

training epoch 196 / 500, batch #225 / 625
Loss:	2.080050468444824

training epoch 196 / 500, batch #250 / 625
Loss:	1.6616841554641724

training epoch 196 / 500, batch #275 / 625
Loss:	1.6497422456741333

training epoch 196 / 500, batch #300 / 625
Loss:	1.7903579473495483

training epoch 196 / 500, batch #325 / 625
Loss:	1.6489969491958618

training epoch 196 / 500, batch #350 / 625
Loss:	1.759558916091919

training epoch 196 / 500, batch #375 / 625
Loss:	1.4333195686340332

training epoch 196 / 500, batch #400 / 625
Loss:	1.5700733661651611

training epoch 196 / 500, batch #425 / 625
Loss:	1.8116974830627441

training epoch 196 / 500, batch #450 / 625
Loss:	2.0171518325805664

training epoch 196 / 500, batch #475 / 625
Loss:	1.625638723373413

training epoch 196 / 500, batch #500 / 625
Loss:	1.70737886428833

training epoch 196 / 500, batch #525 / 625
Loss:	2.0541329383850098

training epoch 196 / 500, batch #550 / 625
Loss:	1.8935765027999878

training epoch 196 / 500, batch #575 / 625
Loss:	1.7649441957473755

training epoch 196 / 500, batch #600 / 625
Loss:	1.6899923086166382

training epoch 197 / 500, batch #0 / 625
Loss:	1.5413446426391602

training epoch 197 / 500, batch #25 / 625
Loss:	1.948072910308838

training epoch 197 / 500, batch #50 / 625
Loss:	1.6329513788223267

training epoch 197 / 500, batch #75 / 625
Loss:	1.7710083723068237

training epoch 197 / 500, batch #100 / 625
Loss:	1.5991594791412354

training epoch 197 / 500, batch #125 / 625
Loss:	1.8083833456039429

training epoch 197 / 500, batch #150 / 625
Loss:	1.8482656478881836

training epoch 197 / 500, batch #175 / 625
Loss:	1.6753209829330444

training epoch 197 / 500, batch #200 / 625
Loss:	1.5401533842086792

training epoch 197 / 500, batch #225 / 625
Loss:	1.768228530883789

training epoch 197 / 500, batch #250 / 625
Loss:	1.661590814590454

training epoch 197 / 500, batch #275 / 625
Loss:	1.5907741785049438

training epoch 197 / 500, batch #300 / 625
Loss:	1.6622400283813477

training epoch 197 / 500, batch #325 / 625
Loss:	1.8869202136993408

training epoch 197 / 500, batch #350 / 625
Loss:	1.707611083984375

training epoch 197 / 500, batch #375 / 625
Loss:	1.8886148929595947

training epoch 197 / 500, batch #400 / 625
Loss:	1.6853173971176147

training epoch 197 / 500, batch #425 / 625
Loss:	1.8532036542892456

training epoch 197 / 500, batch #450 / 625
Loss:	1.927918791770935

training epoch 197 / 500, batch #475 / 625
Loss:	1.6512993574142456

training epoch 197 / 500, batch #500 / 625
Loss:	1.7969022989273071

training epoch 197 / 500, batch #525 / 625
Loss:	1.7218111753463745

training epoch 197 / 500, batch #550 / 625
Loss:	1.8092583417892456

training epoch 197 / 500, batch #575 / 625
Loss:	1.786821961402893

training epoch 197 / 500, batch #600 / 625
Loss:	1.7059460878372192

training epoch 198 / 500, batch #0 / 625
Loss:	1.7836791276931763

training epoch 198 / 500, batch #25 / 625
Loss:	2.0305893421173096

training epoch 198 / 500, batch #50 / 625
Loss:	1.5393049716949463

training epoch 198 / 500, batch #75 / 625
Loss:	1.6935698986053467

training epoch 198 / 500, batch #100 / 625
Loss:	2.026153564453125

training epoch 198 / 500, batch #125 / 625
Loss:	1.562928318977356

training epoch 198 / 500, batch #150 / 625
Loss:	1.7420047521591187

training epoch 198 / 500, batch #175 / 625
Loss:	1.5877869129180908

training epoch 198 / 500, batch #200 / 625
Loss:	1.6774333715438843

training epoch 198 / 500, batch #225 / 625
Loss:	1.9649498462677002

training epoch 198 / 500, batch #250 / 625
Loss:	1.7793983221054077

training epoch 198 / 500, batch #275 / 625
Loss:	1.7875337600708008

training epoch 198 / 500, batch #300 / 625
Loss:	1.7790635824203491

training epoch 198 / 500, batch #325 / 625
Loss:	1.7680306434631348

training epoch 198 / 500, batch #350 / 625
Loss:	1.6176490783691406

training epoch 198 / 500, batch #375 / 625
Loss:	1.6621259450912476

training epoch 198 / 500, batch #400 / 625
Loss:	1.804283618927002

training epoch 198 / 500, batch #425 / 625
Loss:	1.7009730339050293

training epoch 198 / 500, batch #450 / 625
Loss:	1.7748225927352905

training epoch 198 / 500, batch #475 / 625
Loss:	1.7313385009765625

training epoch 198 / 500, batch #500 / 625
Loss:	1.5534292459487915

training epoch 198 / 500, batch #525 / 625
Loss:	1.876634120941162

training epoch 198 / 500, batch #550 / 625
Loss:	1.9816248416900635

training epoch 198 / 500, batch #575 / 625
Loss:	1.590898036956787

training epoch 198 / 500, batch #600 / 625
Loss:	1.6401162147521973

training epoch 199 / 500, batch #0 / 625
Loss:	1.8330364227294922

training epoch 199 / 500, batch #25 / 625
Loss:	1.6585339307785034

training epoch 199 / 500, batch #50 / 625
Loss:	1.5972410440444946

training epoch 199 / 500, batch #75 / 625
Loss:	1.9637162685394287

training epoch 199 / 500, batch #100 / 625
Loss:	1.3825539350509644

training epoch 199 / 500, batch #125 / 625
Loss:	1.7986948490142822

training epoch 199 / 500, batch #150 / 625
Loss:	1.6836556196212769

training epoch 199 / 500, batch #175 / 625
Loss:	1.7018518447875977

training epoch 199 / 500, batch #200 / 625
Loss:	1.5831950902938843

training epoch 199 / 500, batch #225 / 625
Loss:	1.7737928628921509

training epoch 199 / 500, batch #250 / 625
Loss:	1.980865478515625

training epoch 199 / 500, batch #275 / 625
Loss:	1.9020249843597412

training epoch 199 / 500, batch #300 / 625
Loss:	1.8756877183914185

training epoch 199 / 500, batch #325 / 625
Loss:	1.7604005336761475

training epoch 199 / 500, batch #350 / 625
Loss:	1.6619126796722412

training epoch 199 / 500, batch #375 / 625
Loss:	1.7688417434692383

training epoch 199 / 500, batch #400 / 625
Loss:	1.8055460453033447

training epoch 199 / 500, batch #425 / 625
Loss:	1.7485463619232178

training epoch 199 / 500, batch #450 / 625
Loss:	1.836222767829895

training epoch 199 / 500, batch #475 / 625
Loss:	1.78325355052948

training epoch 199 / 500, batch #500 / 625
Loss:	1.825946569442749

training epoch 199 / 500, batch #525 / 625
Loss:	1.868053674697876

training epoch 199 / 500, batch #550 / 625
Loss:	1.8933857679367065

training epoch 199 / 500, batch #575 / 625
Loss:	1.8374098539352417

training epoch 199 / 500, batch #600 / 625
Loss:	1.583409309387207

training epoch 200 / 500, batch #0 / 625
Loss:	1.8647300004959106

training epoch 200 / 500, batch #25 / 625
Loss:	1.9434583187103271

training epoch 200 / 500, batch #50 / 625
Loss:	2.0715043544769287

training epoch 200 / 500, batch #75 / 625
Loss:	1.6765224933624268

training epoch 200 / 500, batch #100 / 625
Loss:	1.7155135869979858

training epoch 200 / 500, batch #125 / 625
Loss:	1.8669837713241577

training epoch 200 / 500, batch #150 / 625
Loss:	1.6533786058425903

training epoch 200 / 500, batch #175 / 625
Loss:	1.8166099786758423

training epoch 200 / 500, batch #200 / 625
Loss:	1.8597708940505981

training epoch 200 / 500, batch #225 / 625
Loss:	1.819353461265564

training epoch 200 / 500, batch #250 / 625
Loss:	2.1732535362243652

training epoch 200 / 500, batch #275 / 625
Loss:	1.9264743328094482

training epoch 200 / 500, batch #300 / 625
Loss:	1.6825497150421143

training epoch 200 / 500, batch #325 / 625
Loss:	1.5183659791946411

training epoch 200 / 500, batch #350 / 625
Loss:	1.9892241954803467

training epoch 200 / 500, batch #375 / 625
Loss:	1.6950010061264038

training epoch 200 / 500, batch #400 / 625
Loss:	1.7053183317184448

training epoch 200 / 500, batch #425 / 625
Loss:	1.832963466644287

training epoch 200 / 500, batch #450 / 625
Loss:	1.8418735265731812

training epoch 200 / 500, batch #475 / 625
Loss:	1.7483937740325928

training epoch 200 / 500, batch #500 / 625
Loss:	1.8989503383636475

training epoch 200 / 500, batch #525 / 625
Loss:	1.779404640197754

training epoch 200 / 500, batch #550 / 625
Loss:	1.8823806047439575

training epoch 200 / 500, batch #575 / 625
Loss:	1.938151478767395

training epoch 200 / 500, batch #600 / 625
Loss:	1.7134984731674194

training epoch 201 / 500, batch #0 / 625
Loss:	1.7779327630996704

training epoch 201 / 500, batch #25 / 625
Loss:	1.771266222000122

training epoch 201 / 500, batch #50 / 625
Loss:	1.860518455505371

training epoch 201 / 500, batch #75 / 625
Loss:	1.4162999391555786

training epoch 201 / 500, batch #100 / 625
Loss:	1.8295660018920898

training epoch 201 / 500, batch #125 / 625
Loss:	1.9899518489837646

training epoch 201 / 500, batch #150 / 625
Loss:	1.769013524055481

training epoch 201 / 500, batch #175 / 625
Loss:	1.6244114637374878

training epoch 201 / 500, batch #200 / 625
Loss:	1.7331193685531616

training epoch 201 / 500, batch #225 / 625
Loss:	1.7818347215652466

training epoch 201 / 500, batch #250 / 625
Loss:	1.847131609916687

training epoch 201 / 500, batch #275 / 625
Loss:	1.5691375732421875

training epoch 201 / 500, batch #300 / 625
Loss:	1.8366698026657104

training epoch 201 / 500, batch #325 / 625
Loss:	1.6030669212341309

training epoch 201 / 500, batch #350 / 625
Loss:	1.610039472579956

training epoch 201 / 500, batch #375 / 625
Loss:	1.5511188507080078

training epoch 201 / 500, batch #400 / 625
Loss:	1.9365745782852173

training epoch 201 / 500, batch #425 / 625
Loss:	1.962697982788086

training epoch 201 / 500, batch #450 / 625
Loss:	1.7098679542541504

training epoch 201 / 500, batch #475 / 625
Loss:	1.9941482543945312

training epoch 201 / 500, batch #500 / 625
Loss:	1.7890257835388184

training epoch 201 / 500, batch #525 / 625
Loss:	2.03755784034729

training epoch 201 / 500, batch #550 / 625
Loss:	1.7206529378890991

training epoch 201 / 500, batch #575 / 625
Loss:	1.5588068962097168

training epoch 201 / 500, batch #600 / 625
Loss:	1.7342464923858643

training epoch 202 / 500, batch #0 / 625
Loss:	1.7624589204788208

training epoch 202 / 500, batch #25 / 625
Loss:	1.820624589920044

training epoch 202 / 500, batch #50 / 625
Loss:	1.676318883895874

training epoch 202 / 500, batch #75 / 625
Loss:	1.6845793724060059

training epoch 202 / 500, batch #100 / 625
Loss:	1.842218041419983

training epoch 202 / 500, batch #125 / 625
Loss:	1.8422280550003052

training epoch 202 / 500, batch #150 / 625
Loss:	1.6254098415374756

training epoch 202 / 500, batch #175 / 625
Loss:	1.7980678081512451

training epoch 202 / 500, batch #200 / 625
Loss:	1.686928629875183

training epoch 202 / 500, batch #225 / 625
Loss:	1.9503967761993408

training epoch 202 / 500, batch #250 / 625
Loss:	1.5325064659118652

training epoch 202 / 500, batch #275 / 625
Loss:	1.7005484104156494

training epoch 202 / 500, batch #300 / 625
Loss:	1.870735764503479

training epoch 202 / 500, batch #325 / 625
Loss:	1.9747613668441772

training epoch 202 / 500, batch #350 / 625
Loss:	1.6309351921081543

training epoch 202 / 500, batch #375 / 625
Loss:	1.7386280298233032

training epoch 202 / 500, batch #400 / 625
Loss:	1.839524745941162

training epoch 202 / 500, batch #425 / 625
Loss:	1.683995246887207

training epoch 202 / 500, batch #450 / 625
Loss:	1.6788612604141235

training epoch 202 / 500, batch #475 / 625
Loss:	1.7625858783721924

training epoch 202 / 500, batch #500 / 625
Loss:	1.667572259902954

training epoch 202 / 500, batch #525 / 625
Loss:	1.787489414215088

training epoch 202 / 500, batch #550 / 625
Loss:	1.9071474075317383

training epoch 202 / 500, batch #575 / 625
Loss:	1.8831804990768433

training epoch 202 / 500, batch #600 / 625
Loss:	1.7394168376922607

training epoch 203 / 500, batch #0 / 625
Loss:	1.5995858907699585

training epoch 203 / 500, batch #25 / 625
Loss:	1.7645490169525146

training epoch 203 / 500, batch #50 / 625
Loss:	1.6738475561141968

training epoch 203 / 500, batch #75 / 625
Loss:	1.8841896057128906

training epoch 203 / 500, batch #100 / 625
Loss:	1.7675061225891113

training epoch 203 / 500, batch #125 / 625
Loss:	1.81113862991333

training epoch 203 / 500, batch #150 / 625
Loss:	2.0051662921905518

training epoch 203 / 500, batch #175 / 625
Loss:	1.9012446403503418

training epoch 203 / 500, batch #200 / 625
Loss:	1.6541980504989624

training epoch 203 / 500, batch #225 / 625
Loss:	1.7966543436050415

training epoch 203 / 500, batch #250 / 625
Loss:	1.5832329988479614

training epoch 203 / 500, batch #275 / 625
Loss:	1.6868631839752197

training epoch 203 / 500, batch #300 / 625
Loss:	1.9122066497802734

training epoch 203 / 500, batch #325 / 625
Loss:	1.6121560335159302

training epoch 203 / 500, batch #350 / 625
Loss:	1.7690374851226807

training epoch 203 / 500, batch #375 / 625
Loss:	1.8034769296646118

training epoch 203 / 500, batch #400 / 625
Loss:	1.7591338157653809

training epoch 203 / 500, batch #425 / 625
Loss:	1.755149006843567

training epoch 203 / 500, batch #450 / 625
Loss:	1.5193992853164673

training epoch 203 / 500, batch #475 / 625
Loss:	1.5305544137954712

training epoch 203 / 500, batch #500 / 625
Loss:	1.6544557809829712

training epoch 203 / 500, batch #525 / 625
Loss:	1.7757142782211304

training epoch 203 / 500, batch #550 / 625
Loss:	1.69003164768219

training epoch 203 / 500, batch #575 / 625
Loss:	1.7249444723129272

training epoch 203 / 500, batch #600 / 625
Loss:	1.8327502012252808

training epoch 204 / 500, batch #0 / 625
Loss:	1.7707675695419312

training epoch 204 / 500, batch #25 / 625
Loss:	1.5847796201705933

training epoch 204 / 500, batch #50 / 625
Loss:	1.9211788177490234

training epoch 204 / 500, batch #75 / 625
Loss:	1.9263705015182495

training epoch 204 / 500, batch #100 / 625
Loss:	2.0092034339904785

training epoch 204 / 500, batch #125 / 625
Loss:	1.6881847381591797

training epoch 204 / 500, batch #150 / 625
Loss:	1.7284351587295532

training epoch 204 / 500, batch #175 / 625
Loss:	2.0473504066467285

training epoch 204 / 500, batch #200 / 625
Loss:	1.7653162479400635

training epoch 204 / 500, batch #225 / 625
Loss:	1.7716115713119507

training epoch 204 / 500, batch #250 / 625
Loss:	1.443793535232544

training epoch 204 / 500, batch #275 / 625
Loss:	1.71840238571167

training epoch 204 / 500, batch #300 / 625
Loss:	1.73881995677948

training epoch 204 / 500, batch #325 / 625
Loss:	1.9228469133377075

training epoch 204 / 500, batch #350 / 625
Loss:	1.8477543592453003

training epoch 204 / 500, batch #375 / 625
Loss:	2.0675148963928223

training epoch 204 / 500, batch #400 / 625
Loss:	1.64443039894104

training epoch 204 / 500, batch #425 / 625
Loss:	1.901640772819519

training epoch 204 / 500, batch #450 / 625
Loss:	1.8612273931503296

training epoch 204 / 500, batch #475 / 625
Loss:	1.934207558631897

training epoch 204 / 500, batch #500 / 625
Loss:	1.8030498027801514

training epoch 204 / 500, batch #525 / 625
Loss:	1.7363721132278442

training epoch 204 / 500, batch #550 / 625
Loss:	1.7707245349884033

training epoch 204 / 500, batch #575 / 625
Loss:	1.8498311042785645

training epoch 204 / 500, batch #600 / 625
Loss:	1.8143123388290405

training epoch 205 / 500, batch #0 / 625
Loss:	1.7513196468353271

training epoch 205 / 500, batch #25 / 625
Loss:	1.773500680923462

training epoch 205 / 500, batch #50 / 625
Loss:	1.7222646474838257

training epoch 205 / 500, batch #75 / 625
Loss:	1.8533366918563843

training epoch 205 / 500, batch #100 / 625
Loss:	1.5547199249267578

training epoch 205 / 500, batch #125 / 625
Loss:	1.660009503364563

training epoch 205 / 500, batch #150 / 625
Loss:	1.581602692604065

training epoch 205 / 500, batch #175 / 625
Loss:	1.90382719039917

training epoch 205 / 500, batch #200 / 625
Loss:	1.8946869373321533

training epoch 205 / 500, batch #225 / 625
Loss:	1.8946250677108765

training epoch 205 / 500, batch #250 / 625
Loss:	1.7796071767807007

training epoch 205 / 500, batch #275 / 625
Loss:	1.7566914558410645

training epoch 205 / 500, batch #300 / 625
Loss:	1.8152192831039429

training epoch 205 / 500, batch #325 / 625
Loss:	1.7075697183609009

training epoch 205 / 500, batch #350 / 625
Loss:	1.6290559768676758

training epoch 205 / 500, batch #375 / 625
Loss:	1.7491596937179565

training epoch 205 / 500, batch #400 / 625
Loss:	1.6648046970367432

training epoch 205 / 500, batch #425 / 625
Loss:	1.564666986465454

training epoch 205 / 500, batch #450 / 625
Loss:	1.5393619537353516

training epoch 205 / 500, batch #475 / 625
Loss:	1.8805694580078125

training epoch 205 / 500, batch #500 / 625
Loss:	1.8650362491607666

training epoch 205 / 500, batch #525 / 625
Loss:	1.7332313060760498

training epoch 205 / 500, batch #550 / 625
Loss:	1.8845521211624146

training epoch 205 / 500, batch #575 / 625
Loss:	1.9015007019042969

training epoch 205 / 500, batch #600 / 625
Loss:	1.6225039958953857

training epoch 206 / 500, batch #0 / 625
Loss:	1.5877310037612915

training epoch 206 / 500, batch #25 / 625
Loss:	1.732790231704712

training epoch 206 / 500, batch #50 / 625
Loss:	1.5231658220291138

training epoch 206 / 500, batch #75 / 625
Loss:	1.7314512729644775

training epoch 206 / 500, batch #100 / 625
Loss:	1.9702610969543457

training epoch 206 / 500, batch #125 / 625
Loss:	1.8279120922088623

training epoch 206 / 500, batch #150 / 625
Loss:	1.7350356578826904

training epoch 206 / 500, batch #175 / 625
Loss:	2.034528970718384

training epoch 206 / 500, batch #200 / 625
Loss:	1.4867604970932007

training epoch 206 / 500, batch #225 / 625
Loss:	1.8926873207092285

training epoch 206 / 500, batch #250 / 625
Loss:	1.7144215106964111

training epoch 206 / 500, batch #275 / 625
Loss:	1.7327183485031128

training epoch 206 / 500, batch #300 / 625
Loss:	1.6099857091903687

training epoch 206 / 500, batch #325 / 625
Loss:	1.8375824689865112

training epoch 206 / 500, batch #350 / 625
Loss:	1.642132043838501

training epoch 206 / 500, batch #375 / 625
Loss:	1.7886792421340942

training epoch 206 / 500, batch #400 / 625
Loss:	1.8001549243927002

training epoch 206 / 500, batch #425 / 625
Loss:	1.7319000959396362

training epoch 206 / 500, batch #450 / 625
Loss:	1.7681406736373901

training epoch 206 / 500, batch #475 / 625
Loss:	1.8082833290100098

training epoch 206 / 500, batch #500 / 625
Loss:	1.760880947113037

training epoch 206 / 500, batch #525 / 625
Loss:	1.7311804294586182

training epoch 206 / 500, batch #550 / 625
Loss:	1.6923270225524902

training epoch 206 / 500, batch #575 / 625
Loss:	2.0095551013946533

training epoch 206 / 500, batch #600 / 625
Loss:	1.688395380973816

training epoch 207 / 500, batch #0 / 625
Loss:	1.5277185440063477

training epoch 207 / 500, batch #25 / 625
Loss:	1.678619384765625

training epoch 207 / 500, batch #50 / 625
Loss:	1.5569707155227661

training epoch 207 / 500, batch #75 / 625
Loss:	1.5307657718658447

training epoch 207 / 500, batch #100 / 625
Loss:	1.7126175165176392

training epoch 207 / 500, batch #125 / 625
Loss:	1.7385427951812744

training epoch 207 / 500, batch #150 / 625
Loss:	1.865182876586914

training epoch 207 / 500, batch #175 / 625
Loss:	1.6927382946014404

training epoch 207 / 500, batch #200 / 625
Loss:	1.799280047416687

training epoch 207 / 500, batch #225 / 625
Loss:	1.640291690826416

training epoch 207 / 500, batch #250 / 625
Loss:	1.7079787254333496

training epoch 207 / 500, batch #275 / 625
Loss:	1.8896666765213013

training epoch 207 / 500, batch #300 / 625
Loss:	1.7983393669128418

training epoch 207 / 500, batch #325 / 625
Loss:	2.0236456394195557

training epoch 207 / 500, batch #350 / 625
Loss:	1.8633986711502075

training epoch 207 / 500, batch #375 / 625
Loss:	1.802115559577942

training epoch 207 / 500, batch #400 / 625
Loss:	1.8096287250518799

training epoch 207 / 500, batch #425 / 625
Loss:	1.7138473987579346

training epoch 207 / 500, batch #450 / 625
Loss:	1.8617634773254395

training epoch 207 / 500, batch #475 / 625
Loss:	1.6097385883331299

training epoch 207 / 500, batch #500 / 625
Loss:	1.7045060396194458

training epoch 207 / 500, batch #525 / 625
Loss:	1.8439898490905762

training epoch 207 / 500, batch #550 / 625
Loss:	1.966572880744934

training epoch 207 / 500, batch #575 / 625
Loss:	1.8009212017059326

training epoch 207 / 500, batch #600 / 625
Loss:	1.5791025161743164

training epoch 208 / 500, batch #0 / 625
Loss:	1.7092827558517456

training epoch 208 / 500, batch #25 / 625
Loss:	1.6939151287078857

training epoch 208 / 500, batch #50 / 625
Loss:	1.8196539878845215

training epoch 208 / 500, batch #75 / 625
Loss:	1.6649515628814697

training epoch 208 / 500, batch #100 / 625
Loss:	1.8099782466888428

training epoch 208 / 500, batch #125 / 625
Loss:	1.7382655143737793

training epoch 208 / 500, batch #150 / 625
Loss:	1.6752034425735474

training epoch 208 / 500, batch #175 / 625
Loss:	2.0369787216186523

training epoch 208 / 500, batch #200 / 625
Loss:	1.7546123266220093

training epoch 208 / 500, batch #225 / 625
Loss:	1.9251964092254639

training epoch 208 / 500, batch #250 / 625
Loss:	1.515465497970581

training epoch 208 / 500, batch #275 / 625
Loss:	1.6979455947875977

training epoch 208 / 500, batch #300 / 625
Loss:	1.4497737884521484

training epoch 208 / 500, batch #325 / 625
Loss:	1.852520227432251

training epoch 208 / 500, batch #350 / 625
Loss:	1.681994080543518

training epoch 208 / 500, batch #375 / 625
Loss:	1.5016615390777588

training epoch 208 / 500, batch #400 / 625
Loss:	1.9849963188171387

training epoch 208 / 500, batch #425 / 625
Loss:	1.6898404359817505

training epoch 208 / 500, batch #450 / 625
Loss:	1.4861562252044678

training epoch 208 / 500, batch #475 / 625
Loss:	1.9245078563690186

training epoch 208 / 500, batch #500 / 625
Loss:	2.113718032836914

training epoch 208 / 500, batch #525 / 625
Loss:	1.9350248575210571

training epoch 208 / 500, batch #550 / 625
Loss:	1.7138556241989136

training epoch 208 / 500, batch #575 / 625
Loss:	1.828087568283081

training epoch 208 / 500, batch #600 / 625
Loss:	1.729866862297058

training epoch 209 / 500, batch #0 / 625
Loss:	1.6509625911712646

training epoch 209 / 500, batch #25 / 625
Loss:	1.5517165660858154

training epoch 209 / 500, batch #50 / 625
Loss:	1.7225145101547241

training epoch 209 / 500, batch #75 / 625
Loss:	1.6261942386627197

training epoch 209 / 500, batch #100 / 625
Loss:	1.8403522968292236

training epoch 209 / 500, batch #125 / 625
Loss:	1.7484630346298218

training epoch 209 / 500, batch #150 / 625
Loss:	1.816563367843628

training epoch 209 / 500, batch #175 / 625
Loss:	1.9740742444992065

training epoch 209 / 500, batch #200 / 625
Loss:	1.7688366174697876

training epoch 209 / 500, batch #225 / 625
Loss:	1.857609748840332

training epoch 209 / 500, batch #250 / 625
Loss:	1.6172112226486206

training epoch 209 / 500, batch #275 / 625
Loss:	1.7127799987792969

training epoch 209 / 500, batch #300 / 625
Loss:	1.9956508874893188

training epoch 209 / 500, batch #325 / 625
Loss:	1.8177069425582886

training epoch 209 / 500, batch #350 / 625
Loss:	1.873966097831726

training epoch 209 / 500, batch #375 / 625
Loss:	1.7223241329193115

training epoch 209 / 500, batch #400 / 625
Loss:	1.842497706413269

training epoch 209 / 500, batch #425 / 625
Loss:	1.7391761541366577

training epoch 209 / 500, batch #450 / 625
Loss:	1.7572256326675415

training epoch 209 / 500, batch #475 / 625
Loss:	1.65977942943573

training epoch 209 / 500, batch #500 / 625
Loss:	1.8761425018310547

training epoch 209 / 500, batch #525 / 625
Loss:	2.0034899711608887

training epoch 209 / 500, batch #550 / 625
Loss:	2.020660161972046

training epoch 209 / 500, batch #575 / 625
Loss:	1.5711181163787842

training epoch 209 / 500, batch #600 / 625
Loss:	1.827243685722351

training epoch 210 / 500, batch #0 / 625
Loss:	1.8682042360305786

training epoch 210 / 500, batch #25 / 625
Loss:	1.4788333177566528

training epoch 210 / 500, batch #50 / 625
Loss:	1.7307623624801636

training epoch 210 / 500, batch #75 / 625
Loss:	1.95767343044281

training epoch 210 / 500, batch #100 / 625
Loss:	1.6231966018676758

training epoch 210 / 500, batch #125 / 625
Loss:	1.7640279531478882

training epoch 210 / 500, batch #150 / 625
Loss:	1.6768256425857544

training epoch 210 / 500, batch #175 / 625
Loss:	1.7225091457366943

training epoch 210 / 500, batch #200 / 625
Loss:	1.706148624420166

training epoch 210 / 500, batch #225 / 625
Loss:	1.508882999420166

training epoch 210 / 500, batch #250 / 625
Loss:	1.8103593587875366

training epoch 210 / 500, batch #275 / 625
Loss:	1.757055401802063

training epoch 210 / 500, batch #300 / 625
Loss:	1.4793285131454468

training epoch 210 / 500, batch #325 / 625
Loss:	1.768402338027954

training epoch 210 / 500, batch #350 / 625
Loss:	1.7785251140594482

training epoch 210 / 500, batch #375 / 625
Loss:	1.619720458984375

training epoch 210 / 500, batch #400 / 625
Loss:	1.9742604494094849

training epoch 210 / 500, batch #425 / 625
Loss:	1.6804158687591553

training epoch 210 / 500, batch #450 / 625
Loss:	1.705904245376587

training epoch 210 / 500, batch #475 / 625
Loss:	1.8566197156906128

training epoch 210 / 500, batch #500 / 625
Loss:	1.719472050666809

training epoch 210 / 500, batch #525 / 625
Loss:	1.8149853944778442

training epoch 210 / 500, batch #550 / 625
Loss:	1.8370200395584106

training epoch 210 / 500, batch #575 / 625
Loss:	1.6747323274612427

training epoch 210 / 500, batch #600 / 625
Loss:	1.7233819961547852

training epoch 211 / 500, batch #0 / 625
Loss:	1.4262160062789917

training epoch 211 / 500, batch #25 / 625
Loss:	1.959380030632019

training epoch 211 / 500, batch #50 / 625
Loss:	1.718261957168579

training epoch 211 / 500, batch #75 / 625
Loss:	1.4569486379623413

training epoch 211 / 500, batch #100 / 625
Loss:	1.5982744693756104

training epoch 211 / 500, batch #125 / 625
Loss:	1.9525972604751587

training epoch 211 / 500, batch #150 / 625
Loss:	1.5201077461242676

training epoch 211 / 500, batch #175 / 625
Loss:	1.7848349809646606

training epoch 211 / 500, batch #200 / 625
Loss:	1.886185646057129

training epoch 211 / 500, batch #225 / 625
Loss:	1.676753044128418

training epoch 211 / 500, batch #250 / 625
Loss:	2.0383920669555664

training epoch 211 / 500, batch #275 / 625
Loss:	1.738997220993042

training epoch 211 / 500, batch #300 / 625
Loss:	1.6031509637832642

training epoch 211 / 500, batch #325 / 625
Loss:	1.621548056602478

training epoch 211 / 500, batch #350 / 625
Loss:	1.8570281267166138

training epoch 211 / 500, batch #375 / 625
Loss:	1.6534850597381592

training epoch 211 / 500, batch #400 / 625
Loss:	1.9186327457427979

training epoch 211 / 500, batch #425 / 625
Loss:	1.6552155017852783

training epoch 211 / 500, batch #450 / 625
Loss:	1.550553321838379

training epoch 211 / 500, batch #475 / 625
Loss:	1.7969452142715454

training epoch 211 / 500, batch #500 / 625
Loss:	1.7272368669509888

training epoch 211 / 500, batch #525 / 625
Loss:	1.79591703414917

training epoch 211 / 500, batch #550 / 625
Loss:	1.752593755722046

training epoch 211 / 500, batch #575 / 625
Loss:	1.7308341264724731

training epoch 211 / 500, batch #600 / 625
Loss:	1.837407112121582

training epoch 212 / 500, batch #0 / 625
Loss:	1.8314107656478882

training epoch 212 / 500, batch #25 / 625
Loss:	1.8318449258804321

training epoch 212 / 500, batch #50 / 625
Loss:	1.9741898775100708

training epoch 212 / 500, batch #75 / 625
Loss:	1.7582370042800903

training epoch 212 / 500, batch #100 / 625
Loss:	1.6815674304962158

training epoch 212 / 500, batch #125 / 625
Loss:	1.930171251296997

training epoch 212 / 500, batch #150 / 625
Loss:	1.7345683574676514

training epoch 212 / 500, batch #175 / 625
Loss:	1.562695860862732

training epoch 212 / 500, batch #200 / 625
Loss:	1.5517408847808838

training epoch 212 / 500, batch #225 / 625
Loss:	2.0307986736297607

training epoch 212 / 500, batch #250 / 625
Loss:	1.827558994293213

training epoch 212 / 500, batch #275 / 625
Loss:	1.6604366302490234

training epoch 212 / 500, batch #300 / 625
Loss:	1.613660454750061

training epoch 212 / 500, batch #325 / 625
Loss:	1.4797303676605225

training epoch 212 / 500, batch #350 / 625
Loss:	1.870924949645996

training epoch 212 / 500, batch #375 / 625
Loss:	1.791363000869751

training epoch 212 / 500, batch #400 / 625
Loss:	1.7761318683624268

training epoch 212 / 500, batch #425 / 625
Loss:	1.663232684135437

training epoch 212 / 500, batch #450 / 625
Loss:	1.8053239583969116

training epoch 212 / 500, batch #475 / 625
Loss:	1.5523881912231445

training epoch 212 / 500, batch #500 / 625
Loss:	1.815825343132019

training epoch 212 / 500, batch #525 / 625
Loss:	1.8280761241912842

training epoch 212 / 500, batch #550 / 625
Loss:	1.9450886249542236

training epoch 212 / 500, batch #575 / 625
Loss:	1.7142597436904907

training epoch 212 / 500, batch #600 / 625
Loss:	1.9175440073013306

training epoch 213 / 500, batch #0 / 625
Loss:	1.7202545404434204

training epoch 213 / 500, batch #25 / 625
Loss:	1.7511862516403198

training epoch 213 / 500, batch #50 / 625
Loss:	1.8463996648788452

training epoch 213 / 500, batch #75 / 625
Loss:	1.9741945266723633

training epoch 213 / 500, batch #100 / 625
Loss:	1.6850976943969727

training epoch 213 / 500, batch #125 / 625
Loss:	1.6937464475631714

training epoch 213 / 500, batch #150 / 625
Loss:	1.9067538976669312

training epoch 213 / 500, batch #175 / 625
Loss:	1.6478315591812134

training epoch 213 / 500, batch #200 / 625
Loss:	1.799800157546997

training epoch 213 / 500, batch #225 / 625
Loss:	1.6541006565093994

training epoch 213 / 500, batch #250 / 625
Loss:	1.7063148021697998

training epoch 213 / 500, batch #275 / 625
Loss:	1.6639347076416016

training epoch 213 / 500, batch #300 / 625
Loss:	1.8251497745513916

training epoch 213 / 500, batch #325 / 625
Loss:	2.056594133377075

training epoch 213 / 500, batch #350 / 625
Loss:	1.757098913192749

training epoch 213 / 500, batch #375 / 625
Loss:	1.6414014101028442

training epoch 213 / 500, batch #400 / 625
Loss:	1.8023985624313354

training epoch 213 / 500, batch #425 / 625
Loss:	1.6285165548324585

training epoch 213 / 500, batch #450 / 625
Loss:	1.7874913215637207

training epoch 213 / 500, batch #475 / 625
Loss:	2.0027427673339844

training epoch 213 / 500, batch #500 / 625
Loss:	1.748457670211792

training epoch 213 / 500, batch #525 / 625
Loss:	1.7993531227111816

training epoch 213 / 500, batch #550 / 625
Loss:	1.6824816465377808

training epoch 213 / 500, batch #575 / 625
Loss:	1.6234984397888184

training epoch 213 / 500, batch #600 / 625
Loss:	1.6037253141403198

training epoch 214 / 500, batch #0 / 625
Loss:	1.5085835456848145

training epoch 214 / 500, batch #25 / 625
Loss:	1.6886961460113525

training epoch 214 / 500, batch #50 / 625
Loss:	1.6509687900543213

training epoch 214 / 500, batch #75 / 625
Loss:	1.709066390991211

training epoch 214 / 500, batch #100 / 625
Loss:	1.9442991018295288

training epoch 214 / 500, batch #125 / 625
Loss:	1.7566089630126953

training epoch 214 / 500, batch #150 / 625
Loss:	1.7491425275802612

training epoch 214 / 500, batch #175 / 625
Loss:	1.6472190618515015

training epoch 214 / 500, batch #200 / 625
Loss:	1.7081608772277832

training epoch 214 / 500, batch #225 / 625
Loss:	1.6866453886032104

training epoch 214 / 500, batch #250 / 625
Loss:	1.648108959197998

training epoch 214 / 500, batch #275 / 625
Loss:	1.8896832466125488

training epoch 214 / 500, batch #300 / 625
Loss:	1.669676661491394

training epoch 214 / 500, batch #325 / 625
Loss:	1.7948710918426514

training epoch 214 / 500, batch #350 / 625
Loss:	1.7376725673675537

training epoch 214 / 500, batch #375 / 625
Loss:	1.856048583984375

training epoch 214 / 500, batch #400 / 625
Loss:	1.7546933889389038

training epoch 214 / 500, batch #425 / 625
Loss:	1.927361249923706

training epoch 214 / 500, batch #450 / 625
Loss:	1.877015471458435

training epoch 214 / 500, batch #475 / 625
Loss:	2.1063754558563232

training epoch 214 / 500, batch #500 / 625
Loss:	1.5853842496871948

training epoch 214 / 500, batch #525 / 625
Loss:	1.6243669986724854

training epoch 214 / 500, batch #550 / 625
Loss:	1.8173131942749023

training epoch 214 / 500, batch #575 / 625
Loss:	1.6755436658859253

training epoch 214 / 500, batch #600 / 625
Loss:	1.5991008281707764

training epoch 215 / 500, batch #0 / 625
Loss:	1.4944223165512085

training epoch 215 / 500, batch #25 / 625
Loss:	1.8919044733047485

training epoch 215 / 500, batch #50 / 625
Loss:	1.6237186193466187

training epoch 215 / 500, batch #75 / 625
Loss:	1.699772596359253

training epoch 215 / 500, batch #100 / 625
Loss:	1.7310974597930908

training epoch 215 / 500, batch #125 / 625
Loss:	1.6668405532836914

training epoch 215 / 500, batch #150 / 625
Loss:	1.7494869232177734

training epoch 215 / 500, batch #175 / 625
Loss:	1.7187329530715942

training epoch 215 / 500, batch #200 / 625
Loss:	1.648032307624817

training epoch 215 / 500, batch #225 / 625
Loss:	1.6713217496871948

training epoch 215 / 500, batch #250 / 625
Loss:	1.649665117263794

training epoch 215 / 500, batch #275 / 625
Loss:	1.6101906299591064

training epoch 215 / 500, batch #300 / 625
Loss:	1.6893272399902344

training epoch 215 / 500, batch #325 / 625
Loss:	1.694826364517212

training epoch 215 / 500, batch #350 / 625
Loss:	1.6992075443267822

training epoch 215 / 500, batch #375 / 625
Loss:	1.794076919555664

training epoch 215 / 500, batch #400 / 625
Loss:	1.50432550907135

training epoch 215 / 500, batch #425 / 625
Loss:	1.7187271118164062

training epoch 215 / 500, batch #450 / 625
Loss:	1.7295342683792114

training epoch 215 / 500, batch #475 / 625
Loss:	1.8106563091278076

training epoch 215 / 500, batch #500 / 625
Loss:	1.7212436199188232

training epoch 215 / 500, batch #525 / 625
Loss:	1.4666613340377808

training epoch 215 / 500, batch #550 / 625
Loss:	2.0327768325805664

training epoch 215 / 500, batch #575 / 625
Loss:	1.6642143726348877

training epoch 215 / 500, batch #600 / 625
Loss:	1.8494817018508911

training epoch 216 / 500, batch #0 / 625
Loss:	1.821361780166626

training epoch 216 / 500, batch #25 / 625
Loss:	1.7666590213775635

training epoch 216 / 500, batch #50 / 625
Loss:	1.8785810470581055

training epoch 216 / 500, batch #75 / 625
Loss:	1.8296548128128052

training epoch 216 / 500, batch #100 / 625
Loss:	1.730844259262085

training epoch 216 / 500, batch #125 / 625
Loss:	1.6226731538772583

training epoch 216 / 500, batch #150 / 625
Loss:	1.6722594499588013

training epoch 216 / 500, batch #175 / 625
Loss:	1.9206167459487915

training epoch 216 / 500, batch #200 / 625
Loss:	1.6696689128875732

training epoch 216 / 500, batch #225 / 625
Loss:	1.8639936447143555

training epoch 216 / 500, batch #250 / 625
Loss:	1.8044739961624146

training epoch 216 / 500, batch #275 / 625
Loss:	1.504096508026123

training epoch 216 / 500, batch #300 / 625
Loss:	2.208961248397827

training epoch 216 / 500, batch #325 / 625
Loss:	1.5340362787246704

training epoch 216 / 500, batch #350 / 625
Loss:	1.471738576889038

training epoch 216 / 500, batch #375 / 625
Loss:	2.151291847229004

training epoch 216 / 500, batch #400 / 625
Loss:	1.7824395895004272

training epoch 216 / 500, batch #425 / 625
Loss:	1.8746861219406128

training epoch 216 / 500, batch #450 / 625
Loss:	1.6955424547195435

training epoch 216 / 500, batch #475 / 625
Loss:	1.7380532026290894

training epoch 216 / 500, batch #500 / 625
Loss:	1.8677250146865845

training epoch 216 / 500, batch #525 / 625
Loss:	1.7127978801727295

training epoch 216 / 500, batch #550 / 625
Loss:	1.8039944171905518

training epoch 216 / 500, batch #575 / 625
Loss:	1.7358969449996948

training epoch 216 / 500, batch #600 / 625
Loss:	1.842124104499817

training epoch 217 / 500, batch #0 / 625
Loss:	1.5899852514266968

training epoch 217 / 500, batch #25 / 625
Loss:	2.0503833293914795

training epoch 217 / 500, batch #50 / 625
Loss:	1.6827839612960815

training epoch 217 / 500, batch #75 / 625
Loss:	1.7352533340454102

training epoch 217 / 500, batch #100 / 625
Loss:	1.6538527011871338

training epoch 217 / 500, batch #125 / 625
Loss:	1.6168416738510132

training epoch 217 / 500, batch #150 / 625
Loss:	1.6035926342010498

training epoch 217 / 500, batch #175 / 625
Loss:	1.3514931201934814

training epoch 217 / 500, batch #200 / 625
Loss:	1.710915207862854

training epoch 217 / 500, batch #225 / 625
Loss:	1.6963433027267456

training epoch 217 / 500, batch #250 / 625
Loss:	1.8732911348342896

training epoch 217 / 500, batch #275 / 625
Loss:	1.812195897102356

training epoch 217 / 500, batch #300 / 625
Loss:	1.5201717615127563

training epoch 217 / 500, batch #325 / 625
Loss:	1.6304514408111572

training epoch 217 / 500, batch #350 / 625
Loss:	1.8380472660064697

training epoch 217 / 500, batch #375 / 625
Loss:	1.8143272399902344

training epoch 217 / 500, batch #400 / 625
Loss:	1.865565538406372

training epoch 217 / 500, batch #425 / 625
Loss:	1.6952934265136719

training epoch 217 / 500, batch #450 / 625
Loss:	1.6079623699188232

training epoch 217 / 500, batch #475 / 625
Loss:	1.8221420049667358

training epoch 217 / 500, batch #500 / 625
Loss:	1.9461898803710938

training epoch 217 / 500, batch #525 / 625
Loss:	1.8298784494400024

training epoch 217 / 500, batch #550 / 625
Loss:	1.6854528188705444

training epoch 217 / 500, batch #575 / 625
Loss:	1.7756030559539795

training epoch 217 / 500, batch #600 / 625
Loss:	1.761584758758545

training epoch 218 / 500, batch #0 / 625
Loss:	1.8573249578475952

training epoch 218 / 500, batch #25 / 625
Loss:	1.7347861528396606

training epoch 218 / 500, batch #50 / 625
Loss:	1.5418598651885986

training epoch 218 / 500, batch #75 / 625
Loss:	1.7210395336151123

training epoch 218 / 500, batch #100 / 625
Loss:	1.7537564039230347

training epoch 218 / 500, batch #125 / 625
Loss:	1.8006398677825928

training epoch 218 / 500, batch #150 / 625
Loss:	1.6265511512756348

training epoch 218 / 500, batch #175 / 625
Loss:	1.7705293893814087

training epoch 218 / 500, batch #200 / 625
Loss:	1.838945746421814

training epoch 218 / 500, batch #225 / 625
Loss:	1.8065202236175537

training epoch 218 / 500, batch #250 / 625
Loss:	1.6117550134658813

training epoch 218 / 500, batch #275 / 625
Loss:	1.7599185705184937

training epoch 218 / 500, batch #300 / 625
Loss:	1.5750709772109985

training epoch 218 / 500, batch #325 / 625
Loss:	2.2222325801849365

training epoch 218 / 500, batch #350 / 625
Loss:	1.609852910041809

training epoch 218 / 500, batch #375 / 625
Loss:	1.6344093084335327

training epoch 218 / 500, batch #400 / 625
Loss:	1.6855567693710327

training epoch 218 / 500, batch #425 / 625
Loss:	1.5330796241760254

training epoch 218 / 500, batch #450 / 625
Loss:	1.6350727081298828

training epoch 218 / 500, batch #475 / 625
Loss:	1.6782830953598022

training epoch 218 / 500, batch #500 / 625
Loss:	1.804085612297058

training epoch 218 / 500, batch #525 / 625
Loss:	1.6048662662506104

training epoch 218 / 500, batch #550 / 625
Loss:	1.8172037601470947

training epoch 218 / 500, batch #575 / 625
Loss:	1.882164478302002

training epoch 218 / 500, batch #600 / 625
Loss:	1.8472907543182373

training epoch 219 / 500, batch #0 / 625
Loss:	1.6769987344741821

training epoch 219 / 500, batch #25 / 625
Loss:	2.128706216812134

training epoch 219 / 500, batch #50 / 625
Loss:	1.9825515747070312

training epoch 219 / 500, batch #75 / 625
Loss:	1.7469260692596436

training epoch 219 / 500, batch #100 / 625
Loss:	2.0811190605163574

training epoch 219 / 500, batch #125 / 625
Loss:	1.5540202856063843

training epoch 219 / 500, batch #150 / 625
Loss:	1.6840723752975464

training epoch 219 / 500, batch #175 / 625
Loss:	1.7045822143554688

training epoch 219 / 500, batch #200 / 625
Loss:	1.6661365032196045

training epoch 219 / 500, batch #225 / 625
Loss:	1.7693753242492676

training epoch 219 / 500, batch #250 / 625
Loss:	1.5769145488739014

training epoch 219 / 500, batch #275 / 625
Loss:	1.886980414390564

training epoch 219 / 500, batch #300 / 625
Loss:	1.8950121402740479

training epoch 219 / 500, batch #325 / 625
Loss:	1.4874789714813232

training epoch 219 / 500, batch #350 / 625
Loss:	1.8810745477676392

training epoch 219 / 500, batch #375 / 625
Loss:	1.7016239166259766

training epoch 219 / 500, batch #400 / 625
Loss:	1.8362014293670654

training epoch 219 / 500, batch #425 / 625
Loss:	1.673344612121582

training epoch 219 / 500, batch #450 / 625
Loss:	1.8578059673309326

training epoch 219 / 500, batch #475 / 625
Loss:	1.6878479719161987

training epoch 219 / 500, batch #500 / 625
Loss:	1.5790427923202515

training epoch 219 / 500, batch #525 / 625
Loss:	1.5962635278701782

training epoch 219 / 500, batch #550 / 625
Loss:	1.656684160232544

training epoch 219 / 500, batch #575 / 625
Loss:	1.930938720703125

training epoch 219 / 500, batch #600 / 625
Loss:	1.7236382961273193

training epoch 220 / 500, batch #0 / 625
Loss:	1.7854716777801514

training epoch 220 / 500, batch #25 / 625
Loss:	1.749035358428955

training epoch 220 / 500, batch #50 / 625
Loss:	1.5710548162460327

training epoch 220 / 500, batch #75 / 625
Loss:	1.659529685974121

training epoch 220 / 500, batch #100 / 625
Loss:	1.81864595413208

training epoch 220 / 500, batch #125 / 625
Loss:	1.5879156589508057

training epoch 220 / 500, batch #150 / 625
Loss:	1.7708536386489868

training epoch 220 / 500, batch #175 / 625
Loss:	1.4907324314117432

training epoch 220 / 500, batch #200 / 625
Loss:	1.7652641534805298

training epoch 220 / 500, batch #225 / 625
Loss:	1.5070406198501587

training epoch 220 / 500, batch #250 / 625
Loss:	1.5623772144317627

training epoch 220 / 500, batch #275 / 625
Loss:	1.9141247272491455

training epoch 220 / 500, batch #300 / 625
Loss:	1.765905499458313

training epoch 220 / 500, batch #325 / 625
Loss:	2.053680181503296

training epoch 220 / 500, batch #350 / 625
Loss:	1.819894552230835

training epoch 220 / 500, batch #375 / 625
Loss:	1.7395291328430176

training epoch 220 / 500, batch #400 / 625
Loss:	1.6084269285202026

training epoch 220 / 500, batch #425 / 625
Loss:	1.7653982639312744

training epoch 220 / 500, batch #450 / 625
Loss:	1.9109818935394287

training epoch 220 / 500, batch #475 / 625
Loss:	1.8532363176345825

training epoch 220 / 500, batch #500 / 625
Loss:	1.710497498512268

training epoch 220 / 500, batch #525 / 625
Loss:	1.5786714553833008

training epoch 220 / 500, batch #550 / 625
Loss:	1.7182879447937012

training epoch 220 / 500, batch #575 / 625
Loss:	1.8619776964187622

training epoch 220 / 500, batch #600 / 625
Loss:	1.8656796216964722

training epoch 221 / 500, batch #0 / 625
Loss:	1.768214464187622

training epoch 221 / 500, batch #25 / 625
Loss:	1.7496763467788696

training epoch 221 / 500, batch #50 / 625
Loss:	1.487929344177246

training epoch 221 / 500, batch #75 / 625
Loss:	1.6412357091903687

training epoch 221 / 500, batch #100 / 625
Loss:	1.9839192628860474

training epoch 221 / 500, batch #125 / 625
Loss:	1.606238842010498

training epoch 221 / 500, batch #150 / 625
Loss:	1.912046194076538

training epoch 221 / 500, batch #175 / 625
Loss:	1.687309980392456

training epoch 221 / 500, batch #200 / 625
Loss:	1.751510500907898

training epoch 221 / 500, batch #225 / 625
Loss:	1.7479921579360962

training epoch 221 / 500, batch #250 / 625
Loss:	1.7668808698654175

training epoch 221 / 500, batch #275 / 625
Loss:	1.6932536363601685

training epoch 221 / 500, batch #300 / 625
Loss:	1.715503454208374

training epoch 221 / 500, batch #325 / 625
Loss:	1.6643365621566772

training epoch 221 / 500, batch #350 / 625
Loss:	1.7200398445129395

training epoch 221 / 500, batch #375 / 625
Loss:	1.7723722457885742

training epoch 221 / 500, batch #400 / 625
Loss:	1.7538682222366333

training epoch 221 / 500, batch #425 / 625
Loss:	1.8057918548583984

training epoch 221 / 500, batch #450 / 625
Loss:	1.9535048007965088

training epoch 221 / 500, batch #475 / 625
Loss:	1.877598762512207

training epoch 221 / 500, batch #500 / 625
Loss:	2.0366601943969727

training epoch 221 / 500, batch #525 / 625
Loss:	1.6777806282043457

training epoch 221 / 500, batch #550 / 625
Loss:	1.7372972965240479

training epoch 221 / 500, batch #575 / 625
Loss:	1.6794923543930054

training epoch 221 / 500, batch #600 / 625
Loss:	1.7021772861480713

training epoch 222 / 500, batch #0 / 625
Loss:	1.6635688543319702

training epoch 222 / 500, batch #25 / 625
Loss:	1.6659557819366455

training epoch 222 / 500, batch #50 / 625
Loss:	1.6179121732711792

training epoch 222 / 500, batch #75 / 625
Loss:	1.7504183053970337

training epoch 222 / 500, batch #100 / 625
Loss:	1.5824573040008545

training epoch 222 / 500, batch #125 / 625
Loss:	1.9924184083938599

training epoch 222 / 500, batch #150 / 625
Loss:	1.8097440004348755

training epoch 222 / 500, batch #175 / 625
Loss:	1.8195770978927612

training epoch 222 / 500, batch #200 / 625
Loss:	1.7227355241775513

training epoch 222 / 500, batch #225 / 625
Loss:	1.7601690292358398

training epoch 222 / 500, batch #250 / 625
Loss:	1.8530786037445068

training epoch 222 / 500, batch #275 / 625
Loss:	1.7226603031158447

training epoch 222 / 500, batch #300 / 625
Loss:	1.8068952560424805

training epoch 222 / 500, batch #325 / 625
Loss:	1.6090071201324463

training epoch 222 / 500, batch #350 / 625
Loss:	1.7976889610290527

training epoch 222 / 500, batch #375 / 625
Loss:	1.6701645851135254

training epoch 222 / 500, batch #400 / 625
Loss:	1.8667161464691162

training epoch 222 / 500, batch #425 / 625
Loss:	1.8666083812713623

training epoch 222 / 500, batch #450 / 625
Loss:	1.6352777481079102

training epoch 222 / 500, batch #475 / 625
Loss:	1.5450942516326904

training epoch 222 / 500, batch #500 / 625
Loss:	1.6086088418960571

training epoch 222 / 500, batch #525 / 625
Loss:	1.7674891948699951

training epoch 222 / 500, batch #550 / 625
Loss:	1.6205273866653442

training epoch 222 / 500, batch #575 / 625
Loss:	1.7813472747802734

training epoch 222 / 500, batch #600 / 625
Loss:	1.731819987297058

training epoch 223 / 500, batch #0 / 625
Loss:	1.7434955835342407

training epoch 223 / 500, batch #25 / 625
Loss:	1.789842963218689

training epoch 223 / 500, batch #50 / 625
Loss:	2.0224380493164062

training epoch 223 / 500, batch #75 / 625
Loss:	1.9070404767990112

training epoch 223 / 500, batch #100 / 625
Loss:	1.6302398443222046

training epoch 223 / 500, batch #125 / 625
Loss:	1.7191661596298218

training epoch 223 / 500, batch #150 / 625
Loss:	1.6708282232284546

training epoch 223 / 500, batch #175 / 625
Loss:	1.4917731285095215

training epoch 223 / 500, batch #200 / 625
Loss:	1.833412528038025

training epoch 223 / 500, batch #225 / 625
Loss:	1.5706132650375366

training epoch 223 / 500, batch #250 / 625
Loss:	1.6106418371200562

training epoch 223 / 500, batch #275 / 625
Loss:	1.8022671937942505

training epoch 223 / 500, batch #300 / 625
Loss:	1.769644021987915

training epoch 223 / 500, batch #325 / 625
Loss:	1.8043726682662964

training epoch 223 / 500, batch #350 / 625
Loss:	1.4299029111862183

training epoch 223 / 500, batch #375 / 625
Loss:	1.7208894491195679

training epoch 223 / 500, batch #400 / 625
Loss:	1.739723801612854

training epoch 223 / 500, batch #425 / 625
Loss:	1.785288691520691

training epoch 223 / 500, batch #450 / 625
Loss:	1.6753867864608765

training epoch 223 / 500, batch #475 / 625
Loss:	1.9283084869384766

training epoch 223 / 500, batch #500 / 625
Loss:	2.0372908115386963

training epoch 223 / 500, batch #525 / 625
Loss:	1.7831403017044067

training epoch 223 / 500, batch #550 / 625
Loss:	1.5049691200256348

training epoch 223 / 500, batch #575 / 625
Loss:	1.7444016933441162

training epoch 223 / 500, batch #600 / 625
Loss:	1.7853493690490723

training epoch 224 / 500, batch #0 / 625
Loss:	1.697736144065857

training epoch 224 / 500, batch #25 / 625
Loss:	1.7443615198135376

training epoch 224 / 500, batch #50 / 625
Loss:	1.746724247932434

training epoch 224 / 500, batch #75 / 625
Loss:	1.5368759632110596

training epoch 224 / 500, batch #100 / 625
Loss:	1.7157713174819946

training epoch 224 / 500, batch #125 / 625
Loss:	1.572238802909851

training epoch 224 / 500, batch #150 / 625
Loss:	1.5479497909545898

training epoch 224 / 500, batch #175 / 625
Loss:	1.8569977283477783

training epoch 224 / 500, batch #200 / 625
Loss:	1.6421009302139282

training epoch 224 / 500, batch #225 / 625
Loss:	1.7642375230789185

training epoch 224 / 500, batch #250 / 625
Loss:	1.823192834854126

training epoch 224 / 500, batch #275 / 625
Loss:	1.6805732250213623

training epoch 224 / 500, batch #300 / 625
Loss:	1.814038872718811

training epoch 224 / 500, batch #325 / 625
Loss:	1.6992419958114624

training epoch 224 / 500, batch #350 / 625
Loss:	1.7499350309371948

training epoch 224 / 500, batch #375 / 625
Loss:	1.7094318866729736

training epoch 224 / 500, batch #400 / 625
Loss:	1.7125815153121948

training epoch 224 / 500, batch #425 / 625
Loss:	1.594753384590149

training epoch 224 / 500, batch #450 / 625
Loss:	1.70448899269104

training epoch 224 / 500, batch #475 / 625
Loss:	1.6505593061447144

training epoch 224 / 500, batch #500 / 625
Loss:	2.02805757522583

training epoch 224 / 500, batch #525 / 625
Loss:	1.607801914215088

training epoch 224 / 500, batch #550 / 625
Loss:	1.8284204006195068

training epoch 224 / 500, batch #575 / 625
Loss:	1.8539799451828003

training epoch 224 / 500, batch #600 / 625
Loss:	1.6947054862976074

training epoch 225 / 500, batch #0 / 625
Loss:	1.6492539644241333

training epoch 225 / 500, batch #25 / 625
Loss:	1.6437031030654907

training epoch 225 / 500, batch #50 / 625
Loss:	1.8643131256103516

training epoch 225 / 500, batch #75 / 625
Loss:	1.6669209003448486

training epoch 225 / 500, batch #100 / 625
Loss:	2.0175564289093018

training epoch 225 / 500, batch #125 / 625
Loss:	1.9047884941101074

training epoch 225 / 500, batch #150 / 625
Loss:	1.6724634170532227

training epoch 225 / 500, batch #175 / 625
Loss:	1.7191294431686401

training epoch 225 / 500, batch #200 / 625
Loss:	1.7737723588943481

training epoch 225 / 500, batch #225 / 625
Loss:	1.9872243404388428

training epoch 225 / 500, batch #250 / 625
Loss:	1.778255820274353

training epoch 225 / 500, batch #275 / 625
Loss:	1.9166234731674194

training epoch 225 / 500, batch #300 / 625
Loss:	1.4703956842422485

training epoch 225 / 500, batch #325 / 625
Loss:	1.7208163738250732

training epoch 225 / 500, batch #350 / 625
Loss:	1.4272040128707886

training epoch 225 / 500, batch #375 / 625
Loss:	1.815234899520874

training epoch 225 / 500, batch #400 / 625
Loss:	1.7407267093658447

training epoch 225 / 500, batch #425 / 625
Loss:	1.9315299987792969

training epoch 225 / 500, batch #450 / 625
Loss:	1.6199842691421509

training epoch 225 / 500, batch #475 / 625
Loss:	1.9296867847442627

training epoch 225 / 500, batch #500 / 625
Loss:	1.9451112747192383

training epoch 225 / 500, batch #525 / 625
Loss:	1.8287522792816162

training epoch 225 / 500, batch #550 / 625
Loss:	1.8085802793502808

training epoch 225 / 500, batch #575 / 625
Loss:	1.7704130411148071

training epoch 225 / 500, batch #600 / 625
Loss:	1.7736477851867676

training epoch 226 / 500, batch #0 / 625
Loss:	1.8890985250473022

training epoch 226 / 500, batch #25 / 625
Loss:	1.78138267993927

training epoch 226 / 500, batch #50 / 625
Loss:	1.6917102336883545

training epoch 226 / 500, batch #75 / 625
Loss:	1.5135183334350586

training epoch 226 / 500, batch #100 / 625
Loss:	1.8634666204452515

training epoch 226 / 500, batch #125 / 625
Loss:	1.8553595542907715

training epoch 226 / 500, batch #150 / 625
Loss:	1.9048967361450195

training epoch 226 / 500, batch #175 / 625
Loss:	1.7822340726852417

training epoch 226 / 500, batch #200 / 625
Loss:	1.7524009943008423

training epoch 226 / 500, batch #225 / 625
Loss:	1.9518816471099854

training epoch 226 / 500, batch #250 / 625
Loss:	2.068108558654785

training epoch 226 / 500, batch #275 / 625
Loss:	1.8960587978363037

training epoch 226 / 500, batch #300 / 625
Loss:	1.5514745712280273

training epoch 226 / 500, batch #325 / 625
Loss:	1.8736159801483154

training epoch 226 / 500, batch #350 / 625
Loss:	1.7268729209899902

training epoch 226 / 500, batch #375 / 625
Loss:	1.6025879383087158

training epoch 226 / 500, batch #400 / 625
Loss:	1.8209625482559204

training epoch 226 / 500, batch #425 / 625
Loss:	1.8031530380249023

training epoch 226 / 500, batch #450 / 625
Loss:	1.5683159828186035

training epoch 226 / 500, batch #475 / 625
Loss:	1.8935120105743408

training epoch 226 / 500, batch #500 / 625
Loss:	1.6759830713272095

training epoch 226 / 500, batch #525 / 625
Loss:	1.8463504314422607

training epoch 226 / 500, batch #550 / 625
Loss:	1.4808439016342163

training epoch 226 / 500, batch #575 / 625
Loss:	2.0262300968170166

training epoch 226 / 500, batch #600 / 625
Loss:	1.8422739505767822

training epoch 227 / 500, batch #0 / 625
Loss:	1.7329552173614502

training epoch 227 / 500, batch #25 / 625
Loss:	1.7282845973968506

training epoch 227 / 500, batch #50 / 625
Loss:	1.5278352499008179

training epoch 227 / 500, batch #75 / 625
Loss:	1.7505511045455933

training epoch 227 / 500, batch #100 / 625
Loss:	1.5777454376220703

training epoch 227 / 500, batch #125 / 625
Loss:	1.5127582550048828

training epoch 227 / 500, batch #150 / 625
Loss:	1.9150007963180542

training epoch 227 / 500, batch #175 / 625
Loss:	1.7842915058135986

training epoch 227 / 500, batch #200 / 625
Loss:	1.7236260175704956

training epoch 227 / 500, batch #225 / 625
Loss:	1.6632241010665894

training epoch 227 / 500, batch #250 / 625
Loss:	1.568787932395935

training epoch 227 / 500, batch #275 / 625
Loss:	1.9926280975341797

training epoch 227 / 500, batch #300 / 625
Loss:	1.6316536664962769

training epoch 227 / 500, batch #325 / 625
Loss:	1.8232346773147583

training epoch 227 / 500, batch #350 / 625
Loss:	1.424535870552063

training epoch 227 / 500, batch #375 / 625
Loss:	1.7080682516098022

training epoch 227 / 500, batch #400 / 625
Loss:	1.590435266494751

training epoch 227 / 500, batch #425 / 625
Loss:	1.9505362510681152

training epoch 227 / 500, batch #450 / 625
Loss:	1.8658902645111084

training epoch 227 / 500, batch #475 / 625
Loss:	1.9065375328063965

training epoch 227 / 500, batch #500 / 625
Loss:	1.7839242219924927

training epoch 227 / 500, batch #525 / 625
Loss:	1.6994709968566895

training epoch 227 / 500, batch #550 / 625
Loss:	1.8402955532073975

training epoch 227 / 500, batch #575 / 625
Loss:	1.5503597259521484

training epoch 227 / 500, batch #600 / 625
Loss:	1.4114620685577393

training epoch 228 / 500, batch #0 / 625
Loss:	1.6633423566818237

training epoch 228 / 500, batch #25 / 625
Loss:	1.8871699571609497

training epoch 228 / 500, batch #50 / 625
Loss:	1.814758062362671

training epoch 228 / 500, batch #75 / 625
Loss:	1.6454471349716187

training epoch 228 / 500, batch #100 / 625
Loss:	1.7369499206542969

training epoch 228 / 500, batch #125 / 625
Loss:	1.5501309633255005

training epoch 228 / 500, batch #150 / 625
Loss:	1.6268664598464966

training epoch 228 / 500, batch #175 / 625
Loss:	1.5965240001678467

training epoch 228 / 500, batch #200 / 625
Loss:	1.7795346975326538

training epoch 228 / 500, batch #225 / 625
Loss:	1.587739109992981

training epoch 228 / 500, batch #250 / 625
Loss:	1.6515488624572754

training epoch 228 / 500, batch #275 / 625
Loss:	1.748490333557129

training epoch 228 / 500, batch #300 / 625
Loss:	1.7507612705230713

training epoch 228 / 500, batch #325 / 625
Loss:	1.911490797996521

training epoch 228 / 500, batch #350 / 625
Loss:	1.676604986190796

training epoch 228 / 500, batch #375 / 625
Loss:	1.8649934530258179

training epoch 228 / 500, batch #400 / 625
Loss:	1.739241123199463

training epoch 228 / 500, batch #425 / 625
Loss:	1.828587293624878

training epoch 228 / 500, batch #450 / 625
Loss:	1.7397373914718628

training epoch 228 / 500, batch #475 / 625
Loss:	1.766133189201355

training epoch 228 / 500, batch #500 / 625
Loss:	1.7537505626678467

training epoch 228 / 500, batch #525 / 625
Loss:	1.896759271621704

training epoch 228 / 500, batch #550 / 625
Loss:	1.6694180965423584

training epoch 228 / 500, batch #575 / 625
Loss:	1.7541699409484863

training epoch 228 / 500, batch #600 / 625
Loss:	1.8642518520355225

training epoch 229 / 500, batch #0 / 625
Loss:	1.897640585899353

training epoch 229 / 500, batch #25 / 625
Loss:	1.8295570611953735

training epoch 229 / 500, batch #50 / 625
Loss:	1.8990167379379272

training epoch 229 / 500, batch #75 / 625
Loss:	1.6953481435775757

training epoch 229 / 500, batch #100 / 625
Loss:	1.592191219329834

training epoch 229 / 500, batch #125 / 625
Loss:	1.8251307010650635

training epoch 229 / 500, batch #150 / 625
Loss:	1.8078666925430298

training epoch 229 / 500, batch #175 / 625
Loss:	1.765836477279663

training epoch 229 / 500, batch #200 / 625
Loss:	1.6168811321258545

training epoch 229 / 500, batch #225 / 625
Loss:	1.9025379419326782

training epoch 229 / 500, batch #250 / 625
Loss:	1.7087031602859497

training epoch 229 / 500, batch #275 / 625
Loss:	1.9118971824645996

training epoch 229 / 500, batch #300 / 625
Loss:	1.6836931705474854

training epoch 229 / 500, batch #325 / 625
Loss:	1.730808973312378

training epoch 229 / 500, batch #350 / 625
Loss:	1.821988582611084

training epoch 229 / 500, batch #375 / 625
Loss:	1.7955986261367798

training epoch 229 / 500, batch #400 / 625
Loss:	2.1062588691711426

training epoch 229 / 500, batch #425 / 625
Loss:	1.734961748123169

training epoch 229 / 500, batch #450 / 625
Loss:	1.7945424318313599

training epoch 229 / 500, batch #475 / 625
Loss:	1.7654047012329102

training epoch 229 / 500, batch #500 / 625
Loss:	1.6639103889465332

training epoch 229 / 500, batch #525 / 625
Loss:	1.7232557535171509

training epoch 229 / 500, batch #550 / 625
Loss:	1.2771450281143188

training epoch 229 / 500, batch #575 / 625
Loss:	1.7300529479980469

training epoch 229 / 500, batch #600 / 625
Loss:	1.5094857215881348

training epoch 230 / 500, batch #0 / 625
Loss:	1.6019606590270996

training epoch 230 / 500, batch #25 / 625
Loss:	1.8465441465377808

training epoch 230 / 500, batch #50 / 625
Loss:	1.8117889165878296

training epoch 230 / 500, batch #75 / 625
Loss:	1.6931513547897339

training epoch 230 / 500, batch #100 / 625
Loss:	1.9903640747070312

training epoch 230 / 500, batch #125 / 625
Loss:	1.566429853439331

training epoch 230 / 500, batch #150 / 625
Loss:	1.577301025390625

training epoch 230 / 500, batch #175 / 625
Loss:	1.7663267850875854

training epoch 230 / 500, batch #200 / 625
Loss:	1.8520559072494507

training epoch 230 / 500, batch #225 / 625
Loss:	1.9054102897644043

training epoch 230 / 500, batch #250 / 625
Loss:	1.7960816621780396

training epoch 230 / 500, batch #275 / 625
Loss:	1.6942698955535889

training epoch 230 / 500, batch #300 / 625
Loss:	1.6455621719360352

training epoch 230 / 500, batch #325 / 625
Loss:	1.5803543329238892

training epoch 230 / 500, batch #350 / 625
Loss:	1.8513575792312622

training epoch 230 / 500, batch #375 / 625
Loss:	1.5825986862182617

training epoch 230 / 500, batch #400 / 625
Loss:	1.6945663690567017

training epoch 230 / 500, batch #425 / 625
Loss:	1.7722053527832031

training epoch 230 / 500, batch #450 / 625
Loss:	1.7783232927322388

training epoch 230 / 500, batch #475 / 625
Loss:	1.787712574005127

training epoch 230 / 500, batch #500 / 625
Loss:	1.9260210990905762

training epoch 230 / 500, batch #525 / 625
Loss:	1.6581765413284302

training epoch 230 / 500, batch #550 / 625
Loss:	1.9001613855361938

training epoch 230 / 500, batch #575 / 625
Loss:	1.854899287223816

training epoch 230 / 500, batch #600 / 625
Loss:	1.7606981992721558

training epoch 231 / 500, batch #0 / 625
Loss:	1.7786835432052612

training epoch 231 / 500, batch #25 / 625
Loss:	1.8818352222442627

training epoch 231 / 500, batch #50 / 625
Loss:	1.5533385276794434

training epoch 231 / 500, batch #75 / 625
Loss:	1.6958287954330444

training epoch 231 / 500, batch #100 / 625
Loss:	1.5029151439666748

training epoch 231 / 500, batch #125 / 625
Loss:	1.9568132162094116

training epoch 231 / 500, batch #150 / 625
Loss:	1.7049444913864136

training epoch 231 / 500, batch #175 / 625
Loss:	1.9129830598831177

training epoch 231 / 500, batch #200 / 625
Loss:	1.6609346866607666

training epoch 231 / 500, batch #225 / 625
Loss:	1.7350718975067139

training epoch 231 / 500, batch #250 / 625
Loss:	1.6094026565551758

training epoch 231 / 500, batch #275 / 625
Loss:	1.7441680431365967

training epoch 231 / 500, batch #300 / 625
Loss:	1.5388281345367432

training epoch 231 / 500, batch #325 / 625
Loss:	1.7393312454223633

training epoch 231 / 500, batch #350 / 625
Loss:	1.540202260017395

training epoch 231 / 500, batch #375 / 625
Loss:	1.8938937187194824

training epoch 231 / 500, batch #400 / 625
Loss:	1.6901832818984985

training epoch 231 / 500, batch #425 / 625
Loss:	1.9300838708877563

training epoch 231 / 500, batch #450 / 625
Loss:	1.6666338443756104

training epoch 231 / 500, batch #475 / 625
Loss:	1.7159712314605713

training epoch 231 / 500, batch #500 / 625
Loss:	1.5999791622161865

training epoch 231 / 500, batch #525 / 625
Loss:	1.6814067363739014

training epoch 231 / 500, batch #550 / 625
Loss:	1.9726253747940063

training epoch 231 / 500, batch #575 / 625
Loss:	1.8250731229782104

training epoch 231 / 500, batch #600 / 625
Loss:	1.6916295289993286

training epoch 232 / 500, batch #0 / 625
Loss:	1.689508080482483

training epoch 232 / 500, batch #25 / 625
Loss:	1.5883513689041138

training epoch 232 / 500, batch #50 / 625
Loss:	1.5373963117599487

training epoch 232 / 500, batch #75 / 625
Loss:	1.9127821922302246

training epoch 232 / 500, batch #100 / 625
Loss:	1.5659853219985962

training epoch 232 / 500, batch #125 / 625
Loss:	2.109419584274292

training epoch 232 / 500, batch #150 / 625
Loss:	1.8202998638153076

training epoch 232 / 500, batch #175 / 625
Loss:	1.6321425437927246

training epoch 232 / 500, batch #200 / 625
Loss:	1.7883354425430298

training epoch 232 / 500, batch #225 / 625
Loss:	1.8621958494186401

training epoch 232 / 500, batch #250 / 625
Loss:	1.6212643384933472

training epoch 232 / 500, batch #275 / 625
Loss:	1.5241448879241943

training epoch 232 / 500, batch #300 / 625
Loss:	1.673947811126709

training epoch 232 / 500, batch #325 / 625
Loss:	1.6324145793914795

training epoch 232 / 500, batch #350 / 625
Loss:	1.6617071628570557

training epoch 232 / 500, batch #375 / 625
Loss:	1.568017840385437

training epoch 232 / 500, batch #400 / 625
Loss:	1.83664870262146

training epoch 232 / 500, batch #425 / 625
Loss:	1.6564563512802124

training epoch 232 / 500, batch #450 / 625
Loss:	1.5645904541015625

training epoch 232 / 500, batch #475 / 625
Loss:	1.9904193878173828

training epoch 232 / 500, batch #500 / 625
Loss:	1.7652424573898315

training epoch 232 / 500, batch #525 / 625
Loss:	1.8584871292114258

training epoch 232 / 500, batch #550 / 625
Loss:	1.5774853229522705

training epoch 232 / 500, batch #575 / 625
Loss:	1.7424015998840332

training epoch 232 / 500, batch #600 / 625
Loss:	1.8482965230941772

training epoch 233 / 500, batch #0 / 625
Loss:	1.8277883529663086

training epoch 233 / 500, batch #25 / 625
Loss:	1.3500648736953735

training epoch 233 / 500, batch #50 / 625
Loss:	1.7348031997680664

training epoch 233 / 500, batch #75 / 625
Loss:	1.5743215084075928

training epoch 233 / 500, batch #100 / 625
Loss:	1.5565136671066284

training epoch 233 / 500, batch #125 / 625
Loss:	1.6158010959625244

training epoch 233 / 500, batch #150 / 625
Loss:	1.8411309719085693

training epoch 233 / 500, batch #175 / 625
Loss:	1.9515535831451416

training epoch 233 / 500, batch #200 / 625
Loss:	1.8715333938598633

training epoch 233 / 500, batch #225 / 625
Loss:	1.6676779985427856

training epoch 233 / 500, batch #250 / 625
Loss:	1.964967131614685

training epoch 233 / 500, batch #275 / 625
Loss:	1.9434068202972412

training epoch 233 / 500, batch #300 / 625
Loss:	1.8232059478759766

training epoch 233 / 500, batch #325 / 625
Loss:	1.7696268558502197

training epoch 233 / 500, batch #350 / 625
Loss:	1.467116117477417

training epoch 233 / 500, batch #375 / 625
Loss:	1.880007028579712

training epoch 233 / 500, batch #400 / 625
Loss:	1.5914937257766724

training epoch 233 / 500, batch #425 / 625
Loss:	1.6436190605163574

training epoch 233 / 500, batch #450 / 625
Loss:	1.7228221893310547

training epoch 233 / 500, batch #475 / 625
Loss:	1.8554221391677856

training epoch 233 / 500, batch #500 / 625
Loss:	1.8260998725891113

training epoch 233 / 500, batch #525 / 625
Loss:	1.8310375213623047

training epoch 233 / 500, batch #550 / 625
Loss:	1.640810251235962

training epoch 233 / 500, batch #575 / 625
Loss:	1.689348578453064

training epoch 233 / 500, batch #600 / 625
Loss:	1.7045174837112427

training epoch 234 / 500, batch #0 / 625
Loss:	1.7181029319763184

training epoch 234 / 500, batch #25 / 625
Loss:	1.8660215139389038

training epoch 234 / 500, batch #50 / 625
Loss:	1.5973076820373535

training epoch 234 / 500, batch #75 / 625
Loss:	1.5535354614257812

training epoch 234 / 500, batch #100 / 625
Loss:	1.9434839487075806

training epoch 234 / 500, batch #125 / 625
Loss:	1.84633469581604

training epoch 234 / 500, batch #150 / 625
Loss:	1.697396993637085

training epoch 234 / 500, batch #175 / 625
Loss:	1.553083896636963

training epoch 234 / 500, batch #200 / 625
Loss:	2.0622239112854004

training epoch 234 / 500, batch #225 / 625
Loss:	2.0150513648986816

training epoch 234 / 500, batch #250 / 625
Loss:	2.013223648071289

training epoch 234 / 500, batch #275 / 625
Loss:	1.7397899627685547

training epoch 234 / 500, batch #300 / 625
Loss:	1.8277603387832642

training epoch 234 / 500, batch #325 / 625
Loss:	1.9072074890136719

training epoch 234 / 500, batch #350 / 625
Loss:	1.7675185203552246

training epoch 234 / 500, batch #375 / 625
Loss:	1.516462802886963

training epoch 234 / 500, batch #400 / 625
Loss:	1.8079053163528442

training epoch 234 / 500, batch #425 / 625
Loss:	1.6327298879623413

training epoch 234 / 500, batch #450 / 625
Loss:	1.709163784980774

training epoch 234 / 500, batch #475 / 625
Loss:	1.8026535511016846

training epoch 234 / 500, batch #500 / 625
Loss:	1.8528518676757812

training epoch 234 / 500, batch #525 / 625
Loss:	1.6681177616119385

training epoch 234 / 500, batch #550 / 625
Loss:	2.0182392597198486

training epoch 234 / 500, batch #575 / 625
Loss:	1.7342643737792969

training epoch 234 / 500, batch #600 / 625
Loss:	1.7274006605148315

training epoch 235 / 500, batch #0 / 625
Loss:	1.769212007522583

training epoch 235 / 500, batch #25 / 625
Loss:	2.0882344245910645

training epoch 235 / 500, batch #50 / 625
Loss:	1.7644578218460083

training epoch 235 / 500, batch #75 / 625
Loss:	1.6853182315826416

training epoch 235 / 500, batch #100 / 625
Loss:	1.7626224756240845

training epoch 235 / 500, batch #125 / 625
Loss:	1.7560786008834839

training epoch 235 / 500, batch #150 / 625
Loss:	1.839356780052185

training epoch 235 / 500, batch #175 / 625
Loss:	1.4278202056884766

training epoch 235 / 500, batch #200 / 625
Loss:	1.648702621459961

training epoch 235 / 500, batch #225 / 625
Loss:	1.683375358581543

training epoch 235 / 500, batch #250 / 625
Loss:	1.6584110260009766

training epoch 235 / 500, batch #275 / 625
Loss:	1.7384302616119385

training epoch 235 / 500, batch #300 / 625
Loss:	1.6180171966552734

training epoch 235 / 500, batch #325 / 625
Loss:	1.5245985984802246

training epoch 235 / 500, batch #350 / 625
Loss:	1.7138460874557495

training epoch 235 / 500, batch #375 / 625
Loss:	1.5822672843933105

training epoch 235 / 500, batch #400 / 625
Loss:	1.6152828931808472

training epoch 235 / 500, batch #425 / 625
Loss:	1.8851490020751953

training epoch 235 / 500, batch #450 / 625
Loss:	1.6399246454238892

training epoch 235 / 500, batch #475 / 625
Loss:	1.6851179599761963

training epoch 235 / 500, batch #500 / 625
Loss:	1.778031587600708

training epoch 235 / 500, batch #525 / 625
Loss:	1.6124472618103027

training epoch 235 / 500, batch #550 / 625
Loss:	1.6839464902877808

training epoch 235 / 500, batch #575 / 625
Loss:	1.7691302299499512

training epoch 235 / 500, batch #600 / 625
Loss:	1.4522861242294312

training epoch 236 / 500, batch #0 / 625
Loss:	1.5935126543045044

training epoch 236 / 500, batch #25 / 625
Loss:	1.766940951347351

training epoch 236 / 500, batch #50 / 625
Loss:	1.8811407089233398

training epoch 236 / 500, batch #75 / 625
Loss:	1.7064319849014282

training epoch 236 / 500, batch #100 / 625
Loss:	1.7333333492279053

training epoch 236 / 500, batch #125 / 625
Loss:	1.7199475765228271

training epoch 236 / 500, batch #150 / 625
Loss:	1.604839563369751

training epoch 236 / 500, batch #175 / 625
Loss:	1.6218066215515137

training epoch 236 / 500, batch #200 / 625
Loss:	1.8830201625823975

training epoch 236 / 500, batch #225 / 625
Loss:	1.4352741241455078

training epoch 236 / 500, batch #250 / 625
Loss:	1.970262885093689

training epoch 236 / 500, batch #275 / 625
Loss:	1.581810712814331

training epoch 236 / 500, batch #300 / 625
Loss:	1.6379883289337158

training epoch 236 / 500, batch #325 / 625
Loss:	1.5776149034500122

training epoch 236 / 500, batch #350 / 625
Loss:	1.7853504419326782

training epoch 236 / 500, batch #375 / 625
Loss:	1.9332802295684814

training epoch 236 / 500, batch #400 / 625
Loss:	1.6395268440246582

training epoch 236 / 500, batch #425 / 625
Loss:	1.5868546962738037

training epoch 236 / 500, batch #450 / 625
Loss:	1.8570467233657837

training epoch 236 / 500, batch #475 / 625
Loss:	1.436627984046936

training epoch 236 / 500, batch #500 / 625
Loss:	1.8899600505828857

training epoch 236 / 500, batch #525 / 625
Loss:	1.811586856842041

training epoch 236 / 500, batch #550 / 625
Loss:	1.549537181854248

training epoch 236 / 500, batch #575 / 625
Loss:	1.7944353818893433

training epoch 236 / 500, batch #600 / 625
Loss:	1.773316502571106

training epoch 237 / 500, batch #0 / 625
Loss:	1.8544665575027466

training epoch 237 / 500, batch #25 / 625
Loss:	1.4028692245483398

training epoch 237 / 500, batch #50 / 625
Loss:	1.6617213487625122

training epoch 237 / 500, batch #75 / 625
Loss:	1.6682473421096802

training epoch 237 / 500, batch #100 / 625
Loss:	1.8249263763427734

training epoch 237 / 500, batch #125 / 625
Loss:	1.9403501749038696

training epoch 237 / 500, batch #150 / 625
Loss:	1.7880042791366577

training epoch 237 / 500, batch #175 / 625
Loss:	1.8379900455474854

training epoch 237 / 500, batch #200 / 625
Loss:	1.7559155225753784

training epoch 237 / 500, batch #225 / 625
Loss:	1.7749395370483398

training epoch 237 / 500, batch #250 / 625
Loss:	1.8384429216384888

training epoch 237 / 500, batch #275 / 625
Loss:	1.6136043071746826

training epoch 237 / 500, batch #300 / 625
Loss:	1.7800183296203613

training epoch 237 / 500, batch #325 / 625
Loss:	1.7720738649368286

training epoch 237 / 500, batch #350 / 625
Loss:	1.9457738399505615

training epoch 237 / 500, batch #375 / 625
Loss:	1.5688213109970093

training epoch 237 / 500, batch #400 / 625
Loss:	1.9515180587768555

training epoch 237 / 500, batch #425 / 625
Loss:	1.9769924879074097

training epoch 237 / 500, batch #450 / 625
Loss:	1.7011536359786987

training epoch 237 / 500, batch #475 / 625
Loss:	1.6751257181167603

training epoch 237 / 500, batch #500 / 625
Loss:	1.8559788465499878

training epoch 237 / 500, batch #525 / 625
Loss:	1.7018213272094727

training epoch 237 / 500, batch #550 / 625
Loss:	1.750373363494873

training epoch 237 / 500, batch #575 / 625
Loss:	1.8362832069396973

training epoch 237 / 500, batch #600 / 625
Loss:	1.6031731367111206

training epoch 238 / 500, batch #0 / 625
Loss:	1.7745763063430786

training epoch 238 / 500, batch #25 / 625
Loss:	1.7694865465164185

training epoch 238 / 500, batch #50 / 625
Loss:	1.718355417251587

training epoch 238 / 500, batch #75 / 625
Loss:	1.5347607135772705

training epoch 238 / 500, batch #100 / 625
Loss:	1.572150707244873

training epoch 238 / 500, batch #125 / 625
Loss:	1.9545598030090332

training epoch 238 / 500, batch #150 / 625
Loss:	1.8225096464157104

training epoch 238 / 500, batch #175 / 625
Loss:	1.6715669631958008

training epoch 238 / 500, batch #200 / 625
Loss:	1.729133129119873

training epoch 238 / 500, batch #225 / 625
Loss:	1.9497349262237549

training epoch 238 / 500, batch #250 / 625
Loss:	1.4325685501098633

training epoch 238 / 500, batch #275 / 625
Loss:	1.9122787714004517

training epoch 238 / 500, batch #300 / 625
Loss:	1.8528804779052734

training epoch 238 / 500, batch #325 / 625
Loss:	2.0425236225128174

training epoch 238 / 500, batch #350 / 625
Loss:	1.6970794200897217

training epoch 238 / 500, batch #375 / 625
Loss:	1.7736337184906006

training epoch 238 / 500, batch #400 / 625
Loss:	1.8424508571624756

training epoch 238 / 500, batch #425 / 625
Loss:	1.8609896898269653

training epoch 238 / 500, batch #450 / 625
Loss:	1.7967978715896606

training epoch 238 / 500, batch #475 / 625
Loss:	1.8228427171707153

training epoch 238 / 500, batch #500 / 625
Loss:	1.5982153415679932

training epoch 238 / 500, batch #525 / 625
Loss:	1.5346883535385132

training epoch 238 / 500, batch #550 / 625
Loss:	1.7904702425003052

training epoch 238 / 500, batch #575 / 625
Loss:	1.6208728551864624

training epoch 238 / 500, batch #600 / 625
Loss:	1.7043002843856812

training epoch 239 / 500, batch #0 / 625
Loss:	1.5999420881271362

training epoch 239 / 500, batch #25 / 625
Loss:	1.5417490005493164

training epoch 239 / 500, batch #50 / 625
Loss:	1.757723331451416

training epoch 239 / 500, batch #75 / 625
Loss:	1.7550764083862305

training epoch 239 / 500, batch #100 / 625
Loss:	1.599307894706726

training epoch 239 / 500, batch #125 / 625
Loss:	1.5682669878005981

training epoch 239 / 500, batch #150 / 625
Loss:	1.6779553890228271

training epoch 239 / 500, batch #175 / 625
Loss:	1.9326149225234985

training epoch 239 / 500, batch #200 / 625
Loss:	1.7514638900756836

training epoch 239 / 500, batch #225 / 625
Loss:	1.648113489151001

training epoch 239 / 500, batch #250 / 625
Loss:	1.7955011129379272

training epoch 239 / 500, batch #275 / 625
Loss:	1.7710070610046387

training epoch 239 / 500, batch #300 / 625
Loss:	1.572142243385315

training epoch 239 / 500, batch #325 / 625
Loss:	1.894319772720337

training epoch 239 / 500, batch #350 / 625
Loss:	1.7769378423690796

training epoch 239 / 500, batch #375 / 625
Loss:	1.8297687768936157

training epoch 239 / 500, batch #400 / 625
Loss:	1.8633112907409668

training epoch 239 / 500, batch #425 / 625
Loss:	1.5700527429580688

training epoch 239 / 500, batch #450 / 625
Loss:	1.880194902420044

training epoch 239 / 500, batch #475 / 625
Loss:	1.8651810884475708

training epoch 239 / 500, batch #500 / 625
Loss:	1.6792478561401367

training epoch 239 / 500, batch #525 / 625
Loss:	1.8362971544265747

training epoch 239 / 500, batch #550 / 625
Loss:	1.7175614833831787

training epoch 239 / 500, batch #575 / 625
Loss:	1.6980834007263184

training epoch 239 / 500, batch #600 / 625
Loss:	1.6211678981781006

training epoch 240 / 500, batch #0 / 625
Loss:	1.618707299232483

training epoch 240 / 500, batch #25 / 625
Loss:	1.9361664056777954

training epoch 240 / 500, batch #50 / 625
Loss:	2.1108083724975586

training epoch 240 / 500, batch #75 / 625
Loss:	1.8441189527511597

training epoch 240 / 500, batch #100 / 625
Loss:	1.7730828523635864

training epoch 240 / 500, batch #125 / 625
Loss:	1.7388355731964111

training epoch 240 / 500, batch #150 / 625
Loss:	1.701878309249878

training epoch 240 / 500, batch #175 / 625
Loss:	1.9141638278961182

training epoch 240 / 500, batch #200 / 625
Loss:	1.810244083404541

training epoch 240 / 500, batch #225 / 625
Loss:	1.6816247701644897

training epoch 240 / 500, batch #250 / 625
Loss:	1.5844470262527466

training epoch 240 / 500, batch #275 / 625
Loss:	2.000761032104492

training epoch 240 / 500, batch #300 / 625
Loss:	1.5964112281799316

training epoch 240 / 500, batch #325 / 625
Loss:	1.7061553001403809

training epoch 240 / 500, batch #350 / 625
Loss:	1.6589479446411133

training epoch 240 / 500, batch #375 / 625
Loss:	1.678121566772461

training epoch 240 / 500, batch #400 / 625
Loss:	1.8639682531356812

training epoch 240 / 500, batch #425 / 625
Loss:	1.6381686925888062

training epoch 240 / 500, batch #450 / 625
Loss:	1.9218626022338867

training epoch 240 / 500, batch #475 / 625
Loss:	1.4434229135513306

training epoch 240 / 500, batch #500 / 625
Loss:	1.9150350093841553

training epoch 240 / 500, batch #525 / 625
Loss:	1.736341118812561

training epoch 240 / 500, batch #550 / 625
Loss:	1.6359984874725342

training epoch 240 / 500, batch #575 / 625
Loss:	1.7711859941482544

training epoch 240 / 500, batch #600 / 625
Loss:	1.777533769607544

training epoch 241 / 500, batch #0 / 625
Loss:	1.6172250509262085

training epoch 241 / 500, batch #25 / 625
Loss:	1.7046239376068115

training epoch 241 / 500, batch #50 / 625
Loss:	1.7482753992080688

training epoch 241 / 500, batch #75 / 625
Loss:	1.858302354812622

training epoch 241 / 500, batch #100 / 625
Loss:	1.8294726610183716

training epoch 241 / 500, batch #125 / 625
Loss:	1.6845691204071045

training epoch 241 / 500, batch #150 / 625
Loss:	1.9186829328536987

training epoch 241 / 500, batch #175 / 625
Loss:	1.7287338972091675

training epoch 241 / 500, batch #200 / 625
Loss:	1.594463586807251

training epoch 241 / 500, batch #225 / 625
Loss:	1.6537855863571167

training epoch 241 / 500, batch #250 / 625
Loss:	1.7990633249282837

training epoch 241 / 500, batch #275 / 625
Loss:	1.6054317951202393

training epoch 241 / 500, batch #300 / 625
Loss:	1.7533634901046753

training epoch 241 / 500, batch #325 / 625
Loss:	2.004528284072876

training epoch 241 / 500, batch #350 / 625
Loss:	1.8021303415298462

training epoch 241 / 500, batch #375 / 625
Loss:	1.8160793781280518

training epoch 241 / 500, batch #400 / 625
Loss:	1.7203292846679688

training epoch 241 / 500, batch #425 / 625
Loss:	1.8388080596923828

training epoch 241 / 500, batch #450 / 625
Loss:	1.8309613466262817

training epoch 241 / 500, batch #475 / 625
Loss:	1.683902382850647

training epoch 241 / 500, batch #500 / 625
Loss:	1.8152635097503662

training epoch 241 / 500, batch #525 / 625
Loss:	1.748193383216858

training epoch 241 / 500, batch #550 / 625
Loss:	1.7762032747268677

training epoch 241 / 500, batch #575 / 625
Loss:	1.7181153297424316

training epoch 241 / 500, batch #600 / 625
Loss:	1.733601450920105

training epoch 242 / 500, batch #0 / 625
Loss:	1.7611331939697266

training epoch 242 / 500, batch #25 / 625
Loss:	1.4906485080718994

training epoch 242 / 500, batch #50 / 625
Loss:	2.000476598739624

training epoch 242 / 500, batch #75 / 625
Loss:	1.6282451152801514

training epoch 242 / 500, batch #100 / 625
Loss:	1.7149125337600708

training epoch 242 / 500, batch #125 / 625
Loss:	1.6027249097824097

training epoch 242 / 500, batch #150 / 625
Loss:	1.5773667097091675

training epoch 242 / 500, batch #175 / 625
Loss:	1.6228137016296387

training epoch 242 / 500, batch #200 / 625
Loss:	1.7562499046325684

training epoch 242 / 500, batch #225 / 625
Loss:	1.5323632955551147

training epoch 242 / 500, batch #250 / 625
Loss:	1.8977285623550415

training epoch 242 / 500, batch #275 / 625
Loss:	1.9138743877410889

training epoch 242 / 500, batch #300 / 625
Loss:	1.46248459815979

training epoch 242 / 500, batch #325 / 625
Loss:	1.6458491086959839

training epoch 242 / 500, batch #350 / 625
Loss:	1.7365713119506836

training epoch 242 / 500, batch #375 / 625
Loss:	1.527693510055542

training epoch 242 / 500, batch #400 / 625
Loss:	1.5723309516906738

training epoch 242 / 500, batch #425 / 625
Loss:	1.7392830848693848

training epoch 242 / 500, batch #450 / 625
Loss:	1.5356634855270386

training epoch 242 / 500, batch #475 / 625
Loss:	1.7208296060562134

training epoch 242 / 500, batch #500 / 625
Loss:	1.7202035188674927

training epoch 242 / 500, batch #525 / 625
Loss:	1.743007779121399

training epoch 242 / 500, batch #550 / 625
Loss:	1.8889591693878174

training epoch 242 / 500, batch #575 / 625
Loss:	1.72146475315094

training epoch 242 / 500, batch #600 / 625
Loss:	1.7392120361328125

training epoch 243 / 500, batch #0 / 625
Loss:	1.8450548648834229

training epoch 243 / 500, batch #25 / 625
Loss:	1.5761770009994507

training epoch 243 / 500, batch #50 / 625
Loss:	1.596928358078003

training epoch 243 / 500, batch #75 / 625
Loss:	1.7038273811340332

training epoch 243 / 500, batch #100 / 625
Loss:	1.7600295543670654

training epoch 243 / 500, batch #125 / 625
Loss:	1.9937772750854492

training epoch 243 / 500, batch #150 / 625
Loss:	1.723335862159729

training epoch 243 / 500, batch #175 / 625
Loss:	1.787702202796936

training epoch 243 / 500, batch #200 / 625
Loss:	1.8942441940307617

training epoch 243 / 500, batch #225 / 625
Loss:	1.9392831325531006

training epoch 243 / 500, batch #250 / 625
Loss:	1.7536982297897339

training epoch 243 / 500, batch #275 / 625
Loss:	1.5625032186508179

training epoch 243 / 500, batch #300 / 625
Loss:	1.6861618757247925

training epoch 243 / 500, batch #325 / 625
Loss:	1.8075169324874878

training epoch 243 / 500, batch #350 / 625
Loss:	1.6500451564788818

training epoch 243 / 500, batch #375 / 625
Loss:	1.645599603652954

training epoch 243 / 500, batch #400 / 625
Loss:	1.7714684009552002

training epoch 243 / 500, batch #425 / 625
Loss:	1.7214637994766235

training epoch 243 / 500, batch #450 / 625
Loss:	1.8304648399353027

training epoch 243 / 500, batch #475 / 625
Loss:	1.8072761297225952

training epoch 243 / 500, batch #500 / 625
Loss:	1.7856707572937012

training epoch 243 / 500, batch #525 / 625
Loss:	1.677193522453308

training epoch 243 / 500, batch #550 / 625
Loss:	1.6496028900146484

training epoch 243 / 500, batch #575 / 625
Loss:	1.9184279441833496

training epoch 243 / 500, batch #600 / 625
Loss:	1.6681352853775024

training epoch 244 / 500, batch #0 / 625
Loss:	1.9963481426239014

training epoch 244 / 500, batch #25 / 625
Loss:	1.779868245124817

training epoch 244 / 500, batch #50 / 625
Loss:	1.6039550304412842

training epoch 244 / 500, batch #75 / 625
Loss:	1.5305453538894653

training epoch 244 / 500, batch #100 / 625
Loss:	1.7195311784744263

training epoch 244 / 500, batch #125 / 625
Loss:	1.7151232957839966

training epoch 244 / 500, batch #150 / 625
Loss:	1.6455785036087036

training epoch 244 / 500, batch #175 / 625
Loss:	1.5823203325271606

training epoch 244 / 500, batch #200 / 625
Loss:	1.787123203277588

training epoch 244 / 500, batch #225 / 625
Loss:	1.6275838613510132

training epoch 244 / 500, batch #250 / 625
Loss:	1.8350027799606323

training epoch 244 / 500, batch #275 / 625
Loss:	1.8613011837005615

training epoch 244 / 500, batch #300 / 625
Loss:	1.7848306894302368

training epoch 244 / 500, batch #325 / 625
Loss:	1.7883981466293335

training epoch 244 / 500, batch #350 / 625
Loss:	1.5436758995056152

training epoch 244 / 500, batch #375 / 625
Loss:	1.6748040914535522

training epoch 244 / 500, batch #400 / 625
Loss:	1.7802326679229736

training epoch 244 / 500, batch #425 / 625
Loss:	1.5337648391723633

training epoch 244 / 500, batch #450 / 625
Loss:	1.8445326089859009

training epoch 244 / 500, batch #475 / 625
Loss:	1.8326754570007324

training epoch 244 / 500, batch #500 / 625
Loss:	1.578095555305481

training epoch 244 / 500, batch #525 / 625
Loss:	1.8082484006881714

training epoch 244 / 500, batch #550 / 625
Loss:	1.860741138458252

training epoch 244 / 500, batch #575 / 625
Loss:	1.5919970273971558

training epoch 244 / 500, batch #600 / 625
Loss:	1.8272677659988403

training epoch 245 / 500, batch #0 / 625
Loss:	1.7486371994018555

training epoch 245 / 500, batch #25 / 625
Loss:	1.725700855255127

training epoch 245 / 500, batch #50 / 625
Loss:	1.5713250637054443

training epoch 245 / 500, batch #75 / 625
Loss:	1.6949362754821777

training epoch 245 / 500, batch #100 / 625
Loss:	1.8315107822418213

training epoch 245 / 500, batch #125 / 625
Loss:	1.6642402410507202

training epoch 245 / 500, batch #150 / 625
Loss:	1.7652862071990967

training epoch 245 / 500, batch #175 / 625
Loss:	1.6035319566726685

training epoch 245 / 500, batch #200 / 625
Loss:	1.7075930833816528

training epoch 245 / 500, batch #225 / 625
Loss:	1.4702292680740356

training epoch 245 / 500, batch #250 / 625
Loss:	1.607933759689331

training epoch 245 / 500, batch #275 / 625
Loss:	1.8019059896469116

training epoch 245 / 500, batch #300 / 625
Loss:	1.528398871421814

training epoch 245 / 500, batch #325 / 625
Loss:	1.9335862398147583

training epoch 245 / 500, batch #350 / 625
Loss:	1.6979751586914062

training epoch 245 / 500, batch #375 / 625
Loss:	1.6686748266220093

training epoch 245 / 500, batch #400 / 625
Loss:	1.525215744972229

training epoch 245 / 500, batch #425 / 625
Loss:	1.8056727647781372

training epoch 245 / 500, batch #450 / 625
Loss:	1.7434284687042236

training epoch 245 / 500, batch #475 / 625
Loss:	1.8338972330093384

training epoch 245 / 500, batch #500 / 625
Loss:	1.5190297365188599

training epoch 245 / 500, batch #525 / 625
Loss:	1.669468641281128

training epoch 245 / 500, batch #550 / 625
Loss:	1.745178461074829

training epoch 245 / 500, batch #575 / 625
Loss:	1.78307044506073

training epoch 245 / 500, batch #600 / 625
Loss:	1.9994499683380127

training epoch 246 / 500, batch #0 / 625
Loss:	1.7909290790557861

training epoch 246 / 500, batch #25 / 625
Loss:	1.8067195415496826

training epoch 246 / 500, batch #50 / 625
Loss:	1.7199158668518066

training epoch 246 / 500, batch #75 / 625
Loss:	1.6030993461608887

training epoch 246 / 500, batch #100 / 625
Loss:	1.6921138763427734

training epoch 246 / 500, batch #125 / 625
Loss:	1.6860606670379639

training epoch 246 / 500, batch #150 / 625
Loss:	1.7956643104553223

training epoch 246 / 500, batch #175 / 625
Loss:	1.8106269836425781

training epoch 246 / 500, batch #200 / 625
Loss:	2.0661885738372803

training epoch 246 / 500, batch #225 / 625
Loss:	1.9028657674789429

training epoch 246 / 500, batch #250 / 625
Loss:	1.9109187126159668

training epoch 246 / 500, batch #275 / 625
Loss:	1.7950835227966309

training epoch 246 / 500, batch #300 / 625
Loss:	1.7023096084594727

training epoch 246 / 500, batch #325 / 625
Loss:	1.7396281957626343

training epoch 246 / 500, batch #350 / 625
Loss:	1.5921701192855835

training epoch 246 / 500, batch #375 / 625
Loss:	1.9724615812301636

training epoch 246 / 500, batch #400 / 625
Loss:	1.7682414054870605

training epoch 246 / 500, batch #425 / 625
Loss:	1.8178571462631226

training epoch 246 / 500, batch #450 / 625
Loss:	1.8586307764053345

training epoch 246 / 500, batch #475 / 625
Loss:	1.6103019714355469

training epoch 246 / 500, batch #500 / 625
Loss:	1.5507524013519287

training epoch 246 / 500, batch #525 / 625
Loss:	1.830610752105713

training epoch 246 / 500, batch #550 / 625
Loss:	2.087013006210327

training epoch 246 / 500, batch #575 / 625
Loss:	1.793074607849121

training epoch 246 / 500, batch #600 / 625
Loss:	1.628363847732544

training epoch 247 / 500, batch #0 / 625
Loss:	1.8703663349151611

training epoch 247 / 500, batch #25 / 625
Loss:	1.535952091217041

training epoch 247 / 500, batch #50 / 625
Loss:	1.6511330604553223

training epoch 247 / 500, batch #75 / 625
Loss:	1.751734733581543

training epoch 247 / 500, batch #100 / 625
Loss:	1.4146357774734497

training epoch 247 / 500, batch #125 / 625
Loss:	1.7439261674880981

training epoch 247 / 500, batch #150 / 625
Loss:	1.6144189834594727

training epoch 247 / 500, batch #175 / 625
Loss:	1.7494134902954102

training epoch 247 / 500, batch #200 / 625
Loss:	1.8359699249267578

training epoch 247 / 500, batch #225 / 625
Loss:	1.776679515838623

training epoch 247 / 500, batch #250 / 625
Loss:	1.9924495220184326

training epoch 247 / 500, batch #275 / 625
Loss:	1.535640835762024

training epoch 247 / 500, batch #300 / 625
Loss:	1.7672119140625

training epoch 247 / 500, batch #325 / 625
Loss:	1.7996585369110107

training epoch 247 / 500, batch #350 / 625
Loss:	1.7496981620788574

training epoch 247 / 500, batch #375 / 625
Loss:	1.6566169261932373

training epoch 247 / 500, batch #400 / 625
Loss:	1.5963433980941772

training epoch 247 / 500, batch #425 / 625
Loss:	1.831163763999939

training epoch 247 / 500, batch #450 / 625
Loss:	1.7472069263458252

training epoch 247 / 500, batch #475 / 625
Loss:	1.6797451972961426

training epoch 247 / 500, batch #500 / 625
Loss:	1.5451290607452393

training epoch 247 / 500, batch #525 / 625
Loss:	1.6436001062393188

training epoch 247 / 500, batch #550 / 625
Loss:	1.7248564958572388

training epoch 247 / 500, batch #575 / 625
Loss:	1.6972078084945679

training epoch 247 / 500, batch #600 / 625
Loss:	1.8311810493469238

training epoch 248 / 500, batch #0 / 625
Loss:	1.7099225521087646

training epoch 248 / 500, batch #25 / 625
Loss:	1.5023216009140015

training epoch 248 / 500, batch #50 / 625
Loss:	1.7450098991394043

training epoch 248 / 500, batch #75 / 625
Loss:	1.8111015558242798

training epoch 248 / 500, batch #100 / 625
Loss:	1.7793538570404053

training epoch 248 / 500, batch #125 / 625
Loss:	1.5498507022857666

training epoch 248 / 500, batch #150 / 625
Loss:	1.978477954864502

training epoch 248 / 500, batch #175 / 625
Loss:	1.5237350463867188

training epoch 248 / 500, batch #200 / 625
Loss:	1.6540216207504272

training epoch 248 / 500, batch #225 / 625
Loss:	1.912471055984497

training epoch 248 / 500, batch #250 / 625
Loss:	1.8827495574951172

training epoch 248 / 500, batch #275 / 625
Loss:	1.68968665599823

training epoch 248 / 500, batch #300 / 625
Loss:	1.5824611186981201

training epoch 248 / 500, batch #325 / 625
Loss:	1.7527616024017334

training epoch 248 / 500, batch #350 / 625
Loss:	1.9156044721603394

training epoch 248 / 500, batch #375 / 625
Loss:	1.704267978668213

training epoch 248 / 500, batch #400 / 625
Loss:	1.7467126846313477

training epoch 248 / 500, batch #425 / 625
Loss:	1.8252612352371216

training epoch 248 / 500, batch #450 / 625
Loss:	2.040354013442993

training epoch 248 / 500, batch #475 / 625
Loss:	1.7696950435638428

training epoch 248 / 500, batch #500 / 625
Loss:	1.6237354278564453

training epoch 248 / 500, batch #525 / 625
Loss:	1.839756965637207

training epoch 248 / 500, batch #550 / 625
Loss:	1.6063445806503296

training epoch 248 / 500, batch #575 / 625
Loss:	1.7868621349334717

training epoch 248 / 500, batch #600 / 625
Loss:	1.7967970371246338

training epoch 249 / 500, batch #0 / 625
Loss:	1.6079034805297852

training epoch 249 / 500, batch #25 / 625
Loss:	1.8564233779907227

training epoch 249 / 500, batch #50 / 625
Loss:	1.7021448612213135

training epoch 249 / 500, batch #75 / 625
Loss:	1.7885514497756958

training epoch 249 / 500, batch #100 / 625
Loss:	1.8817747831344604

training epoch 249 / 500, batch #125 / 625
Loss:	1.6253067255020142

training epoch 249 / 500, batch #150 / 625
Loss:	1.7110487222671509

training epoch 249 / 500, batch #175 / 625
Loss:	2.1513240337371826

training epoch 249 / 500, batch #200 / 625
Loss:	1.8673795461654663

training epoch 249 / 500, batch #225 / 625
Loss:	1.6868031024932861

training epoch 249 / 500, batch #250 / 625
Loss:	1.839133620262146

training epoch 249 / 500, batch #275 / 625
Loss:	1.4396650791168213

training epoch 249 / 500, batch #300 / 625
Loss:	1.9624079465866089

training epoch 249 / 500, batch #325 / 625
Loss:	1.764894962310791

training epoch 249 / 500, batch #350 / 625
Loss:	1.7521008253097534

training epoch 249 / 500, batch #375 / 625
Loss:	1.7286136150360107

training epoch 249 / 500, batch #400 / 625
Loss:	1.8251065015792847

training epoch 249 / 500, batch #425 / 625
Loss:	1.9478100538253784

training epoch 249 / 500, batch #450 / 625
Loss:	1.7221530675888062

training epoch 249 / 500, batch #475 / 625
Loss:	1.6995837688446045

training epoch 249 / 500, batch #500 / 625
Loss:	1.8314776420593262

training epoch 249 / 500, batch #525 / 625
Loss:	1.5749539136886597

training epoch 249 / 500, batch #550 / 625
Loss:	1.7376995086669922

training epoch 249 / 500, batch #575 / 625
Loss:	1.600913643836975

training epoch 249 / 500, batch #600 / 625
Loss:	1.5671297311782837

training epoch 250 / 500, batch #0 / 625
Loss:	1.6929171085357666

training epoch 250 / 500, batch #25 / 625
Loss:	1.7505741119384766

training epoch 250 / 500, batch #50 / 625
Loss:	1.800722599029541

training epoch 250 / 500, batch #75 / 625
Loss:	1.7212680578231812

training epoch 250 / 500, batch #100 / 625
Loss:	1.7841213941574097

training epoch 250 / 500, batch #125 / 625
Loss:	1.7907217741012573

training epoch 250 / 500, batch #150 / 625
Loss:	1.7024872303009033

training epoch 250 / 500, batch #175 / 625
Loss:	1.9257848262786865

training epoch 250 / 500, batch #200 / 625
Loss:	1.7345832586288452

training epoch 250 / 500, batch #225 / 625
Loss:	1.756288766860962

training epoch 250 / 500, batch #250 / 625
Loss:	1.821571946144104

training epoch 250 / 500, batch #275 / 625
Loss:	1.4579612016677856

training epoch 250 / 500, batch #300 / 625
Loss:	1.674659013748169

training epoch 250 / 500, batch #325 / 625
Loss:	1.9599097967147827

training epoch 250 / 500, batch #350 / 625
Loss:	1.8810865879058838

training epoch 250 / 500, batch #375 / 625
Loss:	1.8364734649658203

training epoch 250 / 500, batch #400 / 625
Loss:	1.6577327251434326

training epoch 250 / 500, batch #425 / 625
Loss:	1.6551703214645386

training epoch 250 / 500, batch #450 / 625
Loss:	1.4651144742965698

training epoch 250 / 500, batch #475 / 625
Loss:	1.777822494506836

training epoch 250 / 500, batch #500 / 625
Loss:	1.8397855758666992

training epoch 250 / 500, batch #525 / 625
Loss:	1.5285497903823853

training epoch 250 / 500, batch #550 / 625
Loss:	1.8429917097091675

training epoch 250 / 500, batch #575 / 625
Loss:	1.8798232078552246

training epoch 250 / 500, batch #600 / 625
Loss:	1.8341723680496216

training epoch 251 / 500, batch #0 / 625
Loss:	1.765965461730957

training epoch 251 / 500, batch #25 / 625
Loss:	1.8447428941726685

training epoch 251 / 500, batch #50 / 625
Loss:	1.8478468656539917

training epoch 251 / 500, batch #75 / 625
Loss:	1.7087023258209229

training epoch 251 / 500, batch #100 / 625
Loss:	1.7201013565063477

training epoch 251 / 500, batch #125 / 625
Loss:	1.4642462730407715

training epoch 251 / 500, batch #150 / 625
Loss:	1.446331262588501

training epoch 251 / 500, batch #175 / 625
Loss:	1.8203850984573364

training epoch 251 / 500, batch #200 / 625
Loss:	1.7120463848114014

training epoch 251 / 500, batch #225 / 625
Loss:	1.797663927078247

training epoch 251 / 500, batch #250 / 625
Loss:	1.7365466356277466

training epoch 251 / 500, batch #275 / 625
Loss:	1.4991250038146973

training epoch 251 / 500, batch #300 / 625
Loss:	1.5713943243026733

training epoch 251 / 500, batch #325 / 625
Loss:	1.5763390064239502

training epoch 251 / 500, batch #350 / 625
Loss:	1.5012295246124268

training epoch 251 / 500, batch #375 / 625
Loss:	1.6987718343734741

training epoch 251 / 500, batch #400 / 625
Loss:	1.8000948429107666

training epoch 251 / 500, batch #425 / 625
Loss:	1.6805245876312256

training epoch 251 / 500, batch #450 / 625
Loss:	1.8235307931900024

training epoch 251 / 500, batch #475 / 625
Loss:	1.7568128108978271

training epoch 251 / 500, batch #500 / 625
Loss:	1.8033009767532349

training epoch 251 / 500, batch #525 / 625
Loss:	1.74019193649292

training epoch 251 / 500, batch #550 / 625
Loss:	1.6455992460250854

training epoch 251 / 500, batch #575 / 625
Loss:	1.7241668701171875

training epoch 251 / 500, batch #600 / 625
Loss:	1.859161615371704

training epoch 252 / 500, batch #0 / 625
Loss:	1.6423479318618774

training epoch 252 / 500, batch #25 / 625
Loss:	1.8924150466918945

training epoch 252 / 500, batch #50 / 625
Loss:	1.7008616924285889

training epoch 252 / 500, batch #75 / 625
Loss:	1.80615234375

training epoch 252 / 500, batch #100 / 625
Loss:	1.5886561870574951

training epoch 252 / 500, batch #125 / 625
Loss:	1.6435222625732422

training epoch 252 / 500, batch #150 / 625
Loss:	1.9178695678710938

training epoch 252 / 500, batch #175 / 625
Loss:	1.8792551755905151

training epoch 252 / 500, batch #200 / 625
Loss:	1.9869157075881958

training epoch 252 / 500, batch #225 / 625
Loss:	1.8245234489440918

training epoch 252 / 500, batch #250 / 625
Loss:	1.850144863128662

training epoch 252 / 500, batch #275 / 625
Loss:	1.5580779314041138

training epoch 252 / 500, batch #300 / 625
Loss:	1.981166124343872

training epoch 252 / 500, batch #325 / 625
Loss:	2.066127300262451

training epoch 252 / 500, batch #350 / 625
Loss:	1.681275725364685

training epoch 252 / 500, batch #375 / 625
Loss:	1.7447614669799805

training epoch 252 / 500, batch #400 / 625
Loss:	1.7142574787139893

training epoch 252 / 500, batch #425 / 625
Loss:	1.8235738277435303

training epoch 252 / 500, batch #450 / 625
Loss:	1.7377829551696777

training epoch 252 / 500, batch #475 / 625
Loss:	1.8061349391937256

training epoch 252 / 500, batch #500 / 625
Loss:	1.5928587913513184

training epoch 252 / 500, batch #525 / 625
Loss:	1.6631721258163452

training epoch 252 / 500, batch #550 / 625
Loss:	1.6991279125213623

training epoch 252 / 500, batch #575 / 625
Loss:	1.5149180889129639

training epoch 252 / 500, batch #600 / 625
Loss:	1.8919804096221924

training epoch 253 / 500, batch #0 / 625
Loss:	1.7094591856002808

training epoch 253 / 500, batch #25 / 625
Loss:	1.7142657041549683

training epoch 253 / 500, batch #50 / 625
Loss:	1.5333303213119507

training epoch 253 / 500, batch #75 / 625
Loss:	1.9145909547805786

training epoch 253 / 500, batch #100 / 625
Loss:	1.8921153545379639

training epoch 253 / 500, batch #125 / 625
Loss:	1.739291787147522

training epoch 253 / 500, batch #150 / 625
Loss:	1.7071421146392822

training epoch 253 / 500, batch #175 / 625
Loss:	1.8392508029937744

training epoch 253 / 500, batch #200 / 625
Loss:	1.5370292663574219

training epoch 253 / 500, batch #225 / 625
Loss:	1.8861364126205444

training epoch 253 / 500, batch #250 / 625
Loss:	1.684429407119751

training epoch 253 / 500, batch #275 / 625
Loss:	1.7609740495681763

training epoch 253 / 500, batch #300 / 625
Loss:	1.6363509893417358

training epoch 253 / 500, batch #325 / 625
Loss:	1.9351930618286133

training epoch 253 / 500, batch #350 / 625
Loss:	1.9090633392333984

training epoch 253 / 500, batch #375 / 625
Loss:	1.7443957328796387

training epoch 253 / 500, batch #400 / 625
Loss:	1.747524619102478

training epoch 253 / 500, batch #425 / 625
Loss:	1.708236575126648

training epoch 253 / 500, batch #450 / 625
Loss:	1.578170657157898

training epoch 253 / 500, batch #475 / 625
Loss:	1.9520256519317627

training epoch 253 / 500, batch #500 / 625
Loss:	1.7137010097503662

training epoch 253 / 500, batch #525 / 625
Loss:	1.7655017375946045

training epoch 253 / 500, batch #550 / 625
Loss:	1.6784926652908325

training epoch 253 / 500, batch #575 / 625
Loss:	1.5497878789901733

training epoch 253 / 500, batch #600 / 625
Loss:	1.7010749578475952

training epoch 254 / 500, batch #0 / 625
Loss:	1.7662737369537354

training epoch 254 / 500, batch #25 / 625
Loss:	1.6679178476333618

training epoch 254 / 500, batch #50 / 625
Loss:	1.7575241327285767

training epoch 254 / 500, batch #75 / 625
Loss:	1.5568742752075195

training epoch 254 / 500, batch #100 / 625
Loss:	1.8326557874679565

training epoch 254 / 500, batch #125 / 625
Loss:	1.533257007598877

training epoch 254 / 500, batch #150 / 625
Loss:	1.8954532146453857

training epoch 254 / 500, batch #175 / 625
Loss:	1.9477958679199219

training epoch 254 / 500, batch #200 / 625
Loss:	1.7893216609954834

training epoch 254 / 500, batch #225 / 625
Loss:	1.658586859703064

training epoch 254 / 500, batch #250 / 625
Loss:	1.5279614925384521

training epoch 254 / 500, batch #275 / 625
Loss:	1.5364958047866821

training epoch 254 / 500, batch #300 / 625
Loss:	1.721352219581604

training epoch 254 / 500, batch #325 / 625
Loss:	1.7410515546798706

training epoch 254 / 500, batch #350 / 625
Loss:	1.494179606437683

training epoch 254 / 500, batch #375 / 625
Loss:	1.7558159828186035

training epoch 254 / 500, batch #400 / 625
Loss:	1.686813473701477

training epoch 254 / 500, batch #425 / 625
Loss:	1.5285049676895142

training epoch 254 / 500, batch #450 / 625
Loss:	1.9298591613769531

training epoch 254 / 500, batch #475 / 625
Loss:	1.6654950380325317

training epoch 254 / 500, batch #500 / 625
Loss:	1.8386449813842773

training epoch 254 / 500, batch #525 / 625
Loss:	2.202437162399292

training epoch 254 / 500, batch #550 / 625
Loss:	1.7444953918457031

training epoch 254 / 500, batch #575 / 625
Loss:	1.9623299837112427

training epoch 254 / 500, batch #600 / 625
Loss:	1.414169192314148

training epoch 255 / 500, batch #0 / 625
Loss:	1.9800140857696533

training epoch 255 / 500, batch #25 / 625
Loss:	1.7267208099365234

training epoch 255 / 500, batch #50 / 625
Loss:	1.7623755931854248

training epoch 255 / 500, batch #75 / 625
Loss:	1.612087368965149

training epoch 255 / 500, batch #100 / 625
Loss:	1.7162480354309082

training epoch 255 / 500, batch #125 / 625
Loss:	1.799128532409668

training epoch 255 / 500, batch #150 / 625
Loss:	1.649263858795166

training epoch 255 / 500, batch #175 / 625
Loss:	1.8276475667953491

training epoch 255 / 500, batch #200 / 625
Loss:	1.9350957870483398

training epoch 255 / 500, batch #225 / 625
Loss:	1.6739176511764526

training epoch 255 / 500, batch #250 / 625
Loss:	1.7990599870681763

training epoch 255 / 500, batch #275 / 625
Loss:	1.6995229721069336

training epoch 255 / 500, batch #300 / 625
Loss:	1.8224742412567139

training epoch 255 / 500, batch #325 / 625
Loss:	1.6449253559112549

training epoch 255 / 500, batch #350 / 625
Loss:	1.7533628940582275

training epoch 255 / 500, batch #375 / 625
Loss:	1.7831238508224487

training epoch 255 / 500, batch #400 / 625
Loss:	1.633095383644104

training epoch 255 / 500, batch #425 / 625
Loss:	1.7515465021133423

training epoch 255 / 500, batch #450 / 625
Loss:	1.5842187404632568

training epoch 255 / 500, batch #475 / 625
Loss:	1.5997611284255981

training epoch 255 / 500, batch #500 / 625
Loss:	1.6000397205352783

training epoch 255 / 500, batch #525 / 625
Loss:	1.5658291578292847

training epoch 255 / 500, batch #550 / 625
Loss:	1.7172363996505737

training epoch 255 / 500, batch #575 / 625
Loss:	1.7973887920379639

training epoch 255 / 500, batch #600 / 625
Loss:	1.642289161682129

training epoch 256 / 500, batch #0 / 625
Loss:	1.756577968597412

training epoch 256 / 500, batch #25 / 625
Loss:	1.7854727506637573

training epoch 256 / 500, batch #50 / 625
Loss:	1.644801139831543

training epoch 256 / 500, batch #75 / 625
Loss:	1.837392807006836

training epoch 256 / 500, batch #100 / 625
Loss:	1.647594690322876

training epoch 256 / 500, batch #125 / 625
Loss:	1.6233737468719482

training epoch 256 / 500, batch #150 / 625
Loss:	1.7390390634536743

training epoch 256 / 500, batch #175 / 625
Loss:	1.8315768241882324

training epoch 256 / 500, batch #200 / 625
Loss:	1.7272812128067017

training epoch 256 / 500, batch #225 / 625
Loss:	1.9262514114379883

training epoch 256 / 500, batch #250 / 625
Loss:	1.7307124137878418

training epoch 256 / 500, batch #275 / 625
Loss:	1.6107146739959717

training epoch 256 / 500, batch #300 / 625
Loss:	1.57088041305542

training epoch 256 / 500, batch #325 / 625
Loss:	1.7125201225280762

training epoch 256 / 500, batch #350 / 625
Loss:	1.7831372022628784

training epoch 256 / 500, batch #375 / 625
Loss:	1.865080714225769

training epoch 256 / 500, batch #400 / 625
Loss:	1.7742377519607544

training epoch 256 / 500, batch #425 / 625
Loss:	1.812474012374878

training epoch 256 / 500, batch #450 / 625
Loss:	1.5574740171432495

training epoch 256 / 500, batch #475 / 625
Loss:	1.4045363664627075

training epoch 256 / 500, batch #500 / 625
Loss:	1.6629047393798828

training epoch 256 / 500, batch #525 / 625
Loss:	1.635969638824463

training epoch 256 / 500, batch #550 / 625
Loss:	1.9802250862121582

training epoch 256 / 500, batch #575 / 625
Loss:	1.5446817874908447

training epoch 256 / 500, batch #600 / 625
Loss:	1.7193607091903687

training epoch 257 / 500, batch #0 / 625
Loss:	1.7342860698699951

training epoch 257 / 500, batch #25 / 625
Loss:	1.8400517702102661

training epoch 257 / 500, batch #50 / 625
Loss:	1.8200492858886719

training epoch 257 / 500, batch #75 / 625
Loss:	1.8826391696929932

training epoch 257 / 500, batch #100 / 625
Loss:	1.9588123559951782

training epoch 257 / 500, batch #125 / 625
Loss:	1.6059401035308838

training epoch 257 / 500, batch #150 / 625
Loss:	1.748578667640686

training epoch 257 / 500, batch #175 / 625
Loss:	1.7117242813110352

training epoch 257 / 500, batch #200 / 625
Loss:	1.990732192993164

training epoch 257 / 500, batch #225 / 625
Loss:	1.6000759601593018

training epoch 257 / 500, batch #250 / 625
Loss:	1.7140493392944336

training epoch 257 / 500, batch #275 / 625
Loss:	1.918939471244812

training epoch 257 / 500, batch #300 / 625
Loss:	1.640018105506897

training epoch 257 / 500, batch #325 / 625
Loss:	1.5226824283599854

training epoch 257 / 500, batch #350 / 625
Loss:	1.5213983058929443

training epoch 257 / 500, batch #375 / 625
Loss:	1.7019845247268677

training epoch 257 / 500, batch #400 / 625
Loss:	1.6151851415634155

training epoch 257 / 500, batch #425 / 625
Loss:	1.6052464246749878

training epoch 257 / 500, batch #450 / 625
Loss:	1.8945363759994507

training epoch 257 / 500, batch #475 / 625
Loss:	1.640271782875061

training epoch 257 / 500, batch #500 / 625
Loss:	1.6344902515411377

training epoch 257 / 500, batch #525 / 625
Loss:	1.7804157733917236

training epoch 257 / 500, batch #550 / 625
Loss:	1.9090558290481567

training epoch 257 / 500, batch #575 / 625
Loss:	1.4438341856002808

training epoch 257 / 500, batch #600 / 625
Loss:	1.7909144163131714

training epoch 258 / 500, batch #0 / 625
Loss:	1.8338721990585327

training epoch 258 / 500, batch #25 / 625
Loss:	1.7256629467010498

training epoch 258 / 500, batch #50 / 625
Loss:	1.9478074312210083

training epoch 258 / 500, batch #75 / 625
Loss:	1.7973212003707886

training epoch 258 / 500, batch #100 / 625
Loss:	1.5627559423446655

training epoch 258 / 500, batch #125 / 625
Loss:	1.8368101119995117

training epoch 258 / 500, batch #150 / 625
Loss:	1.826155424118042

training epoch 258 / 500, batch #175 / 625
Loss:	1.7356688976287842

training epoch 258 / 500, batch #200 / 625
Loss:	1.8587204217910767

training epoch 258 / 500, batch #225 / 625
Loss:	1.4714815616607666

training epoch 258 / 500, batch #250 / 625
Loss:	1.398871898651123

training epoch 258 / 500, batch #275 / 625
Loss:	1.5755534172058105

training epoch 258 / 500, batch #300 / 625
Loss:	1.7130149602890015

training epoch 258 / 500, batch #325 / 625
Loss:	1.6976922750473022

training epoch 258 / 500, batch #350 / 625
Loss:	1.6034178733825684

training epoch 258 / 500, batch #375 / 625
Loss:	1.6259934902191162

training epoch 258 / 500, batch #400 / 625
Loss:	1.6039113998413086

training epoch 258 / 500, batch #425 / 625
Loss:	1.8626543283462524

training epoch 258 / 500, batch #450 / 625
Loss:	1.68535578250885

training epoch 258 / 500, batch #475 / 625
Loss:	1.6206306219100952

training epoch 258 / 500, batch #500 / 625
Loss:	1.9254170656204224

training epoch 258 / 500, batch #525 / 625
Loss:	1.7148213386535645

training epoch 258 / 500, batch #550 / 625
Loss:	1.5225586891174316

training epoch 258 / 500, batch #575 / 625
Loss:	1.9893792867660522

training epoch 258 / 500, batch #600 / 625
Loss:	1.7341738939285278

training epoch 259 / 500, batch #0 / 625
Loss:	1.624064326286316

training epoch 259 / 500, batch #25 / 625
Loss:	1.4846464395523071

training epoch 259 / 500, batch #50 / 625
Loss:	1.9445997476577759

training epoch 259 / 500, batch #75 / 625
Loss:	1.6798192262649536

training epoch 259 / 500, batch #100 / 625
Loss:	1.6889827251434326

training epoch 259 / 500, batch #125 / 625
Loss:	1.9440994262695312

training epoch 259 / 500, batch #150 / 625
Loss:	1.6161874532699585

training epoch 259 / 500, batch #175 / 625
Loss:	1.8371328115463257

training epoch 259 / 500, batch #200 / 625
Loss:	1.8465451002120972

training epoch 259 / 500, batch #225 / 625
Loss:	1.514365315437317

training epoch 259 / 500, batch #250 / 625
Loss:	1.7083821296691895

training epoch 259 / 500, batch #275 / 625
Loss:	1.7552320957183838

training epoch 259 / 500, batch #300 / 625
Loss:	1.835666537284851

training epoch 259 / 500, batch #325 / 625
Loss:	1.7106212377548218

training epoch 259 / 500, batch #350 / 625
Loss:	1.690861701965332

training epoch 259 / 500, batch #375 / 625
Loss:	1.7635791301727295

training epoch 259 / 500, batch #400 / 625
Loss:	1.691275954246521

training epoch 259 / 500, batch #425 / 625
Loss:	1.6192556619644165

training epoch 259 / 500, batch #450 / 625
Loss:	1.699083685874939

training epoch 259 / 500, batch #475 / 625
Loss:	1.6551690101623535

training epoch 259 / 500, batch #500 / 625
Loss:	1.6975157260894775

training epoch 259 / 500, batch #525 / 625
Loss:	1.6936085224151611

training epoch 259 / 500, batch #550 / 625
Loss:	1.5934942960739136

training epoch 259 / 500, batch #575 / 625
Loss:	1.4975688457489014

training epoch 259 / 500, batch #600 / 625
Loss:	1.7618043422698975

training epoch 260 / 500, batch #0 / 625
Loss:	1.6917251348495483

training epoch 260 / 500, batch #25 / 625
Loss:	1.7117955684661865

training epoch 260 / 500, batch #50 / 625
Loss:	2.0069358348846436

training epoch 260 / 500, batch #75 / 625
Loss:	1.815099835395813

training epoch 260 / 500, batch #100 / 625
Loss:	1.8580431938171387

training epoch 260 / 500, batch #125 / 625
Loss:	1.5098737478256226

training epoch 260 / 500, batch #150 / 625
Loss:	1.8591312170028687

training epoch 260 / 500, batch #175 / 625
Loss:	1.8839826583862305

training epoch 260 / 500, batch #200 / 625
Loss:	1.6361916065216064

training epoch 260 / 500, batch #225 / 625
Loss:	1.4751152992248535

training epoch 260 / 500, batch #250 / 625
Loss:	1.927441120147705

training epoch 260 / 500, batch #275 / 625
Loss:	1.8942993879318237

training epoch 260 / 500, batch #300 / 625
Loss:	1.9056369066238403

training epoch 260 / 500, batch #325 / 625
Loss:	1.9024829864501953

training epoch 260 / 500, batch #350 / 625
Loss:	1.5881192684173584

training epoch 260 / 500, batch #375 / 625
Loss:	1.8985686302185059

training epoch 260 / 500, batch #400 / 625
Loss:	1.5970629453659058

training epoch 260 / 500, batch #425 / 625
Loss:	1.6930185556411743

training epoch 260 / 500, batch #450 / 625
Loss:	1.7791101932525635

training epoch 260 / 500, batch #475 / 625
Loss:	1.9542187452316284

training epoch 260 / 500, batch #500 / 625
Loss:	1.8469122648239136

training epoch 260 / 500, batch #525 / 625
Loss:	1.8626753091812134

training epoch 260 / 500, batch #550 / 625
Loss:	1.635855793952942

training epoch 260 / 500, batch #575 / 625
Loss:	1.888680100440979

training epoch 260 / 500, batch #600 / 625
Loss:	1.859337568283081

training epoch 261 / 500, batch #0 / 625
Loss:	1.9363458156585693

training epoch 261 / 500, batch #25 / 625
Loss:	1.640000343322754

training epoch 261 / 500, batch #50 / 625
Loss:	1.6227457523345947

training epoch 261 / 500, batch #75 / 625
Loss:	1.9778046607971191

training epoch 261 / 500, batch #100 / 625
Loss:	1.6122584342956543

training epoch 261 / 500, batch #125 / 625
Loss:	1.8719743490219116

training epoch 261 / 500, batch #150 / 625
Loss:	1.8151088953018188

training epoch 261 / 500, batch #175 / 625
Loss:	1.3505886793136597

training epoch 261 / 500, batch #200 / 625
Loss:	1.7590471506118774

training epoch 261 / 500, batch #225 / 625
Loss:	1.8210989236831665

training epoch 261 / 500, batch #250 / 625
Loss:	1.9144173860549927

training epoch 261 / 500, batch #275 / 625
Loss:	1.7806816101074219

training epoch 261 / 500, batch #300 / 625
Loss:	1.581404447555542

training epoch 261 / 500, batch #325 / 625
Loss:	1.715280532836914

training epoch 261 / 500, batch #350 / 625
Loss:	1.5735669136047363

training epoch 261 / 500, batch #375 / 625
Loss:	1.686905860900879

training epoch 261 / 500, batch #400 / 625
Loss:	1.5671508312225342

training epoch 261 / 500, batch #425 / 625
Loss:	1.8072952032089233

training epoch 261 / 500, batch #450 / 625
Loss:	1.8606685400009155

training epoch 261 / 500, batch #475 / 625
Loss:	1.809971809387207

training epoch 261 / 500, batch #500 / 625
Loss:	1.9204639196395874

training epoch 261 / 500, batch #525 / 625
Loss:	1.9070894718170166

training epoch 261 / 500, batch #550 / 625
Loss:	2.0443952083587646

training epoch 261 / 500, batch #575 / 625
Loss:	1.8312277793884277

training epoch 261 / 500, batch #600 / 625
Loss:	1.664223074913025

training epoch 262 / 500, batch #0 / 625
Loss:	1.6065267324447632

training epoch 262 / 500, batch #25 / 625
Loss:	1.7875524759292603

training epoch 262 / 500, batch #50 / 625
Loss:	1.668064832687378

training epoch 262 / 500, batch #75 / 625
Loss:	1.5228129625320435

training epoch 262 / 500, batch #100 / 625
Loss:	1.9562819004058838

training epoch 262 / 500, batch #125 / 625
Loss:	1.9485044479370117

training epoch 262 / 500, batch #150 / 625
Loss:	1.718808889389038

training epoch 262 / 500, batch #175 / 625
Loss:	1.5609523057937622

training epoch 262 / 500, batch #200 / 625
Loss:	1.4851707220077515

training epoch 262 / 500, batch #225 / 625
Loss:	1.5292083024978638

training epoch 262 / 500, batch #250 / 625
Loss:	1.7527375221252441

training epoch 262 / 500, batch #275 / 625
Loss:	1.5438600778579712

training epoch 262 / 500, batch #300 / 625
Loss:	1.6444549560546875

training epoch 262 / 500, batch #325 / 625
Loss:	1.9823296070098877

training epoch 262 / 500, batch #350 / 625
Loss:	1.659796953201294

training epoch 262 / 500, batch #375 / 625
Loss:	1.7303906679153442

training epoch 262 / 500, batch #400 / 625
Loss:	1.8537484407424927

training epoch 262 / 500, batch #425 / 625
Loss:	1.5896347761154175

training epoch 262 / 500, batch #450 / 625
Loss:	1.6774505376815796

training epoch 262 / 500, batch #475 / 625
Loss:	1.7184264659881592

training epoch 262 / 500, batch #500 / 625
Loss:	1.6392426490783691

training epoch 262 / 500, batch #525 / 625
Loss:	1.8389079570770264

training epoch 262 / 500, batch #550 / 625
Loss:	1.585628867149353

training epoch 262 / 500, batch #575 / 625
Loss:	1.723703145980835

training epoch 262 / 500, batch #600 / 625
Loss:	1.848780632019043

training epoch 263 / 500, batch #0 / 625
Loss:	1.8955583572387695

training epoch 263 / 500, batch #25 / 625
Loss:	1.8156840801239014

training epoch 263 / 500, batch #50 / 625
Loss:	1.6053436994552612

training epoch 263 / 500, batch #75 / 625
Loss:	1.7071946859359741

training epoch 263 / 500, batch #100 / 625
Loss:	1.8154269456863403

training epoch 263 / 500, batch #125 / 625
Loss:	1.5667139291763306

training epoch 263 / 500, batch #150 / 625
Loss:	2.0290346145629883

training epoch 263 / 500, batch #175 / 625
Loss:	1.7540948390960693

training epoch 263 / 500, batch #200 / 625
Loss:	1.8521547317504883

training epoch 263 / 500, batch #225 / 625
Loss:	1.766135573387146

training epoch 263 / 500, batch #250 / 625
Loss:	1.7057254314422607

training epoch 263 / 500, batch #275 / 625
Loss:	1.9906764030456543

training epoch 263 / 500, batch #300 / 625
Loss:	1.6446506977081299

training epoch 263 / 500, batch #325 / 625
Loss:	2.0341038703918457

training epoch 263 / 500, batch #350 / 625
Loss:	1.7492378950119019

training epoch 263 / 500, batch #375 / 625
Loss:	1.7181134223937988

training epoch 263 / 500, batch #400 / 625
Loss:	1.7465423345565796

training epoch 263 / 500, batch #425 / 625
Loss:	1.7769839763641357

training epoch 263 / 500, batch #450 / 625
Loss:	1.7714197635650635

training epoch 263 / 500, batch #475 / 625
Loss:	1.6980524063110352

training epoch 263 / 500, batch #500 / 625
Loss:	1.86033296585083

training epoch 263 / 500, batch #525 / 625
Loss:	1.7953078746795654

training epoch 263 / 500, batch #550 / 625
Loss:	1.4913055896759033

training epoch 263 / 500, batch #575 / 625
Loss:	1.573610782623291

training epoch 263 / 500, batch #600 / 625
Loss:	1.6919798851013184

training epoch 264 / 500, batch #0 / 625
Loss:	1.7897502183914185

training epoch 264 / 500, batch #25 / 625
Loss:	1.600913166999817

training epoch 264 / 500, batch #50 / 625
Loss:	1.9366343021392822

training epoch 264 / 500, batch #75 / 625
Loss:	1.9507167339324951

training epoch 264 / 500, batch #100 / 625
Loss:	1.7466111183166504

training epoch 264 / 500, batch #125 / 625
Loss:	1.8321477174758911

training epoch 264 / 500, batch #150 / 625
Loss:	1.7027506828308105

training epoch 264 / 500, batch #175 / 625
Loss:	1.6557447910308838

training epoch 264 / 500, batch #200 / 625
Loss:	1.8110507726669312

training epoch 264 / 500, batch #225 / 625
Loss:	1.5654652118682861

training epoch 264 / 500, batch #250 / 625
Loss:	1.6967267990112305

training epoch 264 / 500, batch #275 / 625
Loss:	1.6934642791748047

training epoch 264 / 500, batch #300 / 625
Loss:	1.581339955329895

training epoch 264 / 500, batch #325 / 625
Loss:	1.7052456140518188

training epoch 264 / 500, batch #350 / 625
Loss:	1.660674810409546

training epoch 264 / 500, batch #375 / 625
Loss:	1.6567420959472656

training epoch 264 / 500, batch #400 / 625
Loss:	1.6927129030227661

training epoch 264 / 500, batch #425 / 625
Loss:	1.6512165069580078

training epoch 264 / 500, batch #450 / 625
Loss:	2.0487003326416016

training epoch 264 / 500, batch #475 / 625
Loss:	1.8109115362167358

training epoch 264 / 500, batch #500 / 625
Loss:	1.7972910404205322

training epoch 264 / 500, batch #525 / 625
Loss:	1.7186301946640015

training epoch 264 / 500, batch #550 / 625
Loss:	1.7835263013839722

training epoch 264 / 500, batch #575 / 625
Loss:	1.70261549949646

training epoch 264 / 500, batch #600 / 625
Loss:	1.717874526977539

training epoch 265 / 500, batch #0 / 625
Loss:	1.6103028059005737

training epoch 265 / 500, batch #25 / 625
Loss:	1.7262696027755737

training epoch 265 / 500, batch #50 / 625
Loss:	1.5491223335266113

training epoch 265 / 500, batch #75 / 625
Loss:	1.4902373552322388

training epoch 265 / 500, batch #100 / 625
Loss:	1.5833680629730225

training epoch 265 / 500, batch #125 / 625
Loss:	1.7698466777801514

training epoch 265 / 500, batch #150 / 625
Loss:	1.5892008543014526

training epoch 265 / 500, batch #175 / 625
Loss:	1.7357673645019531

training epoch 265 / 500, batch #200 / 625
Loss:	1.9744549989700317

training epoch 265 / 500, batch #225 / 625
Loss:	1.8438235521316528

training epoch 265 / 500, batch #250 / 625
Loss:	1.4306668043136597

training epoch 265 / 500, batch #275 / 625
Loss:	1.5903022289276123

training epoch 265 / 500, batch #300 / 625
Loss:	1.6111453771591187

training epoch 265 / 500, batch #325 / 625
Loss:	1.6617212295532227

training epoch 265 / 500, batch #350 / 625
Loss:	1.7318673133850098

training epoch 265 / 500, batch #375 / 625
Loss:	1.726622462272644

training epoch 265 / 500, batch #400 / 625
Loss:	1.8747787475585938

training epoch 265 / 500, batch #425 / 625
Loss:	1.689858317375183

training epoch 265 / 500, batch #450 / 625
Loss:	1.7971162796020508

training epoch 265 / 500, batch #475 / 625
Loss:	1.6189570426940918

training epoch 265 / 500, batch #500 / 625
Loss:	1.9972915649414062

training epoch 265 / 500, batch #525 / 625
Loss:	1.726765751838684

training epoch 265 / 500, batch #550 / 625
Loss:	1.9448200464248657

training epoch 265 / 500, batch #575 / 625
Loss:	1.6886905431747437

training epoch 265 / 500, batch #600 / 625
Loss:	1.8903474807739258

training epoch 266 / 500, batch #0 / 625
Loss:	1.571239709854126

training epoch 266 / 500, batch #25 / 625
Loss:	1.9778355360031128

training epoch 266 / 500, batch #50 / 625
Loss:	1.8205276727676392

training epoch 266 / 500, batch #75 / 625
Loss:	1.6469014883041382

training epoch 266 / 500, batch #100 / 625
Loss:	1.5461663007736206

training epoch 266 / 500, batch #125 / 625
Loss:	1.7631678581237793

training epoch 266 / 500, batch #150 / 625
Loss:	2.1891822814941406

training epoch 266 / 500, batch #175 / 625
Loss:	1.6500989198684692

training epoch 266 / 500, batch #200 / 625
Loss:	1.7167068719863892

training epoch 266 / 500, batch #225 / 625
Loss:	1.855859398841858

training epoch 266 / 500, batch #250 / 625
Loss:	1.6651915311813354

training epoch 266 / 500, batch #275 / 625
Loss:	1.694270372390747

training epoch 266 / 500, batch #300 / 625
Loss:	1.5848193168640137

training epoch 266 / 500, batch #325 / 625
Loss:	1.7973988056182861

training epoch 266 / 500, batch #350 / 625
Loss:	1.8303546905517578

training epoch 266 / 500, batch #375 / 625
Loss:	1.7305033206939697

training epoch 266 / 500, batch #400 / 625
Loss:	1.5011605024337769

training epoch 266 / 500, batch #425 / 625
Loss:	1.8009560108184814

training epoch 266 / 500, batch #450 / 625
Loss:	1.7884230613708496

training epoch 266 / 500, batch #475 / 625
Loss:	1.6499125957489014

training epoch 266 / 500, batch #500 / 625
Loss:	1.964887261390686

training epoch 266 / 500, batch #525 / 625
Loss:	1.585446834564209

training epoch 266 / 500, batch #550 / 625
Loss:	1.8493196964263916

training epoch 266 / 500, batch #575 / 625
Loss:	1.7881982326507568

training epoch 266 / 500, batch #600 / 625
Loss:	1.7328040599822998

training epoch 267 / 500, batch #0 / 625
Loss:	1.8057528734207153

training epoch 267 / 500, batch #25 / 625
Loss:	1.7250587940216064

training epoch 267 / 500, batch #50 / 625
Loss:	1.7637410163879395

training epoch 267 / 500, batch #75 / 625
Loss:	1.7224791049957275

training epoch 267 / 500, batch #100 / 625
Loss:	2.1586549282073975

training epoch 267 / 500, batch #125 / 625
Loss:	1.737687349319458

training epoch 267 / 500, batch #150 / 625
Loss:	2.042447328567505

training epoch 267 / 500, batch #175 / 625
Loss:	1.5239359140396118

training epoch 267 / 500, batch #200 / 625
Loss:	1.712713360786438

training epoch 267 / 500, batch #225 / 625
Loss:	1.6827178001403809

training epoch 267 / 500, batch #250 / 625
Loss:	1.7961013317108154

training epoch 267 / 500, batch #275 / 625
Loss:	2.051539897918701

training epoch 267 / 500, batch #300 / 625
Loss:	1.7797220945358276

training epoch 267 / 500, batch #325 / 625
Loss:	1.5745941400527954

training epoch 267 / 500, batch #350 / 625
Loss:	1.6366897821426392

training epoch 267 / 500, batch #375 / 625
Loss:	1.759440541267395

training epoch 267 / 500, batch #400 / 625
Loss:	1.799755334854126

training epoch 267 / 500, batch #425 / 625
Loss:	1.6162534952163696

training epoch 267 / 500, batch #450 / 625
Loss:	1.636845588684082

training epoch 267 / 500, batch #475 / 625
Loss:	1.8229304552078247

training epoch 267 / 500, batch #500 / 625
Loss:	1.7221566438674927

training epoch 267 / 500, batch #525 / 625
Loss:	1.8189172744750977

training epoch 267 / 500, batch #550 / 625
Loss:	1.598841667175293

training epoch 267 / 500, batch #575 / 625
Loss:	1.5804708003997803

training epoch 267 / 500, batch #600 / 625
Loss:	1.9075194597244263

training epoch 268 / 500, batch #0 / 625
Loss:	1.722116470336914

training epoch 268 / 500, batch #25 / 625
Loss:	1.5922865867614746

training epoch 268 / 500, batch #50 / 625
Loss:	1.4703466892242432

training epoch 268 / 500, batch #75 / 625
Loss:	1.9008166790008545

training epoch 268 / 500, batch #100 / 625
Loss:	1.7818940877914429

training epoch 268 / 500, batch #125 / 625
Loss:	1.9427272081375122

training epoch 268 / 500, batch #150 / 625
Loss:	1.4960463047027588

training epoch 268 / 500, batch #175 / 625
Loss:	1.9442939758300781

training epoch 268 / 500, batch #200 / 625
Loss:	1.5715093612670898

training epoch 268 / 500, batch #225 / 625
Loss:	1.7673277854919434

training epoch 268 / 500, batch #250 / 625
Loss:	1.4793436527252197

training epoch 268 / 500, batch #275 / 625
Loss:	1.792285680770874

training epoch 268 / 500, batch #300 / 625
Loss:	1.616753339767456

training epoch 268 / 500, batch #325 / 625
Loss:	1.562215805053711

training epoch 268 / 500, batch #350 / 625
Loss:	1.509761929512024

training epoch 268 / 500, batch #375 / 625
Loss:	1.7069557905197144

training epoch 268 / 500, batch #400 / 625
Loss:	1.864020586013794

training epoch 268 / 500, batch #425 / 625
Loss:	1.9277870655059814

training epoch 268 / 500, batch #450 / 625
Loss:	1.847205638885498

training epoch 268 / 500, batch #475 / 625
Loss:	1.7216458320617676

training epoch 268 / 500, batch #500 / 625
Loss:	1.6705691814422607

training epoch 268 / 500, batch #525 / 625
Loss:	1.8549535274505615

training epoch 268 / 500, batch #550 / 625
Loss:	1.7526897192001343

training epoch 268 / 500, batch #575 / 625
Loss:	1.699126124382019

training epoch 268 / 500, batch #600 / 625
Loss:	1.2815499305725098

training epoch 269 / 500, batch #0 / 625
Loss:	1.6669927835464478

training epoch 269 / 500, batch #25 / 625
Loss:	1.5646891593933105

training epoch 269 / 500, batch #50 / 625
Loss:	1.563916563987732

training epoch 269 / 500, batch #75 / 625
Loss:	1.7233392000198364

training epoch 269 / 500, batch #100 / 625
Loss:	1.6743134260177612

training epoch 269 / 500, batch #125 / 625
Loss:	1.8608012199401855

training epoch 269 / 500, batch #150 / 625
Loss:	1.5402193069458008

training epoch 269 / 500, batch #175 / 625
Loss:	1.7258732318878174

training epoch 269 / 500, batch #200 / 625
Loss:	1.9966442584991455

training epoch 269 / 500, batch #225 / 625
Loss:	1.6587368249893188

training epoch 269 / 500, batch #250 / 625
Loss:	1.4129881858825684

training epoch 269 / 500, batch #275 / 625
Loss:	1.8811237812042236

training epoch 269 / 500, batch #300 / 625
Loss:	1.708106279373169

training epoch 269 / 500, batch #325 / 625
Loss:	1.6946189403533936

training epoch 269 / 500, batch #350 / 625
Loss:	1.9205695390701294

training epoch 269 / 500, batch #375 / 625
Loss:	1.879285216331482

training epoch 269 / 500, batch #400 / 625
Loss:	1.6955313682556152

training epoch 269 / 500, batch #425 / 625
Loss:	1.600244164466858

training epoch 269 / 500, batch #450 / 625
Loss:	1.7208514213562012

training epoch 269 / 500, batch #475 / 625
Loss:	1.8659262657165527

training epoch 269 / 500, batch #500 / 625
Loss:	1.8370356559753418

training epoch 269 / 500, batch #525 / 625
Loss:	1.8424595594406128

training epoch 269 / 500, batch #550 / 625
Loss:	1.95021653175354

training epoch 269 / 500, batch #575 / 625
Loss:	1.837136149406433

training epoch 269 / 500, batch #600 / 625
Loss:	1.863141655921936

training epoch 270 / 500, batch #0 / 625
Loss:	1.5712324380874634

training epoch 270 / 500, batch #25 / 625
Loss:	1.9242377281188965

training epoch 270 / 500, batch #50 / 625
Loss:	1.6190845966339111

training epoch 270 / 500, batch #75 / 625
Loss:	1.6758955717086792

training epoch 270 / 500, batch #100 / 625
Loss:	1.86283278465271

training epoch 270 / 500, batch #125 / 625
Loss:	1.4710028171539307

training epoch 270 / 500, batch #150 / 625
Loss:	1.8020942211151123

training epoch 270 / 500, batch #175 / 625
Loss:	1.804516315460205

training epoch 270 / 500, batch #200 / 625
Loss:	1.8586015701293945

training epoch 270 / 500, batch #225 / 625
Loss:	1.6501200199127197

training epoch 270 / 500, batch #250 / 625
Loss:	1.7258926630020142

training epoch 270 / 500, batch #275 / 625
Loss:	1.7899671792984009

training epoch 270 / 500, batch #300 / 625
Loss:	1.5289915800094604

training epoch 270 / 500, batch #325 / 625
Loss:	1.811883568763733

training epoch 270 / 500, batch #350 / 625
Loss:	1.7019190788269043

training epoch 270 / 500, batch #375 / 625
Loss:	1.6578001976013184

training epoch 270 / 500, batch #400 / 625
Loss:	1.8477481603622437

training epoch 270 / 500, batch #425 / 625
Loss:	1.5065813064575195

training epoch 270 / 500, batch #450 / 625
Loss:	1.6310811042785645

training epoch 270 / 500, batch #475 / 625
Loss:	1.7589001655578613

training epoch 270 / 500, batch #500 / 625
Loss:	1.62100088596344

training epoch 270 / 500, batch #525 / 625
Loss:	1.8656108379364014

training epoch 270 / 500, batch #550 / 625
Loss:	1.979767084121704

training epoch 270 / 500, batch #575 / 625
Loss:	1.8160912990570068

training epoch 270 / 500, batch #600 / 625
Loss:	1.8382841348648071

training epoch 271 / 500, batch #0 / 625
Loss:	1.734861135482788

training epoch 271 / 500, batch #25 / 625
Loss:	1.661856770515442

training epoch 271 / 500, batch #50 / 625
Loss:	1.8282214403152466

training epoch 271 / 500, batch #75 / 625
Loss:	1.6679844856262207

training epoch 271 / 500, batch #100 / 625
Loss:	1.6861482858657837

training epoch 271 / 500, batch #125 / 625
Loss:	1.6229034662246704

training epoch 271 / 500, batch #150 / 625
Loss:	1.6405669450759888

training epoch 271 / 500, batch #175 / 625
Loss:	1.7846603393554688

training epoch 271 / 500, batch #200 / 625
Loss:	1.7443363666534424

training epoch 271 / 500, batch #225 / 625
Loss:	1.7770588397979736

training epoch 271 / 500, batch #250 / 625
Loss:	1.6190968751907349

training epoch 271 / 500, batch #275 / 625
Loss:	1.8263580799102783

training epoch 271 / 500, batch #300 / 625
Loss:	1.7023472785949707

training epoch 271 / 500, batch #325 / 625
Loss:	1.6648050546646118

training epoch 271 / 500, batch #350 / 625
Loss:	1.9250595569610596

training epoch 271 / 500, batch #375 / 625
Loss:	1.7571640014648438

training epoch 271 / 500, batch #400 / 625
Loss:	1.7923237085342407

training epoch 271 / 500, batch #425 / 625
Loss:	2.0090675354003906

training epoch 271 / 500, batch #450 / 625
Loss:	1.7581108808517456

training epoch 271 / 500, batch #475 / 625
Loss:	1.9449083805084229

training epoch 271 / 500, batch #500 / 625
Loss:	1.793571949005127

training epoch 271 / 500, batch #525 / 625
Loss:	1.8688114881515503

training epoch 271 / 500, batch #550 / 625
Loss:	1.7708170413970947

training epoch 271 / 500, batch #575 / 625
Loss:	1.6819705963134766

training epoch 271 / 500, batch #600 / 625
Loss:	1.529626488685608

training epoch 272 / 500, batch #0 / 625
Loss:	1.832918405532837

training epoch 272 / 500, batch #25 / 625
Loss:	1.8490265607833862

training epoch 272 / 500, batch #50 / 625
Loss:	1.645246982574463

training epoch 272 / 500, batch #75 / 625
Loss:	1.8216681480407715

training epoch 272 / 500, batch #100 / 625
Loss:	1.5703182220458984

training epoch 272 / 500, batch #125 / 625
Loss:	1.6892751455307007

training epoch 272 / 500, batch #150 / 625
Loss:	1.7304922342300415

training epoch 272 / 500, batch #175 / 625
Loss:	1.6406279802322388

training epoch 272 / 500, batch #200 / 625
Loss:	1.4260088205337524

training epoch 272 / 500, batch #225 / 625
Loss:	1.9365386962890625

training epoch 272 / 500, batch #250 / 625
Loss:	1.8584527969360352

training epoch 272 / 500, batch #275 / 625
Loss:	1.7806447744369507

training epoch 272 / 500, batch #300 / 625
Loss:	1.6996135711669922

training epoch 272 / 500, batch #325 / 625
Loss:	1.4749293327331543

training epoch 272 / 500, batch #350 / 625
Loss:	1.8626174926757812

training epoch 272 / 500, batch #375 / 625
Loss:	1.7575758695602417

training epoch 272 / 500, batch #400 / 625
Loss:	1.7862024307250977

training epoch 272 / 500, batch #425 / 625
Loss:	1.4834696054458618

training epoch 272 / 500, batch #450 / 625
Loss:	1.6658612489700317

training epoch 272 / 500, batch #475 / 625
Loss:	1.6697293519973755

training epoch 272 / 500, batch #500 / 625
Loss:	1.8810431957244873

training epoch 272 / 500, batch #525 / 625
Loss:	1.5103150606155396

training epoch 272 / 500, batch #550 / 625
Loss:	1.673365592956543

training epoch 272 / 500, batch #575 / 625
Loss:	1.6427689790725708

training epoch 272 / 500, batch #600 / 625
Loss:	1.9161057472229004

training epoch 273 / 500, batch #0 / 625
Loss:	1.3911545276641846

training epoch 273 / 500, batch #25 / 625
Loss:	1.5771141052246094

training epoch 273 / 500, batch #50 / 625
Loss:	1.703322410583496

training epoch 273 / 500, batch #75 / 625
Loss:	1.8005815744400024

training epoch 273 / 500, batch #100 / 625
Loss:	1.751766562461853

training epoch 273 / 500, batch #125 / 625
Loss:	1.8947017192840576

training epoch 273 / 500, batch #150 / 625
Loss:	1.687964677810669

training epoch 273 / 500, batch #175 / 625
Loss:	1.7044456005096436

training epoch 273 / 500, batch #200 / 625
Loss:	1.7640759944915771

training epoch 273 / 500, batch #225 / 625
Loss:	1.8922723531723022

training epoch 273 / 500, batch #250 / 625
Loss:	1.8399914503097534

training epoch 273 / 500, batch #275 / 625
Loss:	1.6510217189788818

training epoch 273 / 500, batch #300 / 625
Loss:	1.833500623703003

training epoch 273 / 500, batch #325 / 625
Loss:	1.6312512159347534

training epoch 273 / 500, batch #350 / 625
Loss:	1.7697045803070068

training epoch 273 / 500, batch #375 / 625
Loss:	1.5737104415893555

training epoch 273 / 500, batch #400 / 625
Loss:	1.7432199716567993

training epoch 273 / 500, batch #425 / 625
Loss:	1.7808741331100464

training epoch 273 / 500, batch #450 / 625
Loss:	1.8869823217391968

training epoch 273 / 500, batch #475 / 625
Loss:	1.712714433670044

training epoch 273 / 500, batch #500 / 625
Loss:	1.3932580947875977

training epoch 273 / 500, batch #525 / 625
Loss:	1.6914098262786865

training epoch 273 / 500, batch #550 / 625
Loss:	1.5446254014968872

training epoch 273 / 500, batch #575 / 625
Loss:	1.7897931337356567

training epoch 273 / 500, batch #600 / 625
Loss:	1.7833044528961182

training epoch 274 / 500, batch #0 / 625
Loss:	1.7408636808395386

training epoch 274 / 500, batch #25 / 625
Loss:	1.6333562135696411

training epoch 274 / 500, batch #50 / 625
Loss:	1.8704251050949097

training epoch 274 / 500, batch #75 / 625
Loss:	1.5673974752426147

training epoch 274 / 500, batch #100 / 625
Loss:	1.8454519510269165

training epoch 274 / 500, batch #125 / 625
Loss:	1.7257111072540283

training epoch 274 / 500, batch #150 / 625
Loss:	1.8185985088348389

training epoch 274 / 500, batch #175 / 625
Loss:	1.7922890186309814

training epoch 274 / 500, batch #200 / 625
Loss:	1.4017853736877441

training epoch 274 / 500, batch #225 / 625
Loss:	1.7447510957717896

training epoch 274 / 500, batch #250 / 625
Loss:	1.6938598155975342

training epoch 274 / 500, batch #275 / 625
Loss:	1.696967363357544

training epoch 274 / 500, batch #300 / 625
Loss:	1.615217685699463

training epoch 274 / 500, batch #325 / 625
Loss:	1.7217849493026733

training epoch 274 / 500, batch #350 / 625
Loss:	1.5567913055419922

training epoch 274 / 500, batch #375 / 625
Loss:	1.9127203226089478

training epoch 274 / 500, batch #400 / 625
Loss:	1.771519422531128

training epoch 274 / 500, batch #425 / 625
Loss:	1.6850430965423584

training epoch 274 / 500, batch #450 / 625
Loss:	1.9232033491134644

training epoch 274 / 500, batch #475 / 625
Loss:	1.5961095094680786

training epoch 274 / 500, batch #500 / 625
Loss:	1.5548014640808105

training epoch 274 / 500, batch #525 / 625
Loss:	1.5625981092453003

training epoch 274 / 500, batch #550 / 625
Loss:	2.146172523498535

training epoch 274 / 500, batch #575 / 625
Loss:	1.405287742614746

training epoch 274 / 500, batch #600 / 625
Loss:	1.7555290460586548

training epoch 275 / 500, batch #0 / 625
Loss:	1.7236379384994507

training epoch 275 / 500, batch #25 / 625
Loss:	1.8513413667678833

training epoch 275 / 500, batch #50 / 625
Loss:	1.6178467273712158

training epoch 275 / 500, batch #75 / 625
Loss:	1.6404401063919067

training epoch 275 / 500, batch #100 / 625
Loss:	1.871188759803772

training epoch 275 / 500, batch #125 / 625
Loss:	1.7729442119598389

training epoch 275 / 500, batch #150 / 625
Loss:	1.7401330471038818

training epoch 275 / 500, batch #175 / 625
Loss:	1.9795610904693604

training epoch 275 / 500, batch #200 / 625
Loss:	1.8178529739379883

training epoch 275 / 500, batch #225 / 625
Loss:	1.5544183254241943

training epoch 275 / 500, batch #250 / 625
Loss:	1.6731595993041992

training epoch 275 / 500, batch #275 / 625
Loss:	1.8089556694030762

training epoch 275 / 500, batch #300 / 625
Loss:	1.7982650995254517

training epoch 275 / 500, batch #325 / 625
Loss:	1.4663143157958984

training epoch 275 / 500, batch #350 / 625
Loss:	1.9424660205841064

training epoch 275 / 500, batch #375 / 625
Loss:	1.7046269178390503

training epoch 275 / 500, batch #400 / 625
Loss:	1.8907088041305542

training epoch 275 / 500, batch #425 / 625
Loss:	1.7008007764816284

training epoch 275 / 500, batch #450 / 625
Loss:	1.7487140893936157

training epoch 275 / 500, batch #475 / 625
Loss:	1.8632657527923584

training epoch 275 / 500, batch #500 / 625
Loss:	1.7937179803848267

training epoch 275 / 500, batch #525 / 625
Loss:	1.6495890617370605

training epoch 275 / 500, batch #550 / 625
Loss:	1.7247962951660156

training epoch 275 / 500, batch #575 / 625
Loss:	1.749313473701477

training epoch 275 / 500, batch #600 / 625
Loss:	1.6417890787124634

training epoch 276 / 500, batch #0 / 625
Loss:	1.6953158378601074

training epoch 276 / 500, batch #25 / 625
Loss:	1.733779788017273

training epoch 276 / 500, batch #50 / 625
Loss:	1.5073162317276

training epoch 276 / 500, batch #75 / 625
Loss:	1.6678110361099243

training epoch 276 / 500, batch #100 / 625
Loss:	1.8945684432983398

training epoch 276 / 500, batch #125 / 625
Loss:	1.631493091583252

training epoch 276 / 500, batch #150 / 625
Loss:	1.779839038848877

training epoch 276 / 500, batch #175 / 625
Loss:	1.7093579769134521

training epoch 276 / 500, batch #200 / 625
Loss:	1.817604660987854

training epoch 276 / 500, batch #225 / 625
Loss:	1.6120268106460571

training epoch 276 / 500, batch #250 / 625
Loss:	1.8752862215042114

training epoch 276 / 500, batch #275 / 625
Loss:	1.512534737586975

training epoch 276 / 500, batch #300 / 625
Loss:	1.680381417274475

training epoch 276 / 500, batch #325 / 625
Loss:	1.8843144178390503

training epoch 276 / 500, batch #350 / 625
Loss:	1.9140011072158813

training epoch 276 / 500, batch #375 / 625
Loss:	1.7617794275283813

training epoch 276 / 500, batch #400 / 625
Loss:	1.5473204851150513

training epoch 276 / 500, batch #425 / 625
Loss:	2.2762744426727295

training epoch 276 / 500, batch #450 / 625
Loss:	1.8444182872772217

training epoch 276 / 500, batch #475 / 625
Loss:	1.7008030414581299

training epoch 276 / 500, batch #500 / 625
Loss:	1.622053623199463

training epoch 276 / 500, batch #525 / 625
Loss:	1.8798874616622925

training epoch 276 / 500, batch #550 / 625
Loss:	1.9003238677978516

training epoch 276 / 500, batch #575 / 625
Loss:	1.7954654693603516

training epoch 276 / 500, batch #600 / 625
Loss:	1.504412055015564

training epoch 277 / 500, batch #0 / 625
Loss:	1.8261011838912964

training epoch 277 / 500, batch #25 / 625
Loss:	1.7528865337371826

training epoch 277 / 500, batch #50 / 625
Loss:	1.8490557670593262

training epoch 277 / 500, batch #75 / 625
Loss:	1.8043757677078247

training epoch 277 / 500, batch #100 / 625
Loss:	1.798601746559143

training epoch 277 / 500, batch #125 / 625
Loss:	1.4765969514846802

training epoch 277 / 500, batch #150 / 625
Loss:	1.606214165687561

training epoch 277 / 500, batch #175 / 625
Loss:	1.6136146783828735

training epoch 277 / 500, batch #200 / 625
Loss:	1.8593699932098389

training epoch 277 / 500, batch #225 / 625
Loss:	1.6295217275619507

training epoch 277 / 500, batch #250 / 625
Loss:	1.742385745048523

training epoch 277 / 500, batch #275 / 625
Loss:	1.8127856254577637

training epoch 277 / 500, batch #300 / 625
Loss:	1.6249512434005737

training epoch 277 / 500, batch #325 / 625
Loss:	1.8431239128112793

training epoch 277 / 500, batch #350 / 625
Loss:	1.6223196983337402

training epoch 277 / 500, batch #375 / 625
Loss:	1.8303096294403076

training epoch 277 / 500, batch #400 / 625
Loss:	1.3794209957122803

training epoch 277 / 500, batch #425 / 625
Loss:	1.7143808603286743

training epoch 277 / 500, batch #450 / 625
Loss:	1.9580341577529907

training epoch 277 / 500, batch #475 / 625
Loss:	1.7087855339050293

training epoch 277 / 500, batch #500 / 625
Loss:	1.8132199048995972

training epoch 277 / 500, batch #525 / 625
Loss:	1.6964670419692993

training epoch 277 / 500, batch #550 / 625
Loss:	2.123884439468384

training epoch 277 / 500, batch #575 / 625
Loss:	1.7502634525299072

training epoch 277 / 500, batch #600 / 625
Loss:	1.7291021347045898

training epoch 278 / 500, batch #0 / 625
Loss:	1.7216134071350098

training epoch 278 / 500, batch #25 / 625
Loss:	1.8366252183914185

training epoch 278 / 500, batch #50 / 625
Loss:	1.579193353652954

training epoch 278 / 500, batch #75 / 625
Loss:	1.605258584022522

training epoch 278 / 500, batch #100 / 625
Loss:	1.826041340827942

training epoch 278 / 500, batch #125 / 625
Loss:	1.7221788167953491

training epoch 278 / 500, batch #150 / 625
Loss:	1.5732125043869019

training epoch 278 / 500, batch #175 / 625
Loss:	1.616298794746399

training epoch 278 / 500, batch #200 / 625
Loss:	1.5578525066375732

training epoch 278 / 500, batch #225 / 625
Loss:	1.8624132871627808

training epoch 278 / 500, batch #250 / 625
Loss:	1.7227836847305298

training epoch 278 / 500, batch #275 / 625
Loss:	1.5859737396240234

training epoch 278 / 500, batch #300 / 625
Loss:	1.6105951070785522

training epoch 278 / 500, batch #325 / 625
Loss:	1.5989333391189575

training epoch 278 / 500, batch #350 / 625
Loss:	1.9869070053100586

training epoch 278 / 500, batch #375 / 625
Loss:	1.635949730873108

training epoch 278 / 500, batch #400 / 625
Loss:	1.6376014947891235

training epoch 278 / 500, batch #425 / 625
Loss:	1.6694061756134033

training epoch 278 / 500, batch #450 / 625
Loss:	1.56479811668396

training epoch 278 / 500, batch #475 / 625
Loss:	1.4514342546463013

training epoch 278 / 500, batch #500 / 625
Loss:	1.7178218364715576

training epoch 278 / 500, batch #525 / 625
Loss:	1.7780160903930664

training epoch 278 / 500, batch #550 / 625
Loss:	1.6515514850616455

training epoch 278 / 500, batch #575 / 625
Loss:	1.6582000255584717

training epoch 278 / 500, batch #600 / 625
Loss:	1.8146172761917114

training epoch 279 / 500, batch #0 / 625
Loss:	1.7781131267547607

training epoch 279 / 500, batch #25 / 625
Loss:	1.7143235206604004

training epoch 279 / 500, batch #50 / 625
Loss:	1.7768337726593018

training epoch 279 / 500, batch #75 / 625
Loss:	1.780133843421936

training epoch 279 / 500, batch #100 / 625
Loss:	1.7729392051696777

training epoch 279 / 500, batch #125 / 625
Loss:	1.7007451057434082

training epoch 279 / 500, batch #150 / 625
Loss:	1.976178765296936

training epoch 279 / 500, batch #175 / 625
Loss:	2.0648033618927

training epoch 279 / 500, batch #200 / 625
Loss:	1.7715805768966675

training epoch 279 / 500, batch #225 / 625
Loss:	1.7801283597946167

training epoch 279 / 500, batch #250 / 625
Loss:	1.7403470277786255

training epoch 279 / 500, batch #275 / 625
Loss:	1.8967362642288208

training epoch 279 / 500, batch #300 / 625
Loss:	1.9793566465377808

training epoch 279 / 500, batch #325 / 625
Loss:	1.9076745510101318

training epoch 279 / 500, batch #350 / 625
Loss:	1.8844562768936157

training epoch 279 / 500, batch #375 / 625
Loss:	1.6022675037384033

training epoch 279 / 500, batch #400 / 625
Loss:	1.7307227849960327

training epoch 279 / 500, batch #425 / 625
Loss:	1.8205605745315552

training epoch 279 / 500, batch #450 / 625
Loss:	1.7100602388381958

training epoch 279 / 500, batch #475 / 625
Loss:	1.6160222291946411

training epoch 279 / 500, batch #500 / 625
Loss:	1.7794991731643677

training epoch 279 / 500, batch #525 / 625
Loss:	1.8092060089111328

training epoch 279 / 500, batch #550 / 625
Loss:	1.7552211284637451

training epoch 279 / 500, batch #575 / 625
Loss:	1.746948480606079

training epoch 279 / 500, batch #600 / 625
Loss:	1.805195689201355

training epoch 280 / 500, batch #0 / 625
Loss:	1.5893064737319946

training epoch 280 / 500, batch #25 / 625
Loss:	1.8024823665618896

training epoch 280 / 500, batch #50 / 625
Loss:	1.6953325271606445

training epoch 280 / 500, batch #75 / 625
Loss:	2.0555684566497803

training epoch 280 / 500, batch #100 / 625
Loss:	1.559118628501892

training epoch 280 / 500, batch #125 / 625
Loss:	1.7965242862701416

training epoch 280 / 500, batch #150 / 625
Loss:	1.6569132804870605

training epoch 280 / 500, batch #175 / 625
Loss:	1.7059996128082275

training epoch 280 / 500, batch #200 / 625
Loss:	1.6834967136383057

training epoch 280 / 500, batch #225 / 625
Loss:	1.8237366676330566

training epoch 280 / 500, batch #250 / 625
Loss:	1.6842613220214844

training epoch 280 / 500, batch #275 / 625
Loss:	1.9317965507507324

training epoch 280 / 500, batch #300 / 625
Loss:	1.5719172954559326

training epoch 280 / 500, batch #325 / 625
Loss:	1.5995783805847168

training epoch 280 / 500, batch #350 / 625
Loss:	1.5651605129241943

training epoch 280 / 500, batch #375 / 625
Loss:	1.4271937608718872

training epoch 280 / 500, batch #400 / 625
Loss:	1.790047287940979

training epoch 280 / 500, batch #425 / 625
Loss:	1.8428269624710083

training epoch 280 / 500, batch #450 / 625
Loss:	1.7552964687347412

training epoch 280 / 500, batch #475 / 625
Loss:	1.9004499912261963

training epoch 280 / 500, batch #500 / 625
Loss:	1.8701590299606323

training epoch 280 / 500, batch #525 / 625
Loss:	1.5827713012695312

training epoch 280 / 500, batch #550 / 625
Loss:	1.7212530374526978

training epoch 280 / 500, batch #575 / 625
Loss:	1.7699589729309082

training epoch 280 / 500, batch #600 / 625
Loss:	1.7079511880874634

training epoch 281 / 500, batch #0 / 625
Loss:	1.8082849979400635

training epoch 281 / 500, batch #25 / 625
Loss:	1.6526750326156616

training epoch 281 / 500, batch #50 / 625
Loss:	1.7422761917114258

training epoch 281 / 500, batch #75 / 625
Loss:	1.7696350812911987

training epoch 281 / 500, batch #100 / 625
Loss:	1.6346997022628784

training epoch 281 / 500, batch #125 / 625
Loss:	1.9567830562591553

training epoch 281 / 500, batch #150 / 625
Loss:	1.92193603515625

training epoch 281 / 500, batch #175 / 625
Loss:	1.7413052320480347

training epoch 281 / 500, batch #200 / 625
Loss:	1.6882466077804565

training epoch 281 / 500, batch #225 / 625
Loss:	1.6083027124404907

training epoch 281 / 500, batch #250 / 625
Loss:	1.6679366827011108

training epoch 281 / 500, batch #275 / 625
Loss:	1.5756120681762695

training epoch 281 / 500, batch #300 / 625
Loss:	1.7954202890396118

training epoch 281 / 500, batch #325 / 625
Loss:	1.7916699647903442

training epoch 281 / 500, batch #350 / 625
Loss:	1.6884385347366333

training epoch 281 / 500, batch #375 / 625
Loss:	1.8526448011398315

training epoch 281 / 500, batch #400 / 625
Loss:	1.6921076774597168

training epoch 281 / 500, batch #425 / 625
Loss:	1.7285043001174927

training epoch 281 / 500, batch #450 / 625
Loss:	1.6078555583953857

training epoch 281 / 500, batch #475 / 625
Loss:	1.6380386352539062

training epoch 281 / 500, batch #500 / 625
Loss:	1.7541486024856567

training epoch 281 / 500, batch #525 / 625
Loss:	1.784027338027954

training epoch 281 / 500, batch #550 / 625
Loss:	1.6779656410217285

training epoch 281 / 500, batch #575 / 625
Loss:	1.677916169166565

training epoch 281 / 500, batch #600 / 625
Loss:	1.870273470878601

training epoch 282 / 500, batch #0 / 625
Loss:	2.0087156295776367

training epoch 282 / 500, batch #25 / 625
Loss:	1.8374323844909668

training epoch 282 / 500, batch #50 / 625
Loss:	1.504947543144226

training epoch 282 / 500, batch #75 / 625
Loss:	1.741672158241272

training epoch 282 / 500, batch #100 / 625
Loss:	1.5344784259796143

training epoch 282 / 500, batch #125 / 625
Loss:	1.7603731155395508

training epoch 282 / 500, batch #150 / 625
Loss:	1.7387725114822388

training epoch 282 / 500, batch #175 / 625
Loss:	1.8005479574203491

training epoch 282 / 500, batch #200 / 625
Loss:	1.6674569845199585

training epoch 282 / 500, batch #225 / 625
Loss:	1.7590190172195435

training epoch 282 / 500, batch #250 / 625
Loss:	1.892331600189209

training epoch 282 / 500, batch #275 / 625
Loss:	1.7377573251724243

training epoch 282 / 500, batch #300 / 625
Loss:	1.6265215873718262

training epoch 282 / 500, batch #325 / 625
Loss:	1.5485068559646606

training epoch 282 / 500, batch #350 / 625
Loss:	1.812015175819397

training epoch 282 / 500, batch #375 / 625
Loss:	1.7009371519088745

training epoch 282 / 500, batch #400 / 625
Loss:	1.7938777208328247

training epoch 282 / 500, batch #425 / 625
Loss:	1.5861934423446655

training epoch 282 / 500, batch #450 / 625
Loss:	1.7938289642333984

training epoch 282 / 500, batch #475 / 625
Loss:	1.7985949516296387

training epoch 282 / 500, batch #500 / 625
Loss:	1.8084328174591064

training epoch 282 / 500, batch #525 / 625
Loss:	1.592820167541504

training epoch 282 / 500, batch #550 / 625
Loss:	1.8645188808441162

training epoch 282 / 500, batch #575 / 625
Loss:	1.6093562841415405

training epoch 282 / 500, batch #600 / 625
Loss:	1.57083261013031

training epoch 283 / 500, batch #0 / 625
Loss:	1.6604923009872437

training epoch 283 / 500, batch #25 / 625
Loss:	1.665228009223938

training epoch 283 / 500, batch #50 / 625
Loss:	1.6831775903701782

training epoch 283 / 500, batch #75 / 625
Loss:	1.4492394924163818

training epoch 283 / 500, batch #100 / 625
Loss:	1.7810770273208618

training epoch 283 / 500, batch #125 / 625
Loss:	1.6484025716781616

training epoch 283 / 500, batch #150 / 625
Loss:	1.7354153394699097

training epoch 283 / 500, batch #175 / 625
Loss:	1.7092853784561157

training epoch 283 / 500, batch #200 / 625
Loss:	1.6383440494537354

training epoch 283 / 500, batch #225 / 625
Loss:	1.7139434814453125

training epoch 283 / 500, batch #250 / 625
Loss:	1.5273479223251343

training epoch 283 / 500, batch #275 / 625
Loss:	1.69181489944458

training epoch 283 / 500, batch #300 / 625
Loss:	1.7798830270767212

training epoch 283 / 500, batch #325 / 625
Loss:	1.6496316194534302

training epoch 283 / 500, batch #350 / 625
Loss:	1.8173335790634155

training epoch 283 / 500, batch #375 / 625
Loss:	1.9896413087844849

training epoch 283 / 500, batch #400 / 625
Loss:	1.6801036596298218

training epoch 283 / 500, batch #425 / 625
Loss:	1.6308413743972778

training epoch 283 / 500, batch #450 / 625
Loss:	1.6922338008880615

training epoch 283 / 500, batch #475 / 625
Loss:	1.8025881052017212

training epoch 283 / 500, batch #500 / 625
Loss:	1.8443493843078613

training epoch 283 / 500, batch #525 / 625
Loss:	1.8688892126083374

training epoch 283 / 500, batch #550 / 625
Loss:	2.0273892879486084

training epoch 283 / 500, batch #575 / 625
Loss:	1.8694064617156982

training epoch 283 / 500, batch #600 / 625
Loss:	1.8602626323699951

training epoch 284 / 500, batch #0 / 625
Loss:	1.7127896547317505

training epoch 284 / 500, batch #25 / 625
Loss:	1.7208644151687622

training epoch 284 / 500, batch #50 / 625
Loss:	1.5675989389419556

training epoch 284 / 500, batch #75 / 625
Loss:	1.9203648567199707

training epoch 284 / 500, batch #100 / 625
Loss:	1.8886964321136475

training epoch 284 / 500, batch #125 / 625
Loss:	1.8013592958450317

training epoch 284 / 500, batch #150 / 625
Loss:	1.6658631563186646

training epoch 284 / 500, batch #175 / 625
Loss:	1.7975785732269287

training epoch 284 / 500, batch #200 / 625
Loss:	1.7611061334609985

training epoch 284 / 500, batch #225 / 625
Loss:	1.6035912036895752

training epoch 284 / 500, batch #250 / 625
Loss:	1.3685152530670166

training epoch 284 / 500, batch #275 / 625
Loss:	1.9273402690887451

training epoch 284 / 500, batch #300 / 625
Loss:	1.8317009210586548

training epoch 284 / 500, batch #325 / 625
Loss:	1.848875641822815

training epoch 284 / 500, batch #350 / 625
Loss:	2.0373573303222656

training epoch 284 / 500, batch #375 / 625
Loss:	1.740906000137329

training epoch 284 / 500, batch #400 / 625
Loss:	1.6468307971954346

training epoch 284 / 500, batch #425 / 625
Loss:	1.5836020708084106

training epoch 284 / 500, batch #450 / 625
Loss:	1.6660603284835815

training epoch 284 / 500, batch #475 / 625
Loss:	1.7718873023986816

training epoch 284 / 500, batch #500 / 625
Loss:	1.912243366241455

training epoch 284 / 500, batch #525 / 625
Loss:	1.7529321908950806

training epoch 284 / 500, batch #550 / 625
Loss:	1.577771782875061

training epoch 284 / 500, batch #575 / 625
Loss:	1.8528307676315308

training epoch 284 / 500, batch #600 / 625
Loss:	1.797675609588623

training epoch 285 / 500, batch #0 / 625
Loss:	1.574256181716919

training epoch 285 / 500, batch #25 / 625
Loss:	1.614905595779419

training epoch 285 / 500, batch #50 / 625
Loss:	1.9186842441558838

training epoch 285 / 500, batch #75 / 625
Loss:	1.6892238855361938

training epoch 285 / 500, batch #100 / 625
Loss:	1.6087032556533813

training epoch 285 / 500, batch #125 / 625
Loss:	1.7004830837249756

training epoch 285 / 500, batch #150 / 625
Loss:	1.8927056789398193

training epoch 285 / 500, batch #175 / 625
Loss:	1.840635895729065

training epoch 285 / 500, batch #200 / 625
Loss:	1.5471611022949219

training epoch 285 / 500, batch #225 / 625
Loss:	1.6656543016433716

training epoch 285 / 500, batch #250 / 625
Loss:	1.759458065032959

training epoch 285 / 500, batch #275 / 625
Loss:	1.8166431188583374

training epoch 285 / 500, batch #300 / 625
Loss:	1.6894810199737549

training epoch 285 / 500, batch #325 / 625
Loss:	1.8401267528533936

training epoch 285 / 500, batch #350 / 625
Loss:	1.7590196132659912

training epoch 285 / 500, batch #375 / 625
Loss:	1.7521988153457642

training epoch 285 / 500, batch #400 / 625
Loss:	1.714855432510376

training epoch 285 / 500, batch #425 / 625
Loss:	1.8899604082107544

training epoch 285 / 500, batch #450 / 625
Loss:	1.8277041912078857

training epoch 285 / 500, batch #475 / 625
Loss:	1.718048334121704

training epoch 285 / 500, batch #500 / 625
Loss:	1.682071566581726

training epoch 285 / 500, batch #525 / 625
Loss:	1.9927153587341309

training epoch 285 / 500, batch #550 / 625
Loss:	1.5187373161315918

training epoch 285 / 500, batch #575 / 625
Loss:	1.655941367149353

training epoch 285 / 500, batch #600 / 625
Loss:	1.8472880125045776

training epoch 286 / 500, batch #0 / 625
Loss:	1.703957438468933

training epoch 286 / 500, batch #25 / 625
Loss:	1.9152405261993408

training epoch 286 / 500, batch #50 / 625
Loss:	1.9171807765960693

training epoch 286 / 500, batch #75 / 625
Loss:	1.6752526760101318

training epoch 286 / 500, batch #100 / 625
Loss:	2.314924955368042

training epoch 286 / 500, batch #125 / 625
Loss:	2.071282386779785

training epoch 286 / 500, batch #150 / 625
Loss:	1.9992865324020386

training epoch 286 / 500, batch #175 / 625
Loss:	1.8966712951660156

training epoch 286 / 500, batch #200 / 625
Loss:	1.8245362043380737

training epoch 286 / 500, batch #225 / 625
Loss:	1.5994035005569458

training epoch 286 / 500, batch #250 / 625
Loss:	1.7568551301956177

training epoch 286 / 500, batch #275 / 625
Loss:	1.9197942018508911

training epoch 286 / 500, batch #300 / 625
Loss:	1.948563814163208

training epoch 286 / 500, batch #325 / 625
Loss:	1.4988194704055786

training epoch 286 / 500, batch #350 / 625
Loss:	1.7672348022460938

training epoch 286 / 500, batch #375 / 625
Loss:	1.7233513593673706

training epoch 286 / 500, batch #400 / 625
Loss:	1.6197150945663452

training epoch 286 / 500, batch #425 / 625
Loss:	1.8886123895645142

training epoch 286 / 500, batch #450 / 625
Loss:	1.8390675783157349

training epoch 286 / 500, batch #475 / 625
Loss:	1.7037594318389893

training epoch 286 / 500, batch #500 / 625
Loss:	1.8251229524612427

training epoch 286 / 500, batch #525 / 625
Loss:	1.6371992826461792

training epoch 286 / 500, batch #550 / 625
Loss:	1.7937854528427124

training epoch 286 / 500, batch #575 / 625
Loss:	1.656782627105713

training epoch 286 / 500, batch #600 / 625
Loss:	1.707388162612915

training epoch 287 / 500, batch #0 / 625
Loss:	1.6455652713775635

training epoch 287 / 500, batch #25 / 625
Loss:	1.7635517120361328

training epoch 287 / 500, batch #50 / 625
Loss:	1.7393327951431274

training epoch 287 / 500, batch #75 / 625
Loss:	1.772560715675354

training epoch 287 / 500, batch #100 / 625
Loss:	1.4678590297698975

training epoch 287 / 500, batch #125 / 625
Loss:	1.7635087966918945

training epoch 287 / 500, batch #150 / 625
Loss:	1.7540513277053833

training epoch 287 / 500, batch #175 / 625
Loss:	1.9842123985290527

training epoch 287 / 500, batch #200 / 625
Loss:	1.7101699113845825

training epoch 287 / 500, batch #225 / 625
Loss:	1.808108925819397

training epoch 287 / 500, batch #250 / 625
Loss:	1.717666506767273

training epoch 287 / 500, batch #275 / 625
Loss:	1.816569209098816

training epoch 287 / 500, batch #300 / 625
Loss:	1.7097644805908203

training epoch 287 / 500, batch #325 / 625
Loss:	1.6339563131332397

training epoch 287 / 500, batch #350 / 625
Loss:	1.8577451705932617

training epoch 287 / 500, batch #375 / 625
Loss:	1.3650120496749878

training epoch 287 / 500, batch #400 / 625
Loss:	1.8383210897445679

training epoch 287 / 500, batch #425 / 625
Loss:	1.670422077178955

training epoch 287 / 500, batch #450 / 625
Loss:	1.6828556060791016

training epoch 287 / 500, batch #475 / 625
Loss:	1.7431217432022095

training epoch 287 / 500, batch #500 / 625
Loss:	1.830973744392395

training epoch 287 / 500, batch #525 / 625
Loss:	2.0783607959747314

training epoch 287 / 500, batch #550 / 625
Loss:	1.5189626216888428

training epoch 287 / 500, batch #575 / 625
Loss:	1.6339759826660156

training epoch 287 / 500, batch #600 / 625
Loss:	1.8138484954833984

training epoch 288 / 500, batch #0 / 625
Loss:	1.8370485305786133

training epoch 288 / 500, batch #25 / 625
Loss:	1.7908973693847656

training epoch 288 / 500, batch #50 / 625
Loss:	1.7958918809890747

training epoch 288 / 500, batch #75 / 625
Loss:	1.6753414869308472

training epoch 288 / 500, batch #100 / 625
Loss:	1.6499875783920288

training epoch 288 / 500, batch #125 / 625
Loss:	1.779850959777832

training epoch 288 / 500, batch #150 / 625
Loss:	1.6423593759536743

training epoch 288 / 500, batch #175 / 625
Loss:	1.639879584312439

training epoch 288 / 500, batch #200 / 625
Loss:	1.6681004762649536

training epoch 288 / 500, batch #225 / 625
Loss:	1.8700861930847168

training epoch 288 / 500, batch #250 / 625
Loss:	1.7688109874725342

training epoch 288 / 500, batch #275 / 625
Loss:	1.529127836227417

training epoch 288 / 500, batch #300 / 625
Loss:	1.6879608631134033

training epoch 288 / 500, batch #325 / 625
Loss:	1.6919918060302734

training epoch 288 / 500, batch #350 / 625
Loss:	1.7502646446228027

training epoch 288 / 500, batch #375 / 625
Loss:	1.7521920204162598

training epoch 288 / 500, batch #400 / 625
Loss:	1.6004056930541992

training epoch 288 / 500, batch #425 / 625
Loss:	1.830458164215088

training epoch 288 / 500, batch #450 / 625
Loss:	1.6191309690475464

training epoch 288 / 500, batch #475 / 625
Loss:	1.5323305130004883

training epoch 288 / 500, batch #500 / 625
Loss:	1.5282199382781982

training epoch 288 / 500, batch #525 / 625
Loss:	1.5426666736602783

training epoch 288 / 500, batch #550 / 625
Loss:	1.7866063117980957

training epoch 288 / 500, batch #575 / 625
Loss:	1.8733419179916382

training epoch 288 / 500, batch #600 / 625
Loss:	1.7709276676177979

training epoch 289 / 500, batch #0 / 625
Loss:	1.7326164245605469

training epoch 289 / 500, batch #25 / 625
Loss:	1.7416462898254395

training epoch 289 / 500, batch #50 / 625
Loss:	1.6322574615478516

training epoch 289 / 500, batch #75 / 625
Loss:	1.631430983543396

training epoch 289 / 500, batch #100 / 625
Loss:	1.5651330947875977

training epoch 289 / 500, batch #125 / 625
Loss:	1.569089412689209

training epoch 289 / 500, batch #150 / 625
Loss:	1.7533397674560547

training epoch 289 / 500, batch #175 / 625
Loss:	1.931941270828247

training epoch 289 / 500, batch #200 / 625
Loss:	1.6647107601165771

training epoch 289 / 500, batch #225 / 625
Loss:	1.93264639377594

training epoch 289 / 500, batch #250 / 625
Loss:	1.9298619031906128

training epoch 289 / 500, batch #275 / 625
Loss:	1.7591829299926758

training epoch 289 / 500, batch #300 / 625
Loss:	1.8461641073226929

training epoch 289 / 500, batch #325 / 625
Loss:	1.6174877882003784

training epoch 289 / 500, batch #350 / 625
Loss:	1.6747007369995117

training epoch 289 / 500, batch #375 / 625
Loss:	1.6449772119522095

training epoch 289 / 500, batch #400 / 625
Loss:	1.6404225826263428

training epoch 289 / 500, batch #425 / 625
Loss:	1.8349876403808594

training epoch 289 / 500, batch #450 / 625
Loss:	1.5862289667129517

training epoch 289 / 500, batch #475 / 625
Loss:	1.642676591873169

training epoch 289 / 500, batch #500 / 625
Loss:	1.8542170524597168

training epoch 289 / 500, batch #525 / 625
Loss:	1.7075824737548828

training epoch 289 / 500, batch #550 / 625
Loss:	1.4966332912445068

training epoch 289 / 500, batch #575 / 625
Loss:	2.0334599018096924

training epoch 289 / 500, batch #600 / 625
Loss:	1.7046109437942505

training epoch 290 / 500, batch #0 / 625
Loss:	1.4766693115234375

training epoch 290 / 500, batch #25 / 625
Loss:	1.8808956146240234

training epoch 290 / 500, batch #50 / 625
Loss:	2.07966947555542

training epoch 290 / 500, batch #75 / 625
Loss:	1.8001813888549805

training epoch 290 / 500, batch #100 / 625
Loss:	1.618640661239624

training epoch 290 / 500, batch #125 / 625
Loss:	1.6175771951675415

training epoch 290 / 500, batch #150 / 625
Loss:	1.5718717575073242

training epoch 290 / 500, batch #175 / 625
Loss:	1.7839829921722412

training epoch 290 / 500, batch #200 / 625
Loss:	1.8704944849014282

training epoch 290 / 500, batch #225 / 625
Loss:	1.6382218599319458

training epoch 290 / 500, batch #250 / 625
Loss:	1.6483863592147827

training epoch 290 / 500, batch #275 / 625
Loss:	1.671196460723877

training epoch 290 / 500, batch #300 / 625
Loss:	1.7334368228912354

training epoch 290 / 500, batch #325 / 625
Loss:	1.7685455083847046

training epoch 290 / 500, batch #350 / 625
Loss:	1.829354166984558

training epoch 290 / 500, batch #375 / 625
Loss:	1.91342031955719

training epoch 290 / 500, batch #400 / 625
Loss:	1.443568229675293

training epoch 290 / 500, batch #425 / 625
Loss:	1.5566730499267578

training epoch 290 / 500, batch #450 / 625
Loss:	1.6668052673339844

training epoch 290 / 500, batch #475 / 625
Loss:	1.848696231842041

training epoch 290 / 500, batch #500 / 625
Loss:	1.7382915019989014

training epoch 290 / 500, batch #525 / 625
Loss:	1.4637142419815063

training epoch 290 / 500, batch #550 / 625
Loss:	1.705430269241333

training epoch 290 / 500, batch #575 / 625
Loss:	1.7252167463302612

training epoch 290 / 500, batch #600 / 625
Loss:	1.8073341846466064

training epoch 291 / 500, batch #0 / 625
Loss:	1.608660340309143

training epoch 291 / 500, batch #25 / 625
Loss:	1.6418789625167847

training epoch 291 / 500, batch #50 / 625
Loss:	1.9175639152526855

training epoch 291 / 500, batch #75 / 625
Loss:	1.8252644538879395

training epoch 291 / 500, batch #100 / 625
Loss:	1.7911626100540161

training epoch 291 / 500, batch #125 / 625
Loss:	1.707411289215088

training epoch 291 / 500, batch #150 / 625
Loss:	1.6883080005645752

training epoch 291 / 500, batch #175 / 625
Loss:	1.859405517578125

training epoch 291 / 500, batch #200 / 625
Loss:	1.774848222732544

training epoch 291 / 500, batch #225 / 625
Loss:	1.6854923963546753

training epoch 291 / 500, batch #250 / 625
Loss:	1.5947792530059814

training epoch 291 / 500, batch #275 / 625
Loss:	1.5550177097320557

training epoch 291 / 500, batch #300 / 625
Loss:	1.3531631231307983

training epoch 291 / 500, batch #325 / 625
Loss:	1.5126501321792603

training epoch 291 / 500, batch #350 / 625
Loss:	1.8937267065048218

training epoch 291 / 500, batch #375 / 625
Loss:	1.5609605312347412

training epoch 291 / 500, batch #400 / 625
Loss:	1.9344220161437988

training epoch 291 / 500, batch #425 / 625
Loss:	1.616847276687622

training epoch 291 / 500, batch #450 / 625
Loss:	1.793265461921692

training epoch 291 / 500, batch #475 / 625
Loss:	1.9950246810913086

training epoch 291 / 500, batch #500 / 625
Loss:	1.6183500289916992

training epoch 291 / 500, batch #525 / 625
Loss:	1.591544508934021

training epoch 291 / 500, batch #550 / 625
Loss:	1.6327358484268188

training epoch 291 / 500, batch #575 / 625
Loss:	1.8637632131576538

training epoch 291 / 500, batch #600 / 625
Loss:	1.9558109045028687

training epoch 292 / 500, batch #0 / 625
Loss:	1.626409888267517

training epoch 292 / 500, batch #25 / 625
Loss:	1.5659910440444946

training epoch 292 / 500, batch #50 / 625
Loss:	1.5729016065597534

training epoch 292 / 500, batch #75 / 625
Loss:	1.5033544301986694

training epoch 292 / 500, batch #100 / 625
Loss:	1.4736448526382446

training epoch 292 / 500, batch #125 / 625
Loss:	1.8679907321929932

training epoch 292 / 500, batch #150 / 625
Loss:	1.687266230583191

training epoch 292 / 500, batch #175 / 625
Loss:	1.8651530742645264

training epoch 292 / 500, batch #200 / 625
Loss:	1.7317463159561157

training epoch 292 / 500, batch #225 / 625
Loss:	1.7086186408996582

training epoch 292 / 500, batch #250 / 625
Loss:	1.7695401906967163

training epoch 292 / 500, batch #275 / 625
Loss:	1.7273924350738525

training epoch 292 / 500, batch #300 / 625
Loss:	2.079620599746704

training epoch 292 / 500, batch #325 / 625
Loss:	1.6345335245132446

training epoch 292 / 500, batch #350 / 625
Loss:	1.7828049659729004

training epoch 292 / 500, batch #375 / 625
Loss:	1.9313715696334839

training epoch 292 / 500, batch #400 / 625
Loss:	1.6712887287139893

training epoch 292 / 500, batch #425 / 625
Loss:	1.7907819747924805

training epoch 292 / 500, batch #450 / 625
Loss:	1.735095739364624

training epoch 292 / 500, batch #475 / 625
Loss:	1.8652591705322266

training epoch 292 / 500, batch #500 / 625
Loss:	1.9988491535186768

training epoch 292 / 500, batch #525 / 625
Loss:	1.7841718196868896

training epoch 292 / 500, batch #550 / 625
Loss:	1.608773946762085

training epoch 292 / 500, batch #575 / 625
Loss:	1.632930874824524

training epoch 292 / 500, batch #600 / 625
Loss:	1.9330551624298096

training epoch 293 / 500, batch #0 / 625
Loss:	1.7761306762695312

training epoch 293 / 500, batch #25 / 625
Loss:	1.6075029373168945

training epoch 293 / 500, batch #50 / 625
Loss:	1.5875641107559204

training epoch 293 / 500, batch #75 / 625
Loss:	1.7587776184082031

training epoch 293 / 500, batch #100 / 625
Loss:	1.7095112800598145

training epoch 293 / 500, batch #125 / 625
Loss:	1.7848520278930664

training epoch 293 / 500, batch #150 / 625
Loss:	1.9151976108551025

training epoch 293 / 500, batch #175 / 625
Loss:	1.7647491693496704

training epoch 293 / 500, batch #200 / 625
Loss:	1.9173870086669922

training epoch 293 / 500, batch #225 / 625
Loss:	1.624582052230835

training epoch 293 / 500, batch #250 / 625
Loss:	1.7713282108306885

training epoch 293 / 500, batch #275 / 625
Loss:	1.5893644094467163

training epoch 293 / 500, batch #300 / 625
Loss:	1.7167141437530518

training epoch 293 / 500, batch #325 / 625
Loss:	1.6696574687957764

training epoch 293 / 500, batch #350 / 625
Loss:	2.047234296798706

training epoch 293 / 500, batch #375 / 625
Loss:	1.9239625930786133

training epoch 293 / 500, batch #400 / 625
Loss:	1.7321144342422485

training epoch 293 / 500, batch #425 / 625
Loss:	1.624290943145752

training epoch 293 / 500, batch #450 / 625
Loss:	1.501792550086975

training epoch 293 / 500, batch #475 / 625
Loss:	1.689700961112976

training epoch 293 / 500, batch #500 / 625
Loss:	1.6503338813781738

training epoch 293 / 500, batch #525 / 625
Loss:	1.6143622398376465

training epoch 293 / 500, batch #550 / 625
Loss:	1.6908456087112427

training epoch 293 / 500, batch #575 / 625
Loss:	1.8111212253570557

training epoch 293 / 500, batch #600 / 625
Loss:	1.766469955444336

training epoch 294 / 500, batch #0 / 625
Loss:	1.5955278873443604

training epoch 294 / 500, batch #25 / 625
Loss:	1.7634592056274414

training epoch 294 / 500, batch #50 / 625
Loss:	1.5964685678482056

training epoch 294 / 500, batch #75 / 625
Loss:	1.9390497207641602

training epoch 294 / 500, batch #100 / 625
Loss:	1.6173362731933594

training epoch 294 / 500, batch #125 / 625
Loss:	1.8484348058700562

training epoch 294 / 500, batch #150 / 625
Loss:	1.624816656112671

training epoch 294 / 500, batch #175 / 625
Loss:	1.497200846672058

training epoch 294 / 500, batch #200 / 625
Loss:	1.642977237701416

training epoch 294 / 500, batch #225 / 625
Loss:	1.660656452178955

training epoch 294 / 500, batch #250 / 625
Loss:	1.9079480171203613

training epoch 294 / 500, batch #275 / 625
Loss:	1.618896484375

training epoch 294 / 500, batch #300 / 625
Loss:	1.729753017425537

training epoch 294 / 500, batch #325 / 625
Loss:	1.8060706853866577

training epoch 294 / 500, batch #350 / 625
Loss:	1.7903857231140137

training epoch 294 / 500, batch #375 / 625
Loss:	1.5441834926605225

training epoch 294 / 500, batch #400 / 625
Loss:	1.747873306274414

training epoch 294 / 500, batch #425 / 625
Loss:	1.6906278133392334

training epoch 294 / 500, batch #450 / 625
Loss:	1.7019728422164917

training epoch 294 / 500, batch #475 / 625
Loss:	1.8171846866607666

training epoch 294 / 500, batch #500 / 625
Loss:	1.8187164068222046

training epoch 294 / 500, batch #525 / 625
Loss:	1.8217576742172241

training epoch 294 / 500, batch #550 / 625
Loss:	1.6869993209838867

training epoch 294 / 500, batch #575 / 625
Loss:	1.651661992073059

training epoch 294 / 500, batch #600 / 625
Loss:	1.6541306972503662

training epoch 295 / 500, batch #0 / 625
Loss:	1.781821370124817

training epoch 295 / 500, batch #25 / 625
Loss:	1.6964834928512573

training epoch 295 / 500, batch #50 / 625
Loss:	1.5429493188858032

training epoch 295 / 500, batch #75 / 625
Loss:	1.6592106819152832

training epoch 295 / 500, batch #100 / 625
Loss:	1.8814029693603516

training epoch 295 / 500, batch #125 / 625
Loss:	1.454901099205017

training epoch 295 / 500, batch #150 / 625
Loss:	1.7205419540405273

training epoch 295 / 500, batch #175 / 625
Loss:	1.733443260192871

training epoch 295 / 500, batch #200 / 625
Loss:	1.5087997913360596

training epoch 295 / 500, batch #225 / 625
Loss:	1.7255544662475586

training epoch 295 / 500, batch #250 / 625
Loss:	1.7976324558258057

training epoch 295 / 500, batch #275 / 625
Loss:	1.8597168922424316

training epoch 295 / 500, batch #300 / 625
Loss:	1.769361138343811

training epoch 295 / 500, batch #325 / 625
Loss:	1.596218228340149

training epoch 295 / 500, batch #350 / 625
Loss:	1.7914986610412598

training epoch 295 / 500, batch #375 / 625
Loss:	1.6857202053070068

training epoch 295 / 500, batch #400 / 625
Loss:	1.6007177829742432

training epoch 295 / 500, batch #425 / 625
Loss:	1.866706132888794

training epoch 295 / 500, batch #450 / 625
Loss:	1.5627449750900269

training epoch 295 / 500, batch #475 / 625
Loss:	2.1314895153045654

training epoch 295 / 500, batch #500 / 625
Loss:	1.6630167961120605

training epoch 295 / 500, batch #525 / 625
Loss:	1.776442289352417

training epoch 295 / 500, batch #550 / 625
Loss:	1.9603406190872192

training epoch 295 / 500, batch #575 / 625
Loss:	1.6256823539733887

training epoch 295 / 500, batch #600 / 625
Loss:	1.7629668712615967

training epoch 296 / 500, batch #0 / 625
Loss:	1.9040700197219849

training epoch 296 / 500, batch #25 / 625
Loss:	1.8213269710540771

training epoch 296 / 500, batch #50 / 625
Loss:	1.9105416536331177

training epoch 296 / 500, batch #75 / 625
Loss:	1.4628639221191406

training epoch 296 / 500, batch #100 / 625
Loss:	1.7948328256607056

training epoch 296 / 500, batch #125 / 625
Loss:	1.8749616146087646

training epoch 296 / 500, batch #150 / 625
Loss:	1.6100800037384033

training epoch 296 / 500, batch #175 / 625
Loss:	1.60606849193573

training epoch 296 / 500, batch #200 / 625
Loss:	1.7697138786315918

training epoch 296 / 500, batch #225 / 625
Loss:	1.7740552425384521

training epoch 296 / 500, batch #250 / 625
Loss:	1.5860822200775146

training epoch 296 / 500, batch #275 / 625
Loss:	1.583347201347351

training epoch 296 / 500, batch #300 / 625
Loss:	1.7125372886657715

training epoch 296 / 500, batch #325 / 625
Loss:	1.6378216743469238

training epoch 296 / 500, batch #350 / 625
Loss:	1.303541898727417

training epoch 296 / 500, batch #375 / 625
Loss:	1.967965841293335

training epoch 296 / 500, batch #400 / 625
Loss:	1.575750708580017

training epoch 296 / 500, batch #425 / 625
Loss:	1.6975603103637695

training epoch 296 / 500, batch #450 / 625
Loss:	1.6847748756408691

training epoch 296 / 500, batch #475 / 625
Loss:	1.7466256618499756

training epoch 296 / 500, batch #500 / 625
Loss:	1.915442705154419

training epoch 296 / 500, batch #525 / 625
Loss:	1.8307721614837646

training epoch 296 / 500, batch #550 / 625
Loss:	1.6766265630722046

training epoch 296 / 500, batch #575 / 625
Loss:	1.6808946132659912

training epoch 296 / 500, batch #600 / 625
Loss:	1.8213815689086914

training epoch 297 / 500, batch #0 / 625
Loss:	1.738342046737671

training epoch 297 / 500, batch #25 / 625
Loss:	1.9543346166610718

training epoch 297 / 500, batch #50 / 625
Loss:	1.6863218545913696

training epoch 297 / 500, batch #75 / 625
Loss:	1.7803453207015991

training epoch 297 / 500, batch #100 / 625
Loss:	1.8359012603759766

training epoch 297 / 500, batch #125 / 625
Loss:	1.920831561088562

training epoch 297 / 500, batch #150 / 625
Loss:	1.5688546895980835

training epoch 297 / 500, batch #175 / 625
Loss:	1.8470582962036133

training epoch 297 / 500, batch #200 / 625
Loss:	1.558953046798706

training epoch 297 / 500, batch #225 / 625
Loss:	1.4320147037506104

training epoch 297 / 500, batch #250 / 625
Loss:	1.505522608757019

training epoch 297 / 500, batch #275 / 625
Loss:	1.5845750570297241

training epoch 297 / 500, batch #300 / 625
Loss:	1.9043657779693604

training epoch 297 / 500, batch #325 / 625
Loss:	1.7547835111618042

training epoch 297 / 500, batch #350 / 625
Loss:	1.7956104278564453

training epoch 297 / 500, batch #375 / 625
Loss:	1.8764245510101318

training epoch 297 / 500, batch #400 / 625
Loss:	1.7133342027664185

training epoch 297 / 500, batch #425 / 625
Loss:	1.366478443145752

training epoch 297 / 500, batch #450 / 625
Loss:	1.6021727323532104

training epoch 297 / 500, batch #475 / 625
Loss:	1.8401004076004028

training epoch 297 / 500, batch #500 / 625
Loss:	1.4835560321807861

training epoch 297 / 500, batch #525 / 625
Loss:	1.831091284751892

training epoch 297 / 500, batch #550 / 625
Loss:	1.5581568479537964

training epoch 297 / 500, batch #575 / 625
Loss:	1.6813910007476807

training epoch 297 / 500, batch #600 / 625
Loss:	1.7737162113189697

training epoch 298 / 500, batch #0 / 625
Loss:	1.7124744653701782

training epoch 298 / 500, batch #25 / 625
Loss:	1.7417064905166626

training epoch 298 / 500, batch #50 / 625
Loss:	1.5169706344604492

training epoch 298 / 500, batch #75 / 625
Loss:	1.580952763557434

training epoch 298 / 500, batch #100 / 625
Loss:	1.776222586631775

training epoch 298 / 500, batch #125 / 625
Loss:	1.6538316011428833

training epoch 298 / 500, batch #150 / 625
Loss:	2.032244920730591

training epoch 298 / 500, batch #175 / 625
Loss:	1.5842523574829102

training epoch 298 / 500, batch #200 / 625
Loss:	1.395890712738037

training epoch 298 / 500, batch #225 / 625
Loss:	1.8236552476882935

training epoch 298 / 500, batch #250 / 625
Loss:	1.9249402284622192

training epoch 298 / 500, batch #275 / 625
Loss:	1.759065866470337

training epoch 298 / 500, batch #300 / 625
Loss:	1.6000688076019287

training epoch 298 / 500, batch #325 / 625
Loss:	1.772260069847107

training epoch 298 / 500, batch #350 / 625
Loss:	1.7377889156341553

training epoch 298 / 500, batch #375 / 625
Loss:	1.480409860610962

training epoch 298 / 500, batch #400 / 625
Loss:	1.7022234201431274

training epoch 298 / 500, batch #425 / 625
Loss:	1.3069992065429688

training epoch 298 / 500, batch #450 / 625
Loss:	1.9429922103881836

training epoch 298 / 500, batch #475 / 625
Loss:	1.8257801532745361

training epoch 298 / 500, batch #500 / 625
Loss:	1.6543464660644531

training epoch 298 / 500, batch #525 / 625
Loss:	1.6256256103515625

training epoch 298 / 500, batch #550 / 625
Loss:	1.6020700931549072

training epoch 298 / 500, batch #575 / 625
Loss:	1.6467148065567017

training epoch 298 / 500, batch #600 / 625
Loss:	1.6168402433395386

training epoch 299 / 500, batch #0 / 625
Loss:	1.4948463439941406

training epoch 299 / 500, batch #25 / 625
Loss:	1.7374261617660522

training epoch 299 / 500, batch #50 / 625
Loss:	1.6556203365325928

training epoch 299 / 500, batch #75 / 625
Loss:	1.504533290863037

training epoch 299 / 500, batch #100 / 625
Loss:	1.6238884925842285

training epoch 299 / 500, batch #125 / 625
Loss:	1.872093915939331

training epoch 299 / 500, batch #150 / 625
Loss:	1.6872797012329102

training epoch 299 / 500, batch #175 / 625
Loss:	1.4974806308746338

training epoch 299 / 500, batch #200 / 625
Loss:	1.7077566385269165

training epoch 299 / 500, batch #225 / 625
Loss:	1.653881311416626

training epoch 299 / 500, batch #250 / 625
Loss:	1.7880812883377075

training epoch 299 / 500, batch #275 / 625
Loss:	1.5156123638153076

training epoch 299 / 500, batch #300 / 625
Loss:	1.5089777708053589

training epoch 299 / 500, batch #325 / 625
Loss:	1.7243168354034424

training epoch 299 / 500, batch #350 / 625
Loss:	1.6029173135757446

training epoch 299 / 500, batch #375 / 625
Loss:	1.697501540184021

training epoch 299 / 500, batch #400 / 625
Loss:	1.481942057609558

training epoch 299 / 500, batch #425 / 625
Loss:	1.910642147064209

training epoch 299 / 500, batch #450 / 625
Loss:	1.5991802215576172

training epoch 299 / 500, batch #475 / 625
Loss:	1.6874324083328247

training epoch 299 / 500, batch #500 / 625
Loss:	1.856560468673706

training epoch 299 / 500, batch #525 / 625
Loss:	2.1036834716796875

training epoch 299 / 500, batch #550 / 625
Loss:	1.5517916679382324

training epoch 299 / 500, batch #575 / 625
Loss:	1.5683917999267578

training epoch 299 / 500, batch #600 / 625
Loss:	1.6252797842025757

training epoch 300 / 500, batch #0 / 625
Loss:	1.8077605962753296

training epoch 300 / 500, batch #25 / 625
Loss:	1.6495060920715332

training epoch 300 / 500, batch #50 / 625
Loss:	1.544620394706726

training epoch 300 / 500, batch #75 / 625
Loss:	1.596835732460022

training epoch 300 / 500, batch #100 / 625
Loss:	1.8392362594604492

training epoch 300 / 500, batch #125 / 625
Loss:	1.773544192314148

training epoch 300 / 500, batch #150 / 625
Loss:	1.651932716369629

training epoch 300 / 500, batch #175 / 625
Loss:	1.8843414783477783

training epoch 300 / 500, batch #200 / 625
Loss:	1.641641616821289

training epoch 300 / 500, batch #225 / 625
Loss:	1.7217997312545776

training epoch 300 / 500, batch #250 / 625
Loss:	1.630043625831604

training epoch 300 / 500, batch #275 / 625
Loss:	1.7107387781143188

training epoch 300 / 500, batch #300 / 625
Loss:	1.479251742362976

training epoch 300 / 500, batch #325 / 625
Loss:	1.5231552124023438

training epoch 300 / 500, batch #350 / 625
Loss:	1.8035067319869995

training epoch 300 / 500, batch #375 / 625
Loss:	1.6198126077651978

training epoch 300 / 500, batch #400 / 625
Loss:	1.491066575050354

training epoch 300 / 500, batch #425 / 625
Loss:	1.572465181350708

training epoch 300 / 500, batch #450 / 625
Loss:	1.82783842086792

training epoch 300 / 500, batch #475 / 625
Loss:	1.7763123512268066

training epoch 300 / 500, batch #500 / 625
Loss:	1.6655150651931763

training epoch 300 / 500, batch #525 / 625
Loss:	1.7596179246902466

training epoch 300 / 500, batch #550 / 625
Loss:	1.729927659034729

training epoch 300 / 500, batch #575 / 625
Loss:	1.8843600749969482

training epoch 300 / 500, batch #600 / 625
Loss:	1.6190770864486694

training epoch 301 / 500, batch #0 / 625
Loss:	1.5272619724273682

training epoch 301 / 500, batch #25 / 625
Loss:	1.6845135688781738

training epoch 301 / 500, batch #50 / 625
Loss:	1.741422176361084

training epoch 301 / 500, batch #75 / 625
Loss:	1.797793984413147

training epoch 301 / 500, batch #100 / 625
Loss:	1.6330024003982544

training epoch 301 / 500, batch #125 / 625
Loss:	1.6284462213516235

training epoch 301 / 500, batch #150 / 625
Loss:	1.6275827884674072

training epoch 301 / 500, batch #175 / 625
Loss:	1.9325963258743286

training epoch 301 / 500, batch #200 / 625
Loss:	1.5664552450180054

training epoch 301 / 500, batch #225 / 625
Loss:	1.6097503900527954

training epoch 301 / 500, batch #250 / 625
Loss:	1.9290627241134644

training epoch 301 / 500, batch #275 / 625
Loss:	1.6271637678146362

training epoch 301 / 500, batch #300 / 625
Loss:	1.7101188898086548

training epoch 301 / 500, batch #325 / 625
Loss:	1.8808449506759644

training epoch 301 / 500, batch #350 / 625
Loss:	1.5571990013122559

training epoch 301 / 500, batch #375 / 625
Loss:	1.6319776773452759

training epoch 301 / 500, batch #400 / 625
Loss:	1.7037783861160278

training epoch 301 / 500, batch #425 / 625
Loss:	1.7034969329833984

training epoch 301 / 500, batch #450 / 625
Loss:	1.9290320873260498

training epoch 301 / 500, batch #475 / 625
Loss:	1.645856261253357

training epoch 301 / 500, batch #500 / 625
Loss:	1.452130913734436

training epoch 301 / 500, batch #525 / 625
Loss:	1.8611235618591309

training epoch 301 / 500, batch #550 / 625
Loss:	1.3594473600387573

training epoch 301 / 500, batch #575 / 625
Loss:	1.7539677619934082

training epoch 301 / 500, batch #600 / 625
Loss:	1.8406291007995605

training epoch 302 / 500, batch #0 / 625
Loss:	1.5663166046142578

training epoch 302 / 500, batch #25 / 625
Loss:	1.7118198871612549

training epoch 302 / 500, batch #50 / 625
Loss:	1.5657777786254883

training epoch 302 / 500, batch #75 / 625
Loss:	2.1451942920684814

training epoch 302 / 500, batch #100 / 625
Loss:	1.8104779720306396

training epoch 302 / 500, batch #125 / 625
Loss:	1.8977469205856323

training epoch 302 / 500, batch #150 / 625
Loss:	2.058394193649292

training epoch 302 / 500, batch #175 / 625
Loss:	1.8382718563079834

training epoch 302 / 500, batch #200 / 625
Loss:	1.7306976318359375

training epoch 302 / 500, batch #225 / 625
Loss:	1.7765159606933594

training epoch 302 / 500, batch #250 / 625
Loss:	2.0070242881774902

training epoch 302 / 500, batch #275 / 625
Loss:	1.6709991693496704

training epoch 302 / 500, batch #300 / 625
Loss:	1.6217424869537354

training epoch 302 / 500, batch #325 / 625
Loss:	1.6237303018569946

training epoch 302 / 500, batch #350 / 625
Loss:	1.7240519523620605

training epoch 302 / 500, batch #375 / 625
Loss:	1.8412810564041138

training epoch 302 / 500, batch #400 / 625
Loss:	2.0286567211151123

training epoch 302 / 500, batch #425 / 625
Loss:	1.6469833850860596

training epoch 302 / 500, batch #450 / 625
Loss:	1.5713810920715332

training epoch 302 / 500, batch #475 / 625
Loss:	1.7217828035354614

training epoch 302 / 500, batch #500 / 625
Loss:	1.7744015455245972

training epoch 302 / 500, batch #525 / 625
Loss:	1.8825278282165527

training epoch 302 / 500, batch #550 / 625
Loss:	2.0329644680023193

training epoch 302 / 500, batch #575 / 625
Loss:	1.7779821157455444

training epoch 302 / 500, batch #600 / 625
Loss:	1.5835562944412231

training epoch 303 / 500, batch #0 / 625
Loss:	1.782842993736267

training epoch 303 / 500, batch #25 / 625
Loss:	1.6147139072418213

training epoch 303 / 500, batch #50 / 625
Loss:	1.5587135553359985

training epoch 303 / 500, batch #75 / 625
Loss:	1.9139214754104614

training epoch 303 / 500, batch #100 / 625
Loss:	1.5349191427230835

training epoch 303 / 500, batch #125 / 625
Loss:	1.7646183967590332

training epoch 303 / 500, batch #150 / 625
Loss:	1.7537342309951782

training epoch 303 / 500, batch #175 / 625
Loss:	1.8492275476455688

training epoch 303 / 500, batch #200 / 625
Loss:	1.9449907541275024

training epoch 303 / 500, batch #225 / 625
Loss:	1.7381623983383179

training epoch 303 / 500, batch #250 / 625
Loss:	1.7220697402954102

training epoch 303 / 500, batch #275 / 625
Loss:	1.800478219985962

training epoch 303 / 500, batch #300 / 625
Loss:	1.735549807548523

training epoch 303 / 500, batch #325 / 625
Loss:	1.7170153856277466

training epoch 303 / 500, batch #350 / 625
Loss:	1.6620423793792725

training epoch 303 / 500, batch #375 / 625
Loss:	1.645190954208374

training epoch 303 / 500, batch #400 / 625
Loss:	2.05964732170105

training epoch 303 / 500, batch #425 / 625
Loss:	1.853111982345581

training epoch 303 / 500, batch #450 / 625
Loss:	1.7015457153320312

training epoch 303 / 500, batch #475 / 625
Loss:	1.5778679847717285

training epoch 303 / 500, batch #500 / 625
Loss:	1.4716172218322754

training epoch 303 / 500, batch #525 / 625
Loss:	1.8394882678985596

training epoch 303 / 500, batch #550 / 625
Loss:	1.7656793594360352

training epoch 303 / 500, batch #575 / 625
Loss:	1.7153781652450562

training epoch 303 / 500, batch #600 / 625
Loss:	1.7678395509719849

training epoch 304 / 500, batch #0 / 625
Loss:	1.5773571729660034

training epoch 304 / 500, batch #25 / 625
Loss:	1.6714056730270386

training epoch 304 / 500, batch #50 / 625
Loss:	1.6565321683883667

training epoch 304 / 500, batch #75 / 625
Loss:	1.8068219423294067

training epoch 304 / 500, batch #100 / 625
Loss:	1.5411021709442139

training epoch 304 / 500, batch #125 / 625
Loss:	1.8521976470947266

training epoch 304 / 500, batch #150 / 625
Loss:	1.776206612586975

training epoch 304 / 500, batch #175 / 625
Loss:	1.7120935916900635

training epoch 304 / 500, batch #200 / 625
Loss:	1.712502121925354

training epoch 304 / 500, batch #225 / 625
Loss:	1.7751487493515015

training epoch 304 / 500, batch #250 / 625
Loss:	1.797347068786621

training epoch 304 / 500, batch #275 / 625
Loss:	2.1424646377563477

training epoch 304 / 500, batch #300 / 625
Loss:	1.6635938882827759

training epoch 304 / 500, batch #325 / 625
Loss:	1.9114099740982056

training epoch 304 / 500, batch #350 / 625
Loss:	1.7910529375076294

training epoch 304 / 500, batch #375 / 625
Loss:	1.677821397781372

training epoch 304 / 500, batch #400 / 625
Loss:	1.773835301399231

training epoch 304 / 500, batch #425 / 625
Loss:	1.5667564868927002

training epoch 304 / 500, batch #450 / 625
Loss:	1.7232654094696045

training epoch 304 / 500, batch #475 / 625
Loss:	1.8858308792114258

training epoch 304 / 500, batch #500 / 625
Loss:	1.8442591428756714

training epoch 304 / 500, batch #525 / 625
Loss:	1.6937471628189087

training epoch 304 / 500, batch #550 / 625
Loss:	1.7904584407806396

training epoch 304 / 500, batch #575 / 625
Loss:	1.6924761533737183

training epoch 304 / 500, batch #600 / 625
Loss:	1.5890839099884033

training epoch 305 / 500, batch #0 / 625
Loss:	1.9154958724975586

training epoch 305 / 500, batch #25 / 625
Loss:	1.7683141231536865

training epoch 305 / 500, batch #50 / 625
Loss:	1.582510232925415

training epoch 305 / 500, batch #75 / 625
Loss:	1.8432613611221313

training epoch 305 / 500, batch #100 / 625
Loss:	1.7591440677642822

training epoch 305 / 500, batch #125 / 625
Loss:	1.857946515083313

training epoch 305 / 500, batch #150 / 625
Loss:	1.8560758829116821

training epoch 305 / 500, batch #175 / 625
Loss:	1.711647868156433

training epoch 305 / 500, batch #200 / 625
Loss:	1.8360222578048706

training epoch 305 / 500, batch #225 / 625
Loss:	1.7402716875076294

training epoch 305 / 500, batch #250 / 625
Loss:	1.825836420059204

training epoch 305 / 500, batch #275 / 625
Loss:	1.5886586904525757

training epoch 305 / 500, batch #300 / 625
Loss:	1.8982120752334595

training epoch 305 / 500, batch #325 / 625
Loss:	1.6480554342269897

training epoch 305 / 500, batch #350 / 625
Loss:	1.7228721380233765

training epoch 305 / 500, batch #375 / 625
Loss:	1.4854176044464111

training epoch 305 / 500, batch #400 / 625
Loss:	1.706687092781067

training epoch 305 / 500, batch #425 / 625
Loss:	1.8382595777511597

training epoch 305 / 500, batch #450 / 625
Loss:	1.3344403505325317

training epoch 305 / 500, batch #475 / 625
Loss:	1.9072362184524536

training epoch 305 / 500, batch #500 / 625
Loss:	1.9861433506011963

training epoch 305 / 500, batch #525 / 625
Loss:	1.834833025932312

training epoch 305 / 500, batch #550 / 625
Loss:	1.8186542987823486

training epoch 305 / 500, batch #575 / 625
Loss:	1.7417739629745483

training epoch 305 / 500, batch #600 / 625
Loss:	1.7099123001098633

training epoch 306 / 500, batch #0 / 625
Loss:	1.751997709274292

training epoch 306 / 500, batch #25 / 625
Loss:	1.8534587621688843

training epoch 306 / 500, batch #50 / 625
Loss:	1.7424026727676392

training epoch 306 / 500, batch #75 / 625
Loss:	1.7141965627670288

training epoch 306 / 500, batch #100 / 625
Loss:	1.466821312904358

training epoch 306 / 500, batch #125 / 625
Loss:	1.8805046081542969

training epoch 306 / 500, batch #150 / 625
Loss:	1.7921749353408813

training epoch 306 / 500, batch #175 / 625
Loss:	1.7625300884246826

training epoch 306 / 500, batch #200 / 625
Loss:	1.7407960891723633

training epoch 306 / 500, batch #225 / 625
Loss:	1.6939777135849

training epoch 306 / 500, batch #250 / 625
Loss:	1.9245423078536987

training epoch 306 / 500, batch #275 / 625
Loss:	1.7243142127990723

training epoch 306 / 500, batch #300 / 625
Loss:	1.5552185773849487

training epoch 306 / 500, batch #325 / 625
Loss:	1.6918869018554688

training epoch 306 / 500, batch #350 / 625
Loss:	1.833035945892334

training epoch 306 / 500, batch #375 / 625
Loss:	2.062455892562866

training epoch 306 / 500, batch #400 / 625
Loss:	1.673242211341858

training epoch 306 / 500, batch #425 / 625
Loss:	1.9306720495224

training epoch 306 / 500, batch #450 / 625
Loss:	1.7645094394683838

training epoch 306 / 500, batch #475 / 625
Loss:	1.8962880373001099

training epoch 306 / 500, batch #500 / 625
Loss:	1.6703091859817505

training epoch 306 / 500, batch #525 / 625
Loss:	2.0091683864593506

training epoch 306 / 500, batch #550 / 625
Loss:	1.678845763206482

training epoch 306 / 500, batch #575 / 625
Loss:	1.8267498016357422

training epoch 306 / 500, batch #600 / 625
Loss:	1.7634776830673218

training epoch 307 / 500, batch #0 / 625
Loss:	1.4830938577651978

training epoch 307 / 500, batch #25 / 625
Loss:	1.655276894569397

training epoch 307 / 500, batch #50 / 625
Loss:	1.6811795234680176

training epoch 307 / 500, batch #75 / 625
Loss:	1.7622439861297607

training epoch 307 / 500, batch #100 / 625
Loss:	1.8011269569396973

training epoch 307 / 500, batch #125 / 625
Loss:	1.782523512840271

training epoch 307 / 500, batch #150 / 625
Loss:	1.7590305805206299

training epoch 307 / 500, batch #175 / 625
Loss:	1.6801068782806396

training epoch 307 / 500, batch #200 / 625
Loss:	1.8455532789230347

training epoch 307 / 500, batch #225 / 625
Loss:	1.6726676225662231

training epoch 307 / 500, batch #250 / 625
Loss:	1.642510175704956

training epoch 307 / 500, batch #275 / 625
Loss:	1.5444557666778564

training epoch 307 / 500, batch #300 / 625
Loss:	1.887585997581482

training epoch 307 / 500, batch #325 / 625
Loss:	1.4053959846496582

training epoch 307 / 500, batch #350 / 625
Loss:	1.6406244039535522

training epoch 307 / 500, batch #375 / 625
Loss:	1.792616844177246

training epoch 307 / 500, batch #400 / 625
Loss:	1.8924322128295898

training epoch 307 / 500, batch #425 / 625
Loss:	1.8856501579284668

training epoch 307 / 500, batch #450 / 625
Loss:	1.6461963653564453

training epoch 307 / 500, batch #475 / 625
Loss:	1.635364055633545

training epoch 307 / 500, batch #500 / 625
Loss:	1.4480993747711182

training epoch 307 / 500, batch #525 / 625
Loss:	1.9092779159545898

training epoch 307 / 500, batch #550 / 625
Loss:	1.7454843521118164

training epoch 307 / 500, batch #575 / 625
Loss:	1.3812233209609985

training epoch 307 / 500, batch #600 / 625
Loss:	1.775771141052246

training epoch 308 / 500, batch #0 / 625
Loss:	1.6639186143875122

training epoch 308 / 500, batch #25 / 625
Loss:	1.762047529220581

training epoch 308 / 500, batch #50 / 625
Loss:	1.4860683679580688

training epoch 308 / 500, batch #75 / 625
Loss:	1.529780387878418

training epoch 308 / 500, batch #100 / 625
Loss:	1.7210824489593506

training epoch 308 / 500, batch #125 / 625
Loss:	1.7318247556686401

training epoch 308 / 500, batch #150 / 625
Loss:	1.5521070957183838

training epoch 308 / 500, batch #175 / 625
Loss:	1.6801769733428955

training epoch 308 / 500, batch #200 / 625
Loss:	1.7212166786193848

training epoch 308 / 500, batch #225 / 625
Loss:	1.6811037063598633

training epoch 308 / 500, batch #250 / 625
Loss:	1.6408084630966187

training epoch 308 / 500, batch #275 / 625
Loss:	1.6997092962265015

training epoch 308 / 500, batch #300 / 625
Loss:	1.5958176851272583

training epoch 308 / 500, batch #325 / 625
Loss:	1.7704366445541382

training epoch 308 / 500, batch #350 / 625
Loss:	1.9213131666183472

training epoch 308 / 500, batch #375 / 625
Loss:	1.828582525253296

training epoch 308 / 500, batch #400 / 625
Loss:	1.5937553644180298

training epoch 308 / 500, batch #425 / 625
Loss:	1.7490817308425903

training epoch 308 / 500, batch #450 / 625
Loss:	1.6550745964050293

training epoch 308 / 500, batch #475 / 625
Loss:	2.001668691635132

training epoch 308 / 500, batch #500 / 625
Loss:	1.9875125885009766

training epoch 308 / 500, batch #525 / 625
Loss:	1.5787359476089478

training epoch 308 / 500, batch #550 / 625
Loss:	1.6856555938720703

training epoch 308 / 500, batch #575 / 625
Loss:	1.4568136930465698

training epoch 308 / 500, batch #600 / 625
Loss:	1.6834698915481567

training epoch 309 / 500, batch #0 / 625
Loss:	1.7055120468139648

training epoch 309 / 500, batch #25 / 625
Loss:	1.7408896684646606

training epoch 309 / 500, batch #50 / 625
Loss:	1.741760492324829

training epoch 309 / 500, batch #75 / 625
Loss:	1.6683599948883057

training epoch 309 / 500, batch #100 / 625
Loss:	1.6502184867858887

training epoch 309 / 500, batch #125 / 625
Loss:	1.6801522970199585

training epoch 309 / 500, batch #150 / 625
Loss:	1.6504076719284058

training epoch 309 / 500, batch #175 / 625
Loss:	1.6872881650924683

training epoch 309 / 500, batch #200 / 625
Loss:	2.162450075149536

training epoch 309 / 500, batch #225 / 625
Loss:	1.8341072797775269

training epoch 309 / 500, batch #250 / 625
Loss:	1.709223747253418

training epoch 309 / 500, batch #275 / 625
Loss:	1.7682431936264038

training epoch 309 / 500, batch #300 / 625
Loss:	1.5807826519012451

training epoch 309 / 500, batch #325 / 625
Loss:	1.5555499792099

training epoch 309 / 500, batch #350 / 625
Loss:	1.9095622301101685

training epoch 309 / 500, batch #375 / 625
Loss:	1.7254260778427124

training epoch 309 / 500, batch #400 / 625
Loss:	1.866716980934143

training epoch 309 / 500, batch #425 / 625
Loss:	1.8051203489303589

training epoch 309 / 500, batch #450 / 625
Loss:	2.013230562210083

training epoch 309 / 500, batch #475 / 625
Loss:	1.5619852542877197

training epoch 309 / 500, batch #500 / 625
Loss:	1.670218825340271

training epoch 309 / 500, batch #525 / 625
Loss:	1.9059256315231323

training epoch 309 / 500, batch #550 / 625
Loss:	1.8494993448257446

training epoch 309 / 500, batch #575 / 625
Loss:	1.6498883962631226

training epoch 309 / 500, batch #600 / 625
Loss:	1.6531950235366821

training epoch 310 / 500, batch #0 / 625
Loss:	1.6495286226272583

training epoch 310 / 500, batch #25 / 625
Loss:	1.6766417026519775

training epoch 310 / 500, batch #50 / 625
Loss:	1.8301115036010742

training epoch 310 / 500, batch #75 / 625
Loss:	1.6517425775527954

training epoch 310 / 500, batch #100 / 625
Loss:	1.6645452976226807

training epoch 310 / 500, batch #125 / 625
Loss:	1.3940225839614868

training epoch 310 / 500, batch #150 / 625
Loss:	1.5794888734817505

training epoch 310 / 500, batch #175 / 625
Loss:	1.6722464561462402

training epoch 310 / 500, batch #200 / 625
Loss:	1.6097214221954346

training epoch 310 / 500, batch #225 / 625
Loss:	1.9912829399108887

training epoch 310 / 500, batch #250 / 625
Loss:	1.8979367017745972

training epoch 310 / 500, batch #275 / 625
Loss:	1.8678351640701294

training epoch 310 / 500, batch #300 / 625
Loss:	1.5734935998916626

training epoch 310 / 500, batch #325 / 625
Loss:	1.7144067287445068

training epoch 310 / 500, batch #350 / 625
Loss:	1.788063883781433

training epoch 310 / 500, batch #375 / 625
Loss:	1.6566529273986816

training epoch 310 / 500, batch #400 / 625
Loss:	1.9009360074996948

training epoch 310 / 500, batch #425 / 625
Loss:	1.6492609977722168

training epoch 310 / 500, batch #450 / 625
Loss:	1.8127862215042114

training epoch 310 / 500, batch #475 / 625
Loss:	1.9659420251846313

training epoch 310 / 500, batch #500 / 625
Loss:	1.6202611923217773

training epoch 310 / 500, batch #525 / 625
Loss:	1.511365294456482

training epoch 310 / 500, batch #550 / 625
Loss:	1.3601993322372437

training epoch 310 / 500, batch #575 / 625
Loss:	1.9311513900756836

training epoch 310 / 500, batch #600 / 625
Loss:	1.8834643363952637

training epoch 311 / 500, batch #0 / 625
Loss:	1.6395952701568604

training epoch 311 / 500, batch #25 / 625
Loss:	1.9098315238952637

training epoch 311 / 500, batch #50 / 625
Loss:	1.4870096445083618

training epoch 311 / 500, batch #75 / 625
Loss:	1.690063238143921

training epoch 311 / 500, batch #100 / 625
Loss:	1.6181648969650269

training epoch 311 / 500, batch #125 / 625
Loss:	1.6795201301574707

training epoch 311 / 500, batch #150 / 625
Loss:	1.824938416481018

training epoch 311 / 500, batch #175 / 625
Loss:	1.5066200494766235

training epoch 311 / 500, batch #200 / 625
Loss:	1.942367672920227

training epoch 311 / 500, batch #225 / 625
Loss:	1.7008450031280518

training epoch 311 / 500, batch #250 / 625
Loss:	1.672475814819336

training epoch 311 / 500, batch #275 / 625
Loss:	1.8650637865066528

training epoch 311 / 500, batch #300 / 625
Loss:	1.812642216682434

training epoch 311 / 500, batch #325 / 625
Loss:	1.6792947053909302

training epoch 311 / 500, batch #350 / 625
Loss:	1.857506275177002

training epoch 311 / 500, batch #375 / 625
Loss:	1.7576881647109985

training epoch 311 / 500, batch #400 / 625
Loss:	1.6433632373809814

training epoch 311 / 500, batch #425 / 625
Loss:	1.6346057653427124

training epoch 311 / 500, batch #450 / 625
Loss:	1.773320198059082

training epoch 311 / 500, batch #475 / 625
Loss:	1.9333289861679077

training epoch 311 / 500, batch #500 / 625
Loss:	1.650160789489746

training epoch 311 / 500, batch #525 / 625
Loss:	1.5700551271438599

training epoch 311 / 500, batch #550 / 625
Loss:	1.6655604839324951

training epoch 311 / 500, batch #575 / 625
Loss:	1.66183602809906

training epoch 311 / 500, batch #600 / 625
Loss:	1.8469173908233643

training epoch 312 / 500, batch #0 / 625
Loss:	1.850669503211975

training epoch 312 / 500, batch #25 / 625
Loss:	1.6434204578399658

training epoch 312 / 500, batch #50 / 625
Loss:	1.6119149923324585

training epoch 312 / 500, batch #75 / 625
Loss:	1.4697304964065552

training epoch 312 / 500, batch #100 / 625
Loss:	1.6444025039672852

training epoch 312 / 500, batch #125 / 625
Loss:	1.7475119829177856

training epoch 312 / 500, batch #150 / 625
Loss:	1.6531867980957031

training epoch 312 / 500, batch #175 / 625
Loss:	1.7772265672683716

training epoch 312 / 500, batch #200 / 625
Loss:	1.7389698028564453

training epoch 312 / 500, batch #225 / 625
Loss:	1.6887390613555908

training epoch 312 / 500, batch #250 / 625
Loss:	1.5971488952636719

training epoch 312 / 500, batch #275 / 625
Loss:	1.6044442653656006

training epoch 312 / 500, batch #300 / 625
Loss:	1.6834778785705566

training epoch 312 / 500, batch #325 / 625
Loss:	1.8425490856170654

training epoch 312 / 500, batch #350 / 625
Loss:	1.8913038969039917

training epoch 312 / 500, batch #375 / 625
Loss:	1.7715568542480469

training epoch 312 / 500, batch #400 / 625
Loss:	1.795109510421753

training epoch 312 / 500, batch #425 / 625
Loss:	1.7302888631820679

training epoch 312 / 500, batch #450 / 625
Loss:	1.9634943008422852

training epoch 312 / 500, batch #475 / 625
Loss:	1.5740355253219604

training epoch 312 / 500, batch #500 / 625
Loss:	1.8031061887741089

training epoch 312 / 500, batch #525 / 625
Loss:	1.9064756631851196

training epoch 312 / 500, batch #550 / 625
Loss:	1.7123568058013916

training epoch 312 / 500, batch #575 / 625
Loss:	1.5308423042297363

training epoch 312 / 500, batch #600 / 625
Loss:	1.915055274963379

training epoch 313 / 500, batch #0 / 625
Loss:	1.7125215530395508

training epoch 313 / 500, batch #25 / 625
Loss:	1.5446481704711914

training epoch 313 / 500, batch #50 / 625
Loss:	1.6250708103179932

training epoch 313 / 500, batch #75 / 625
Loss:	1.6984692811965942

training epoch 313 / 500, batch #100 / 625
Loss:	1.9999310970306396

training epoch 313 / 500, batch #125 / 625
Loss:	1.9682387113571167

training epoch 313 / 500, batch #150 / 625
Loss:	1.7752883434295654

training epoch 313 / 500, batch #175 / 625
Loss:	1.6625510454177856

training epoch 313 / 500, batch #200 / 625
Loss:	1.6003546714782715

training epoch 313 / 500, batch #225 / 625
Loss:	1.6252987384796143

training epoch 313 / 500, batch #250 / 625
Loss:	1.8059977293014526

training epoch 313 / 500, batch #275 / 625
Loss:	1.8959161043167114

training epoch 313 / 500, batch #300 / 625
Loss:	1.7382563352584839

training epoch 313 / 500, batch #325 / 625
Loss:	1.7762964963912964

training epoch 313 / 500, batch #350 / 625
Loss:	1.724670171737671

training epoch 313 / 500, batch #375 / 625
Loss:	2.0084328651428223

training epoch 313 / 500, batch #400 / 625
Loss:	1.8506041765213013

training epoch 313 / 500, batch #425 / 625
Loss:	2.0370171070098877

training epoch 313 / 500, batch #450 / 625
Loss:	1.6155726909637451

training epoch 313 / 500, batch #475 / 625
Loss:	1.6704843044281006

training epoch 313 / 500, batch #500 / 625
Loss:	1.297265648841858

training epoch 313 / 500, batch #525 / 625
Loss:	1.7724720239639282

training epoch 313 / 500, batch #550 / 625
Loss:	1.3854806423187256

training epoch 313 / 500, batch #575 / 625
Loss:	1.7073043584823608

training epoch 313 / 500, batch #600 / 625
Loss:	1.6918715238571167

training epoch 314 / 500, batch #0 / 625
Loss:	1.935976505279541

training epoch 314 / 500, batch #25 / 625
Loss:	1.5162297487258911

training epoch 314 / 500, batch #50 / 625
Loss:	1.6505244970321655

training epoch 314 / 500, batch #75 / 625
Loss:	1.8390382528305054

training epoch 314 / 500, batch #100 / 625
Loss:	1.8453973531723022

training epoch 314 / 500, batch #125 / 625
Loss:	1.8465667963027954

training epoch 314 / 500, batch #150 / 625
Loss:	1.8427010774612427

training epoch 314 / 500, batch #175 / 625
Loss:	1.6939247846603394

training epoch 314 / 500, batch #200 / 625
Loss:	1.9468891620635986

training epoch 314 / 500, batch #225 / 625
Loss:	1.6619009971618652

training epoch 314 / 500, batch #250 / 625
Loss:	1.7233569622039795

training epoch 314 / 500, batch #275 / 625
Loss:	1.672062635421753

training epoch 314 / 500, batch #300 / 625
Loss:	1.8235576152801514

training epoch 314 / 500, batch #325 / 625
Loss:	1.5576175451278687

training epoch 314 / 500, batch #350 / 625
Loss:	1.7365697622299194

training epoch 314 / 500, batch #375 / 625
Loss:	1.6610260009765625

training epoch 314 / 500, batch #400 / 625
Loss:	1.6776982545852661

training epoch 314 / 500, batch #425 / 625
Loss:	1.7020825147628784

training epoch 314 / 500, batch #450 / 625
Loss:	1.5701823234558105

training epoch 314 / 500, batch #475 / 625
Loss:	1.9371135234832764

training epoch 314 / 500, batch #500 / 625
Loss:	1.6547592878341675

training epoch 314 / 500, batch #525 / 625
Loss:	1.70787513256073

training epoch 314 / 500, batch #550 / 625
Loss:	1.818466067314148

training epoch 314 / 500, batch #575 / 625
Loss:	1.7060885429382324

training epoch 314 / 500, batch #600 / 625
Loss:	1.587741732597351

training epoch 315 / 500, batch #0 / 625
Loss:	1.6242510080337524

training epoch 315 / 500, batch #25 / 625
Loss:	1.7934750318527222

training epoch 315 / 500, batch #50 / 625
Loss:	1.6900113821029663

training epoch 315 / 500, batch #75 / 625
Loss:	1.579177737236023

training epoch 315 / 500, batch #100 / 625
Loss:	1.6956830024719238

training epoch 315 / 500, batch #125 / 625
Loss:	1.7302876710891724

training epoch 315 / 500, batch #150 / 625
Loss:	1.5152618885040283

training epoch 315 / 500, batch #175 / 625
Loss:	1.5752092599868774

training epoch 315 / 500, batch #200 / 625
Loss:	1.8052308559417725

training epoch 315 / 500, batch #225 / 625
Loss:	1.892372965812683

training epoch 315 / 500, batch #250 / 625
Loss:	1.638974905014038

training epoch 315 / 500, batch #275 / 625
Loss:	1.546770453453064

training epoch 315 / 500, batch #300 / 625
Loss:	1.7522258758544922

training epoch 315 / 500, batch #325 / 625
Loss:	1.931623935699463

training epoch 315 / 500, batch #350 / 625
Loss:	1.8096638917922974

training epoch 315 / 500, batch #375 / 625
Loss:	1.707932949066162

training epoch 315 / 500, batch #400 / 625
Loss:	1.7806366682052612

training epoch 315 / 500, batch #425 / 625
Loss:	1.6861517429351807

training epoch 315 / 500, batch #450 / 625
Loss:	1.6936310529708862

training epoch 315 / 500, batch #475 / 625
Loss:	1.6477779150009155

training epoch 315 / 500, batch #500 / 625
Loss:	1.8316917419433594

training epoch 315 / 500, batch #525 / 625
Loss:	1.5103445053100586

training epoch 315 / 500, batch #550 / 625
Loss:	1.897780418395996

training epoch 315 / 500, batch #575 / 625
Loss:	1.7878105640411377

training epoch 315 / 500, batch #600 / 625
Loss:	2.000096321105957

training epoch 316 / 500, batch #0 / 625
Loss:	1.9182425737380981

training epoch 316 / 500, batch #25 / 625
Loss:	1.7969704866409302

training epoch 316 / 500, batch #50 / 625
Loss:	1.7407257556915283

training epoch 316 / 500, batch #75 / 625
Loss:	1.7729463577270508

training epoch 316 / 500, batch #100 / 625
Loss:	2.253824234008789

training epoch 316 / 500, batch #125 / 625
Loss:	1.6732754707336426

training epoch 316 / 500, batch #150 / 625
Loss:	1.726388931274414

training epoch 316 / 500, batch #175 / 625
Loss:	1.6348732709884644

training epoch 316 / 500, batch #200 / 625
Loss:	1.6349477767944336

training epoch 316 / 500, batch #225 / 625
Loss:	1.7049962282180786

training epoch 316 / 500, batch #250 / 625
Loss:	1.9268908500671387

training epoch 316 / 500, batch #275 / 625
Loss:	1.8008334636688232

training epoch 316 / 500, batch #300 / 625
Loss:	1.8416186571121216

training epoch 316 / 500, batch #325 / 625
Loss:	1.9322538375854492

training epoch 316 / 500, batch #350 / 625
Loss:	1.6125309467315674

training epoch 316 / 500, batch #375 / 625
Loss:	1.5474474430084229

training epoch 316 / 500, batch #400 / 625
Loss:	1.7948368787765503

training epoch 316 / 500, batch #425 / 625
Loss:	1.6703959703445435

training epoch 316 / 500, batch #450 / 625
Loss:	1.6436175107955933

training epoch 316 / 500, batch #475 / 625
Loss:	1.8091415166854858

training epoch 316 / 500, batch #500 / 625
Loss:	1.792701005935669

training epoch 316 / 500, batch #525 / 625
Loss:	1.5766100883483887

training epoch 316 / 500, batch #550 / 625
Loss:	1.719124674797058

training epoch 316 / 500, batch #575 / 625
Loss:	1.5267637968063354

training epoch 316 / 500, batch #600 / 625
Loss:	1.8618137836456299

training epoch 317 / 500, batch #0 / 625
Loss:	1.8601694107055664

training epoch 317 / 500, batch #25 / 625
Loss:	1.706464409828186

training epoch 317 / 500, batch #50 / 625
Loss:	1.7468839883804321

training epoch 317 / 500, batch #75 / 625
Loss:	1.5915169715881348

training epoch 317 / 500, batch #100 / 625
Loss:	1.902129888534546

training epoch 317 / 500, batch #125 / 625
Loss:	1.6732125282287598

training epoch 317 / 500, batch #150 / 625
Loss:	1.751766324043274

training epoch 317 / 500, batch #175 / 625
Loss:	1.6754006147384644

training epoch 317 / 500, batch #200 / 625
Loss:	1.8849124908447266

training epoch 317 / 500, batch #225 / 625
Loss:	1.8357560634613037

training epoch 317 / 500, batch #250 / 625
Loss:	1.7285963296890259

training epoch 317 / 500, batch #275 / 625
Loss:	1.8273462057113647

training epoch 317 / 500, batch #300 / 625
Loss:	2.025113344192505

training epoch 317 / 500, batch #325 / 625
Loss:	1.6636717319488525

training epoch 317 / 500, batch #350 / 625
Loss:	1.6117273569107056

training epoch 317 / 500, batch #375 / 625
Loss:	1.5904512405395508

training epoch 317 / 500, batch #400 / 625
Loss:	1.9460760354995728

training epoch 317 / 500, batch #425 / 625
Loss:	1.577226161956787

training epoch 317 / 500, batch #450 / 625
Loss:	1.778550624847412

training epoch 317 / 500, batch #475 / 625
Loss:	1.6937493085861206

training epoch 317 / 500, batch #500 / 625
Loss:	1.7140450477600098

training epoch 317 / 500, batch #525 / 625
Loss:	1.6995123624801636

training epoch 317 / 500, batch #550 / 625
Loss:	1.7418947219848633

training epoch 317 / 500, batch #575 / 625
Loss:	1.6750919818878174

training epoch 317 / 500, batch #600 / 625
Loss:	1.5007288455963135

training epoch 318 / 500, batch #0 / 625
Loss:	1.8082334995269775

training epoch 318 / 500, batch #25 / 625
Loss:	1.7392903566360474

training epoch 318 / 500, batch #50 / 625
Loss:	1.6214653253555298

training epoch 318 / 500, batch #75 / 625
Loss:	1.4488807916641235

training epoch 318 / 500, batch #100 / 625
Loss:	1.5175440311431885

training epoch 318 / 500, batch #125 / 625
Loss:	1.5726016759872437

training epoch 318 / 500, batch #150 / 625
Loss:	1.5881849527359009

training epoch 318 / 500, batch #175 / 625
Loss:	1.5759425163269043

training epoch 318 / 500, batch #200 / 625
Loss:	1.8194252252578735

training epoch 318 / 500, batch #225 / 625
Loss:	1.8262296915054321

training epoch 318 / 500, batch #250 / 625
Loss:	1.826784610748291

training epoch 318 / 500, batch #275 / 625
Loss:	1.7848035097122192

training epoch 318 / 500, batch #300 / 625
Loss:	1.83195161819458

training epoch 318 / 500, batch #325 / 625
Loss:	1.944678783416748

training epoch 318 / 500, batch #350 / 625
Loss:	1.57926344871521

training epoch 318 / 500, batch #375 / 625
Loss:	1.8249987363815308

training epoch 318 / 500, batch #400 / 625
Loss:	1.7346268892288208

training epoch 318 / 500, batch #425 / 625
Loss:	1.8803752660751343

training epoch 318 / 500, batch #450 / 625
Loss:	1.6622508764266968

training epoch 318 / 500, batch #475 / 625
Loss:	1.7975341081619263

training epoch 318 / 500, batch #500 / 625
Loss:	1.7075388431549072

training epoch 318 / 500, batch #525 / 625
Loss:	1.7941519021987915

training epoch 318 / 500, batch #550 / 625
Loss:	1.7486706972122192

training epoch 318 / 500, batch #575 / 625
Loss:	1.6378471851348877

training epoch 318 / 500, batch #600 / 625
Loss:	1.8814388513565063

training epoch 319 / 500, batch #0 / 625
Loss:	1.7002899646759033

training epoch 319 / 500, batch #25 / 625
Loss:	1.689741849899292

training epoch 319 / 500, batch #50 / 625
Loss:	1.7266935110092163

training epoch 319 / 500, batch #75 / 625
Loss:	1.6124398708343506

training epoch 319 / 500, batch #100 / 625
Loss:	1.8419172763824463

training epoch 319 / 500, batch #125 / 625
Loss:	1.582788109779358

training epoch 319 / 500, batch #150 / 625
Loss:	1.5750360488891602

training epoch 319 / 500, batch #175 / 625
Loss:	1.6973730325698853

training epoch 319 / 500, batch #200 / 625
Loss:	1.7210501432418823

training epoch 319 / 500, batch #225 / 625
Loss:	1.7759370803833008

training epoch 319 / 500, batch #250 / 625
Loss:	1.5337512493133545

training epoch 319 / 500, batch #275 / 625
Loss:	1.7161693572998047

training epoch 319 / 500, batch #300 / 625
Loss:	1.8345818519592285

training epoch 319 / 500, batch #325 / 625
Loss:	1.558239221572876

training epoch 319 / 500, batch #350 / 625
Loss:	1.5955681800842285

training epoch 319 / 500, batch #375 / 625
Loss:	1.601264476776123

training epoch 319 / 500, batch #400 / 625
Loss:	1.6273267269134521

training epoch 319 / 500, batch #425 / 625
Loss:	1.866072177886963

training epoch 319 / 500, batch #450 / 625
Loss:	1.7523772716522217

training epoch 319 / 500, batch #475 / 625
Loss:	1.5336045026779175

training epoch 319 / 500, batch #500 / 625
Loss:	1.5374339818954468

training epoch 319 / 500, batch #525 / 625
Loss:	1.811719298362732

training epoch 319 / 500, batch #550 / 625
Loss:	1.7930344343185425

training epoch 319 / 500, batch #575 / 625
Loss:	1.8487744331359863

training epoch 319 / 500, batch #600 / 625
Loss:	1.8205184936523438

training epoch 320 / 500, batch #0 / 625
Loss:	1.6340622901916504

training epoch 320 / 500, batch #25 / 625
Loss:	1.907236099243164

training epoch 320 / 500, batch #50 / 625
Loss:	1.9759631156921387

training epoch 320 / 500, batch #75 / 625
Loss:	1.62971031665802

training epoch 320 / 500, batch #100 / 625
Loss:	1.7517194747924805

training epoch 320 / 500, batch #125 / 625
Loss:	1.7642042636871338

training epoch 320 / 500, batch #150 / 625
Loss:	1.5627940893173218

training epoch 320 / 500, batch #175 / 625
Loss:	1.925363540649414

training epoch 320 / 500, batch #200 / 625
Loss:	1.8014723062515259

training epoch 320 / 500, batch #225 / 625
Loss:	1.709682583808899

training epoch 320 / 500, batch #250 / 625
Loss:	1.7214125394821167

training epoch 320 / 500, batch #275 / 625
Loss:	1.7654013633728027

training epoch 320 / 500, batch #300 / 625
Loss:	1.7452647686004639

training epoch 320 / 500, batch #325 / 625
Loss:	1.5972528457641602

training epoch 320 / 500, batch #350 / 625
Loss:	1.5147268772125244

training epoch 320 / 500, batch #375 / 625
Loss:	1.8465588092803955

training epoch 320 / 500, batch #400 / 625
Loss:	1.421901822090149

training epoch 320 / 500, batch #425 / 625
Loss:	1.6699514389038086

training epoch 320 / 500, batch #450 / 625
Loss:	1.5391656160354614

training epoch 320 / 500, batch #475 / 625
Loss:	1.8137751817703247

training epoch 320 / 500, batch #500 / 625
Loss:	1.9156025648117065

training epoch 320 / 500, batch #525 / 625
Loss:	1.631028413772583

training epoch 320 / 500, batch #550 / 625
Loss:	1.7554199695587158

training epoch 320 / 500, batch #575 / 625
Loss:	1.3971582651138306

training epoch 320 / 500, batch #600 / 625
Loss:	1.4853137731552124

training epoch 321 / 500, batch #0 / 625
Loss:	1.6906077861785889

training epoch 321 / 500, batch #25 / 625
Loss:	1.7418931722640991

training epoch 321 / 500, batch #50 / 625
Loss:	2.0308566093444824

training epoch 321 / 500, batch #75 / 625
Loss:	1.8070532083511353

training epoch 321 / 500, batch #100 / 625
Loss:	1.80013906955719

training epoch 321 / 500, batch #125 / 625
Loss:	1.698204517364502

training epoch 321 / 500, batch #150 / 625
Loss:	1.883447527885437

training epoch 321 / 500, batch #175 / 625
Loss:	1.834946870803833

training epoch 321 / 500, batch #200 / 625
Loss:	1.4920027256011963

training epoch 321 / 500, batch #225 / 625
Loss:	1.5925990343093872

training epoch 321 / 500, batch #250 / 625
Loss:	1.6239560842514038

training epoch 321 / 500, batch #275 / 625
Loss:	1.5397881269454956

training epoch 321 / 500, batch #300 / 625
Loss:	1.5654938220977783

training epoch 321 / 500, batch #325 / 625
Loss:	1.5633347034454346

training epoch 321 / 500, batch #350 / 625
Loss:	1.8673254251480103

training epoch 321 / 500, batch #375 / 625
Loss:	1.6163361072540283

training epoch 321 / 500, batch #400 / 625
Loss:	1.9007794857025146

training epoch 321 / 500, batch #425 / 625
Loss:	1.4460477828979492

training epoch 321 / 500, batch #450 / 625
Loss:	1.8101485967636108

training epoch 321 / 500, batch #475 / 625
Loss:	1.8495672941207886

training epoch 321 / 500, batch #500 / 625
Loss:	1.831114411354065

training epoch 321 / 500, batch #525 / 625
Loss:	1.5347012281417847

training epoch 321 / 500, batch #550 / 625
Loss:	1.623147964477539

training epoch 321 / 500, batch #575 / 625
Loss:	1.8196136951446533

training epoch 321 / 500, batch #600 / 625
Loss:	1.7004464864730835

training epoch 322 / 500, batch #0 / 625
Loss:	1.7632672786712646

training epoch 322 / 500, batch #25 / 625
Loss:	1.438409686088562

training epoch 322 / 500, batch #50 / 625
Loss:	1.9294233322143555

training epoch 322 / 500, batch #75 / 625
Loss:	1.8794984817504883

training epoch 322 / 500, batch #100 / 625
Loss:	1.605314016342163

training epoch 322 / 500, batch #125 / 625
Loss:	1.831944465637207

training epoch 322 / 500, batch #150 / 625
Loss:	1.4567404985427856

training epoch 322 / 500, batch #175 / 625
Loss:	1.8038626909255981

training epoch 322 / 500, batch #200 / 625
Loss:	1.5408344268798828

training epoch 322 / 500, batch #225 / 625
Loss:	1.5622162818908691

training epoch 322 / 500, batch #250 / 625
Loss:	1.7836955785751343

training epoch 322 / 500, batch #275 / 625
Loss:	1.8340445756912231

training epoch 322 / 500, batch #300 / 625
Loss:	1.8738195896148682

training epoch 322 / 500, batch #325 / 625
Loss:	1.8133565187454224

training epoch 322 / 500, batch #350 / 625
Loss:	1.8296761512756348

training epoch 322 / 500, batch #375 / 625
Loss:	1.8369793891906738

training epoch 322 / 500, batch #400 / 625
Loss:	1.7669906616210938

training epoch 322 / 500, batch #425 / 625
Loss:	1.6870663166046143

training epoch 322 / 500, batch #450 / 625
Loss:	1.6846702098846436

training epoch 322 / 500, batch #475 / 625
Loss:	1.784636378288269

training epoch 322 / 500, batch #500 / 625
Loss:	1.6071858406066895

training epoch 322 / 500, batch #525 / 625
Loss:	1.8681764602661133

training epoch 322 / 500, batch #550 / 625
Loss:	1.679767370223999

training epoch 322 / 500, batch #575 / 625
Loss:	1.618578314781189

training epoch 322 / 500, batch #600 / 625
Loss:	1.6799038648605347

training epoch 323 / 500, batch #0 / 625
Loss:	1.6206307411193848

training epoch 323 / 500, batch #25 / 625
Loss:	1.6906152963638306

training epoch 323 / 500, batch #50 / 625
Loss:	1.712584376335144

training epoch 323 / 500, batch #75 / 625
Loss:	1.7330609560012817

training epoch 323 / 500, batch #100 / 625
Loss:	1.700042724609375

training epoch 323 / 500, batch #125 / 625
Loss:	1.635492205619812

training epoch 323 / 500, batch #150 / 625
Loss:	1.8463033437728882

training epoch 323 / 500, batch #175 / 625
Loss:	1.6766438484191895

training epoch 323 / 500, batch #200 / 625
Loss:	1.874871015548706

training epoch 323 / 500, batch #225 / 625
Loss:	1.6240172386169434

training epoch 323 / 500, batch #250 / 625
Loss:	1.6317203044891357

training epoch 323 / 500, batch #275 / 625
Loss:	1.811484932899475

training epoch 323 / 500, batch #300 / 625
Loss:	1.5428475141525269

training epoch 323 / 500, batch #325 / 625
Loss:	1.756211280822754

training epoch 323 / 500, batch #350 / 625
Loss:	1.7376110553741455

training epoch 323 / 500, batch #375 / 625
Loss:	1.6753756999969482

training epoch 323 / 500, batch #400 / 625
Loss:	1.8105523586273193

training epoch 323 / 500, batch #425 / 625
Loss:	1.8218966722488403

training epoch 323 / 500, batch #450 / 625
Loss:	1.4266839027404785

training epoch 323 / 500, batch #475 / 625
Loss:	1.3699619770050049

training epoch 323 / 500, batch #500 / 625
Loss:	1.6366543769836426

training epoch 323 / 500, batch #525 / 625
Loss:	1.8140490055084229

training epoch 323 / 500, batch #550 / 625
Loss:	1.4959155321121216

training epoch 323 / 500, batch #575 / 625
Loss:	1.8584734201431274

training epoch 323 / 500, batch #600 / 625
Loss:	1.6400152444839478

training epoch 324 / 500, batch #0 / 625
Loss:	1.9378929138183594

training epoch 324 / 500, batch #25 / 625
Loss:	1.5304619073867798

training epoch 324 / 500, batch #50 / 625
Loss:	1.7138030529022217

training epoch 324 / 500, batch #75 / 625
Loss:	1.702364444732666

training epoch 324 / 500, batch #100 / 625
Loss:	1.5338114500045776

training epoch 324 / 500, batch #125 / 625
Loss:	1.7107034921646118

training epoch 324 / 500, batch #150 / 625
Loss:	1.6360368728637695

training epoch 324 / 500, batch #175 / 625
Loss:	1.5116435289382935

training epoch 324 / 500, batch #200 / 625
Loss:	1.5945552587509155

training epoch 324 / 500, batch #225 / 625
Loss:	1.8488153219223022

training epoch 324 / 500, batch #250 / 625
Loss:	1.564011573791504

training epoch 324 / 500, batch #275 / 625
Loss:	1.9633591175079346

training epoch 324 / 500, batch #300 / 625
Loss:	1.7780249118804932

training epoch 324 / 500, batch #325 / 625
Loss:	1.7361876964569092

training epoch 324 / 500, batch #350 / 625
Loss:	2.0129222869873047

training epoch 324 / 500, batch #375 / 625
Loss:	1.878568172454834

training epoch 324 / 500, batch #400 / 625
Loss:	1.7728745937347412

training epoch 324 / 500, batch #425 / 625
Loss:	1.901126742362976

training epoch 324 / 500, batch #450 / 625
Loss:	1.7726161479949951

training epoch 324 / 500, batch #475 / 625
Loss:	1.7945380210876465

training epoch 324 / 500, batch #500 / 625
Loss:	1.6841124296188354

training epoch 324 / 500, batch #525 / 625
Loss:	1.6071463823318481

training epoch 324 / 500, batch #550 / 625
Loss:	1.7316733598709106

training epoch 324 / 500, batch #575 / 625
Loss:	1.7860127687454224

training epoch 324 / 500, batch #600 / 625
Loss:	1.592015027999878

training epoch 325 / 500, batch #0 / 625
Loss:	1.5247806310653687

training epoch 325 / 500, batch #25 / 625
Loss:	1.7390471696853638

training epoch 325 / 500, batch #50 / 625
Loss:	1.6534476280212402

training epoch 325 / 500, batch #75 / 625
Loss:	1.417785406112671

training epoch 325 / 500, batch #100 / 625
Loss:	1.6390273571014404

training epoch 325 / 500, batch #125 / 625
Loss:	1.7663575410842896

training epoch 325 / 500, batch #150 / 625
Loss:	1.6460182666778564

training epoch 325 / 500, batch #175 / 625
Loss:	1.562322974205017

training epoch 325 / 500, batch #200 / 625
Loss:	1.872050166130066

training epoch 325 / 500, batch #225 / 625
Loss:	1.6999531984329224

training epoch 325 / 500, batch #250 / 625
Loss:	1.6696598529815674

training epoch 325 / 500, batch #275 / 625
Loss:	1.817575216293335

training epoch 325 / 500, batch #300 / 625
Loss:	1.6496175527572632

training epoch 325 / 500, batch #325 / 625
Loss:	1.6446592807769775

training epoch 325 / 500, batch #350 / 625
Loss:	1.7085151672363281

training epoch 325 / 500, batch #375 / 625
Loss:	1.8201887607574463

training epoch 325 / 500, batch #400 / 625
Loss:	1.5770243406295776

training epoch 325 / 500, batch #425 / 625
Loss:	1.7898409366607666

training epoch 325 / 500, batch #450 / 625
Loss:	1.6577407121658325

training epoch 325 / 500, batch #475 / 625
Loss:	1.5982850790023804

training epoch 325 / 500, batch #500 / 625
Loss:	1.8265920877456665

training epoch 325 / 500, batch #525 / 625
Loss:	1.7117445468902588

training epoch 325 / 500, batch #550 / 625
Loss:	1.7653229236602783

training epoch 325 / 500, batch #575 / 625
Loss:	1.6592047214508057

training epoch 325 / 500, batch #600 / 625
Loss:	1.5644099712371826

training epoch 326 / 500, batch #0 / 625
Loss:	1.7537671327590942

training epoch 326 / 500, batch #25 / 625
Loss:	1.7370291948318481

training epoch 326 / 500, batch #50 / 625
Loss:	1.6471410989761353

training epoch 326 / 500, batch #75 / 625
Loss:	1.8998587131500244

training epoch 326 / 500, batch #100 / 625
Loss:	1.8274351358413696

training epoch 326 / 500, batch #125 / 625
Loss:	1.7376548051834106

training epoch 326 / 500, batch #150 / 625
Loss:	1.8877301216125488

training epoch 326 / 500, batch #175 / 625
Loss:	1.6468274593353271

training epoch 326 / 500, batch #200 / 625
Loss:	1.6856353282928467

training epoch 326 / 500, batch #225 / 625
Loss:	1.5656709671020508

training epoch 326 / 500, batch #250 / 625
Loss:	1.7001346349716187

training epoch 326 / 500, batch #275 / 625
Loss:	1.7188924551010132

training epoch 326 / 500, batch #300 / 625
Loss:	1.738082766532898

training epoch 326 / 500, batch #325 / 625
Loss:	1.8429784774780273

training epoch 326 / 500, batch #350 / 625
Loss:	1.632188081741333

training epoch 326 / 500, batch #375 / 625
Loss:	1.7676591873168945

training epoch 326 / 500, batch #400 / 625
Loss:	1.9234510660171509

training epoch 326 / 500, batch #425 / 625
Loss:	2.0048418045043945

training epoch 326 / 500, batch #450 / 625
Loss:	1.7258270978927612

training epoch 326 / 500, batch #475 / 625
Loss:	1.7760570049285889

training epoch 326 / 500, batch #500 / 625
Loss:	1.6406669616699219

training epoch 326 / 500, batch #525 / 625
Loss:	1.7432996034622192

training epoch 326 / 500, batch #550 / 625
Loss:	1.9229995012283325

training epoch 326 / 500, batch #575 / 625
Loss:	1.9058443307876587

training epoch 326 / 500, batch #600 / 625
Loss:	1.8439778089523315

training epoch 327 / 500, batch #0 / 625
Loss:	1.8665292263031006

training epoch 327 / 500, batch #25 / 625
Loss:	1.7119579315185547

training epoch 327 / 500, batch #50 / 625
Loss:	1.7222914695739746

training epoch 327 / 500, batch #75 / 625
Loss:	1.4896831512451172

training epoch 327 / 500, batch #100 / 625
Loss:	1.9195524454116821

training epoch 327 / 500, batch #125 / 625
Loss:	1.4805036783218384

training epoch 327 / 500, batch #150 / 625
Loss:	1.6180484294891357

training epoch 327 / 500, batch #175 / 625
Loss:	1.552108883857727

training epoch 327 / 500, batch #200 / 625
Loss:	1.6179176568984985

training epoch 327 / 500, batch #225 / 625
Loss:	1.7462809085845947

training epoch 327 / 500, batch #250 / 625
Loss:	1.9064120054244995

training epoch 327 / 500, batch #275 / 625
Loss:	1.6534640789031982

training epoch 327 / 500, batch #300 / 625
Loss:	1.6220427751541138

training epoch 327 / 500, batch #325 / 625
Loss:	1.8299643993377686

training epoch 327 / 500, batch #350 / 625
Loss:	1.591530680656433

training epoch 327 / 500, batch #375 / 625
Loss:	1.7235922813415527

training epoch 327 / 500, batch #400 / 625
Loss:	1.6860661506652832

training epoch 327 / 500, batch #425 / 625
Loss:	1.7947970628738403

training epoch 327 / 500, batch #450 / 625
Loss:	1.4845592975616455

training epoch 327 / 500, batch #475 / 625
Loss:	1.8045026063919067

training epoch 327 / 500, batch #500 / 625
Loss:	1.7952871322631836

training epoch 327 / 500, batch #525 / 625
Loss:	1.4783416986465454

training epoch 327 / 500, batch #550 / 625
Loss:	1.5988081693649292

training epoch 327 / 500, batch #575 / 625
Loss:	1.5830942392349243

training epoch 327 / 500, batch #600 / 625
Loss:	1.7344114780426025

training epoch 328 / 500, batch #0 / 625
Loss:	1.8388651609420776

training epoch 328 / 500, batch #25 / 625
Loss:	1.8808976411819458

training epoch 328 / 500, batch #50 / 625
Loss:	1.7058929204940796

training epoch 328 / 500, batch #75 / 625
Loss:	1.5451278686523438

training epoch 328 / 500, batch #100 / 625
Loss:	1.7193658351898193

training epoch 328 / 500, batch #125 / 625
Loss:	1.846634030342102

training epoch 328 / 500, batch #150 / 625
Loss:	1.7949782609939575

training epoch 328 / 500, batch #175 / 625
Loss:	1.7724030017852783

training epoch 328 / 500, batch #200 / 625
Loss:	1.5045756101608276

training epoch 328 / 500, batch #225 / 625
Loss:	1.640930414199829

training epoch 328 / 500, batch #250 / 625
Loss:	1.6886228322982788

training epoch 328 / 500, batch #275 / 625
Loss:	1.7437254190444946

training epoch 328 / 500, batch #300 / 625
Loss:	1.9196957349777222

training epoch 328 / 500, batch #325 / 625
Loss:	1.7569289207458496

training epoch 328 / 500, batch #350 / 625
Loss:	1.971590518951416

training epoch 328 / 500, batch #375 / 625
Loss:	1.6408517360687256

training epoch 328 / 500, batch #400 / 625
Loss:	1.8914811611175537

training epoch 328 / 500, batch #425 / 625
Loss:	1.579474687576294

training epoch 328 / 500, batch #450 / 625
Loss:	1.8191756010055542

training epoch 328 / 500, batch #475 / 625
Loss:	1.8788962364196777

training epoch 328 / 500, batch #500 / 625
Loss:	1.6725770235061646

training epoch 328 / 500, batch #525 / 625
Loss:	1.7783008813858032

training epoch 328 / 500, batch #550 / 625
Loss:	1.7252498865127563

training epoch 328 / 500, batch #575 / 625
Loss:	1.6548089981079102

training epoch 328 / 500, batch #600 / 625
Loss:	1.97221839427948

training epoch 329 / 500, batch #0 / 625
Loss:	1.8128880262374878

training epoch 329 / 500, batch #25 / 625
Loss:	1.7773706912994385

training epoch 329 / 500, batch #50 / 625
Loss:	1.7878389358520508

training epoch 329 / 500, batch #75 / 625
Loss:	1.5165762901306152

training epoch 329 / 500, batch #100 / 625
Loss:	1.6325006484985352

training epoch 329 / 500, batch #125 / 625
Loss:	1.6700267791748047

training epoch 329 / 500, batch #150 / 625
Loss:	1.5681483745574951

training epoch 329 / 500, batch #175 / 625
Loss:	1.679039716720581

training epoch 329 / 500, batch #200 / 625
Loss:	1.9264073371887207

training epoch 329 / 500, batch #225 / 625
Loss:	1.7391682863235474

training epoch 329 / 500, batch #250 / 625
Loss:	1.698282241821289

training epoch 329 / 500, batch #275 / 625
Loss:	1.852794885635376

training epoch 329 / 500, batch #300 / 625
Loss:	1.6269627809524536

training epoch 329 / 500, batch #325 / 625
Loss:	1.8832939863204956

training epoch 329 / 500, batch #350 / 625
Loss:	1.7222235202789307

training epoch 329 / 500, batch #375 / 625
Loss:	1.539373755455017

training epoch 329 / 500, batch #400 / 625
Loss:	1.773710012435913

training epoch 329 / 500, batch #425 / 625
Loss:	1.7649455070495605

training epoch 329 / 500, batch #450 / 625
Loss:	1.7257249355316162

training epoch 329 / 500, batch #475 / 625
Loss:	1.6443606615066528

training epoch 329 / 500, batch #500 / 625
Loss:	1.7196511030197144

training epoch 329 / 500, batch #525 / 625
Loss:	1.6002651453018188

training epoch 329 / 500, batch #550 / 625
Loss:	1.684780478477478

training epoch 329 / 500, batch #575 / 625
Loss:	2.093357563018799

training epoch 329 / 500, batch #600 / 625
Loss:	1.6776604652404785

training epoch 330 / 500, batch #0 / 625
Loss:	1.8933899402618408

training epoch 330 / 500, batch #25 / 625
Loss:	1.6609492301940918

training epoch 330 / 500, batch #50 / 625
Loss:	1.5049281120300293

training epoch 330 / 500, batch #75 / 625
Loss:	1.6845859289169312

training epoch 330 / 500, batch #100 / 625
Loss:	1.8745932579040527

training epoch 330 / 500, batch #125 / 625
Loss:	1.7649307250976562

training epoch 330 / 500, batch #150 / 625
Loss:	2.0804028511047363

training epoch 330 / 500, batch #175 / 625
Loss:	1.6196260452270508

training epoch 330 / 500, batch #200 / 625
Loss:	1.7037358283996582

training epoch 330 / 500, batch #225 / 625
Loss:	1.9864892959594727

training epoch 330 / 500, batch #250 / 625
Loss:	1.6014118194580078

training epoch 330 / 500, batch #275 / 625
Loss:	1.6183388233184814

training epoch 330 / 500, batch #300 / 625
Loss:	1.9143297672271729

training epoch 330 / 500, batch #325 / 625
Loss:	1.575315237045288

training epoch 330 / 500, batch #350 / 625
Loss:	1.8228436708450317

training epoch 330 / 500, batch #375 / 625
Loss:	1.7249661684036255

training epoch 330 / 500, batch #400 / 625
Loss:	1.8770555257797241

training epoch 330 / 500, batch #425 / 625
Loss:	1.8962178230285645

training epoch 330 / 500, batch #450 / 625
Loss:	1.5794099569320679

training epoch 330 / 500, batch #475 / 625
Loss:	1.7721220254898071

training epoch 330 / 500, batch #500 / 625
Loss:	1.8033040761947632

training epoch 330 / 500, batch #525 / 625
Loss:	1.562411904335022

training epoch 330 / 500, batch #550 / 625
Loss:	1.7071160078048706

training epoch 330 / 500, batch #575 / 625
Loss:	1.9574580192565918

training epoch 330 / 500, batch #600 / 625
Loss:	1.570407748222351

training epoch 331 / 500, batch #0 / 625
Loss:	1.821003794670105

training epoch 331 / 500, batch #25 / 625
Loss:	1.6932694911956787

training epoch 331 / 500, batch #50 / 625
Loss:	1.6219133138656616

training epoch 331 / 500, batch #75 / 625
Loss:	1.6185921430587769

training epoch 331 / 500, batch #100 / 625
Loss:	1.7676548957824707

training epoch 331 / 500, batch #125 / 625
Loss:	1.7829922437667847

training epoch 331 / 500, batch #150 / 625
Loss:	1.692063570022583

training epoch 331 / 500, batch #175 / 625
Loss:	1.5849021673202515

training epoch 331 / 500, batch #200 / 625
Loss:	1.676286220550537

training epoch 331 / 500, batch #225 / 625
Loss:	1.7461562156677246

training epoch 331 / 500, batch #250 / 625
Loss:	1.5395615100860596

training epoch 331 / 500, batch #275 / 625
Loss:	1.75436270236969

training epoch 331 / 500, batch #300 / 625
Loss:	1.9744592905044556

training epoch 331 / 500, batch #325 / 625
Loss:	1.8273167610168457

training epoch 331 / 500, batch #350 / 625
Loss:	1.6967756748199463

training epoch 331 / 500, batch #375 / 625
Loss:	1.7359468936920166

training epoch 331 / 500, batch #400 / 625
Loss:	1.7839577198028564

training epoch 331 / 500, batch #425 / 625
Loss:	1.8554061651229858

training epoch 331 / 500, batch #450 / 625
Loss:	1.5889043807983398

training epoch 331 / 500, batch #475 / 625
Loss:	1.6686851978302002

training epoch 331 / 500, batch #500 / 625
Loss:	1.6813791990280151

training epoch 331 / 500, batch #525 / 625
Loss:	1.7075746059417725

training epoch 331 / 500, batch #550 / 625
Loss:	1.7760941982269287

training epoch 331 / 500, batch #575 / 625
Loss:	1.6597412824630737

training epoch 331 / 500, batch #600 / 625
Loss:	1.6574350595474243

training epoch 332 / 500, batch #0 / 625
Loss:	1.871520757675171

training epoch 332 / 500, batch #25 / 625
Loss:	2.0300567150115967

training epoch 332 / 500, batch #50 / 625
Loss:	1.7004565000534058

training epoch 332 / 500, batch #75 / 625
Loss:	1.6224206686019897

training epoch 332 / 500, batch #100 / 625
Loss:	1.5915781259536743

training epoch 332 / 500, batch #125 / 625
Loss:	1.6887468099594116

training epoch 332 / 500, batch #150 / 625
Loss:	1.562317132949829

training epoch 332 / 500, batch #175 / 625
Loss:	1.9985431432724

training epoch 332 / 500, batch #200 / 625
Loss:	1.814008355140686

training epoch 332 / 500, batch #225 / 625
Loss:	1.6014976501464844

training epoch 332 / 500, batch #250 / 625
Loss:	1.5800844430923462

training epoch 332 / 500, batch #275 / 625
Loss:	1.6079039573669434

training epoch 332 / 500, batch #300 / 625
Loss:	1.5436558723449707

training epoch 332 / 500, batch #325 / 625
Loss:	1.6911654472351074

training epoch 332 / 500, batch #350 / 625
Loss:	1.899853229522705

training epoch 332 / 500, batch #375 / 625
Loss:	1.6206640005111694

training epoch 332 / 500, batch #400 / 625
Loss:	1.7955634593963623

training epoch 332 / 500, batch #425 / 625
Loss:	1.7256745100021362

training epoch 332 / 500, batch #450 / 625
Loss:	1.8710099458694458

training epoch 332 / 500, batch #475 / 625
Loss:	1.7603379487991333

training epoch 332 / 500, batch #500 / 625
Loss:	1.6696289777755737

training epoch 332 / 500, batch #525 / 625
Loss:	1.661251425743103

training epoch 332 / 500, batch #550 / 625
Loss:	1.693573236465454

training epoch 332 / 500, batch #575 / 625
Loss:	1.4550800323486328

training epoch 332 / 500, batch #600 / 625
Loss:	1.8116141557693481

training epoch 333 / 500, batch #0 / 625
Loss:	1.899361491203308

training epoch 333 / 500, batch #25 / 625
Loss:	1.6010191440582275

training epoch 333 / 500, batch #50 / 625
Loss:	1.7290921211242676

training epoch 333 / 500, batch #75 / 625
Loss:	1.6821844577789307

training epoch 333 / 500, batch #100 / 625
Loss:	1.5111275911331177

training epoch 333 / 500, batch #125 / 625
Loss:	1.6200529336929321

training epoch 333 / 500, batch #150 / 625
Loss:	1.6919152736663818

training epoch 333 / 500, batch #175 / 625
Loss:	1.4212735891342163

training epoch 333 / 500, batch #200 / 625
Loss:	1.8654803037643433

training epoch 333 / 500, batch #225 / 625
Loss:	1.43603515625

training epoch 333 / 500, batch #250 / 625
Loss:	1.7422051429748535

training epoch 333 / 500, batch #275 / 625
Loss:	1.6116536855697632

training epoch 333 / 500, batch #300 / 625
Loss:	1.7786775827407837

training epoch 333 / 500, batch #325 / 625
Loss:	1.6972041130065918

training epoch 333 / 500, batch #350 / 625
Loss:	1.855902075767517

training epoch 333 / 500, batch #375 / 625
Loss:	1.4559736251831055

training epoch 333 / 500, batch #400 / 625
Loss:	1.6636393070220947

training epoch 333 / 500, batch #425 / 625
Loss:	2.0842525959014893

training epoch 333 / 500, batch #450 / 625
Loss:	1.6862932443618774

training epoch 333 / 500, batch #475 / 625
Loss:	1.8230284452438354

training epoch 333 / 500, batch #500 / 625
Loss:	1.8354909420013428

training epoch 333 / 500, batch #525 / 625
Loss:	1.8858600854873657

training epoch 333 / 500, batch #550 / 625
Loss:	1.7725800275802612

training epoch 333 / 500, batch #575 / 625
Loss:	1.7891045808792114

training epoch 333 / 500, batch #600 / 625
Loss:	1.7185381650924683

training epoch 334 / 500, batch #0 / 625
Loss:	1.8935637474060059

training epoch 334 / 500, batch #25 / 625
Loss:	1.8094468116760254

training epoch 334 / 500, batch #50 / 625
Loss:	1.4803986549377441

training epoch 334 / 500, batch #75 / 625
Loss:	1.8374916315078735

training epoch 334 / 500, batch #100 / 625
Loss:	1.9732893705368042

training epoch 334 / 500, batch #125 / 625
Loss:	1.7066839933395386

training epoch 334 / 500, batch #150 / 625
Loss:	1.639638066291809

training epoch 334 / 500, batch #175 / 625
Loss:	1.6945509910583496

training epoch 334 / 500, batch #200 / 625
Loss:	1.9153257608413696

training epoch 334 / 500, batch #225 / 625
Loss:	1.8276023864746094

training epoch 334 / 500, batch #250 / 625
Loss:	1.5793116092681885

training epoch 334 / 500, batch #275 / 625
Loss:	1.683604121208191

training epoch 334 / 500, batch #300 / 625
Loss:	1.9453753232955933

training epoch 334 / 500, batch #325 / 625
Loss:	1.5281256437301636

training epoch 334 / 500, batch #350 / 625
Loss:	1.78433358669281

training epoch 334 / 500, batch #375 / 625
Loss:	1.6882601976394653

training epoch 334 / 500, batch #400 / 625
Loss:	1.8630609512329102

training epoch 334 / 500, batch #425 / 625
Loss:	1.8626450300216675

training epoch 334 / 500, batch #450 / 625
Loss:	1.6208666563034058

training epoch 334 / 500, batch #475 / 625
Loss:	1.6478471755981445

training epoch 334 / 500, batch #500 / 625
Loss:	1.7432304620742798

training epoch 334 / 500, batch #525 / 625
Loss:	1.6835359334945679

training epoch 334 / 500, batch #550 / 625
Loss:	1.576387882232666

training epoch 334 / 500, batch #575 / 625
Loss:	1.841636300086975

training epoch 334 / 500, batch #600 / 625
Loss:	1.7471152544021606

training epoch 335 / 500, batch #0 / 625
Loss:	1.5396006107330322

training epoch 335 / 500, batch #25 / 625
Loss:	1.7453391551971436

training epoch 335 / 500, batch #50 / 625
Loss:	1.766860842704773

training epoch 335 / 500, batch #75 / 625
Loss:	1.6455409526824951

training epoch 335 / 500, batch #100 / 625
Loss:	1.95429527759552

training epoch 335 / 500, batch #125 / 625
Loss:	1.7234948873519897

training epoch 335 / 500, batch #150 / 625
Loss:	1.7157055139541626

training epoch 335 / 500, batch #175 / 625
Loss:	1.5357015132904053

training epoch 335 / 500, batch #200 / 625
Loss:	1.74261474609375

training epoch 335 / 500, batch #225 / 625
Loss:	1.5457886457443237

training epoch 335 / 500, batch #250 / 625
Loss:	1.5665380954742432

training epoch 335 / 500, batch #275 / 625
Loss:	1.7206687927246094

training epoch 335 / 500, batch #300 / 625
Loss:	1.9830793142318726

training epoch 335 / 500, batch #325 / 625
Loss:	1.8303202390670776

training epoch 335 / 500, batch #350 / 625
Loss:	1.5753055810928345

training epoch 335 / 500, batch #375 / 625
Loss:	1.8743789196014404

training epoch 335 / 500, batch #400 / 625
Loss:	1.6310656070709229

training epoch 335 / 500, batch #425 / 625
Loss:	1.9112474918365479

training epoch 335 / 500, batch #450 / 625
Loss:	1.6614668369293213

training epoch 335 / 500, batch #475 / 625
Loss:	1.8231309652328491

training epoch 335 / 500, batch #500 / 625
Loss:	1.7516896724700928

training epoch 335 / 500, batch #525 / 625
Loss:	1.7914683818817139

training epoch 335 / 500, batch #550 / 625
Loss:	1.5440870523452759

training epoch 335 / 500, batch #575 / 625
Loss:	2.251417636871338

training epoch 335 / 500, batch #600 / 625
Loss:	1.697061538696289

training epoch 336 / 500, batch #0 / 625
Loss:	1.5211347341537476

training epoch 336 / 500, batch #25 / 625
Loss:	1.8306699991226196

training epoch 336 / 500, batch #50 / 625
Loss:	1.7758594751358032

training epoch 336 / 500, batch #75 / 625
Loss:	1.7496579885482788

training epoch 336 / 500, batch #100 / 625
Loss:	1.768005609512329

training epoch 336 / 500, batch #125 / 625
Loss:	1.6294374465942383

training epoch 336 / 500, batch #150 / 625
Loss:	1.7223455905914307

training epoch 336 / 500, batch #175 / 625
Loss:	1.5288165807724

training epoch 336 / 500, batch #200 / 625
Loss:	1.831752896308899

training epoch 336 / 500, batch #225 / 625
Loss:	1.6618574857711792

training epoch 336 / 500, batch #250 / 625
Loss:	1.783076524734497

training epoch 336 / 500, batch #275 / 625
Loss:	1.4934802055358887

training epoch 336 / 500, batch #300 / 625
Loss:	1.6070483922958374

training epoch 336 / 500, batch #325 / 625
Loss:	1.5117602348327637

training epoch 336 / 500, batch #350 / 625
Loss:	1.6034218072891235

training epoch 336 / 500, batch #375 / 625
Loss:	1.5508614778518677

training epoch 336 / 500, batch #400 / 625
Loss:	1.6348419189453125

training epoch 336 / 500, batch #425 / 625
Loss:	1.9272634983062744

training epoch 336 / 500, batch #450 / 625
Loss:	1.7004280090332031

training epoch 336 / 500, batch #475 / 625
Loss:	1.6453523635864258

training epoch 336 / 500, batch #500 / 625
Loss:	1.6847444772720337

training epoch 336 / 500, batch #525 / 625
Loss:	1.7931122779846191

training epoch 336 / 500, batch #550 / 625
Loss:	1.6570912599563599

training epoch 336 / 500, batch #575 / 625
Loss:	1.2363685369491577

training epoch 336 / 500, batch #600 / 625
Loss:	1.7248281240463257

training epoch 337 / 500, batch #0 / 625
Loss:	1.543289065361023

training epoch 337 / 500, batch #25 / 625
Loss:	1.476025104522705

training epoch 337 / 500, batch #50 / 625
Loss:	1.5959675312042236

training epoch 337 / 500, batch #75 / 625
Loss:	1.5673184394836426

training epoch 337 / 500, batch #100 / 625
Loss:	1.8477891683578491

training epoch 337 / 500, batch #125 / 625
Loss:	1.95648992061615

training epoch 337 / 500, batch #150 / 625
Loss:	1.725110411643982

training epoch 337 / 500, batch #175 / 625
Loss:	1.6340885162353516

training epoch 337 / 500, batch #200 / 625
Loss:	1.735654354095459

training epoch 337 / 500, batch #225 / 625
Loss:	1.809719443321228

training epoch 337 / 500, batch #250 / 625
Loss:	1.7731763124465942

training epoch 337 / 500, batch #275 / 625
Loss:	1.6768966913223267

training epoch 337 / 500, batch #300 / 625
Loss:	1.4854806661605835

training epoch 337 / 500, batch #325 / 625
Loss:	1.744915246963501

training epoch 337 / 500, batch #350 / 625
Loss:	1.7809805870056152

training epoch 337 / 500, batch #375 / 625
Loss:	1.7302565574645996

training epoch 337 / 500, batch #400 / 625
Loss:	1.543980360031128

training epoch 337 / 500, batch #425 / 625
Loss:	1.6266026496887207

training epoch 337 / 500, batch #450 / 625
Loss:	1.8864742517471313

training epoch 337 / 500, batch #475 / 625
Loss:	1.8015179634094238

training epoch 337 / 500, batch #500 / 625
Loss:	1.635988473892212

training epoch 337 / 500, batch #525 / 625
Loss:	1.7303240299224854

training epoch 337 / 500, batch #550 / 625
Loss:	1.6858303546905518

training epoch 337 / 500, batch #575 / 625
Loss:	1.7527481317520142

training epoch 337 / 500, batch #600 / 625
Loss:	1.8176028728485107

training epoch 338 / 500, batch #0 / 625
Loss:	1.525383472442627

training epoch 338 / 500, batch #25 / 625
Loss:	1.525850534439087

training epoch 338 / 500, batch #50 / 625
Loss:	1.8438122272491455

training epoch 338 / 500, batch #75 / 625
Loss:	1.7603814601898193

training epoch 338 / 500, batch #100 / 625
Loss:	1.9515271186828613

training epoch 338 / 500, batch #125 / 625
Loss:	1.7775278091430664

training epoch 338 / 500, batch #150 / 625
Loss:	1.8234729766845703

training epoch 338 / 500, batch #175 / 625
Loss:	1.6094528436660767

training epoch 338 / 500, batch #200 / 625
Loss:	1.8410016298294067

training epoch 338 / 500, batch #225 / 625
Loss:	1.6879713535308838

training epoch 338 / 500, batch #250 / 625
Loss:	1.6678906679153442

training epoch 338 / 500, batch #275 / 625
Loss:	1.4560092687606812

training epoch 338 / 500, batch #300 / 625
Loss:	1.700222373008728

training epoch 338 / 500, batch #325 / 625
Loss:	1.602120041847229

training epoch 338 / 500, batch #350 / 625
Loss:	1.7446798086166382

training epoch 338 / 500, batch #375 / 625
Loss:	1.9175478219985962

training epoch 338 / 500, batch #400 / 625
Loss:	1.6740086078643799

training epoch 338 / 500, batch #425 / 625
Loss:	1.916900873184204

training epoch 338 / 500, batch #450 / 625
Loss:	1.6716314554214478

training epoch 338 / 500, batch #475 / 625
Loss:	1.7568271160125732

training epoch 338 / 500, batch #500 / 625
Loss:	1.4340453147888184

training epoch 338 / 500, batch #525 / 625
Loss:	1.6419446468353271

training epoch 338 / 500, batch #550 / 625
Loss:	1.7050871849060059

training epoch 338 / 500, batch #575 / 625
Loss:	1.9047400951385498

training epoch 338 / 500, batch #600 / 625
Loss:	1.457934021949768

training epoch 339 / 500, batch #0 / 625
Loss:	1.6086369752883911

training epoch 339 / 500, batch #25 / 625
Loss:	1.7400187253952026

training epoch 339 / 500, batch #50 / 625
Loss:	1.6945585012435913

training epoch 339 / 500, batch #75 / 625
Loss:	1.5099760293960571

training epoch 339 / 500, batch #100 / 625
Loss:	1.4865211248397827

training epoch 339 / 500, batch #125 / 625
Loss:	1.5404804944992065

training epoch 339 / 500, batch #150 / 625
Loss:	1.652103066444397

training epoch 339 / 500, batch #175 / 625
Loss:	1.9466005563735962

training epoch 339 / 500, batch #200 / 625
Loss:	1.6504199504852295

training epoch 339 / 500, batch #225 / 625
Loss:	1.7067452669143677

training epoch 339 / 500, batch #250 / 625
Loss:	1.7346270084381104

training epoch 339 / 500, batch #275 / 625
Loss:	1.7750757932662964

training epoch 339 / 500, batch #300 / 625
Loss:	1.3743934631347656

training epoch 339 / 500, batch #325 / 625
Loss:	1.6751012802124023

training epoch 339 / 500, batch #350 / 625
Loss:	1.586457371711731

training epoch 339 / 500, batch #375 / 625
Loss:	1.8135855197906494

training epoch 339 / 500, batch #400 / 625
Loss:	1.782474160194397

training epoch 339 / 500, batch #425 / 625
Loss:	1.78939950466156

training epoch 339 / 500, batch #450 / 625
Loss:	1.9278801679611206

training epoch 339 / 500, batch #475 / 625
Loss:	1.4906624555587769

training epoch 339 / 500, batch #500 / 625
Loss:	1.7277852296829224

training epoch 339 / 500, batch #525 / 625
Loss:	1.8814690113067627

training epoch 339 / 500, batch #550 / 625
Loss:	1.7718766927719116

training epoch 339 / 500, batch #575 / 625
Loss:	1.9344265460968018

training epoch 339 / 500, batch #600 / 625
Loss:	1.6300325393676758

training epoch 340 / 500, batch #0 / 625
Loss:	1.6823811531066895

training epoch 340 / 500, batch #25 / 625
Loss:	2.0304534435272217

training epoch 340 / 500, batch #50 / 625
Loss:	1.521665334701538

training epoch 340 / 500, batch #75 / 625
Loss:	1.7267496585845947

training epoch 340 / 500, batch #100 / 625
Loss:	1.7118959426879883

training epoch 340 / 500, batch #125 / 625
Loss:	1.8221763372421265

training epoch 340 / 500, batch #150 / 625
Loss:	1.818498134613037

training epoch 340 / 500, batch #175 / 625
Loss:	1.795339584350586

training epoch 340 / 500, batch #200 / 625
Loss:	1.6743336915969849

training epoch 340 / 500, batch #225 / 625
Loss:	1.5621602535247803

training epoch 340 / 500, batch #250 / 625
Loss:	1.7466083765029907

training epoch 340 / 500, batch #275 / 625
Loss:	1.7185108661651611

training epoch 340 / 500, batch #300 / 625
Loss:	1.745538353919983

training epoch 340 / 500, batch #325 / 625
Loss:	1.7294963598251343

training epoch 340 / 500, batch #350 / 625
Loss:	1.7135326862335205

training epoch 340 / 500, batch #375 / 625
Loss:	1.9305341243743896

training epoch 340 / 500, batch #400 / 625
Loss:	1.6808826923370361

training epoch 340 / 500, batch #425 / 625
Loss:	1.6463115215301514

training epoch 340 / 500, batch #450 / 625
Loss:	1.571685552597046

training epoch 340 / 500, batch #475 / 625
Loss:	1.954734444618225

training epoch 340 / 500, batch #500 / 625
Loss:	1.801479458808899

training epoch 340 / 500, batch #525 / 625
Loss:	1.6465336084365845

training epoch 340 / 500, batch #550 / 625
Loss:	1.8033475875854492

training epoch 340 / 500, batch #575 / 625
Loss:	1.7662396430969238

training epoch 340 / 500, batch #600 / 625
Loss:	1.7894601821899414

training epoch 341 / 500, batch #0 / 625
Loss:	1.7766159772872925

training epoch 341 / 500, batch #25 / 625
Loss:	2.0086748600006104

training epoch 341 / 500, batch #50 / 625
Loss:	1.6644253730773926

training epoch 341 / 500, batch #75 / 625
Loss:	1.5115060806274414

training epoch 341 / 500, batch #100 / 625
Loss:	1.8119006156921387

training epoch 341 / 500, batch #125 / 625
Loss:	1.9785946607589722

training epoch 341 / 500, batch #150 / 625
Loss:	1.7950843572616577

training epoch 341 / 500, batch #175 / 625
Loss:	1.7967206239700317

training epoch 341 / 500, batch #200 / 625
Loss:	1.6052292585372925

training epoch 341 / 500, batch #225 / 625
Loss:	1.7030770778656006

training epoch 341 / 500, batch #250 / 625
Loss:	1.5914206504821777

training epoch 341 / 500, batch #275 / 625
Loss:	1.724056601524353

training epoch 341 / 500, batch #300 / 625
Loss:	2.0076234340667725

training epoch 341 / 500, batch #325 / 625
Loss:	1.7162399291992188

training epoch 341 / 500, batch #350 / 625
Loss:	1.5804775953292847

training epoch 341 / 500, batch #375 / 625
Loss:	1.8925249576568604

training epoch 341 / 500, batch #400 / 625
Loss:	1.8681918382644653

training epoch 341 / 500, batch #425 / 625
Loss:	1.855800986289978

training epoch 341 / 500, batch #450 / 625
Loss:	1.6810280084609985

training epoch 341 / 500, batch #475 / 625
Loss:	1.805694341659546

training epoch 341 / 500, batch #500 / 625
Loss:	1.754597783088684

training epoch 341 / 500, batch #525 / 625
Loss:	1.7999268770217896

training epoch 341 / 500, batch #550 / 625
Loss:	1.720790147781372

training epoch 341 / 500, batch #575 / 625
Loss:	1.9523837566375732

training epoch 341 / 500, batch #600 / 625
Loss:	1.6843253374099731

training epoch 342 / 500, batch #0 / 625
Loss:	1.6809266805648804

training epoch 342 / 500, batch #25 / 625
Loss:	1.760580062866211

training epoch 342 / 500, batch #50 / 625
Loss:	1.9183590412139893

training epoch 342 / 500, batch #75 / 625
Loss:	1.6969236135482788

training epoch 342 / 500, batch #100 / 625
Loss:	1.7101131677627563

training epoch 342 / 500, batch #125 / 625
Loss:	1.8697017431259155

training epoch 342 / 500, batch #150 / 625
Loss:	1.8011529445648193

training epoch 342 / 500, batch #175 / 625
Loss:	1.7259646654129028

training epoch 342 / 500, batch #200 / 625
Loss:	1.7855061292648315

training epoch 342 / 500, batch #225 / 625
Loss:	1.9124585390090942

training epoch 342 / 500, batch #250 / 625
Loss:	1.6328535079956055

training epoch 342 / 500, batch #275 / 625
Loss:	1.4686827659606934

training epoch 342 / 500, batch #300 / 625
Loss:	1.69498610496521

training epoch 342 / 500, batch #325 / 625
Loss:	1.6825093030929565

training epoch 342 / 500, batch #350 / 625
Loss:	1.8237853050231934

training epoch 342 / 500, batch #375 / 625
Loss:	1.7713229656219482

training epoch 342 / 500, batch #400 / 625
Loss:	1.8395878076553345

training epoch 342 / 500, batch #425 / 625
Loss:	1.5635679960250854

training epoch 342 / 500, batch #450 / 625
Loss:	1.7809652090072632

training epoch 342 / 500, batch #475 / 625
Loss:	1.8032840490341187

training epoch 342 / 500, batch #500 / 625
Loss:	1.7249003648757935

training epoch 342 / 500, batch #525 / 625
Loss:	1.5015817880630493

training epoch 342 / 500, batch #550 / 625
Loss:	1.7656984329223633

training epoch 342 / 500, batch #575 / 625
Loss:	1.6849583387374878

training epoch 342 / 500, batch #600 / 625
Loss:	1.8715111017227173

training epoch 343 / 500, batch #0 / 625
Loss:	1.6467127799987793

training epoch 343 / 500, batch #25 / 625
Loss:	1.9359322786331177

training epoch 343 / 500, batch #50 / 625
Loss:	1.6149346828460693

training epoch 343 / 500, batch #75 / 625
Loss:	1.9545314311981201

training epoch 343 / 500, batch #100 / 625
Loss:	1.707066297531128

training epoch 343 / 500, batch #125 / 625
Loss:	1.7523651123046875

training epoch 343 / 500, batch #150 / 625
Loss:	1.5685304403305054

training epoch 343 / 500, batch #175 / 625
Loss:	1.6057947874069214

training epoch 343 / 500, batch #200 / 625
Loss:	1.8279391527175903

training epoch 343 / 500, batch #225 / 625
Loss:	1.7603332996368408

training epoch 343 / 500, batch #250 / 625
Loss:	1.6930227279663086

training epoch 343 / 500, batch #275 / 625
Loss:	1.52945876121521

training epoch 343 / 500, batch #300 / 625
Loss:	1.9424221515655518

training epoch 343 / 500, batch #325 / 625
Loss:	1.7111999988555908

training epoch 343 / 500, batch #350 / 625
Loss:	1.5651599168777466

training epoch 343 / 500, batch #375 / 625
Loss:	1.8041720390319824

training epoch 343 / 500, batch #400 / 625
Loss:	1.7907629013061523

training epoch 343 / 500, batch #425 / 625
Loss:	1.7457904815673828

training epoch 343 / 500, batch #450 / 625
Loss:	1.525827169418335

training epoch 343 / 500, batch #475 / 625
Loss:	1.6800401210784912

training epoch 343 / 500, batch #500 / 625
Loss:	1.700217604637146

training epoch 343 / 500, batch #525 / 625
Loss:	1.8236757516860962

training epoch 343 / 500, batch #550 / 625
Loss:	1.7707408666610718

training epoch 343 / 500, batch #575 / 625
Loss:	1.8275066614151

training epoch 343 / 500, batch #600 / 625
Loss:	1.628551721572876

training epoch 344 / 500, batch #0 / 625
Loss:	1.4575135707855225

training epoch 344 / 500, batch #25 / 625
Loss:	1.6786822080612183

training epoch 344 / 500, batch #50 / 625
Loss:	1.4927562475204468

training epoch 344 / 500, batch #75 / 625
Loss:	1.514832615852356

training epoch 344 / 500, batch #100 / 625
Loss:	1.5611685514450073

training epoch 344 / 500, batch #125 / 625
Loss:	1.7485218048095703

training epoch 344 / 500, batch #150 / 625
Loss:	1.8729276657104492

training epoch 344 / 500, batch #175 / 625
Loss:	1.8852779865264893

training epoch 344 / 500, batch #200 / 625
Loss:	1.6078425645828247

training epoch 344 / 500, batch #225 / 625
Loss:	1.7154616117477417

training epoch 344 / 500, batch #250 / 625
Loss:	1.5858278274536133

training epoch 344 / 500, batch #275 / 625
Loss:	1.4973758459091187

training epoch 344 / 500, batch #300 / 625
Loss:	1.6620392799377441

training epoch 344 / 500, batch #325 / 625
Loss:	1.7965562343597412

training epoch 344 / 500, batch #350 / 625
Loss:	1.7118438482284546

training epoch 344 / 500, batch #375 / 625
Loss:	1.9719048738479614

training epoch 344 / 500, batch #400 / 625
Loss:	1.6449313163757324

training epoch 344 / 500, batch #425 / 625
Loss:	1.9280941486358643

training epoch 344 / 500, batch #450 / 625
Loss:	1.733567237854004

training epoch 344 / 500, batch #475 / 625
Loss:	1.8127435445785522

training epoch 344 / 500, batch #500 / 625
Loss:	1.8925127983093262

training epoch 344 / 500, batch #525 / 625
Loss:	1.7341891527175903

training epoch 344 / 500, batch #550 / 625
Loss:	1.682768702507019

training epoch 344 / 500, batch #575 / 625
Loss:	1.838763952255249

training epoch 344 / 500, batch #600 / 625
Loss:	1.644355297088623

training epoch 345 / 500, batch #0 / 625
Loss:	1.873878002166748

training epoch 345 / 500, batch #25 / 625
Loss:	1.7735352516174316

training epoch 345 / 500, batch #50 / 625
Loss:	1.8827937841415405

training epoch 345 / 500, batch #75 / 625
Loss:	1.856513500213623

training epoch 345 / 500, batch #100 / 625
Loss:	1.825482964515686

training epoch 345 / 500, batch #125 / 625
Loss:	1.5304028987884521

training epoch 345 / 500, batch #150 / 625
Loss:	1.8646342754364014

training epoch 345 / 500, batch #175 / 625
Loss:	1.7161176204681396

training epoch 345 / 500, batch #200 / 625
Loss:	1.9787667989730835

training epoch 345 / 500, batch #225 / 625
Loss:	1.7843481302261353

training epoch 345 / 500, batch #250 / 625
Loss:	1.610355019569397

training epoch 345 / 500, batch #275 / 625
Loss:	1.6391761302947998

training epoch 345 / 500, batch #300 / 625
Loss:	1.7576481103897095

training epoch 345 / 500, batch #325 / 625
Loss:	1.566872477531433

training epoch 345 / 500, batch #350 / 625
Loss:	1.5350583791732788

training epoch 345 / 500, batch #375 / 625
Loss:	1.6402381658554077

training epoch 345 / 500, batch #400 / 625
Loss:	1.7585923671722412

training epoch 345 / 500, batch #425 / 625
Loss:	1.5382812023162842

training epoch 345 / 500, batch #450 / 625
Loss:	1.6562221050262451

training epoch 345 / 500, batch #475 / 625
Loss:	1.737960934638977

training epoch 345 / 500, batch #500 / 625
Loss:	1.9865379333496094

training epoch 345 / 500, batch #525 / 625
Loss:	1.9553648233413696

training epoch 345 / 500, batch #550 / 625
Loss:	1.7858952283859253

training epoch 345 / 500, batch #575 / 625
Loss:	1.5942163467407227

training epoch 345 / 500, batch #600 / 625
Loss:	1.7603607177734375

training epoch 346 / 500, batch #0 / 625
Loss:	1.6849195957183838

training epoch 346 / 500, batch #25 / 625
Loss:	1.832160234451294

training epoch 346 / 500, batch #50 / 625
Loss:	1.5206413269042969

training epoch 346 / 500, batch #75 / 625
Loss:	1.7990838289260864

training epoch 346 / 500, batch #100 / 625
Loss:	1.5663087368011475

training epoch 346 / 500, batch #125 / 625
Loss:	1.6347309350967407

training epoch 346 / 500, batch #150 / 625
Loss:	1.6131902933120728

training epoch 346 / 500, batch #175 / 625
Loss:	1.7216403484344482

training epoch 346 / 500, batch #200 / 625
Loss:	1.6013026237487793

training epoch 346 / 500, batch #225 / 625
Loss:	1.4862499237060547

training epoch 346 / 500, batch #250 / 625
Loss:	1.7530741691589355

training epoch 346 / 500, batch #275 / 625
Loss:	1.6908562183380127

training epoch 346 / 500, batch #300 / 625
Loss:	1.4945201873779297

training epoch 346 / 500, batch #325 / 625
Loss:	1.8168768882751465

training epoch 346 / 500, batch #350 / 625
Loss:	1.7977148294448853

training epoch 346 / 500, batch #375 / 625
Loss:	1.7958362102508545

training epoch 346 / 500, batch #400 / 625
Loss:	1.720060110092163

training epoch 346 / 500, batch #425 / 625
Loss:	1.9788939952850342

training epoch 346 / 500, batch #450 / 625
Loss:	1.9767082929611206

training epoch 346 / 500, batch #475 / 625
Loss:	2.056088924407959

training epoch 346 / 500, batch #500 / 625
Loss:	1.8587278127670288

training epoch 346 / 500, batch #525 / 625
Loss:	1.8125958442687988

training epoch 346 / 500, batch #550 / 625
Loss:	1.6183558702468872

training epoch 346 / 500, batch #575 / 625
Loss:	1.5757197141647339

training epoch 346 / 500, batch #600 / 625
Loss:	1.809996485710144

training epoch 347 / 500, batch #0 / 625
Loss:	1.9053322076797485

training epoch 347 / 500, batch #25 / 625
Loss:	1.9786653518676758

training epoch 347 / 500, batch #50 / 625
Loss:	1.5318176746368408

training epoch 347 / 500, batch #75 / 625
Loss:	1.5252492427825928

training epoch 347 / 500, batch #100 / 625
Loss:	1.840065836906433

training epoch 347 / 500, batch #125 / 625
Loss:	1.7521942853927612

training epoch 347 / 500, batch #150 / 625
Loss:	1.7720272541046143

training epoch 347 / 500, batch #175 / 625
Loss:	1.712051272392273

training epoch 347 / 500, batch #200 / 625
Loss:	1.9028204679489136

training epoch 347 / 500, batch #225 / 625
Loss:	1.7700470685958862

training epoch 347 / 500, batch #250 / 625
Loss:	1.809759497642517

training epoch 347 / 500, batch #275 / 625
Loss:	1.5783867835998535

training epoch 347 / 500, batch #300 / 625
Loss:	1.8825037479400635

training epoch 347 / 500, batch #325 / 625
Loss:	1.6851295232772827

training epoch 347 / 500, batch #350 / 625
Loss:	1.6731948852539062

training epoch 347 / 500, batch #375 / 625
Loss:	1.7470356225967407

training epoch 347 / 500, batch #400 / 625
Loss:	1.8149173259735107

training epoch 347 / 500, batch #425 / 625
Loss:	1.6021145582199097

training epoch 347 / 500, batch #450 / 625
Loss:	1.7036590576171875

training epoch 347 / 500, batch #475 / 625
Loss:	1.7959544658660889

training epoch 347 / 500, batch #500 / 625
Loss:	1.5437647104263306

training epoch 347 / 500, batch #525 / 625
Loss:	1.9631582498550415

training epoch 347 / 500, batch #550 / 625
Loss:	2.0052690505981445

training epoch 347 / 500, batch #575 / 625
Loss:	1.4584031105041504

training epoch 347 / 500, batch #600 / 625
Loss:	1.7854907512664795

training epoch 348 / 500, batch #0 / 625
Loss:	1.8784924745559692

training epoch 348 / 500, batch #25 / 625
Loss:	1.784460425376892

training epoch 348 / 500, batch #50 / 625
Loss:	1.883482813835144

training epoch 348 / 500, batch #75 / 625
Loss:	1.4750101566314697

training epoch 348 / 500, batch #100 / 625
Loss:	1.8551948070526123

training epoch 348 / 500, batch #125 / 625
Loss:	1.9231040477752686

training epoch 348 / 500, batch #150 / 625
Loss:	1.7838389873504639

training epoch 348 / 500, batch #175 / 625
Loss:	1.5646921396255493

training epoch 348 / 500, batch #200 / 625
Loss:	1.6941168308258057

training epoch 348 / 500, batch #225 / 625
Loss:	1.8165791034698486

training epoch 348 / 500, batch #250 / 625
Loss:	1.5211988687515259

training epoch 348 / 500, batch #275 / 625
Loss:	1.6796529293060303

training epoch 348 / 500, batch #300 / 625
Loss:	1.51654052734375

training epoch 348 / 500, batch #325 / 625
Loss:	1.6529957056045532

training epoch 348 / 500, batch #350 / 625
Loss:	1.6871062517166138

training epoch 348 / 500, batch #375 / 625
Loss:	1.6522045135498047

training epoch 348 / 500, batch #400 / 625
Loss:	1.8256059885025024

training epoch 348 / 500, batch #425 / 625
Loss:	1.9547961950302124

training epoch 348 / 500, batch #450 / 625
Loss:	1.8667538166046143

training epoch 348 / 500, batch #475 / 625
Loss:	1.6434624195098877

training epoch 348 / 500, batch #500 / 625
Loss:	1.594645619392395

training epoch 348 / 500, batch #525 / 625
Loss:	1.6438217163085938

training epoch 348 / 500, batch #550 / 625
Loss:	1.6780415773391724

training epoch 348 / 500, batch #575 / 625
Loss:	1.8399988412857056

training epoch 348 / 500, batch #600 / 625
Loss:	1.7784541845321655

training epoch 349 / 500, batch #0 / 625
Loss:	1.6901490688323975

training epoch 349 / 500, batch #25 / 625
Loss:	1.7165683507919312

training epoch 349 / 500, batch #50 / 625
Loss:	1.7578130960464478

training epoch 349 / 500, batch #75 / 625
Loss:	1.7242671251296997

training epoch 349 / 500, batch #100 / 625
Loss:	1.636691927909851

training epoch 349 / 500, batch #125 / 625
Loss:	1.58906090259552

training epoch 349 / 500, batch #150 / 625
Loss:	1.8968578577041626

training epoch 349 / 500, batch #175 / 625
Loss:	1.5354115962982178

training epoch 349 / 500, batch #200 / 625
Loss:	1.3664580583572388

training epoch 349 / 500, batch #225 / 625
Loss:	1.9820643663406372

training epoch 349 / 500, batch #250 / 625
Loss:	1.6127477884292603

training epoch 349 / 500, batch #275 / 625
Loss:	1.6151952743530273

training epoch 349 / 500, batch #300 / 625
Loss:	1.6278326511383057

training epoch 349 / 500, batch #325 / 625
Loss:	1.5332691669464111

training epoch 349 / 500, batch #350 / 625
Loss:	1.6445564031600952

training epoch 349 / 500, batch #375 / 625
Loss:	1.7481874227523804

training epoch 349 / 500, batch #400 / 625
Loss:	1.8018817901611328

training epoch 349 / 500, batch #425 / 625
Loss:	1.8664406538009644

training epoch 349 / 500, batch #450 / 625
Loss:	1.421005368232727

training epoch 349 / 500, batch #475 / 625
Loss:	1.4099345207214355

training epoch 349 / 500, batch #500 / 625
Loss:	1.8237717151641846

training epoch 349 / 500, batch #525 / 625
Loss:	1.8465180397033691

training epoch 349 / 500, batch #550 / 625
Loss:	1.8313214778900146

training epoch 349 / 500, batch #575 / 625
Loss:	1.970680594444275

training epoch 349 / 500, batch #600 / 625
Loss:	1.8774858713150024

training epoch 350 / 500, batch #0 / 625
Loss:	1.726594090461731

training epoch 350 / 500, batch #25 / 625
Loss:	1.7238796949386597

training epoch 350 / 500, batch #50 / 625
Loss:	1.7137256860733032

training epoch 350 / 500, batch #75 / 625
Loss:	1.6517575979232788

training epoch 350 / 500, batch #100 / 625
Loss:	1.6922286748886108

training epoch 350 / 500, batch #125 / 625
Loss:	1.8639765977859497

training epoch 350 / 500, batch #150 / 625
Loss:	1.9002479314804077

training epoch 350 / 500, batch #175 / 625
Loss:	1.544256567955017

training epoch 350 / 500, batch #200 / 625
Loss:	1.752732753753662

training epoch 350 / 500, batch #225 / 625
Loss:	1.585310697555542

training epoch 350 / 500, batch #250 / 625
Loss:	1.4912282228469849

training epoch 350 / 500, batch #275 / 625
Loss:	1.8046236038208008

training epoch 350 / 500, batch #300 / 625
Loss:	1.7125654220581055

training epoch 350 / 500, batch #325 / 625
Loss:	1.6436604261398315

training epoch 350 / 500, batch #350 / 625
Loss:	1.6425604820251465

training epoch 350 / 500, batch #375 / 625
Loss:	1.688517689704895

training epoch 350 / 500, batch #400 / 625
Loss:	1.8464076519012451

training epoch 350 / 500, batch #425 / 625
Loss:	1.6640450954437256

training epoch 350 / 500, batch #450 / 625
Loss:	1.7999457120895386

training epoch 350 / 500, batch #475 / 625
Loss:	1.8637900352478027

training epoch 350 / 500, batch #500 / 625
Loss:	1.7164971828460693

training epoch 350 / 500, batch #525 / 625
Loss:	1.6846473217010498

training epoch 350 / 500, batch #550 / 625
Loss:	1.8360799551010132

training epoch 350 / 500, batch #575 / 625
Loss:	1.6738895177841187

training epoch 350 / 500, batch #600 / 625
Loss:	1.6189677715301514

training epoch 351 / 500, batch #0 / 625
Loss:	1.756957769393921

training epoch 351 / 500, batch #25 / 625
Loss:	1.5647680759429932

training epoch 351 / 500, batch #50 / 625
Loss:	1.955460786819458

training epoch 351 / 500, batch #75 / 625
Loss:	1.8309595584869385

training epoch 351 / 500, batch #100 / 625
Loss:	1.3602741956710815

training epoch 351 / 500, batch #125 / 625
Loss:	1.735530138015747

training epoch 351 / 500, batch #150 / 625
Loss:	1.7390542030334473

training epoch 351 / 500, batch #175 / 625
Loss:	1.6607369184494019

training epoch 351 / 500, batch #200 / 625
Loss:	1.4630560874938965

training epoch 351 / 500, batch #225 / 625
Loss:	1.65966796875

training epoch 351 / 500, batch #250 / 625
Loss:	1.856450080871582

training epoch 351 / 500, batch #275 / 625
Loss:	1.5669384002685547

training epoch 351 / 500, batch #300 / 625
Loss:	1.8616571426391602

training epoch 351 / 500, batch #325 / 625
Loss:	1.420020580291748

training epoch 351 / 500, batch #350 / 625
Loss:	1.6744329929351807

training epoch 351 / 500, batch #375 / 625
Loss:	1.7143515348434448

training epoch 351 / 500, batch #400 / 625
Loss:	1.487420916557312

training epoch 351 / 500, batch #425 / 625
Loss:	1.7203612327575684

training epoch 351 / 500, batch #450 / 625
Loss:	1.8038071393966675

training epoch 351 / 500, batch #475 / 625
Loss:	1.8654557466506958

training epoch 351 / 500, batch #500 / 625
Loss:	1.8565648794174194

training epoch 351 / 500, batch #525 / 625
Loss:	1.9169189929962158

training epoch 351 / 500, batch #550 / 625
Loss:	1.6023088693618774

training epoch 351 / 500, batch #575 / 625
Loss:	1.7096748352050781

training epoch 351 / 500, batch #600 / 625
Loss:	1.7970441579818726

training epoch 352 / 500, batch #0 / 625
Loss:	1.8195146322250366

training epoch 352 / 500, batch #25 / 625
Loss:	1.5265967845916748

training epoch 352 / 500, batch #50 / 625
Loss:	1.7219500541687012

training epoch 352 / 500, batch #75 / 625
Loss:	1.6555845737457275

training epoch 352 / 500, batch #100 / 625
Loss:	1.8634741306304932

training epoch 352 / 500, batch #125 / 625
Loss:	1.8638447523117065

training epoch 352 / 500, batch #150 / 625
Loss:	1.784606695175171

training epoch 352 / 500, batch #175 / 625
Loss:	1.5546197891235352

training epoch 352 / 500, batch #200 / 625
Loss:	1.5160592794418335

training epoch 352 / 500, batch #225 / 625
Loss:	1.8333942890167236

training epoch 352 / 500, batch #250 / 625
Loss:	1.8912265300750732

training epoch 352 / 500, batch #275 / 625
Loss:	1.6170952320098877

training epoch 352 / 500, batch #300 / 625
Loss:	1.7589963674545288

training epoch 352 / 500, batch #325 / 625
Loss:	1.6184159517288208

training epoch 352 / 500, batch #350 / 625
Loss:	1.5842211246490479

training epoch 352 / 500, batch #375 / 625
Loss:	1.6958463191986084

training epoch 352 / 500, batch #400 / 625
Loss:	1.5416882038116455

training epoch 352 / 500, batch #425 / 625
Loss:	1.8936325311660767

training epoch 352 / 500, batch #450 / 625
Loss:	1.7312440872192383

training epoch 352 / 500, batch #475 / 625
Loss:	1.6424059867858887

training epoch 352 / 500, batch #500 / 625
Loss:	1.6871755123138428

training epoch 352 / 500, batch #525 / 625
Loss:	1.9151031970977783

training epoch 352 / 500, batch #550 / 625
Loss:	1.444257378578186

training epoch 352 / 500, batch #575 / 625
Loss:	2.037332534790039

training epoch 352 / 500, batch #600 / 625
Loss:	1.758244514465332

training epoch 353 / 500, batch #0 / 625
Loss:	1.9230842590332031

training epoch 353 / 500, batch #25 / 625
Loss:	1.744807481765747

training epoch 353 / 500, batch #50 / 625
Loss:	1.7520496845245361

training epoch 353 / 500, batch #75 / 625
Loss:	1.738340139389038

training epoch 353 / 500, batch #100 / 625
Loss:	1.7279810905456543

training epoch 353 / 500, batch #125 / 625
Loss:	1.734462857246399

training epoch 353 / 500, batch #150 / 625
Loss:	1.5967594385147095

training epoch 353 / 500, batch #175 / 625
Loss:	1.6059973239898682

training epoch 353 / 500, batch #200 / 625
Loss:	1.6217855215072632

training epoch 353 / 500, batch #225 / 625
Loss:	1.740868091583252

training epoch 353 / 500, batch #250 / 625
Loss:	1.7903835773468018

training epoch 353 / 500, batch #275 / 625
Loss:	2.0909950733184814

training epoch 353 / 500, batch #300 / 625
Loss:	1.6362794637680054

training epoch 353 / 500, batch #325 / 625
Loss:	1.7596290111541748

training epoch 353 / 500, batch #350 / 625
Loss:	1.6328169107437134

training epoch 353 / 500, batch #375 / 625
Loss:	1.8484116792678833

training epoch 353 / 500, batch #400 / 625
Loss:	1.6442580223083496

training epoch 353 / 500, batch #425 / 625
Loss:	1.624659538269043

training epoch 353 / 500, batch #450 / 625
Loss:	1.7611356973648071

training epoch 353 / 500, batch #475 / 625
Loss:	1.7035971879959106

training epoch 353 / 500, batch #500 / 625
Loss:	1.7847965955734253

training epoch 353 / 500, batch #525 / 625
Loss:	1.6637822389602661

training epoch 353 / 500, batch #550 / 625
Loss:	1.7728999853134155

training epoch 353 / 500, batch #575 / 625
Loss:	1.8781882524490356

training epoch 353 / 500, batch #600 / 625
Loss:	2.0232315063476562

training epoch 354 / 500, batch #0 / 625
Loss:	1.6859874725341797

training epoch 354 / 500, batch #25 / 625
Loss:	1.8314303159713745

training epoch 354 / 500, batch #50 / 625
Loss:	1.8580031394958496

training epoch 354 / 500, batch #75 / 625
Loss:	1.6080632209777832

training epoch 354 / 500, batch #100 / 625
Loss:	1.7488435506820679

training epoch 354 / 500, batch #125 / 625
Loss:	1.5519614219665527

training epoch 354 / 500, batch #150 / 625
Loss:	1.6721527576446533

training epoch 354 / 500, batch #175 / 625
Loss:	1.7037405967712402

training epoch 354 / 500, batch #200 / 625
Loss:	1.7334628105163574

training epoch 354 / 500, batch #225 / 625
Loss:	2.084458112716675

training epoch 354 / 500, batch #250 / 625
Loss:	1.7026938199996948

training epoch 354 / 500, batch #275 / 625
Loss:	1.9611749649047852

training epoch 354 / 500, batch #300 / 625
Loss:	1.7526984214782715

training epoch 354 / 500, batch #325 / 625
Loss:	1.6267263889312744

training epoch 354 / 500, batch #350 / 625
Loss:	1.800392985343933

training epoch 354 / 500, batch #375 / 625
Loss:	1.860097885131836

training epoch 354 / 500, batch #400 / 625
Loss:	1.610485315322876

training epoch 354 / 500, batch #425 / 625
Loss:	1.7374275922775269

training epoch 354 / 500, batch #450 / 625
Loss:	1.702463150024414

training epoch 354 / 500, batch #475 / 625
Loss:	1.6407321691513062

training epoch 354 / 500, batch #500 / 625
Loss:	1.8395240306854248

training epoch 354 / 500, batch #525 / 625
Loss:	1.5149873495101929

training epoch 354 / 500, batch #550 / 625
Loss:	1.7746556997299194

training epoch 354 / 500, batch #575 / 625
Loss:	1.7416712045669556

training epoch 354 / 500, batch #600 / 625
Loss:	1.9194157123565674

training epoch 355 / 500, batch #0 / 625
Loss:	1.482041358947754

training epoch 355 / 500, batch #25 / 625
Loss:	1.6056218147277832

training epoch 355 / 500, batch #50 / 625
Loss:	1.7940348386764526

training epoch 355 / 500, batch #75 / 625
Loss:	1.8215901851654053

training epoch 355 / 500, batch #100 / 625
Loss:	1.7876001596450806

training epoch 355 / 500, batch #125 / 625
Loss:	1.665450930595398

training epoch 355 / 500, batch #150 / 625
Loss:	1.9264593124389648

training epoch 355 / 500, batch #175 / 625
Loss:	1.691750407218933

training epoch 355 / 500, batch #200 / 625
Loss:	1.476335048675537

training epoch 355 / 500, batch #225 / 625
Loss:	1.9601624011993408

training epoch 355 / 500, batch #250 / 625
Loss:	1.8788015842437744

training epoch 355 / 500, batch #275 / 625
Loss:	1.9330440759658813

training epoch 355 / 500, batch #300 / 625
Loss:	1.7542744874954224

training epoch 355 / 500, batch #325 / 625
Loss:	1.6366972923278809

training epoch 355 / 500, batch #350 / 625
Loss:	1.8539574146270752

training epoch 355 / 500, batch #375 / 625
Loss:	1.6768652200698853

training epoch 355 / 500, batch #400 / 625
Loss:	1.690906047821045

training epoch 355 / 500, batch #425 / 625
Loss:	1.9249417781829834

training epoch 355 / 500, batch #450 / 625
Loss:	2.0155160427093506

training epoch 355 / 500, batch #475 / 625
Loss:	1.780970811843872

training epoch 355 / 500, batch #500 / 625
Loss:	1.639737844467163

training epoch 355 / 500, batch #525 / 625
Loss:	1.7905641794204712

training epoch 355 / 500, batch #550 / 625
Loss:	1.5895322561264038

training epoch 355 / 500, batch #575 / 625
Loss:	1.7208385467529297

training epoch 355 / 500, batch #600 / 625
Loss:	1.6734776496887207

training epoch 356 / 500, batch #0 / 625
Loss:	1.7825164794921875

training epoch 356 / 500, batch #25 / 625
Loss:	1.6791599988937378

training epoch 356 / 500, batch #50 / 625
Loss:	1.7322618961334229

training epoch 356 / 500, batch #75 / 625
Loss:	1.957432746887207

training epoch 356 / 500, batch #100 / 625
Loss:	1.7323356866836548

training epoch 356 / 500, batch #125 / 625
Loss:	1.850103735923767

training epoch 356 / 500, batch #150 / 625
Loss:	1.6685059070587158

training epoch 356 / 500, batch #175 / 625
Loss:	1.726711630821228

training epoch 356 / 500, batch #200 / 625
Loss:	1.8660650253295898

training epoch 356 / 500, batch #225 / 625
Loss:	1.9100793600082397

training epoch 356 / 500, batch #250 / 625
Loss:	1.8353699445724487

training epoch 356 / 500, batch #275 / 625
Loss:	1.3388416767120361

training epoch 356 / 500, batch #300 / 625
Loss:	1.4866447448730469

training epoch 356 / 500, batch #325 / 625
Loss:	1.7919349670410156

training epoch 356 / 500, batch #350 / 625
Loss:	1.711958885192871

training epoch 356 / 500, batch #375 / 625
Loss:	1.573452353477478

training epoch 356 / 500, batch #400 / 625
Loss:	2.0248124599456787

training epoch 356 / 500, batch #425 / 625
Loss:	2.013662099838257

training epoch 356 / 500, batch #450 / 625
Loss:	1.8810150623321533

training epoch 356 / 500, batch #475 / 625
Loss:	1.6717277765274048

training epoch 356 / 500, batch #500 / 625
Loss:	1.6199724674224854

training epoch 356 / 500, batch #525 / 625
Loss:	1.9223092794418335

training epoch 356 / 500, batch #550 / 625
Loss:	1.791274905204773

training epoch 356 / 500, batch #575 / 625
Loss:	1.911922574043274

training epoch 356 / 500, batch #600 / 625
Loss:	1.3397852182388306

training epoch 357 / 500, batch #0 / 625
Loss:	1.5894566774368286

training epoch 357 / 500, batch #25 / 625
Loss:	1.7829768657684326

training epoch 357 / 500, batch #50 / 625
Loss:	1.725717544555664

training epoch 357 / 500, batch #75 / 625
Loss:	1.4846073389053345

training epoch 357 / 500, batch #100 / 625
Loss:	1.580765724182129

training epoch 357 / 500, batch #125 / 625
Loss:	1.5405486822128296

training epoch 357 / 500, batch #150 / 625
Loss:	1.685619831085205

training epoch 357 / 500, batch #175 / 625
Loss:	1.819144368171692

training epoch 357 / 500, batch #200 / 625
Loss:	1.6997020244598389

training epoch 357 / 500, batch #225 / 625
Loss:	1.793068766593933

training epoch 357 / 500, batch #250 / 625
Loss:	1.6637428998947144

training epoch 357 / 500, batch #275 / 625
Loss:	1.854816198348999

training epoch 357 / 500, batch #300 / 625
Loss:	1.78240966796875

training epoch 357 / 500, batch #325 / 625
Loss:	1.8010176420211792

training epoch 357 / 500, batch #350 / 625
Loss:	1.4195151329040527

training epoch 357 / 500, batch #375 / 625
Loss:	1.8400663137435913

training epoch 357 / 500, batch #400 / 625
Loss:	1.6889469623565674

training epoch 357 / 500, batch #425 / 625
Loss:	1.578403115272522

training epoch 357 / 500, batch #450 / 625
Loss:	1.806986927986145

training epoch 357 / 500, batch #475 / 625
Loss:	1.3456848859786987

training epoch 357 / 500, batch #500 / 625
Loss:	1.4113428592681885

training epoch 357 / 500, batch #525 / 625
Loss:	1.9878668785095215

training epoch 357 / 500, batch #550 / 625
Loss:	1.6785862445831299

training epoch 357 / 500, batch #575 / 625
Loss:	1.6558024883270264

training epoch 357 / 500, batch #600 / 625
Loss:	1.6561647653579712

training epoch 358 / 500, batch #0 / 625
Loss:	1.6655398607254028

training epoch 358 / 500, batch #25 / 625
Loss:	1.6153920888900757

training epoch 358 / 500, batch #50 / 625
Loss:	1.5749564170837402

training epoch 358 / 500, batch #75 / 625
Loss:	1.6668474674224854

training epoch 358 / 500, batch #100 / 625
Loss:	1.596806526184082

training epoch 358 / 500, batch #125 / 625
Loss:	1.6861262321472168

training epoch 358 / 500, batch #150 / 625
Loss:	1.804876446723938

training epoch 358 / 500, batch #175 / 625
Loss:	1.4644564390182495

training epoch 358 / 500, batch #200 / 625
Loss:	1.5885099172592163

training epoch 358 / 500, batch #225 / 625
Loss:	1.7092355489730835

training epoch 358 / 500, batch #250 / 625
Loss:	1.8565013408660889

training epoch 358 / 500, batch #275 / 625
Loss:	1.5468770265579224

training epoch 358 / 500, batch #300 / 625
Loss:	1.7167092561721802

training epoch 358 / 500, batch #325 / 625
Loss:	1.7559082508087158

training epoch 358 / 500, batch #350 / 625
Loss:	1.8557718992233276

training epoch 358 / 500, batch #375 / 625
Loss:	1.7412889003753662

training epoch 358 / 500, batch #400 / 625
Loss:	1.5861473083496094

training epoch 358 / 500, batch #425 / 625
Loss:	1.8021436929702759

training epoch 358 / 500, batch #450 / 625
Loss:	1.8231855630874634

training epoch 358 / 500, batch #475 / 625
Loss:	1.5245245695114136

training epoch 358 / 500, batch #500 / 625
Loss:	1.7945835590362549

training epoch 358 / 500, batch #525 / 625
Loss:	1.8860361576080322

training epoch 358 / 500, batch #550 / 625
Loss:	1.9693330526351929

training epoch 358 / 500, batch #575 / 625
Loss:	1.7436572313308716

training epoch 358 / 500, batch #600 / 625
Loss:	1.6119945049285889

training epoch 359 / 500, batch #0 / 625
Loss:	1.96243417263031

training epoch 359 / 500, batch #25 / 625
Loss:	1.5096248388290405

training epoch 359 / 500, batch #50 / 625
Loss:	1.8135523796081543

training epoch 359 / 500, batch #75 / 625
Loss:	1.5839009284973145

training epoch 359 / 500, batch #100 / 625
Loss:	1.7503294944763184

training epoch 359 / 500, batch #125 / 625
Loss:	1.8919272422790527

training epoch 359 / 500, batch #150 / 625
Loss:	1.5784039497375488

training epoch 359 / 500, batch #175 / 625
Loss:	1.638522982597351

training epoch 359 / 500, batch #200 / 625
Loss:	1.7702053785324097

training epoch 359 / 500, batch #225 / 625
Loss:	1.7033538818359375

training epoch 359 / 500, batch #250 / 625
Loss:	1.5798461437225342

training epoch 359 / 500, batch #275 / 625
Loss:	1.7245326042175293

training epoch 359 / 500, batch #300 / 625
Loss:	1.5747382640838623

training epoch 359 / 500, batch #325 / 625
Loss:	1.5612590312957764

training epoch 359 / 500, batch #350 / 625
Loss:	1.665614128112793

training epoch 359 / 500, batch #375 / 625
Loss:	1.6836938858032227

training epoch 359 / 500, batch #400 / 625
Loss:	1.868813395500183

training epoch 359 / 500, batch #425 / 625
Loss:	1.6461693048477173

training epoch 359 / 500, batch #450 / 625
Loss:	1.65255868434906

training epoch 359 / 500, batch #475 / 625
Loss:	1.5111833810806274

training epoch 359 / 500, batch #500 / 625
Loss:	1.6496292352676392

training epoch 359 / 500, batch #525 / 625
Loss:	1.6677148342132568

training epoch 359 / 500, batch #550 / 625
Loss:	1.4089339971542358

training epoch 359 / 500, batch #575 / 625
Loss:	1.6783114671707153

training epoch 359 / 500, batch #600 / 625
Loss:	1.7982779741287231

training epoch 360 / 500, batch #0 / 625
Loss:	1.65035080909729

training epoch 360 / 500, batch #25 / 625
Loss:	1.4912171363830566

training epoch 360 / 500, batch #50 / 625
Loss:	1.466341257095337

training epoch 360 / 500, batch #75 / 625
Loss:	1.7378644943237305

training epoch 360 / 500, batch #100 / 625
Loss:	1.6626129150390625

training epoch 360 / 500, batch #125 / 625
Loss:	1.6902567148208618

training epoch 360 / 500, batch #150 / 625
Loss:	1.8498021364212036

training epoch 360 / 500, batch #175 / 625
Loss:	1.7361763715744019

training epoch 360 / 500, batch #200 / 625
Loss:	1.6454946994781494

training epoch 360 / 500, batch #225 / 625
Loss:	1.7777520418167114

training epoch 360 / 500, batch #250 / 625
Loss:	1.7806503772735596

training epoch 360 / 500, batch #275 / 625
Loss:	1.6057473421096802

training epoch 360 / 500, batch #300 / 625
Loss:	1.5705159902572632

training epoch 360 / 500, batch #325 / 625
Loss:	1.8893842697143555

training epoch 360 / 500, batch #350 / 625
Loss:	1.774671196937561

training epoch 360 / 500, batch #375 / 625
Loss:	1.5282038450241089

training epoch 360 / 500, batch #400 / 625
Loss:	1.6986241340637207

training epoch 360 / 500, batch #425 / 625
Loss:	1.7908194065093994

training epoch 360 / 500, batch #450 / 625
Loss:	1.7970757484436035

training epoch 360 / 500, batch #475 / 625
Loss:	1.4229668378829956

training epoch 360 / 500, batch #500 / 625
Loss:	1.6071851253509521

training epoch 360 / 500, batch #525 / 625
Loss:	1.9053024053573608

training epoch 360 / 500, batch #550 / 625
Loss:	1.6772518157958984

training epoch 360 / 500, batch #575 / 625
Loss:	1.8563662767410278

training epoch 360 / 500, batch #600 / 625
Loss:	1.797200322151184

training epoch 361 / 500, batch #0 / 625
Loss:	1.555021047592163

training epoch 361 / 500, batch #25 / 625
Loss:	1.7307454347610474

training epoch 361 / 500, batch #50 / 625
Loss:	1.6755374670028687

training epoch 361 / 500, batch #75 / 625
Loss:	1.7449642419815063

training epoch 361 / 500, batch #100 / 625
Loss:	1.735201358795166

training epoch 361 / 500, batch #125 / 625
Loss:	1.799554705619812

training epoch 361 / 500, batch #150 / 625
Loss:	1.54744553565979

training epoch 361 / 500, batch #175 / 625
Loss:	1.6942797899246216

training epoch 361 / 500, batch #200 / 625
Loss:	1.6752046346664429

training epoch 361 / 500, batch #225 / 625
Loss:	1.7222967147827148

training epoch 361 / 500, batch #250 / 625
Loss:	1.6689776182174683

training epoch 361 / 500, batch #275 / 625
Loss:	1.7059253454208374

training epoch 361 / 500, batch #300 / 625
Loss:	1.4606168270111084

training epoch 361 / 500, batch #325 / 625
Loss:	1.4595189094543457

training epoch 361 / 500, batch #350 / 625
Loss:	1.6118310689926147

training epoch 361 / 500, batch #375 / 625
Loss:	1.7953249216079712

training epoch 361 / 500, batch #400 / 625
Loss:	1.6128849983215332

training epoch 361 / 500, batch #425 / 625
Loss:	1.6855534315109253

training epoch 361 / 500, batch #450 / 625
Loss:	1.5128273963928223

training epoch 361 / 500, batch #475 / 625
Loss:	1.8427417278289795

training epoch 361 / 500, batch #500 / 625
Loss:	1.8728221654891968

training epoch 361 / 500, batch #525 / 625
Loss:	1.5425424575805664

training epoch 361 / 500, batch #550 / 625
Loss:	1.7060058116912842

training epoch 361 / 500, batch #575 / 625
Loss:	1.8013817071914673

training epoch 361 / 500, batch #600 / 625
Loss:	1.8267464637756348

training epoch 362 / 500, batch #0 / 625
Loss:	1.5423330068588257

training epoch 362 / 500, batch #25 / 625
Loss:	1.689097285270691

training epoch 362 / 500, batch #50 / 625
Loss:	1.7177201509475708

training epoch 362 / 500, batch #75 / 625
Loss:	1.6952736377716064

training epoch 362 / 500, batch #100 / 625
Loss:	1.855260968208313

training epoch 362 / 500, batch #125 / 625
Loss:	1.8426786661148071

training epoch 362 / 500, batch #150 / 625
Loss:	1.7969986200332642

training epoch 362 / 500, batch #175 / 625
Loss:	1.8291891813278198

training epoch 362 / 500, batch #200 / 625
Loss:	1.936032772064209

training epoch 362 / 500, batch #225 / 625
Loss:	1.755852460861206

training epoch 362 / 500, batch #250 / 625
Loss:	1.7747193574905396

training epoch 362 / 500, batch #275 / 625
Loss:	1.5152900218963623

training epoch 362 / 500, batch #300 / 625
Loss:	1.664154052734375

training epoch 362 / 500, batch #325 / 625
Loss:	1.5018967390060425

training epoch 362 / 500, batch #350 / 625
Loss:	1.7244236469268799

training epoch 362 / 500, batch #375 / 625
Loss:	1.8227814435958862

training epoch 362 / 500, batch #400 / 625
Loss:	1.793100357055664

training epoch 362 / 500, batch #425 / 625
Loss:	1.6962110996246338

training epoch 362 / 500, batch #450 / 625
Loss:	1.6830214262008667

training epoch 362 / 500, batch #475 / 625
Loss:	1.825057029724121

training epoch 362 / 500, batch #500 / 625
Loss:	1.790435552597046

training epoch 362 / 500, batch #525 / 625
Loss:	1.639540433883667

training epoch 362 / 500, batch #550 / 625
Loss:	1.853650689125061

training epoch 362 / 500, batch #575 / 625
Loss:	1.6052740812301636

training epoch 362 / 500, batch #600 / 625
Loss:	1.7668150663375854

training epoch 363 / 500, batch #0 / 625
Loss:	1.7096521854400635

training epoch 363 / 500, batch #25 / 625
Loss:	1.5588195323944092

training epoch 363 / 500, batch #50 / 625
Loss:	1.8194726705551147

training epoch 363 / 500, batch #75 / 625
Loss:	1.7130839824676514

training epoch 363 / 500, batch #100 / 625
Loss:	1.7644585371017456

training epoch 363 / 500, batch #125 / 625
Loss:	1.7603542804718018

training epoch 363 / 500, batch #150 / 625
Loss:	1.8269801139831543

training epoch 363 / 500, batch #175 / 625
Loss:	1.653852939605713

training epoch 363 / 500, batch #200 / 625
Loss:	1.7142431735992432

training epoch 363 / 500, batch #225 / 625
Loss:	1.6216448545455933

training epoch 363 / 500, batch #250 / 625
Loss:	1.5405219793319702

training epoch 363 / 500, batch #275 / 625
Loss:	1.578847050666809

training epoch 363 / 500, batch #300 / 625
Loss:	1.5847630500793457

training epoch 363 / 500, batch #325 / 625
Loss:	1.471096396446228

training epoch 363 / 500, batch #350 / 625
Loss:	1.7094204425811768

training epoch 363 / 500, batch #375 / 625
Loss:	1.825006127357483

training epoch 363 / 500, batch #400 / 625
Loss:	1.719067096710205

training epoch 363 / 500, batch #425 / 625
Loss:	1.740500807762146

training epoch 363 / 500, batch #450 / 625
Loss:	1.8097068071365356

training epoch 363 / 500, batch #475 / 625
Loss:	1.5150089263916016

training epoch 363 / 500, batch #500 / 625
Loss:	1.7724837064743042

training epoch 363 / 500, batch #525 / 625
Loss:	1.6881601810455322

training epoch 363 / 500, batch #550 / 625
Loss:	1.7589185237884521

training epoch 363 / 500, batch #575 / 625
Loss:	1.7967790365219116

training epoch 363 / 500, batch #600 / 625
Loss:	1.6421575546264648

training epoch 364 / 500, batch #0 / 625
Loss:	1.7127362489700317

training epoch 364 / 500, batch #25 / 625
Loss:	1.5618183612823486

training epoch 364 / 500, batch #50 / 625
Loss:	2.0325522422790527

training epoch 364 / 500, batch #75 / 625
Loss:	1.7215393781661987

training epoch 364 / 500, batch #100 / 625
Loss:	1.5427039861679077

training epoch 364 / 500, batch #125 / 625
Loss:	1.7668488025665283

training epoch 364 / 500, batch #150 / 625
Loss:	1.7338281869888306

training epoch 364 / 500, batch #175 / 625
Loss:	1.7057411670684814

training epoch 364 / 500, batch #200 / 625
Loss:	1.736842155456543

training epoch 364 / 500, batch #225 / 625
Loss:	1.6353635787963867

training epoch 364 / 500, batch #250 / 625
Loss:	1.975472331047058

training epoch 364 / 500, batch #275 / 625
Loss:	1.6491070985794067

training epoch 364 / 500, batch #300 / 625
Loss:	1.7526487112045288

training epoch 364 / 500, batch #325 / 625
Loss:	1.8695374727249146

training epoch 364 / 500, batch #350 / 625
Loss:	1.701185941696167

training epoch 364 / 500, batch #375 / 625
Loss:	1.6247016191482544

training epoch 364 / 500, batch #400 / 625
Loss:	1.756898045539856

training epoch 364 / 500, batch #425 / 625
Loss:	1.765940546989441

training epoch 364 / 500, batch #450 / 625
Loss:	1.7591770887374878

training epoch 364 / 500, batch #475 / 625
Loss:	1.8878659009933472

training epoch 364 / 500, batch #500 / 625
Loss:	1.595640778541565

training epoch 364 / 500, batch #525 / 625
Loss:	1.8256860971450806

training epoch 364 / 500, batch #550 / 625
Loss:	1.6508601903915405

training epoch 364 / 500, batch #575 / 625
Loss:	1.6254709959030151

training epoch 364 / 500, batch #600 / 625
Loss:	1.489621639251709

training epoch 365 / 500, batch #0 / 625
Loss:	1.9116761684417725

training epoch 365 / 500, batch #25 / 625
Loss:	1.4640586376190186

training epoch 365 / 500, batch #50 / 625
Loss:	1.7237434387207031

training epoch 365 / 500, batch #75 / 625
Loss:	1.8481473922729492

training epoch 365 / 500, batch #100 / 625
Loss:	1.7150517702102661

training epoch 365 / 500, batch #125 / 625
Loss:	1.5991830825805664

training epoch 365 / 500, batch #150 / 625
Loss:	1.9262522459030151

training epoch 365 / 500, batch #175 / 625
Loss:	1.7594183683395386

training epoch 365 / 500, batch #200 / 625
Loss:	1.6717411279678345

training epoch 365 / 500, batch #225 / 625
Loss:	1.737794041633606

training epoch 365 / 500, batch #250 / 625
Loss:	1.7419618368148804

training epoch 365 / 500, batch #275 / 625
Loss:	1.7478598356246948

training epoch 365 / 500, batch #300 / 625
Loss:	1.6515672206878662

training epoch 365 / 500, batch #325 / 625
Loss:	1.6203705072402954

training epoch 365 / 500, batch #350 / 625
Loss:	2.0252418518066406

training epoch 365 / 500, batch #375 / 625
Loss:	1.8970832824707031

training epoch 365 / 500, batch #400 / 625
Loss:	1.6170824766159058

training epoch 365 / 500, batch #425 / 625
Loss:	1.820043921470642

training epoch 365 / 500, batch #450 / 625
Loss:	1.6569429636001587

training epoch 365 / 500, batch #475 / 625
Loss:	1.4755773544311523

training epoch 365 / 500, batch #500 / 625
Loss:	1.7121250629425049

training epoch 365 / 500, batch #525 / 625
Loss:	1.7140158414840698

training epoch 365 / 500, batch #550 / 625
Loss:	2.0463247299194336

training epoch 365 / 500, batch #575 / 625
Loss:	1.5296515226364136

training epoch 365 / 500, batch #600 / 625
Loss:	1.698853611946106

training epoch 366 / 500, batch #0 / 625
Loss:	1.5899736881256104

training epoch 366 / 500, batch #25 / 625
Loss:	1.7206858396530151

training epoch 366 / 500, batch #50 / 625
Loss:	1.8960853815078735

training epoch 366 / 500, batch #75 / 625
Loss:	1.682658314704895

training epoch 366 / 500, batch #100 / 625
Loss:	1.7406154870986938

training epoch 366 / 500, batch #125 / 625
Loss:	1.629042387008667

training epoch 366 / 500, batch #150 / 625
Loss:	1.5406270027160645

training epoch 366 / 500, batch #175 / 625
Loss:	1.5078794956207275

training epoch 366 / 500, batch #200 / 625
Loss:	1.5536837577819824

training epoch 366 / 500, batch #225 / 625
Loss:	1.9416141510009766

training epoch 366 / 500, batch #250 / 625
Loss:	1.5476478338241577

training epoch 366 / 500, batch #275 / 625
Loss:	1.830043911933899

training epoch 366 / 500, batch #300 / 625
Loss:	1.6940593719482422

training epoch 366 / 500, batch #325 / 625
Loss:	1.736502766609192

training epoch 366 / 500, batch #350 / 625
Loss:	1.793605923652649

training epoch 366 / 500, batch #375 / 625
Loss:	1.8234810829162598

training epoch 366 / 500, batch #400 / 625
Loss:	1.7332335710525513

training epoch 366 / 500, batch #425 / 625
Loss:	1.5935583114624023

training epoch 366 / 500, batch #450 / 625
Loss:	1.6790448427200317

training epoch 366 / 500, batch #475 / 625
Loss:	1.615797758102417

training epoch 366 / 500, batch #500 / 625
Loss:	1.6281625032424927

training epoch 366 / 500, batch #525 / 625
Loss:	1.856431007385254

training epoch 366 / 500, batch #550 / 625
Loss:	1.6470705270767212

training epoch 366 / 500, batch #575 / 625
Loss:	1.7016576528549194

training epoch 366 / 500, batch #600 / 625
Loss:	1.6798841953277588

training epoch 367 / 500, batch #0 / 625
Loss:	1.5850356817245483

training epoch 367 / 500, batch #25 / 625
Loss:	1.9547840356826782

training epoch 367 / 500, batch #50 / 625
Loss:	1.4114224910736084

training epoch 367 / 500, batch #75 / 625
Loss:	1.6476447582244873

training epoch 367 / 500, batch #100 / 625
Loss:	1.5717899799346924

training epoch 367 / 500, batch #125 / 625
Loss:	1.7143739461898804

training epoch 367 / 500, batch #150 / 625
Loss:	1.874140977859497

training epoch 367 / 500, batch #175 / 625
Loss:	1.6954599618911743

training epoch 367 / 500, batch #200 / 625
Loss:	2.0807058811187744

training epoch 367 / 500, batch #225 / 625
Loss:	1.4824379682540894

training epoch 367 / 500, batch #250 / 625
Loss:	1.8239713907241821

training epoch 367 / 500, batch #275 / 625
Loss:	1.3370050191879272

training epoch 367 / 500, batch #300 / 625
Loss:	1.8752251863479614

training epoch 367 / 500, batch #325 / 625
Loss:	1.5909230709075928

training epoch 367 / 500, batch #350 / 625
Loss:	1.6358747482299805

training epoch 367 / 500, batch #375 / 625
Loss:	1.753792643547058

training epoch 367 / 500, batch #400 / 625
Loss:	1.677831768989563

training epoch 367 / 500, batch #425 / 625
Loss:	1.6660256385803223

training epoch 367 / 500, batch #450 / 625
Loss:	1.8105359077453613

training epoch 367 / 500, batch #475 / 625
Loss:	1.8695605993270874

training epoch 367 / 500, batch #500 / 625
Loss:	1.756088376045227

training epoch 367 / 500, batch #525 / 625
Loss:	1.5880945920944214

training epoch 367 / 500, batch #550 / 625
Loss:	1.6163685321807861

training epoch 367 / 500, batch #575 / 625
Loss:	1.6843997240066528

training epoch 367 / 500, batch #600 / 625
Loss:	1.6017999649047852

training epoch 368 / 500, batch #0 / 625
Loss:	1.5571558475494385

training epoch 368 / 500, batch #25 / 625
Loss:	1.7711358070373535

training epoch 368 / 500, batch #50 / 625
Loss:	1.6278939247131348

training epoch 368 / 500, batch #75 / 625
Loss:	1.7302076816558838

training epoch 368 / 500, batch #100 / 625
Loss:	1.8013287782669067

training epoch 368 / 500, batch #125 / 625
Loss:	1.7049416303634644

training epoch 368 / 500, batch #150 / 625
Loss:	1.6706559658050537

training epoch 368 / 500, batch #175 / 625
Loss:	1.6793066263198853

training epoch 368 / 500, batch #200 / 625
Loss:	1.664522647857666

training epoch 368 / 500, batch #225 / 625
Loss:	1.693272590637207

training epoch 368 / 500, batch #250 / 625
Loss:	1.5295169353485107

training epoch 368 / 500, batch #275 / 625
Loss:	1.7033650875091553

training epoch 368 / 500, batch #300 / 625
Loss:	1.493748664855957

training epoch 368 / 500, batch #325 / 625
Loss:	1.676307201385498

training epoch 368 / 500, batch #350 / 625
Loss:	1.855169415473938

training epoch 368 / 500, batch #375 / 625
Loss:	1.5045779943466187

training epoch 368 / 500, batch #400 / 625
Loss:	1.8544838428497314

training epoch 368 / 500, batch #425 / 625
Loss:	1.8220094442367554

training epoch 368 / 500, batch #450 / 625
Loss:	1.8928066492080688

training epoch 368 / 500, batch #475 / 625
Loss:	1.6938530206680298

training epoch 368 / 500, batch #500 / 625
Loss:	1.6966476440429688

training epoch 368 / 500, batch #525 / 625
Loss:	1.9329769611358643

training epoch 368 / 500, batch #550 / 625
Loss:	1.762357234954834

training epoch 368 / 500, batch #575 / 625
Loss:	1.8664453029632568

training epoch 368 / 500, batch #600 / 625
Loss:	1.753941535949707

training epoch 369 / 500, batch #0 / 625
Loss:	1.848925232887268

training epoch 369 / 500, batch #25 / 625
Loss:	1.4620217084884644

training epoch 369 / 500, batch #50 / 625
Loss:	1.7141307592391968

training epoch 369 / 500, batch #75 / 625
Loss:	1.6906343698501587

training epoch 369 / 500, batch #100 / 625
Loss:	1.556731104850769

training epoch 369 / 500, batch #125 / 625
Loss:	1.9305070638656616

training epoch 369 / 500, batch #150 / 625
Loss:	1.61478853225708

training epoch 369 / 500, batch #175 / 625
Loss:	1.553481101989746

training epoch 369 / 500, batch #200 / 625
Loss:	1.673972249031067

training epoch 369 / 500, batch #225 / 625
Loss:	1.790290355682373

training epoch 369 / 500, batch #250 / 625
Loss:	1.9143368005752563

training epoch 369 / 500, batch #275 / 625
Loss:	1.9680163860321045

training epoch 369 / 500, batch #300 / 625
Loss:	1.5451018810272217

training epoch 369 / 500, batch #325 / 625
Loss:	1.7695233821868896

training epoch 369 / 500, batch #350 / 625
Loss:	1.8382744789123535

training epoch 369 / 500, batch #375 / 625
Loss:	1.8607468605041504

training epoch 369 / 500, batch #400 / 625
Loss:	1.6714739799499512

training epoch 369 / 500, batch #425 / 625
Loss:	1.8039429187774658

training epoch 369 / 500, batch #450 / 625
Loss:	1.6753979921340942

training epoch 369 / 500, batch #475 / 625
Loss:	1.7934279441833496

training epoch 369 / 500, batch #500 / 625
Loss:	1.7217857837677002

training epoch 369 / 500, batch #525 / 625
Loss:	1.9907068014144897

training epoch 369 / 500, batch #550 / 625
Loss:	1.9552260637283325

training epoch 369 / 500, batch #575 / 625
Loss:	1.7240151166915894

training epoch 369 / 500, batch #600 / 625
Loss:	1.9126379489898682

training epoch 370 / 500, batch #0 / 625
Loss:	1.5760782957077026

training epoch 370 / 500, batch #25 / 625
Loss:	1.6514753103256226

training epoch 370 / 500, batch #50 / 625
Loss:	1.859424114227295

training epoch 370 / 500, batch #75 / 625
Loss:	1.6145830154418945

training epoch 370 / 500, batch #100 / 625
Loss:	1.601953148841858

training epoch 370 / 500, batch #125 / 625
Loss:	1.5214922428131104

training epoch 370 / 500, batch #150 / 625
Loss:	1.8933838605880737

training epoch 370 / 500, batch #175 / 625
Loss:	1.4576787948608398

training epoch 370 / 500, batch #200 / 625
Loss:	1.6969226598739624

training epoch 370 / 500, batch #225 / 625
Loss:	1.6348328590393066

training epoch 370 / 500, batch #250 / 625
Loss:	1.5657918453216553

training epoch 370 / 500, batch #275 / 625
Loss:	1.8149182796478271

training epoch 370 / 500, batch #300 / 625
Loss:	1.8703333139419556

training epoch 370 / 500, batch #325 / 625
Loss:	1.5989935398101807

training epoch 370 / 500, batch #350 / 625
Loss:	1.7229746580123901

training epoch 370 / 500, batch #375 / 625
Loss:	1.6242916584014893

training epoch 370 / 500, batch #400 / 625
Loss:	1.5581637620925903

training epoch 370 / 500, batch #425 / 625
Loss:	1.697322964668274

training epoch 370 / 500, batch #450 / 625
Loss:	1.907575249671936

training epoch 370 / 500, batch #475 / 625
Loss:	1.6716978549957275

training epoch 370 / 500, batch #500 / 625
Loss:	1.7987697124481201

training epoch 370 / 500, batch #525 / 625
Loss:	1.829696774482727

training epoch 370 / 500, batch #550 / 625
Loss:	1.556419014930725

training epoch 370 / 500, batch #575 / 625
Loss:	1.7578985691070557

training epoch 370 / 500, batch #600 / 625
Loss:	1.6013776063919067

training epoch 371 / 500, batch #0 / 625
Loss:	1.7251088619232178

training epoch 371 / 500, batch #25 / 625
Loss:	2.0843422412872314

training epoch 371 / 500, batch #50 / 625
Loss:	1.894135594367981

training epoch 371 / 500, batch #75 / 625
Loss:	1.7058296203613281

training epoch 371 / 500, batch #100 / 625
Loss:	1.8894556760787964

training epoch 371 / 500, batch #125 / 625
Loss:	1.7710132598876953

training epoch 371 / 500, batch #150 / 625
Loss:	1.5141637325286865

training epoch 371 / 500, batch #175 / 625
Loss:	1.7477205991744995

training epoch 371 / 500, batch #200 / 625
Loss:	1.4711966514587402

training epoch 371 / 500, batch #225 / 625
Loss:	1.9588618278503418

training epoch 371 / 500, batch #250 / 625
Loss:	1.80588698387146

training epoch 371 / 500, batch #275 / 625
Loss:	1.4678541421890259

training epoch 371 / 500, batch #300 / 625
Loss:	1.8933979272842407

training epoch 371 / 500, batch #325 / 625
Loss:	1.7013822793960571

training epoch 371 / 500, batch #350 / 625
Loss:	1.6322417259216309

training epoch 371 / 500, batch #375 / 625
Loss:	1.5924996137619019

training epoch 371 / 500, batch #400 / 625
Loss:	1.8241395950317383

training epoch 371 / 500, batch #425 / 625
Loss:	1.689393401145935

training epoch 371 / 500, batch #450 / 625
Loss:	1.663779616355896

training epoch 371 / 500, batch #475 / 625
Loss:	1.9405637979507446

training epoch 371 / 500, batch #500 / 625
Loss:	1.6320533752441406

training epoch 371 / 500, batch #525 / 625
Loss:	1.486329436302185

training epoch 371 / 500, batch #550 / 625
Loss:	1.802359700202942

training epoch 371 / 500, batch #575 / 625
Loss:	1.6213393211364746

training epoch 371 / 500, batch #600 / 625
Loss:	1.7391854524612427

training epoch 372 / 500, batch #0 / 625
Loss:	1.5011128187179565

training epoch 372 / 500, batch #25 / 625
Loss:	1.7530854940414429

training epoch 372 / 500, batch #50 / 625
Loss:	1.735293984413147

training epoch 372 / 500, batch #75 / 625
Loss:	1.6863781213760376

training epoch 372 / 500, batch #100 / 625
Loss:	1.950490117073059

training epoch 372 / 500, batch #125 / 625
Loss:	1.9154629707336426

training epoch 372 / 500, batch #150 / 625
Loss:	1.5857678651809692

training epoch 372 / 500, batch #175 / 625
Loss:	1.8242276906967163

training epoch 372 / 500, batch #200 / 625
Loss:	1.5544185638427734

training epoch 372 / 500, batch #225 / 625
Loss:	1.8504482507705688

training epoch 372 / 500, batch #250 / 625
Loss:	1.6129423379898071

training epoch 372 / 500, batch #275 / 625
Loss:	1.9988377094268799

training epoch 372 / 500, batch #300 / 625
Loss:	1.7859323024749756

training epoch 372 / 500, batch #325 / 625
Loss:	1.6496278047561646

training epoch 372 / 500, batch #350 / 625
Loss:	1.905598759651184

training epoch 372 / 500, batch #375 / 625
Loss:	1.5897222757339478

training epoch 372 / 500, batch #400 / 625
Loss:	1.7899936437606812

training epoch 372 / 500, batch #425 / 625
Loss:	1.6235530376434326

training epoch 372 / 500, batch #450 / 625
Loss:	1.5329844951629639

training epoch 372 / 500, batch #475 / 625
Loss:	1.7034716606140137

training epoch 372 / 500, batch #500 / 625
Loss:	1.6831222772598267

training epoch 372 / 500, batch #525 / 625
Loss:	1.8415448665618896

training epoch 372 / 500, batch #550 / 625
Loss:	1.4956183433532715

training epoch 372 / 500, batch #575 / 625
Loss:	1.7542974948883057

training epoch 372 / 500, batch #600 / 625
Loss:	1.6320154666900635

training epoch 373 / 500, batch #0 / 625
Loss:	1.4630630016326904

training epoch 373 / 500, batch #25 / 625
Loss:	1.841473937034607

training epoch 373 / 500, batch #50 / 625
Loss:	1.4787070751190186

training epoch 373 / 500, batch #75 / 625
Loss:	1.6613341569900513

training epoch 373 / 500, batch #100 / 625
Loss:	1.5209629535675049

training epoch 373 / 500, batch #125 / 625
Loss:	1.85320246219635

training epoch 373 / 500, batch #150 / 625
Loss:	1.7243167161941528

training epoch 373 / 500, batch #175 / 625
Loss:	1.7595560550689697

training epoch 373 / 500, batch #200 / 625
Loss:	1.7526358366012573

training epoch 373 / 500, batch #225 / 625
Loss:	1.5454274415969849

training epoch 373 / 500, batch #250 / 625
Loss:	1.7361761331558228

training epoch 373 / 500, batch #275 / 625
Loss:	1.672694206237793

training epoch 373 / 500, batch #300 / 625
Loss:	1.6634914875030518

training epoch 373 / 500, batch #325 / 625
Loss:	1.8368651866912842

training epoch 373 / 500, batch #350 / 625
Loss:	1.9183663129806519

training epoch 373 / 500, batch #375 / 625
Loss:	1.3677676916122437

training epoch 373 / 500, batch #400 / 625
Loss:	1.7866251468658447

training epoch 373 / 500, batch #425 / 625
Loss:	1.740787148475647

training epoch 373 / 500, batch #450 / 625
Loss:	1.6909334659576416

training epoch 373 / 500, batch #475 / 625
Loss:	1.846314549446106

training epoch 373 / 500, batch #500 / 625
Loss:	1.8451803922653198

training epoch 373 / 500, batch #525 / 625
Loss:	1.7042553424835205

training epoch 373 / 500, batch #550 / 625
Loss:	1.6607537269592285

training epoch 373 / 500, batch #575 / 625
Loss:	1.9584342241287231

training epoch 373 / 500, batch #600 / 625
Loss:	1.6682723760604858

training epoch 374 / 500, batch #0 / 625
Loss:	1.7299634218215942

training epoch 374 / 500, batch #25 / 625
Loss:	1.8915544748306274

training epoch 374 / 500, batch #50 / 625
Loss:	1.6341866254806519

training epoch 374 / 500, batch #75 / 625
Loss:	1.7746647596359253

training epoch 374 / 500, batch #100 / 625
Loss:	1.791818618774414

training epoch 374 / 500, batch #125 / 625
Loss:	1.6192113161087036

training epoch 374 / 500, batch #150 / 625
Loss:	1.7632049322128296

training epoch 374 / 500, batch #175 / 625
Loss:	1.7041635513305664

training epoch 374 / 500, batch #200 / 625
Loss:	1.5623524188995361

training epoch 374 / 500, batch #225 / 625
Loss:	1.7626442909240723

training epoch 374 / 500, batch #250 / 625
Loss:	1.7412737607955933

training epoch 374 / 500, batch #275 / 625
Loss:	1.8152227401733398

training epoch 374 / 500, batch #300 / 625
Loss:	1.7866853475570679

training epoch 374 / 500, batch #325 / 625
Loss:	1.821974515914917

training epoch 374 / 500, batch #350 / 625
Loss:	1.700737476348877

training epoch 374 / 500, batch #375 / 625
Loss:	1.6271697282791138

training epoch 374 / 500, batch #400 / 625
Loss:	1.5782135725021362

training epoch 374 / 500, batch #425 / 625
Loss:	2.018314838409424

training epoch 374 / 500, batch #450 / 625
Loss:	1.629831075668335

training epoch 374 / 500, batch #475 / 625
Loss:	1.9103970527648926

training epoch 374 / 500, batch #500 / 625
Loss:	1.8573943376541138

training epoch 374 / 500, batch #525 / 625
Loss:	1.776735782623291

training epoch 374 / 500, batch #550 / 625
Loss:	1.7710392475128174

training epoch 374 / 500, batch #575 / 625
Loss:	1.6375631093978882

training epoch 374 / 500, batch #600 / 625
Loss:	1.7656843662261963

training epoch 375 / 500, batch #0 / 625
Loss:	1.6866830587387085

training epoch 375 / 500, batch #25 / 625
Loss:	1.6855213642120361

training epoch 375 / 500, batch #50 / 625
Loss:	1.7529211044311523

training epoch 375 / 500, batch #75 / 625
Loss:	1.8660051822662354

training epoch 375 / 500, batch #100 / 625
Loss:	1.7424578666687012

training epoch 375 / 500, batch #125 / 625
Loss:	1.667190670967102

training epoch 375 / 500, batch #150 / 625
Loss:	1.6388651132583618

training epoch 375 / 500, batch #175 / 625
Loss:	1.7649203538894653

training epoch 375 / 500, batch #200 / 625
Loss:	1.575200080871582

training epoch 375 / 500, batch #225 / 625
Loss:	1.9192357063293457

training epoch 375 / 500, batch #250 / 625
Loss:	1.905235767364502

training epoch 375 / 500, batch #275 / 625
Loss:	2.103461980819702

training epoch 375 / 500, batch #300 / 625
Loss:	1.8507640361785889

training epoch 375 / 500, batch #325 / 625
Loss:	1.7828694581985474

training epoch 375 / 500, batch #350 / 625
Loss:	1.5495833158493042

training epoch 375 / 500, batch #375 / 625
Loss:	1.4828717708587646

training epoch 375 / 500, batch #400 / 625
Loss:	1.561460256576538

training epoch 375 / 500, batch #425 / 625
Loss:	1.7990738153457642

training epoch 375 / 500, batch #450 / 625
Loss:	1.5949811935424805

training epoch 375 / 500, batch #475 / 625
Loss:	1.5227508544921875

training epoch 375 / 500, batch #500 / 625
Loss:	1.6539902687072754

training epoch 375 / 500, batch #525 / 625
Loss:	1.890357255935669

training epoch 375 / 500, batch #550 / 625
Loss:	1.8168121576309204

training epoch 375 / 500, batch #575 / 625
Loss:	1.7618409395217896

training epoch 375 / 500, batch #600 / 625
Loss:	1.7776916027069092

training epoch 376 / 500, batch #0 / 625
Loss:	1.6200647354125977

training epoch 376 / 500, batch #25 / 625
Loss:	1.8591818809509277

training epoch 376 / 500, batch #50 / 625
Loss:	1.484789252281189

training epoch 376 / 500, batch #75 / 625
Loss:	2.051398277282715

training epoch 376 / 500, batch #100 / 625
Loss:	1.68996000289917

training epoch 376 / 500, batch #125 / 625
Loss:	1.629271149635315

training epoch 376 / 500, batch #150 / 625
Loss:	1.5556950569152832

training epoch 376 / 500, batch #175 / 625
Loss:	1.7451497316360474

training epoch 376 / 500, batch #200 / 625
Loss:	1.6769355535507202

training epoch 376 / 500, batch #225 / 625
Loss:	1.756900429725647

training epoch 376 / 500, batch #250 / 625
Loss:	1.6699663400650024

training epoch 376 / 500, batch #275 / 625
Loss:	1.6185322999954224

training epoch 376 / 500, batch #300 / 625
Loss:	1.6432498693466187

training epoch 376 / 500, batch #325 / 625
Loss:	1.4589252471923828

training epoch 376 / 500, batch #350 / 625
Loss:	1.8502815961837769

training epoch 376 / 500, batch #375 / 625
Loss:	1.6756017208099365

training epoch 376 / 500, batch #400 / 625
Loss:	1.6695829629898071

training epoch 376 / 500, batch #425 / 625
Loss:	1.9651408195495605

training epoch 376 / 500, batch #450 / 625
Loss:	1.6827757358551025

training epoch 376 / 500, batch #475 / 625
Loss:	1.6058876514434814

training epoch 376 / 500, batch #500 / 625
Loss:	1.8429632186889648

training epoch 376 / 500, batch #525 / 625
Loss:	1.8860238790512085

training epoch 376 / 500, batch #550 / 625
Loss:	1.799801230430603

training epoch 376 / 500, batch #575 / 625
Loss:	1.804708480834961

training epoch 376 / 500, batch #600 / 625
Loss:	1.731205940246582

training epoch 377 / 500, batch #0 / 625
Loss:	1.5987545251846313

training epoch 377 / 500, batch #25 / 625
Loss:	1.6796700954437256

training epoch 377 / 500, batch #50 / 625
Loss:	1.4522048234939575

training epoch 377 / 500, batch #75 / 625
Loss:	1.651843547821045

training epoch 377 / 500, batch #100 / 625
Loss:	1.7146066427230835

training epoch 377 / 500, batch #125 / 625
Loss:	1.5552217960357666

training epoch 377 / 500, batch #150 / 625
Loss:	1.9418765306472778

training epoch 377 / 500, batch #175 / 625
Loss:	1.7450050115585327

training epoch 377 / 500, batch #200 / 625
Loss:	1.7346351146697998

training epoch 377 / 500, batch #225 / 625
Loss:	1.6533100605010986

training epoch 377 / 500, batch #250 / 625
Loss:	1.754706859588623

training epoch 377 / 500, batch #275 / 625
Loss:	1.7387681007385254

training epoch 377 / 500, batch #300 / 625
Loss:	1.8834458589553833

training epoch 377 / 500, batch #325 / 625
Loss:	2.099433660507202

training epoch 377 / 500, batch #350 / 625
Loss:	1.931051254272461

training epoch 377 / 500, batch #375 / 625
Loss:	1.7106894254684448

training epoch 377 / 500, batch #400 / 625
Loss:	1.7158715724945068

training epoch 377 / 500, batch #425 / 625
Loss:	1.539621114730835

training epoch 377 / 500, batch #450 / 625
Loss:	1.640632152557373

training epoch 377 / 500, batch #475 / 625
Loss:	1.536035180091858

training epoch 377 / 500, batch #500 / 625
Loss:	1.7695679664611816

training epoch 377 / 500, batch #525 / 625
Loss:	1.7312697172164917

training epoch 377 / 500, batch #550 / 625
Loss:	1.4480640888214111

training epoch 377 / 500, batch #575 / 625
Loss:	1.6834787130355835

training epoch 377 / 500, batch #600 / 625
Loss:	1.780880093574524

training epoch 378 / 500, batch #0 / 625
Loss:	1.7610725164413452

training epoch 378 / 500, batch #25 / 625
Loss:	1.7076972723007202

training epoch 378 / 500, batch #50 / 625
Loss:	1.8125420808792114

training epoch 378 / 500, batch #75 / 625
Loss:	1.9155970811843872

training epoch 378 / 500, batch #100 / 625
Loss:	1.796993374824524

training epoch 378 / 500, batch #125 / 625
Loss:	1.6972730159759521

training epoch 378 / 500, batch #150 / 625
Loss:	1.6810014247894287

training epoch 378 / 500, batch #175 / 625
Loss:	1.9584412574768066

training epoch 378 / 500, batch #200 / 625
Loss:	1.6960684061050415

training epoch 378 / 500, batch #225 / 625
Loss:	1.5224159955978394

training epoch 378 / 500, batch #250 / 625
Loss:	1.7403638362884521

training epoch 378 / 500, batch #275 / 625
Loss:	1.6443862915039062

training epoch 378 / 500, batch #300 / 625
Loss:	1.676971673965454

training epoch 378 / 500, batch #325 / 625
Loss:	1.9389755725860596

training epoch 378 / 500, batch #350 / 625
Loss:	1.7109014987945557

training epoch 378 / 500, batch #375 / 625
Loss:	1.8374075889587402

training epoch 378 / 500, batch #400 / 625
Loss:	1.5319925546646118

training epoch 378 / 500, batch #425 / 625
Loss:	1.6758363246917725

training epoch 378 / 500, batch #450 / 625
Loss:	1.7323222160339355

training epoch 378 / 500, batch #475 / 625
Loss:	1.907623529434204

training epoch 378 / 500, batch #500 / 625
Loss:	1.9040180444717407

training epoch 378 / 500, batch #525 / 625
Loss:	1.674762487411499

training epoch 378 / 500, batch #550 / 625
Loss:	1.6727882623672485

training epoch 378 / 500, batch #575 / 625
Loss:	1.7813308238983154

training epoch 378 / 500, batch #600 / 625
Loss:	1.605483055114746

training epoch 379 / 500, batch #0 / 625
Loss:	1.6047203540802002

training epoch 379 / 500, batch #25 / 625
Loss:	1.7833714485168457

training epoch 379 / 500, batch #50 / 625
Loss:	1.4078409671783447

training epoch 379 / 500, batch #75 / 625
Loss:	1.5920071601867676

training epoch 379 / 500, batch #100 / 625
Loss:	1.3934091329574585

training epoch 379 / 500, batch #125 / 625
Loss:	1.7242604494094849

training epoch 379 / 500, batch #150 / 625
Loss:	1.8889341354370117

training epoch 379 / 500, batch #175 / 625
Loss:	1.7220250368118286

training epoch 379 / 500, batch #200 / 625
Loss:	1.814038872718811

training epoch 379 / 500, batch #225 / 625
Loss:	1.9923954010009766

training epoch 379 / 500, batch #250 / 625
Loss:	1.4575741291046143

training epoch 379 / 500, batch #275 / 625
Loss:	1.6445679664611816

training epoch 379 / 500, batch #300 / 625
Loss:	1.6989861726760864

training epoch 379 / 500, batch #325 / 625
Loss:	1.724891185760498

training epoch 379 / 500, batch #350 / 625
Loss:	1.8434288501739502

training epoch 379 / 500, batch #375 / 625
Loss:	1.7698700428009033

training epoch 379 / 500, batch #400 / 625
Loss:	1.7000001668930054

training epoch 379 / 500, batch #425 / 625
Loss:	1.9596257209777832

training epoch 379 / 500, batch #450 / 625
Loss:	1.5824766159057617

training epoch 379 / 500, batch #475 / 625
Loss:	1.8425310850143433

training epoch 379 / 500, batch #500 / 625
Loss:	1.534738302230835

training epoch 379 / 500, batch #525 / 625
Loss:	1.6015141010284424

training epoch 379 / 500, batch #550 / 625
Loss:	1.6463711261749268

training epoch 379 / 500, batch #575 / 625
Loss:	1.6468086242675781

training epoch 379 / 500, batch #600 / 625
Loss:	1.5643672943115234

training epoch 380 / 500, batch #0 / 625
Loss:	1.6110175848007202

training epoch 380 / 500, batch #25 / 625
Loss:	1.8924071788787842

training epoch 380 / 500, batch #50 / 625
Loss:	1.7322536706924438

training epoch 380 / 500, batch #75 / 625
Loss:	1.771500587463379

training epoch 380 / 500, batch #100 / 625
Loss:	1.685634970664978

training epoch 380 / 500, batch #125 / 625
Loss:	1.6525413990020752

training epoch 380 / 500, batch #150 / 625
Loss:	1.7821903228759766

training epoch 380 / 500, batch #175 / 625
Loss:	1.6600089073181152

training epoch 380 / 500, batch #200 / 625
Loss:	1.7769761085510254

training epoch 380 / 500, batch #225 / 625
Loss:	1.4851008653640747

training epoch 380 / 500, batch #250 / 625
Loss:	1.5324656963348389

training epoch 380 / 500, batch #275 / 625
Loss:	2.214777708053589

training epoch 380 / 500, batch #300 / 625
Loss:	1.650639533996582

training epoch 380 / 500, batch #325 / 625
Loss:	1.868237853050232

training epoch 380 / 500, batch #350 / 625
Loss:	1.5605700016021729

training epoch 380 / 500, batch #375 / 625
Loss:	1.7840800285339355

training epoch 380 / 500, batch #400 / 625
Loss:	1.4771769046783447

training epoch 380 / 500, batch #425 / 625
Loss:	2.084484338760376

training epoch 380 / 500, batch #450 / 625
Loss:	1.7894916534423828

training epoch 380 / 500, batch #475 / 625
Loss:	1.5342198610305786

training epoch 380 / 500, batch #500 / 625
Loss:	1.7964314222335815

training epoch 380 / 500, batch #525 / 625
Loss:	1.857243299484253

training epoch 380 / 500, batch #550 / 625
Loss:	1.7295533418655396

training epoch 380 / 500, batch #575 / 625
Loss:	1.8535763025283813

training epoch 380 / 500, batch #600 / 625
Loss:	1.7962678670883179

training epoch 381 / 500, batch #0 / 625
Loss:	1.7612955570220947

training epoch 381 / 500, batch #25 / 625
Loss:	1.7887364625930786

training epoch 381 / 500, batch #50 / 625
Loss:	1.7931106090545654

training epoch 381 / 500, batch #75 / 625
Loss:	1.8996798992156982

training epoch 381 / 500, batch #100 / 625
Loss:	1.801096796989441

training epoch 381 / 500, batch #125 / 625
Loss:	1.6582027673721313

training epoch 381 / 500, batch #150 / 625
Loss:	1.7929426431655884

training epoch 381 / 500, batch #175 / 625
Loss:	1.6852492094039917

training epoch 381 / 500, batch #200 / 625
Loss:	1.5999764204025269

training epoch 381 / 500, batch #225 / 625
Loss:	1.7956266403198242

training epoch 381 / 500, batch #250 / 625
Loss:	1.8588796854019165

training epoch 381 / 500, batch #275 / 625
Loss:	1.7336019277572632

training epoch 381 / 500, batch #300 / 625
Loss:	1.7247999906539917

training epoch 381 / 500, batch #325 / 625
Loss:	1.9971789121627808

training epoch 381 / 500, batch #350 / 625
Loss:	1.6619293689727783

training epoch 381 / 500, batch #375 / 625
Loss:	1.8980228900909424

training epoch 381 / 500, batch #400 / 625
Loss:	1.5923680067062378

training epoch 381 / 500, batch #425 / 625
Loss:	1.7573246955871582

training epoch 381 / 500, batch #450 / 625
Loss:	1.5375139713287354

training epoch 381 / 500, batch #475 / 625
Loss:	1.7411504983901978

training epoch 381 / 500, batch #500 / 625
Loss:	1.7049634456634521

training epoch 381 / 500, batch #525 / 625
Loss:	1.7721723318099976

training epoch 381 / 500, batch #550 / 625
Loss:	1.50932776927948

training epoch 381 / 500, batch #575 / 625
Loss:	1.673518419265747

training epoch 381 / 500, batch #600 / 625
Loss:	2.0741376876831055

training epoch 382 / 500, batch #0 / 625
Loss:	1.7467998266220093

training epoch 382 / 500, batch #25 / 625
Loss:	1.7892318964004517

training epoch 382 / 500, batch #50 / 625
Loss:	1.5811448097229004

training epoch 382 / 500, batch #75 / 625
Loss:	1.642870545387268

training epoch 382 / 500, batch #100 / 625
Loss:	1.4776642322540283

training epoch 382 / 500, batch #125 / 625
Loss:	1.5506480932235718

training epoch 382 / 500, batch #150 / 625
Loss:	1.8178309202194214

training epoch 382 / 500, batch #175 / 625
Loss:	1.8339836597442627

training epoch 382 / 500, batch #200 / 625
Loss:	1.6392327547073364

training epoch 382 / 500, batch #225 / 625
Loss:	2.0582239627838135

training epoch 382 / 500, batch #250 / 625
Loss:	1.8177142143249512

training epoch 382 / 500, batch #275 / 625
Loss:	1.539091944694519

training epoch 382 / 500, batch #300 / 625
Loss:	1.4613615274429321

training epoch 382 / 500, batch #325 / 625
Loss:	1.9307183027267456

training epoch 382 / 500, batch #350 / 625
Loss:	1.6660542488098145

training epoch 382 / 500, batch #375 / 625
Loss:	1.5660510063171387

training epoch 382 / 500, batch #400 / 625
Loss:	1.7747430801391602

training epoch 382 / 500, batch #425 / 625
Loss:	1.686160683631897

training epoch 382 / 500, batch #450 / 625
Loss:	2.1133992671966553

training epoch 382 / 500, batch #475 / 625
Loss:	1.7655447721481323

training epoch 382 / 500, batch #500 / 625
Loss:	1.8993011713027954

training epoch 382 / 500, batch #525 / 625
Loss:	1.5624301433563232

training epoch 382 / 500, batch #550 / 625
Loss:	1.7471586465835571

training epoch 382 / 500, batch #575 / 625
Loss:	1.9816393852233887

training epoch 382 / 500, batch #600 / 625
Loss:	1.6241705417633057

training epoch 383 / 500, batch #0 / 625
Loss:	1.4434261322021484

training epoch 383 / 500, batch #25 / 625
Loss:	1.6784398555755615

training epoch 383 / 500, batch #50 / 625
Loss:	1.4740581512451172

training epoch 383 / 500, batch #75 / 625
Loss:	1.645121693611145

training epoch 383 / 500, batch #100 / 625
Loss:	1.6719582080841064

training epoch 383 / 500, batch #125 / 625
Loss:	1.7459887266159058

training epoch 383 / 500, batch #150 / 625
Loss:	1.6684355735778809

training epoch 383 / 500, batch #175 / 625
Loss:	1.816405177116394

training epoch 383 / 500, batch #200 / 625
Loss:	1.7215852737426758

training epoch 383 / 500, batch #225 / 625
Loss:	1.9032450914382935

training epoch 383 / 500, batch #250 / 625
Loss:	1.7899186611175537

training epoch 383 / 500, batch #275 / 625
Loss:	1.852666974067688

training epoch 383 / 500, batch #300 / 625
Loss:	1.6543864011764526

training epoch 383 / 500, batch #325 / 625
Loss:	1.7411054372787476

training epoch 383 / 500, batch #350 / 625
Loss:	1.6817892789840698

training epoch 383 / 500, batch #375 / 625
Loss:	2.0462679862976074

training epoch 383 / 500, batch #400 / 625
Loss:	1.7433195114135742

training epoch 383 / 500, batch #425 / 625
Loss:	1.7821248769760132

training epoch 383 / 500, batch #450 / 625
Loss:	2.0279488563537598

training epoch 383 / 500, batch #475 / 625
Loss:	1.8892852067947388

training epoch 383 / 500, batch #500 / 625
Loss:	1.790802240371704

training epoch 383 / 500, batch #525 / 625
Loss:	1.7774063348770142

training epoch 383 / 500, batch #550 / 625
Loss:	1.6697163581848145

training epoch 383 / 500, batch #575 / 625
Loss:	1.7242748737335205

training epoch 383 / 500, batch #600 / 625
Loss:	1.543334722518921

training epoch 384 / 500, batch #0 / 625
Loss:	1.7805685997009277

training epoch 384 / 500, batch #25 / 625
Loss:	1.6536530256271362

training epoch 384 / 500, batch #50 / 625
Loss:	1.5826303958892822

training epoch 384 / 500, batch #75 / 625
Loss:	1.7296254634857178

training epoch 384 / 500, batch #100 / 625
Loss:	1.905676007270813

training epoch 384 / 500, batch #125 / 625
Loss:	1.741122841835022

training epoch 384 / 500, batch #150 / 625
Loss:	1.6046770811080933

training epoch 384 / 500, batch #175 / 625
Loss:	1.6886169910430908

training epoch 384 / 500, batch #200 / 625
Loss:	1.7221829891204834

training epoch 384 / 500, batch #225 / 625
Loss:	1.551609754562378

training epoch 384 / 500, batch #250 / 625
Loss:	1.7679392099380493

training epoch 384 / 500, batch #275 / 625
Loss:	1.599553108215332

training epoch 384 / 500, batch #300 / 625
Loss:	1.6788798570632935

training epoch 384 / 500, batch #325 / 625
Loss:	1.5301629304885864

training epoch 384 / 500, batch #350 / 625
Loss:	1.8274750709533691

training epoch 384 / 500, batch #375 / 625
Loss:	1.5802562236785889

training epoch 384 / 500, batch #400 / 625
Loss:	1.396506428718567

training epoch 384 / 500, batch #425 / 625
Loss:	1.876715064048767

training epoch 384 / 500, batch #450 / 625
Loss:	1.6724005937576294

training epoch 384 / 500, batch #475 / 625
Loss:	1.486738681793213

training epoch 384 / 500, batch #500 / 625
Loss:	1.6166257858276367

training epoch 384 / 500, batch #525 / 625
Loss:	1.5848143100738525

training epoch 384 / 500, batch #550 / 625
Loss:	1.7096829414367676

training epoch 384 / 500, batch #575 / 625
Loss:	1.6336803436279297

training epoch 384 / 500, batch #600 / 625
Loss:	1.916680932044983

training epoch 385 / 500, batch #0 / 625
Loss:	1.693850040435791

training epoch 385 / 500, batch #25 / 625
Loss:	1.6706463098526

training epoch 385 / 500, batch #50 / 625
Loss:	1.5659607648849487

training epoch 385 / 500, batch #75 / 625
Loss:	1.849114179611206

training epoch 385 / 500, batch #100 / 625
Loss:	1.8513249158859253

training epoch 385 / 500, batch #125 / 625
Loss:	1.6992311477661133

training epoch 385 / 500, batch #150 / 625
Loss:	1.7769948244094849

training epoch 385 / 500, batch #175 / 625
Loss:	1.664794683456421

training epoch 385 / 500, batch #200 / 625
Loss:	1.411622405052185

training epoch 385 / 500, batch #225 / 625
Loss:	1.5169377326965332

training epoch 385 / 500, batch #250 / 625
Loss:	1.5779238939285278

training epoch 385 / 500, batch #275 / 625
Loss:	1.8600869178771973

training epoch 385 / 500, batch #300 / 625
Loss:	1.915477991104126

training epoch 385 / 500, batch #325 / 625
Loss:	1.7662744522094727

training epoch 385 / 500, batch #350 / 625
Loss:	1.58372962474823

training epoch 385 / 500, batch #375 / 625
Loss:	1.7809064388275146

training epoch 385 / 500, batch #400 / 625
Loss:	1.5379258394241333

training epoch 385 / 500, batch #425 / 625
Loss:	1.7113757133483887

training epoch 385 / 500, batch #450 / 625
Loss:	1.503292441368103

training epoch 385 / 500, batch #475 / 625
Loss:	1.7868547439575195

training epoch 385 / 500, batch #500 / 625
Loss:	1.6338975429534912

training epoch 385 / 500, batch #525 / 625
Loss:	1.5084514617919922

training epoch 385 / 500, batch #550 / 625
Loss:	1.5360842943191528

training epoch 385 / 500, batch #575 / 625
Loss:	1.563169240951538

training epoch 385 / 500, batch #600 / 625
Loss:	1.6487241983413696

training epoch 386 / 500, batch #0 / 625
Loss:	1.8544723987579346

training epoch 386 / 500, batch #25 / 625
Loss:	1.8180568218231201

training epoch 386 / 500, batch #50 / 625
Loss:	1.8600201606750488

training epoch 386 / 500, batch #75 / 625
Loss:	1.7339489459991455

training epoch 386 / 500, batch #100 / 625
Loss:	1.56099271774292

training epoch 386 / 500, batch #125 / 625
Loss:	1.7769660949707031

training epoch 386 / 500, batch #150 / 625
Loss:	1.6152982711791992

training epoch 386 / 500, batch #175 / 625
Loss:	1.7706419229507446

training epoch 386 / 500, batch #200 / 625
Loss:	1.7054355144500732

training epoch 386 / 500, batch #225 / 625
Loss:	1.6826082468032837

training epoch 386 / 500, batch #250 / 625
Loss:	2.093181610107422

training epoch 386 / 500, batch #275 / 625
Loss:	1.5795671939849854

training epoch 386 / 500, batch #300 / 625
Loss:	1.7785030603408813

training epoch 386 / 500, batch #325 / 625
Loss:	1.8300230503082275

training epoch 386 / 500, batch #350 / 625
Loss:	1.7109053134918213

training epoch 386 / 500, batch #375 / 625
Loss:	1.641479253768921

training epoch 386 / 500, batch #400 / 625
Loss:	1.8926057815551758

training epoch 386 / 500, batch #425 / 625
Loss:	1.737847089767456

training epoch 386 / 500, batch #450 / 625
Loss:	1.8796488046646118

training epoch 386 / 500, batch #475 / 625
Loss:	1.7561047077178955

training epoch 386 / 500, batch #500 / 625
Loss:	1.717867136001587

training epoch 386 / 500, batch #525 / 625
Loss:	1.7392222881317139

training epoch 386 / 500, batch #550 / 625
Loss:	1.582564115524292

training epoch 386 / 500, batch #575 / 625
Loss:	1.581305980682373

training epoch 386 / 500, batch #600 / 625
Loss:	1.798060655593872

training epoch 387 / 500, batch #0 / 625
Loss:	1.7099883556365967

training epoch 387 / 500, batch #25 / 625
Loss:	1.8642646074295044

training epoch 387 / 500, batch #50 / 625
Loss:	1.6847389936447144

training epoch 387 / 500, batch #75 / 625
Loss:	1.5979124307632446

training epoch 387 / 500, batch #100 / 625
Loss:	1.7301639318466187

training epoch 387 / 500, batch #125 / 625
Loss:	1.8666741847991943

training epoch 387 / 500, batch #150 / 625
Loss:	1.779822587966919

training epoch 387 / 500, batch #175 / 625
Loss:	1.518593192100525

training epoch 387 / 500, batch #200 / 625
Loss:	1.647729516029358

training epoch 387 / 500, batch #225 / 625
Loss:	1.962768793106079

training epoch 387 / 500, batch #250 / 625
Loss:	1.857114553451538

training epoch 387 / 500, batch #275 / 625
Loss:	1.7291479110717773

training epoch 387 / 500, batch #300 / 625
Loss:	1.5363879203796387

training epoch 387 / 500, batch #325 / 625
Loss:	1.6391328573226929

training epoch 387 / 500, batch #350 / 625
Loss:	1.686518669128418

training epoch 387 / 500, batch #375 / 625
Loss:	1.7534832954406738

training epoch 387 / 500, batch #400 / 625
Loss:	1.5458788871765137

training epoch 387 / 500, batch #425 / 625
Loss:	1.698475956916809

training epoch 387 / 500, batch #450 / 625
Loss:	1.7835397720336914

training epoch 387 / 500, batch #475 / 625
Loss:	1.713597297668457

training epoch 387 / 500, batch #500 / 625
Loss:	1.5906133651733398

training epoch 387 / 500, batch #525 / 625
Loss:	1.577324628829956

training epoch 387 / 500, batch #550 / 625
Loss:	1.7683418989181519

training epoch 387 / 500, batch #575 / 625
Loss:	1.6517562866210938

training epoch 387 / 500, batch #600 / 625
Loss:	1.7882715463638306

training epoch 388 / 500, batch #0 / 625
Loss:	1.9738847017288208

training epoch 388 / 500, batch #25 / 625
Loss:	1.716611623764038

training epoch 388 / 500, batch #50 / 625
Loss:	1.6229420900344849

training epoch 388 / 500, batch #75 / 625
Loss:	1.674688696861267

training epoch 388 / 500, batch #100 / 625
Loss:	1.5729286670684814

training epoch 388 / 500, batch #125 / 625
Loss:	1.9015533924102783

training epoch 388 / 500, batch #150 / 625
Loss:	2.1352779865264893

training epoch 388 / 500, batch #175 / 625
Loss:	1.9431263208389282

training epoch 388 / 500, batch #200 / 625
Loss:	1.9373830556869507

training epoch 388 / 500, batch #225 / 625
Loss:	1.9099206924438477

training epoch 388 / 500, batch #250 / 625
Loss:	1.498360276222229

training epoch 388 / 500, batch #275 / 625
Loss:	1.9600039720535278

training epoch 388 / 500, batch #300 / 625
Loss:	2.2018790245056152

training epoch 388 / 500, batch #325 / 625
Loss:	1.619977593421936

training epoch 388 / 500, batch #350 / 625
Loss:	1.4890164136886597

training epoch 388 / 500, batch #375 / 625
Loss:	1.5010300874710083

training epoch 388 / 500, batch #400 / 625
Loss:	1.7133792638778687

training epoch 388 / 500, batch #425 / 625
Loss:	1.5507162809371948

training epoch 388 / 500, batch #450 / 625
Loss:	1.7951865196228027

training epoch 388 / 500, batch #475 / 625
Loss:	1.5993657112121582

training epoch 388 / 500, batch #500 / 625
Loss:	1.868101716041565

training epoch 388 / 500, batch #525 / 625
Loss:	1.9561437368392944

training epoch 388 / 500, batch #550 / 625
Loss:	1.9394313097000122

training epoch 388 / 500, batch #575 / 625
Loss:	1.754228115081787

training epoch 388 / 500, batch #600 / 625
Loss:	1.8138728141784668

training epoch 389 / 500, batch #0 / 625
Loss:	1.6566368341445923

training epoch 389 / 500, batch #25 / 625
Loss:	1.6151705980300903

training epoch 389 / 500, batch #50 / 625
Loss:	2.0194504261016846

training epoch 389 / 500, batch #75 / 625
Loss:	1.8326430320739746

training epoch 389 / 500, batch #100 / 625
Loss:	1.5569320917129517

training epoch 389 / 500, batch #125 / 625
Loss:	1.5149716138839722

training epoch 389 / 500, batch #150 / 625
Loss:	1.5385044813156128

training epoch 389 / 500, batch #175 / 625
Loss:	1.704353928565979

training epoch 389 / 500, batch #200 / 625
Loss:	1.9720004796981812

training epoch 389 / 500, batch #225 / 625
Loss:	1.8636054992675781

training epoch 389 / 500, batch #250 / 625
Loss:	1.4478578567504883

training epoch 389 / 500, batch #275 / 625
Loss:	1.8432921171188354

training epoch 389 / 500, batch #300 / 625
Loss:	1.8505840301513672

training epoch 389 / 500, batch #325 / 625
Loss:	1.6545695066452026

training epoch 389 / 500, batch #350 / 625
Loss:	1.771260142326355

training epoch 389 / 500, batch #375 / 625
Loss:	1.7400192022323608

training epoch 389 / 500, batch #400 / 625
Loss:	1.6660641431808472

training epoch 389 / 500, batch #425 / 625
Loss:	1.640438437461853

training epoch 389 / 500, batch #450 / 625
Loss:	1.668444037437439

training epoch 389 / 500, batch #475 / 625
Loss:	1.648029088973999

training epoch 389 / 500, batch #500 / 625
Loss:	1.6780846118927002

training epoch 389 / 500, batch #525 / 625
Loss:	2.0481607913970947

training epoch 389 / 500, batch #550 / 625
Loss:	1.6780766248703003

training epoch 389 / 500, batch #575 / 625
Loss:	1.8676538467407227

training epoch 389 / 500, batch #600 / 625
Loss:	2.01839280128479

training epoch 390 / 500, batch #0 / 625
Loss:	1.7363107204437256

training epoch 390 / 500, batch #25 / 625
Loss:	1.7445459365844727

training epoch 390 / 500, batch #50 / 625
Loss:	1.5844457149505615

training epoch 390 / 500, batch #75 / 625
Loss:	1.6145265102386475

training epoch 390 / 500, batch #100 / 625
Loss:	1.7545504570007324

training epoch 390 / 500, batch #125 / 625
Loss:	1.817541480064392

training epoch 390 / 500, batch #150 / 625
Loss:	1.706640601158142

training epoch 390 / 500, batch #175 / 625
Loss:	1.9065444469451904

training epoch 390 / 500, batch #200 / 625
Loss:	1.6230789422988892

training epoch 390 / 500, batch #225 / 625
Loss:	1.6860771179199219

training epoch 390 / 500, batch #250 / 625
Loss:	1.7889763116836548

training epoch 390 / 500, batch #275 / 625
Loss:	1.75118088722229

training epoch 390 / 500, batch #300 / 625
Loss:	1.9667510986328125

training epoch 390 / 500, batch #325 / 625
Loss:	1.6906384229660034

training epoch 390 / 500, batch #350 / 625
Loss:	1.749108076095581

training epoch 390 / 500, batch #375 / 625
Loss:	1.722254753112793

training epoch 390 / 500, batch #400 / 625
Loss:	1.743005633354187

training epoch 390 / 500, batch #425 / 625
Loss:	1.6061140298843384

training epoch 390 / 500, batch #450 / 625
Loss:	1.8478918075561523

training epoch 390 / 500, batch #475 / 625
Loss:	1.8990256786346436

training epoch 390 / 500, batch #500 / 625
Loss:	1.6972637176513672

training epoch 390 / 500, batch #525 / 625
Loss:	1.7190032005310059

training epoch 390 / 500, batch #550 / 625
Loss:	1.5126121044158936

training epoch 390 / 500, batch #575 / 625
Loss:	1.7648487091064453

training epoch 390 / 500, batch #600 / 625
Loss:	1.980821967124939

training epoch 391 / 500, batch #0 / 625
Loss:	1.813676118850708

training epoch 391 / 500, batch #25 / 625
Loss:	1.7401456832885742

training epoch 391 / 500, batch #50 / 625
Loss:	1.6640121936798096

training epoch 391 / 500, batch #75 / 625
Loss:	1.6568706035614014

training epoch 391 / 500, batch #100 / 625
Loss:	1.6725183725357056

training epoch 391 / 500, batch #125 / 625
Loss:	1.7562934160232544

training epoch 391 / 500, batch #150 / 625
Loss:	1.8393185138702393

training epoch 391 / 500, batch #175 / 625
Loss:	1.849537968635559

training epoch 391 / 500, batch #200 / 625
Loss:	1.7198426723480225

training epoch 391 / 500, batch #225 / 625
Loss:	1.6093847751617432

training epoch 391 / 500, batch #250 / 625
Loss:	1.602561116218567

training epoch 391 / 500, batch #275 / 625
Loss:	1.5292303562164307

training epoch 391 / 500, batch #300 / 625
Loss:	1.676796555519104

training epoch 391 / 500, batch #325 / 625
Loss:	1.429331660270691

training epoch 391 / 500, batch #350 / 625
Loss:	1.8358622789382935

training epoch 391 / 500, batch #375 / 625
Loss:	1.8825387954711914

training epoch 391 / 500, batch #400 / 625
Loss:	1.6560814380645752

training epoch 391 / 500, batch #425 / 625
Loss:	1.7973487377166748

training epoch 391 / 500, batch #450 / 625
Loss:	1.6991251707077026

training epoch 391 / 500, batch #475 / 625
Loss:	1.5413386821746826

training epoch 391 / 500, batch #500 / 625
Loss:	1.6141552925109863

training epoch 391 / 500, batch #525 / 625
Loss:	1.572559118270874

training epoch 391 / 500, batch #550 / 625
Loss:	1.484973669052124

training epoch 391 / 500, batch #575 / 625
Loss:	1.458740234375

training epoch 391 / 500, batch #600 / 625
Loss:	1.733243703842163

training epoch 392 / 500, batch #0 / 625
Loss:	1.7419887781143188

training epoch 392 / 500, batch #25 / 625
Loss:	1.7940560579299927

training epoch 392 / 500, batch #50 / 625
Loss:	1.7453866004943848

training epoch 392 / 500, batch #75 / 625
Loss:	1.7496963739395142

training epoch 392 / 500, batch #100 / 625
Loss:	1.6366550922393799

training epoch 392 / 500, batch #125 / 625
Loss:	1.8113857507705688

training epoch 392 / 500, batch #150 / 625
Loss:	1.6519290208816528

training epoch 392 / 500, batch #175 / 625
Loss:	1.6880981922149658

training epoch 392 / 500, batch #200 / 625
Loss:	1.624855875968933

training epoch 392 / 500, batch #225 / 625
Loss:	1.6084234714508057

training epoch 392 / 500, batch #250 / 625
Loss:	1.6808871030807495

training epoch 392 / 500, batch #275 / 625
Loss:	1.7754573822021484

training epoch 392 / 500, batch #300 / 625
Loss:	1.732366681098938

training epoch 392 / 500, batch #325 / 625
Loss:	1.7264907360076904

training epoch 392 / 500, batch #350 / 625
Loss:	1.8214762210845947

training epoch 392 / 500, batch #375 / 625
Loss:	1.7828619480133057

training epoch 392 / 500, batch #400 / 625
Loss:	1.7765367031097412

training epoch 392 / 500, batch #425 / 625
Loss:	1.8514081239700317

training epoch 392 / 500, batch #450 / 625
Loss:	1.6726758480072021

training epoch 392 / 500, batch #475 / 625
Loss:	1.6973522901535034

training epoch 392 / 500, batch #500 / 625
Loss:	1.5075032711029053

training epoch 392 / 500, batch #525 / 625
Loss:	1.9274413585662842

training epoch 392 / 500, batch #550 / 625
Loss:	1.6879311800003052

training epoch 392 / 500, batch #575 / 625
Loss:	1.6265993118286133

training epoch 392 / 500, batch #600 / 625
Loss:	1.967145562171936

training epoch 393 / 500, batch #0 / 625
Loss:	1.4150420427322388

training epoch 393 / 500, batch #25 / 625
Loss:	1.4137318134307861

training epoch 393 / 500, batch #50 / 625
Loss:	1.8649665117263794

training epoch 393 / 500, batch #75 / 625
Loss:	1.5676774978637695

training epoch 393 / 500, batch #100 / 625
Loss:	1.9393279552459717

training epoch 393 / 500, batch #125 / 625
Loss:	1.8693095445632935

training epoch 393 / 500, batch #150 / 625
Loss:	1.972773790359497

training epoch 393 / 500, batch #175 / 625
Loss:	1.547303557395935

training epoch 393 / 500, batch #200 / 625
Loss:	1.8267958164215088

training epoch 393 / 500, batch #225 / 625
Loss:	1.880295991897583

training epoch 393 / 500, batch #250 / 625
Loss:	1.701373815536499

training epoch 393 / 500, batch #275 / 625
Loss:	1.7924425601959229

training epoch 393 / 500, batch #300 / 625
Loss:	1.648223876953125

training epoch 393 / 500, batch #325 / 625
Loss:	1.7625480890274048

training epoch 393 / 500, batch #350 / 625
Loss:	1.7715615034103394

training epoch 393 / 500, batch #375 / 625
Loss:	1.4896876811981201

training epoch 393 / 500, batch #400 / 625
Loss:	1.7909862995147705

training epoch 393 / 500, batch #425 / 625
Loss:	1.5820139646530151

training epoch 393 / 500, batch #450 / 625
Loss:	1.6556646823883057

training epoch 393 / 500, batch #475 / 625
Loss:	1.5226266384124756

training epoch 393 / 500, batch #500 / 625
Loss:	1.7226225137710571

training epoch 393 / 500, batch #525 / 625
Loss:	1.7498892545700073

training epoch 393 / 500, batch #550 / 625
Loss:	1.5436758995056152

training epoch 393 / 500, batch #575 / 625
Loss:	1.851858377456665

training epoch 393 / 500, batch #600 / 625
Loss:	1.7830307483673096

training epoch 394 / 500, batch #0 / 625
Loss:	1.5075925588607788

training epoch 394 / 500, batch #25 / 625
Loss:	1.7458609342575073

training epoch 394 / 500, batch #50 / 625
Loss:	1.5188943147659302

training epoch 394 / 500, batch #75 / 625
Loss:	1.6202512979507446

training epoch 394 / 500, batch #100 / 625
Loss:	1.9024684429168701

training epoch 394 / 500, batch #125 / 625
Loss:	1.7468757629394531

training epoch 394 / 500, batch #150 / 625
Loss:	1.2786891460418701

training epoch 394 / 500, batch #175 / 625
Loss:	1.815920352935791

training epoch 394 / 500, batch #200 / 625
Loss:	1.9112921953201294

training epoch 394 / 500, batch #225 / 625
Loss:	1.4587737321853638

training epoch 394 / 500, batch #250 / 625
Loss:	1.8442492485046387

training epoch 394 / 500, batch #275 / 625
Loss:	1.7366641759872437

training epoch 394 / 500, batch #300 / 625
Loss:	1.6409480571746826

training epoch 394 / 500, batch #325 / 625
Loss:	1.7324610948562622

training epoch 394 / 500, batch #350 / 625
Loss:	1.8599915504455566

training epoch 394 / 500, batch #375 / 625
Loss:	1.7039730548858643

training epoch 394 / 500, batch #400 / 625
Loss:	1.6451315879821777

training epoch 394 / 500, batch #425 / 625
Loss:	1.8976603746414185

training epoch 394 / 500, batch #450 / 625
Loss:	1.793233871459961

training epoch 394 / 500, batch #475 / 625
Loss:	1.7168352603912354

training epoch 394 / 500, batch #500 / 625
Loss:	1.6529592275619507

training epoch 394 / 500, batch #525 / 625
Loss:	2.023634433746338

training epoch 394 / 500, batch #550 / 625
Loss:	1.854550838470459

training epoch 394 / 500, batch #575 / 625
Loss:	1.7608169317245483

training epoch 394 / 500, batch #600 / 625
Loss:	1.739846110343933

training epoch 395 / 500, batch #0 / 625
Loss:	1.8209781646728516

training epoch 395 / 500, batch #25 / 625
Loss:	1.6103203296661377

training epoch 395 / 500, batch #50 / 625
Loss:	1.7968765497207642

training epoch 395 / 500, batch #75 / 625
Loss:	1.802380919456482

training epoch 395 / 500, batch #100 / 625
Loss:	1.8045785427093506

training epoch 395 / 500, batch #125 / 625
Loss:	1.8710626363754272

training epoch 395 / 500, batch #150 / 625
Loss:	1.7390366792678833

training epoch 395 / 500, batch #175 / 625
Loss:	1.7209135293960571

training epoch 395 / 500, batch #200 / 625
Loss:	1.7870419025421143

training epoch 395 / 500, batch #225 / 625
Loss:	1.6320891380310059

training epoch 395 / 500, batch #250 / 625
Loss:	1.6992815732955933

training epoch 395 / 500, batch #275 / 625
Loss:	1.7450547218322754

training epoch 395 / 500, batch #300 / 625
Loss:	1.7228643894195557

training epoch 395 / 500, batch #325 / 625
Loss:	1.6312335729599

training epoch 395 / 500, batch #350 / 625
Loss:	1.615100622177124

training epoch 395 / 500, batch #375 / 625
Loss:	1.583815574645996

training epoch 395 / 500, batch #400 / 625
Loss:	1.8907170295715332

training epoch 395 / 500, batch #425 / 625
Loss:	1.551077127456665

training epoch 395 / 500, batch #450 / 625
Loss:	1.9530225992202759

training epoch 395 / 500, batch #475 / 625
Loss:	1.7372233867645264

training epoch 395 / 500, batch #500 / 625
Loss:	1.7619690895080566

training epoch 395 / 500, batch #525 / 625
Loss:	1.8061741590499878

training epoch 395 / 500, batch #550 / 625
Loss:	1.8389438390731812

training epoch 395 / 500, batch #575 / 625
Loss:	1.7583850622177124

training epoch 395 / 500, batch #600 / 625
Loss:	1.4867337942123413

training epoch 396 / 500, batch #0 / 625
Loss:	1.5933374166488647

training epoch 396 / 500, batch #25 / 625
Loss:	1.7558513879776

training epoch 396 / 500, batch #50 / 625
Loss:	1.7710022926330566

training epoch 396 / 500, batch #75 / 625
Loss:	1.6438653469085693

training epoch 396 / 500, batch #100 / 625
Loss:	1.5436278581619263

training epoch 396 / 500, batch #125 / 625
Loss:	1.5411137342453003

training epoch 396 / 500, batch #150 / 625
Loss:	1.736362099647522

training epoch 396 / 500, batch #175 / 625
Loss:	1.4905319213867188

training epoch 396 / 500, batch #200 / 625
Loss:	1.8189208507537842

training epoch 396 / 500, batch #225 / 625
Loss:	1.851344347000122

training epoch 396 / 500, batch #250 / 625
Loss:	1.5260323286056519

training epoch 396 / 500, batch #275 / 625
Loss:	1.6722183227539062

training epoch 396 / 500, batch #300 / 625
Loss:	1.7319302558898926

training epoch 396 / 500, batch #325 / 625
Loss:	1.507775902748108

training epoch 396 / 500, batch #350 / 625
Loss:	1.708312749862671

training epoch 396 / 500, batch #375 / 625
Loss:	1.5495396852493286

training epoch 396 / 500, batch #400 / 625
Loss:	1.894717812538147

training epoch 396 / 500, batch #425 / 625
Loss:	1.96513032913208

training epoch 396 / 500, batch #450 / 625
Loss:	1.7042951583862305

training epoch 396 / 500, batch #475 / 625
Loss:	1.7310779094696045

training epoch 396 / 500, batch #500 / 625
Loss:	1.7273859977722168

training epoch 396 / 500, batch #525 / 625
Loss:	1.7115415334701538

training epoch 396 / 500, batch #550 / 625
Loss:	1.7072635889053345

training epoch 396 / 500, batch #575 / 625
Loss:	1.761557936668396

training epoch 396 / 500, batch #600 / 625
Loss:	1.7357028722763062

training epoch 397 / 500, batch #0 / 625
Loss:	1.4722750186920166

training epoch 397 / 500, batch #25 / 625
Loss:	1.4819425344467163

training epoch 397 / 500, batch #50 / 625
Loss:	1.5611376762390137

training epoch 397 / 500, batch #75 / 625
Loss:	1.6896274089813232

training epoch 397 / 500, batch #100 / 625
Loss:	2.087834596633911

training epoch 397 / 500, batch #125 / 625
Loss:	1.8416640758514404

training epoch 397 / 500, batch #150 / 625
Loss:	1.9177303314208984

training epoch 397 / 500, batch #175 / 625
Loss:	1.9206132888793945

training epoch 397 / 500, batch #200 / 625
Loss:	1.6476057767868042

training epoch 397 / 500, batch #225 / 625
Loss:	1.7109167575836182

training epoch 397 / 500, batch #250 / 625
Loss:	1.7478123903274536

training epoch 397 / 500, batch #275 / 625
Loss:	2.0150697231292725

training epoch 397 / 500, batch #300 / 625
Loss:	1.677022933959961

training epoch 397 / 500, batch #325 / 625
Loss:	1.8779020309448242

training epoch 397 / 500, batch #350 / 625
Loss:	1.5466769933700562

training epoch 397 / 500, batch #375 / 625
Loss:	1.7209625244140625

training epoch 397 / 500, batch #400 / 625
Loss:	1.7276464700698853

training epoch 397 / 500, batch #425 / 625
Loss:	2.11102557182312

training epoch 397 / 500, batch #450 / 625
Loss:	1.7507874965667725

training epoch 397 / 500, batch #475 / 625
Loss:	1.7158348560333252

training epoch 397 / 500, batch #500 / 625
Loss:	1.6564456224441528

training epoch 397 / 500, batch #525 / 625
Loss:	1.4966883659362793

training epoch 397 / 500, batch #550 / 625
Loss:	1.468447208404541

training epoch 397 / 500, batch #575 / 625
Loss:	1.5889041423797607

training epoch 397 / 500, batch #600 / 625
Loss:	1.6796191930770874

training epoch 398 / 500, batch #0 / 625
Loss:	1.9776805639266968

training epoch 398 / 500, batch #25 / 625
Loss:	1.4906209707260132

training epoch 398 / 500, batch #50 / 625
Loss:	1.4150677919387817

training epoch 398 / 500, batch #75 / 625
Loss:	1.581969141960144

training epoch 398 / 500, batch #100 / 625
Loss:	1.8161096572875977

training epoch 398 / 500, batch #125 / 625
Loss:	1.562180995941162

training epoch 398 / 500, batch #150 / 625
Loss:	1.540859580039978

training epoch 398 / 500, batch #175 / 625
Loss:	1.6926153898239136

training epoch 398 / 500, batch #200 / 625
Loss:	1.767781376838684

training epoch 398 / 500, batch #225 / 625
Loss:	1.6897515058517456

training epoch 398 / 500, batch #250 / 625
Loss:	1.7260445356369019

training epoch 398 / 500, batch #275 / 625
Loss:	1.6743483543395996

training epoch 398 / 500, batch #300 / 625
Loss:	1.7335140705108643

training epoch 398 / 500, batch #325 / 625
Loss:	1.6712110042572021

training epoch 398 / 500, batch #350 / 625
Loss:	1.6038392782211304

training epoch 398 / 500, batch #375 / 625
Loss:	1.648497223854065

training epoch 398 / 500, batch #400 / 625
Loss:	1.5806077718734741

training epoch 398 / 500, batch #425 / 625
Loss:	1.6563173532485962

training epoch 398 / 500, batch #450 / 625
Loss:	1.5494135618209839

training epoch 398 / 500, batch #475 / 625
Loss:	1.6454639434814453

training epoch 398 / 500, batch #500 / 625
Loss:	1.9010854959487915

training epoch 398 / 500, batch #525 / 625
Loss:	1.8445792198181152

training epoch 398 / 500, batch #550 / 625
Loss:	1.7425158023834229

training epoch 398 / 500, batch #575 / 625
Loss:	1.800727367401123

training epoch 398 / 500, batch #600 / 625
Loss:	1.7454512119293213

training epoch 399 / 500, batch #0 / 625
Loss:	2.010329246520996

training epoch 399 / 500, batch #25 / 625
Loss:	1.750052571296692

training epoch 399 / 500, batch #50 / 625
Loss:	1.820457935333252

training epoch 399 / 500, batch #75 / 625
Loss:	1.8810237646102905

training epoch 399 / 500, batch #100 / 625
Loss:	1.5964906215667725

training epoch 399 / 500, batch #125 / 625
Loss:	1.6633647680282593

training epoch 399 / 500, batch #150 / 625
Loss:	1.7818284034729004

training epoch 399 / 500, batch #175 / 625
Loss:	1.5910667181015015

training epoch 399 / 500, batch #200 / 625
Loss:	1.8636586666107178

training epoch 399 / 500, batch #225 / 625
Loss:	1.7621660232543945

training epoch 399 / 500, batch #250 / 625
Loss:	1.643983006477356

training epoch 399 / 500, batch #275 / 625
Loss:	1.6963887214660645

training epoch 399 / 500, batch #300 / 625
Loss:	1.895166277885437

training epoch 399 / 500, batch #325 / 625
Loss:	1.8204766511917114

training epoch 399 / 500, batch #350 / 625
Loss:	1.8717917203903198

training epoch 399 / 500, batch #375 / 625
Loss:	1.6055525541305542

training epoch 399 / 500, batch #400 / 625
Loss:	1.5891801118850708

training epoch 399 / 500, batch #425 / 625
Loss:	1.492700219154358

training epoch 399 / 500, batch #450 / 625
Loss:	1.7017215490341187

training epoch 399 / 500, batch #475 / 625
Loss:	1.8468496799468994

training epoch 399 / 500, batch #500 / 625
Loss:	1.7354072332382202

training epoch 399 / 500, batch #525 / 625
Loss:	1.762590765953064

training epoch 399 / 500, batch #550 / 625
Loss:	1.7873880863189697

training epoch 399 / 500, batch #575 / 625
Loss:	2.0307259559631348

training epoch 399 / 500, batch #600 / 625
Loss:	1.805419683456421

training epoch 400 / 500, batch #0 / 625
Loss:	1.4739454984664917

training epoch 400 / 500, batch #25 / 625
Loss:	1.901313066482544

training epoch 400 / 500, batch #50 / 625
Loss:	1.5643706321716309

training epoch 400 / 500, batch #75 / 625
Loss:	1.7264010906219482

training epoch 400 / 500, batch #100 / 625
Loss:	1.7944750785827637

training epoch 400 / 500, batch #125 / 625
Loss:	1.83909010887146

training epoch 400 / 500, batch #150 / 625
Loss:	1.7687621116638184

training epoch 400 / 500, batch #175 / 625
Loss:	1.52810800075531

training epoch 400 / 500, batch #200 / 625
Loss:	1.5608559846878052

training epoch 400 / 500, batch #225 / 625
Loss:	1.8419687747955322

training epoch 400 / 500, batch #250 / 625
Loss:	1.7642590999603271

training epoch 400 / 500, batch #275 / 625
Loss:	1.7152758836746216

training epoch 400 / 500, batch #300 / 625
Loss:	1.6650948524475098

training epoch 400 / 500, batch #325 / 625
Loss:	1.8381260633468628

training epoch 400 / 500, batch #350 / 625
Loss:	1.636208415031433

training epoch 400 / 500, batch #375 / 625
Loss:	1.7396873235702515

training epoch 400 / 500, batch #400 / 625
Loss:	1.7525553703308105

training epoch 400 / 500, batch #425 / 625
Loss:	1.756946325302124

training epoch 400 / 500, batch #450 / 625
Loss:	1.6947458982467651

training epoch 400 / 500, batch #475 / 625
Loss:	1.740943193435669

training epoch 400 / 500, batch #500 / 625
Loss:	1.789977788925171

training epoch 400 / 500, batch #525 / 625
Loss:	1.6434284448623657

training epoch 400 / 500, batch #550 / 625
Loss:	1.7044703960418701

training epoch 400 / 500, batch #575 / 625
Loss:	1.8093599081039429

training epoch 400 / 500, batch #600 / 625
Loss:	1.721853256225586

training epoch 401 / 500, batch #0 / 625
Loss:	1.7301450967788696

training epoch 401 / 500, batch #25 / 625
Loss:	1.5983779430389404

training epoch 401 / 500, batch #50 / 625
Loss:	1.5532660484313965

training epoch 401 / 500, batch #75 / 625
Loss:	1.6774327754974365

training epoch 401 / 500, batch #100 / 625
Loss:	1.4370276927947998

training epoch 401 / 500, batch #125 / 625
Loss:	1.6731338500976562

training epoch 401 / 500, batch #150 / 625
Loss:	1.6676115989685059

training epoch 401 / 500, batch #175 / 625
Loss:	1.590470790863037

training epoch 401 / 500, batch #200 / 625
Loss:	1.6718324422836304

training epoch 401 / 500, batch #225 / 625
Loss:	1.5008225440979004

training epoch 401 / 500, batch #250 / 625
Loss:	1.6406925916671753

training epoch 401 / 500, batch #275 / 625
Loss:	1.8635730743408203

training epoch 401 / 500, batch #300 / 625
Loss:	1.5575007200241089

training epoch 401 / 500, batch #325 / 625
Loss:	1.7360023260116577

training epoch 401 / 500, batch #350 / 625
Loss:	1.7637017965316772

training epoch 401 / 500, batch #375 / 625
Loss:	1.7619928121566772

training epoch 401 / 500, batch #400 / 625
Loss:	1.8201723098754883

training epoch 401 / 500, batch #425 / 625
Loss:	1.9211636781692505

training epoch 401 / 500, batch #450 / 625
Loss:	1.8613002300262451

training epoch 401 / 500, batch #475 / 625
Loss:	1.6453144550323486

training epoch 401 / 500, batch #500 / 625
Loss:	1.8852859735488892

training epoch 401 / 500, batch #525 / 625
Loss:	1.5778663158416748

training epoch 401 / 500, batch #550 / 625
Loss:	1.5911091566085815

training epoch 401 / 500, batch #575 / 625
Loss:	1.4647117853164673

training epoch 401 / 500, batch #600 / 625
Loss:	1.7152005434036255

training epoch 402 / 500, batch #0 / 625
Loss:	1.7521696090698242

training epoch 402 / 500, batch #25 / 625
Loss:	1.59311044216156

training epoch 402 / 500, batch #50 / 625
Loss:	1.7186946868896484

training epoch 402 / 500, batch #75 / 625
Loss:	1.5956902503967285

training epoch 402 / 500, batch #100 / 625
Loss:	1.9143471717834473

training epoch 402 / 500, batch #125 / 625
Loss:	1.8244280815124512

training epoch 402 / 500, batch #150 / 625
Loss:	1.6916158199310303

training epoch 402 / 500, batch #175 / 625
Loss:	1.5621951818466187

training epoch 402 / 500, batch #200 / 625
Loss:	1.8335578441619873

training epoch 402 / 500, batch #225 / 625
Loss:	1.647038221359253

training epoch 402 / 500, batch #250 / 625
Loss:	1.5441678762435913

training epoch 402 / 500, batch #275 / 625
Loss:	1.8051667213439941

training epoch 402 / 500, batch #300 / 625
Loss:	1.5649127960205078

training epoch 402 / 500, batch #325 / 625
Loss:	1.7270811796188354

training epoch 402 / 500, batch #350 / 625
Loss:	1.7297171354293823

training epoch 402 / 500, batch #375 / 625
Loss:	1.78177809715271

training epoch 402 / 500, batch #400 / 625
Loss:	1.5064430236816406

training epoch 402 / 500, batch #425 / 625
Loss:	1.9153790473937988

training epoch 402 / 500, batch #450 / 625
Loss:	1.6307098865509033

training epoch 402 / 500, batch #475 / 625
Loss:	1.7511433362960815

training epoch 402 / 500, batch #500 / 625
Loss:	1.5062505006790161

training epoch 402 / 500, batch #525 / 625
Loss:	1.6686140298843384

training epoch 402 / 500, batch #550 / 625
Loss:	1.4314045906066895

training epoch 402 / 500, batch #575 / 625
Loss:	1.8802067041397095

training epoch 402 / 500, batch #600 / 625
Loss:	1.5036523342132568

training epoch 403 / 500, batch #0 / 625
Loss:	1.5717811584472656

training epoch 403 / 500, batch #25 / 625
Loss:	1.6576539278030396

training epoch 403 / 500, batch #50 / 625
Loss:	1.7156165838241577

training epoch 403 / 500, batch #75 / 625
Loss:	1.4290493726730347

training epoch 403 / 500, batch #100 / 625
Loss:	1.800944209098816

training epoch 403 / 500, batch #125 / 625
Loss:	1.5939760208129883

training epoch 403 / 500, batch #150 / 625
Loss:	1.6740819215774536

training epoch 403 / 500, batch #175 / 625
Loss:	1.7405750751495361

training epoch 403 / 500, batch #200 / 625
Loss:	1.6874316930770874

training epoch 403 / 500, batch #225 / 625
Loss:	1.945204734802246

training epoch 403 / 500, batch #250 / 625
Loss:	1.831374168395996

training epoch 403 / 500, batch #275 / 625
Loss:	1.885379672050476

training epoch 403 / 500, batch #300 / 625
Loss:	1.7631126642227173

training epoch 403 / 500, batch #325 / 625
Loss:	1.6150797605514526

training epoch 403 / 500, batch #350 / 625
Loss:	1.723059892654419

training epoch 403 / 500, batch #375 / 625
Loss:	1.5743143558502197

training epoch 403 / 500, batch #400 / 625
Loss:	1.7225276231765747

training epoch 403 / 500, batch #425 / 625
Loss:	1.3809691667556763

training epoch 403 / 500, batch #450 / 625
Loss:	1.8112952709197998

training epoch 403 / 500, batch #475 / 625
Loss:	2.00986385345459

training epoch 403 / 500, batch #500 / 625
Loss:	1.7135523557662964

training epoch 403 / 500, batch #525 / 625
Loss:	1.8731402158737183

training epoch 403 / 500, batch #550 / 625
Loss:	1.720571756362915

training epoch 403 / 500, batch #575 / 625
Loss:	1.7133866548538208

training epoch 403 / 500, batch #600 / 625
Loss:	1.8681029081344604

training epoch 404 / 500, batch #0 / 625
Loss:	1.727573275566101

training epoch 404 / 500, batch #25 / 625
Loss:	1.6444323062896729

training epoch 404 / 500, batch #50 / 625
Loss:	1.7215291261672974

training epoch 404 / 500, batch #75 / 625
Loss:	1.6083838939666748

training epoch 404 / 500, batch #100 / 625
Loss:	1.9782801866531372

training epoch 404 / 500, batch #125 / 625
Loss:	1.755383849143982

training epoch 404 / 500, batch #150 / 625
Loss:	1.8921709060668945

training epoch 404 / 500, batch #175 / 625
Loss:	1.837644338607788

training epoch 404 / 500, batch #200 / 625
Loss:	1.6225335597991943

training epoch 404 / 500, batch #225 / 625
Loss:	1.8110357522964478

training epoch 404 / 500, batch #250 / 625
Loss:	1.6842913627624512

training epoch 404 / 500, batch #275 / 625
Loss:	1.6334776878356934

training epoch 404 / 500, batch #300 / 625
Loss:	1.7926857471466064

training epoch 404 / 500, batch #325 / 625
Loss:	1.9693982601165771

training epoch 404 / 500, batch #350 / 625
Loss:	1.768898844718933

training epoch 404 / 500, batch #375 / 625
Loss:	1.5124515295028687

training epoch 404 / 500, batch #400 / 625
Loss:	1.5753129720687866

training epoch 404 / 500, batch #425 / 625
Loss:	1.4044171571731567

training epoch 404 / 500, batch #450 / 625
Loss:	1.968743920326233

training epoch 404 / 500, batch #475 / 625
Loss:	1.7333608865737915

training epoch 404 / 500, batch #500 / 625
Loss:	1.7101686000823975

training epoch 404 / 500, batch #525 / 625
Loss:	1.5242069959640503

training epoch 404 / 500, batch #550 / 625
Loss:	1.9190583229064941

training epoch 404 / 500, batch #575 / 625
Loss:	1.6295716762542725

training epoch 404 / 500, batch #600 / 625
Loss:	1.7252271175384521

training epoch 405 / 500, batch #0 / 625
Loss:	1.764350175857544

training epoch 405 / 500, batch #25 / 625
Loss:	1.51213800907135

training epoch 405 / 500, batch #50 / 625
Loss:	1.8404947519302368

training epoch 405 / 500, batch #75 / 625
Loss:	1.6817582845687866

training epoch 405 / 500, batch #100 / 625
Loss:	1.7668465375900269

training epoch 405 / 500, batch #125 / 625
Loss:	1.868403673171997

training epoch 405 / 500, batch #150 / 625
Loss:	1.8667762279510498

training epoch 405 / 500, batch #175 / 625
Loss:	1.7081689834594727

training epoch 405 / 500, batch #200 / 625
Loss:	1.5813524723052979

training epoch 405 / 500, batch #225 / 625
Loss:	1.7527871131896973

training epoch 405 / 500, batch #250 / 625
Loss:	1.6906406879425049

training epoch 405 / 500, batch #275 / 625
Loss:	1.6205719709396362

training epoch 405 / 500, batch #300 / 625
Loss:	1.5830793380737305

training epoch 405 / 500, batch #325 / 625
Loss:	1.8016525506973267

training epoch 405 / 500, batch #350 / 625
Loss:	2.0656545162200928

training epoch 405 / 500, batch #375 / 625
Loss:	1.7029169797897339

training epoch 405 / 500, batch #400 / 625
Loss:	1.603151559829712

training epoch 405 / 500, batch #425 / 625
Loss:	1.7502366304397583

training epoch 405 / 500, batch #450 / 625
Loss:	1.6785821914672852

training epoch 405 / 500, batch #475 / 625
Loss:	1.6612040996551514

training epoch 405 / 500, batch #500 / 625
Loss:	1.6344860792160034

training epoch 405 / 500, batch #525 / 625
Loss:	1.7843363285064697

training epoch 405 / 500, batch #550 / 625
Loss:	1.5453304052352905

training epoch 405 / 500, batch #575 / 625
Loss:	1.7535884380340576

training epoch 405 / 500, batch #600 / 625
Loss:	1.6086026430130005

training epoch 406 / 500, batch #0 / 625
Loss:	1.830271601676941

training epoch 406 / 500, batch #25 / 625
Loss:	1.57505202293396

training epoch 406 / 500, batch #50 / 625
Loss:	1.8747614622116089

training epoch 406 / 500, batch #75 / 625
Loss:	1.5559157133102417

training epoch 406 / 500, batch #100 / 625
Loss:	1.709501028060913

training epoch 406 / 500, batch #125 / 625
Loss:	1.73502779006958

training epoch 406 / 500, batch #150 / 625
Loss:	1.5914454460144043

training epoch 406 / 500, batch #175 / 625
Loss:	2.0711145401000977

training epoch 406 / 500, batch #200 / 625
Loss:	1.7663854360580444

training epoch 406 / 500, batch #225 / 625
Loss:	1.817697525024414

training epoch 406 / 500, batch #250 / 625
Loss:	1.8292776346206665

training epoch 406 / 500, batch #275 / 625
Loss:	1.6488648653030396

training epoch 406 / 500, batch #300 / 625
Loss:	1.5422769784927368

training epoch 406 / 500, batch #325 / 625
Loss:	1.989548921585083

training epoch 406 / 500, batch #350 / 625
Loss:	1.7855656147003174

training epoch 406 / 500, batch #375 / 625
Loss:	1.7093603610992432

training epoch 406 / 500, batch #400 / 625
Loss:	1.8134071826934814

training epoch 406 / 500, batch #425 / 625
Loss:	1.7553508281707764

training epoch 406 / 500, batch #450 / 625
Loss:	1.6118305921554565

training epoch 406 / 500, batch #475 / 625
Loss:	1.7151747941970825

training epoch 406 / 500, batch #500 / 625
Loss:	1.6835075616836548

training epoch 406 / 500, batch #525 / 625
Loss:	1.5360130071640015

training epoch 406 / 500, batch #550 / 625
Loss:	1.76493239402771

training epoch 406 / 500, batch #575 / 625
Loss:	1.574756383895874

training epoch 406 / 500, batch #600 / 625
Loss:	1.7087539434432983

training epoch 407 / 500, batch #0 / 625
Loss:	1.5109970569610596

training epoch 407 / 500, batch #25 / 625
Loss:	1.6375949382781982

training epoch 407 / 500, batch #50 / 625
Loss:	1.5171172618865967

training epoch 407 / 500, batch #75 / 625
Loss:	2.0830280780792236

training epoch 407 / 500, batch #100 / 625
Loss:	1.5360636711120605

training epoch 407 / 500, batch #125 / 625
Loss:	1.7231444120407104

training epoch 407 / 500, batch #150 / 625
Loss:	1.6842149496078491

training epoch 407 / 500, batch #175 / 625
Loss:	1.588533639907837

training epoch 407 / 500, batch #200 / 625
Loss:	1.6500333547592163

training epoch 407 / 500, batch #225 / 625
Loss:	1.6793570518493652

training epoch 407 / 500, batch #250 / 625
Loss:	1.8588489294052124

training epoch 407 / 500, batch #275 / 625
Loss:	1.8378076553344727

training epoch 407 / 500, batch #300 / 625
Loss:	1.6163257360458374

training epoch 407 / 500, batch #325 / 625
Loss:	1.9054855108261108

training epoch 407 / 500, batch #350 / 625
Loss:	1.8859306573867798

training epoch 407 / 500, batch #375 / 625
Loss:	1.4826853275299072

training epoch 407 / 500, batch #400 / 625
Loss:	1.8660002946853638

training epoch 407 / 500, batch #425 / 625
Loss:	1.5220428705215454

training epoch 407 / 500, batch #450 / 625
Loss:	1.6288721561431885

training epoch 407 / 500, batch #475 / 625
Loss:	1.838846206665039

training epoch 407 / 500, batch #500 / 625
Loss:	1.6653192043304443

training epoch 407 / 500, batch #525 / 625
Loss:	1.984480857849121

training epoch 407 / 500, batch #550 / 625
Loss:	1.514695405960083

training epoch 407 / 500, batch #575 / 625
Loss:	1.4665703773498535

training epoch 407 / 500, batch #600 / 625
Loss:	1.742739200592041

training epoch 408 / 500, batch #0 / 625
Loss:	1.6410608291625977

training epoch 408 / 500, batch #25 / 625
Loss:	1.7198584079742432

training epoch 408 / 500, batch #50 / 625
Loss:	1.6834933757781982

training epoch 408 / 500, batch #75 / 625
Loss:	1.793088674545288

training epoch 408 / 500, batch #100 / 625
Loss:	1.8129132986068726

training epoch 408 / 500, batch #125 / 625
Loss:	1.9550223350524902

training epoch 408 / 500, batch #150 / 625
Loss:	1.660048246383667

training epoch 408 / 500, batch #175 / 625
Loss:	1.6390211582183838

training epoch 408 / 500, batch #200 / 625
Loss:	1.4838570356369019

training epoch 408 / 500, batch #225 / 625
Loss:	1.893445611000061

training epoch 408 / 500, batch #250 / 625
Loss:	1.6549510955810547

training epoch 408 / 500, batch #275 / 625
Loss:	1.7503820657730103

training epoch 408 / 500, batch #300 / 625
Loss:	1.8990072011947632

training epoch 408 / 500, batch #325 / 625
Loss:	2.038410186767578

training epoch 408 / 500, batch #350 / 625
Loss:	1.536492109298706

training epoch 408 / 500, batch #375 / 625
Loss:	1.5872721672058105

training epoch 408 / 500, batch #400 / 625
Loss:	1.819529414176941

training epoch 408 / 500, batch #425 / 625
Loss:	1.4962583780288696

training epoch 408 / 500, batch #450 / 625
Loss:	1.8931045532226562

training epoch 408 / 500, batch #475 / 625
Loss:	1.748500943183899

training epoch 408 / 500, batch #500 / 625
Loss:	1.6288920640945435

training epoch 408 / 500, batch #525 / 625
Loss:	1.7327115535736084

training epoch 408 / 500, batch #550 / 625
Loss:	1.6882383823394775

training epoch 408 / 500, batch #575 / 625
Loss:	1.7102922201156616

training epoch 408 / 500, batch #600 / 625
Loss:	1.489096999168396

training epoch 409 / 500, batch #0 / 625
Loss:	1.4840978384017944

training epoch 409 / 500, batch #25 / 625
Loss:	1.6629951000213623

training epoch 409 / 500, batch #50 / 625
Loss:	1.6860915422439575

training epoch 409 / 500, batch #75 / 625
Loss:	1.6616590023040771

training epoch 409 / 500, batch #100 / 625
Loss:	1.6491005420684814

training epoch 409 / 500, batch #125 / 625
Loss:	1.6185122728347778

training epoch 409 / 500, batch #150 / 625
Loss:	1.7950907945632935

training epoch 409 / 500, batch #175 / 625
Loss:	1.6299220323562622

training epoch 409 / 500, batch #200 / 625
Loss:	1.6271294355392456

training epoch 409 / 500, batch #225 / 625
Loss:	1.7587018013000488

training epoch 409 / 500, batch #250 / 625
Loss:	1.7148311138153076

training epoch 409 / 500, batch #275 / 625
Loss:	1.7330455780029297

training epoch 409 / 500, batch #300 / 625
Loss:	1.3964930772781372

training epoch 409 / 500, batch #325 / 625
Loss:	1.6247087717056274

training epoch 409 / 500, batch #350 / 625
Loss:	1.602292537689209

training epoch 409 / 500, batch #375 / 625
Loss:	1.9575790166854858

training epoch 409 / 500, batch #400 / 625
Loss:	1.6952799558639526

training epoch 409 / 500, batch #425 / 625
Loss:	1.7399581670761108

training epoch 409 / 500, batch #450 / 625
Loss:	1.6349451541900635

training epoch 409 / 500, batch #475 / 625
Loss:	1.5905680656433105

training epoch 409 / 500, batch #500 / 625
Loss:	1.6446905136108398

training epoch 409 / 500, batch #525 / 625
Loss:	1.5067962408065796

training epoch 409 / 500, batch #550 / 625
Loss:	1.7160197496414185

training epoch 409 / 500, batch #575 / 625
Loss:	1.5652204751968384

training epoch 409 / 500, batch #600 / 625
Loss:	1.9265681505203247

training epoch 410 / 500, batch #0 / 625
Loss:	1.7038921117782593

training epoch 410 / 500, batch #25 / 625
Loss:	1.642928123474121

training epoch 410 / 500, batch #50 / 625
Loss:	1.5823935270309448

training epoch 410 / 500, batch #75 / 625
Loss:	1.546945333480835

training epoch 410 / 500, batch #100 / 625
Loss:	1.9525893926620483

training epoch 410 / 500, batch #125 / 625
Loss:	1.6887335777282715

training epoch 410 / 500, batch #150 / 625
Loss:	1.7589305639266968

training epoch 410 / 500, batch #175 / 625
Loss:	1.7309229373931885

training epoch 410 / 500, batch #200 / 625
Loss:	1.8377864360809326

training epoch 410 / 500, batch #225 / 625
Loss:	1.8575890064239502

training epoch 410 / 500, batch #250 / 625
Loss:	1.84201979637146

training epoch 410 / 500, batch #275 / 625
Loss:	1.6373673677444458

training epoch 410 / 500, batch #300 / 625
Loss:	1.5969377756118774

training epoch 410 / 500, batch #325 / 625
Loss:	1.6951429843902588

training epoch 410 / 500, batch #350 / 625
Loss:	1.828850507736206

training epoch 410 / 500, batch #375 / 625
Loss:	1.6861162185668945

training epoch 410 / 500, batch #400 / 625
Loss:	1.9262006282806396

training epoch 410 / 500, batch #425 / 625
Loss:	1.722009539604187

training epoch 410 / 500, batch #450 / 625
Loss:	1.871273159980774

training epoch 410 / 500, batch #475 / 625
Loss:	2.1012415885925293

training epoch 410 / 500, batch #500 / 625
Loss:	1.6507229804992676

training epoch 410 / 500, batch #525 / 625
Loss:	1.7103161811828613

training epoch 410 / 500, batch #550 / 625
Loss:	1.8949813842773438

training epoch 410 / 500, batch #575 / 625
Loss:	1.7657943964004517

training epoch 410 / 500, batch #600 / 625
Loss:	1.6806809902191162

training epoch 411 / 500, batch #0 / 625
Loss:	1.689378023147583

training epoch 411 / 500, batch #25 / 625
Loss:	1.7699466943740845

training epoch 411 / 500, batch #50 / 625
Loss:	1.642859697341919

training epoch 411 / 500, batch #75 / 625
Loss:	1.6586644649505615

training epoch 411 / 500, batch #100 / 625
Loss:	1.5585036277770996

training epoch 411 / 500, batch #125 / 625
Loss:	1.736667513847351

training epoch 411 / 500, batch #150 / 625
Loss:	1.8115822076797485

training epoch 411 / 500, batch #175 / 625
Loss:	1.7043083906173706

training epoch 411 / 500, batch #200 / 625
Loss:	1.835701823234558

training epoch 411 / 500, batch #225 / 625
Loss:	1.8359153270721436

training epoch 411 / 500, batch #250 / 625
Loss:	1.5619473457336426

training epoch 411 / 500, batch #275 / 625
Loss:	1.5999218225479126

training epoch 411 / 500, batch #300 / 625
Loss:	1.7046095132827759

training epoch 411 / 500, batch #325 / 625
Loss:	1.6217174530029297

training epoch 411 / 500, batch #350 / 625
Loss:	1.7106817960739136

training epoch 411 / 500, batch #375 / 625
Loss:	1.696062684059143

training epoch 411 / 500, batch #400 / 625
Loss:	1.5555369853973389

training epoch 411 / 500, batch #425 / 625
Loss:	1.6643918752670288

training epoch 411 / 500, batch #450 / 625
Loss:	1.5767996311187744

training epoch 411 / 500, batch #475 / 625
Loss:	1.5928150415420532

training epoch 411 / 500, batch #500 / 625
Loss:	1.8690094947814941

training epoch 411 / 500, batch #525 / 625
Loss:	1.6726667881011963

training epoch 411 / 500, batch #550 / 625
Loss:	1.63643217086792

training epoch 411 / 500, batch #575 / 625
Loss:	1.7522094249725342

training epoch 411 / 500, batch #600 / 625
Loss:	1.77098548412323

training epoch 412 / 500, batch #0 / 625
Loss:	1.668995976448059

training epoch 412 / 500, batch #25 / 625
Loss:	1.662447452545166

training epoch 412 / 500, batch #50 / 625
Loss:	1.4946435689926147

training epoch 412 / 500, batch #75 / 625
Loss:	1.6464561223983765

training epoch 412 / 500, batch #100 / 625
Loss:	1.9501326084136963

training epoch 412 / 500, batch #125 / 625
Loss:	1.6765004396438599

training epoch 412 / 500, batch #150 / 625
Loss:	1.6679893732070923

training epoch 412 / 500, batch #175 / 625
Loss:	1.794329047203064

training epoch 412 / 500, batch #200 / 625
Loss:	1.6608035564422607

training epoch 412 / 500, batch #225 / 625
Loss:	1.849041223526001

training epoch 412 / 500, batch #250 / 625
Loss:	1.8012624979019165

training epoch 412 / 500, batch #275 / 625
Loss:	1.9913952350616455

training epoch 412 / 500, batch #300 / 625
Loss:	1.6768686771392822

training epoch 412 / 500, batch #325 / 625
Loss:	1.8031377792358398

training epoch 412 / 500, batch #350 / 625
Loss:	1.7982468605041504

training epoch 412 / 500, batch #375 / 625
Loss:	1.5366976261138916

training epoch 412 / 500, batch #400 / 625
Loss:	1.6192708015441895

training epoch 412 / 500, batch #425 / 625
Loss:	1.936760425567627

training epoch 412 / 500, batch #450 / 625
Loss:	1.846152901649475

training epoch 412 / 500, batch #475 / 625
Loss:	1.8585644960403442

training epoch 412 / 500, batch #500 / 625
Loss:	1.6406774520874023

training epoch 412 / 500, batch #525 / 625
Loss:	1.7247023582458496

training epoch 412 / 500, batch #550 / 625
Loss:	1.7946135997772217

training epoch 412 / 500, batch #575 / 625
Loss:	1.615681529045105

training epoch 412 / 500, batch #600 / 625
Loss:	1.850346565246582

training epoch 413 / 500, batch #0 / 625
Loss:	1.676856279373169

training epoch 413 / 500, batch #25 / 625
Loss:	1.6277457475662231

training epoch 413 / 500, batch #50 / 625
Loss:	1.8606770038604736

training epoch 413 / 500, batch #75 / 625
Loss:	1.6925153732299805

training epoch 413 / 500, batch #100 / 625
Loss:	2.0500028133392334

training epoch 413 / 500, batch #125 / 625
Loss:	1.7604997158050537

training epoch 413 / 500, batch #150 / 625
Loss:	1.5927934646606445

training epoch 413 / 500, batch #175 / 625
Loss:	1.6114026308059692

training epoch 413 / 500, batch #200 / 625
Loss:	1.6813327074050903

training epoch 413 / 500, batch #225 / 625
Loss:	1.851432204246521

training epoch 413 / 500, batch #250 / 625
Loss:	1.700831651687622

training epoch 413 / 500, batch #275 / 625
Loss:	1.8183304071426392

training epoch 413 / 500, batch #300 / 625
Loss:	1.680506944656372

training epoch 413 / 500, batch #325 / 625
Loss:	1.8210076093673706

training epoch 413 / 500, batch #350 / 625
Loss:	1.8256088495254517

training epoch 413 / 500, batch #375 / 625
Loss:	1.7633872032165527

training epoch 413 / 500, batch #400 / 625
Loss:	1.8742104768753052

training epoch 413 / 500, batch #425 / 625
Loss:	1.5951640605926514

training epoch 413 / 500, batch #450 / 625
Loss:	1.548875331878662

training epoch 413 / 500, batch #475 / 625
Loss:	1.6798993349075317

training epoch 413 / 500, batch #500 / 625
Loss:	1.6083770990371704

training epoch 413 / 500, batch #525 / 625
Loss:	1.8305915594100952

training epoch 413 / 500, batch #550 / 625
Loss:	1.7806130647659302

training epoch 413 / 500, batch #575 / 625
Loss:	1.5183086395263672

training epoch 413 / 500, batch #600 / 625
Loss:	1.7072548866271973

training epoch 414 / 500, batch #0 / 625
Loss:	1.6812081336975098

training epoch 414 / 500, batch #25 / 625
Loss:	1.6642929315567017

training epoch 414 / 500, batch #50 / 625
Loss:	1.675289273262024

training epoch 414 / 500, batch #75 / 625
Loss:	1.6724319458007812

training epoch 414 / 500, batch #100 / 625
Loss:	1.5401350259780884

training epoch 414 / 500, batch #125 / 625
Loss:	1.637107491493225

training epoch 414 / 500, batch #150 / 625
Loss:	1.5961191654205322

training epoch 414 / 500, batch #175 / 625
Loss:	1.6865159273147583

training epoch 414 / 500, batch #200 / 625
Loss:	2.036393642425537

training epoch 414 / 500, batch #225 / 625
Loss:	1.5630357265472412

training epoch 414 / 500, batch #250 / 625
Loss:	1.7647916078567505

training epoch 414 / 500, batch #275 / 625
Loss:	1.7117223739624023

training epoch 414 / 500, batch #300 / 625
Loss:	1.5122374296188354

training epoch 414 / 500, batch #325 / 625
Loss:	1.8008126020431519

training epoch 414 / 500, batch #350 / 625
Loss:	1.7060508728027344

training epoch 414 / 500, batch #375 / 625
Loss:	1.7151740789413452

training epoch 414 / 500, batch #400 / 625
Loss:	1.716117024421692

training epoch 414 / 500, batch #425 / 625
Loss:	1.8549599647521973

training epoch 414 / 500, batch #450 / 625
Loss:	2.019585609436035

training epoch 414 / 500, batch #475 / 625
Loss:	1.8177684545516968

training epoch 414 / 500, batch #500 / 625
Loss:	1.6955631971359253

training epoch 414 / 500, batch #525 / 625
Loss:	1.7087643146514893

training epoch 414 / 500, batch #550 / 625
Loss:	1.8160773515701294

training epoch 414 / 500, batch #575 / 625
Loss:	1.461288332939148

training epoch 414 / 500, batch #600 / 625
Loss:	1.4603935480117798

training epoch 415 / 500, batch #0 / 625
Loss:	1.7002739906311035

training epoch 415 / 500, batch #25 / 625
Loss:	1.4652025699615479

training epoch 415 / 500, batch #50 / 625
Loss:	2.0848100185394287

training epoch 415 / 500, batch #75 / 625
Loss:	1.5714174509048462

training epoch 415 / 500, batch #100 / 625
Loss:	1.9387983083724976

training epoch 415 / 500, batch #125 / 625
Loss:	2.032965898513794

training epoch 415 / 500, batch #150 / 625
Loss:	1.8588178157806396

training epoch 415 / 500, batch #175 / 625
Loss:	1.820085883140564

training epoch 415 / 500, batch #200 / 625
Loss:	1.702012300491333

training epoch 415 / 500, batch #225 / 625
Loss:	1.837510347366333

training epoch 415 / 500, batch #250 / 625
Loss:	1.8233652114868164

training epoch 415 / 500, batch #275 / 625
Loss:	2.0068984031677246

training epoch 415 / 500, batch #300 / 625
Loss:	1.7689865827560425

training epoch 415 / 500, batch #325 / 625
Loss:	1.6433992385864258

training epoch 415 / 500, batch #350 / 625
Loss:	1.60731041431427

training epoch 415 / 500, batch #375 / 625
Loss:	1.6866551637649536

training epoch 415 / 500, batch #400 / 625
Loss:	1.7262860536575317

training epoch 415 / 500, batch #425 / 625
Loss:	1.5235527753829956

training epoch 415 / 500, batch #450 / 625
Loss:	1.7308200597763062

training epoch 415 / 500, batch #475 / 625
Loss:	1.5911377668380737

training epoch 415 / 500, batch #500 / 625
Loss:	1.7438147068023682

training epoch 415 / 500, batch #525 / 625
Loss:	1.505792498588562

training epoch 415 / 500, batch #550 / 625
Loss:	1.8497802019119263

training epoch 415 / 500, batch #575 / 625
Loss:	1.787231206893921

training epoch 415 / 500, batch #600 / 625
Loss:	1.7463159561157227

training epoch 416 / 500, batch #0 / 625
Loss:	1.684472918510437

training epoch 416 / 500, batch #25 / 625
Loss:	1.822503924369812

training epoch 416 / 500, batch #50 / 625
Loss:	1.7588497400283813

training epoch 416 / 500, batch #75 / 625
Loss:	1.8084951639175415

training epoch 416 / 500, batch #100 / 625
Loss:	1.588384985923767

training epoch 416 / 500, batch #125 / 625
Loss:	1.6386076211929321

training epoch 416 / 500, batch #150 / 625
Loss:	1.8695788383483887

training epoch 416 / 500, batch #175 / 625
Loss:	1.7009742259979248

training epoch 416 / 500, batch #200 / 625
Loss:	1.608655571937561

training epoch 416 / 500, batch #225 / 625
Loss:	1.6613917350769043

training epoch 416 / 500, batch #250 / 625
Loss:	1.7253806591033936

training epoch 416 / 500, batch #275 / 625
Loss:	1.7896894216537476

training epoch 416 / 500, batch #300 / 625
Loss:	1.7935611009597778

training epoch 416 / 500, batch #325 / 625
Loss:	1.6631062030792236

training epoch 416 / 500, batch #350 / 625
Loss:	1.563114881515503

training epoch 416 / 500, batch #375 / 625
Loss:	1.6660706996917725

training epoch 416 / 500, batch #400 / 625
Loss:	1.7870619297027588

training epoch 416 / 500, batch #425 / 625
Loss:	1.7386822700500488

training epoch 416 / 500, batch #450 / 625
Loss:	1.8077296018600464

training epoch 416 / 500, batch #475 / 625
Loss:	1.7089096307754517

training epoch 416 / 500, batch #500 / 625
Loss:	1.6300324201583862

training epoch 416 / 500, batch #525 / 625
Loss:	1.728651523590088

training epoch 416 / 500, batch #550 / 625
Loss:	1.489273190498352

training epoch 416 / 500, batch #575 / 625
Loss:	1.532344102859497

training epoch 416 / 500, batch #600 / 625
Loss:	1.724860668182373

training epoch 417 / 500, batch #0 / 625
Loss:	1.5154478549957275

training epoch 417 / 500, batch #25 / 625
Loss:	1.411853313446045

training epoch 417 / 500, batch #50 / 625
Loss:	1.5683952569961548

training epoch 417 / 500, batch #75 / 625
Loss:	1.7215931415557861

training epoch 417 / 500, batch #100 / 625
Loss:	1.7797757387161255

training epoch 417 / 500, batch #125 / 625
Loss:	1.5175831317901611

training epoch 417 / 500, batch #150 / 625
Loss:	1.6705137491226196

training epoch 417 / 500, batch #175 / 625
Loss:	1.5776065587997437

training epoch 417 / 500, batch #200 / 625
Loss:	1.5512579679489136

training epoch 417 / 500, batch #225 / 625
Loss:	1.5504789352416992

training epoch 417 / 500, batch #250 / 625
Loss:	1.8197416067123413

training epoch 417 / 500, batch #275 / 625
Loss:	1.435534954071045

training epoch 417 / 500, batch #300 / 625
Loss:	1.7097268104553223

training epoch 417 / 500, batch #325 / 625
Loss:	1.8877476453781128

training epoch 417 / 500, batch #350 / 625
Loss:	1.7957849502563477

training epoch 417 / 500, batch #375 / 625
Loss:	1.6786468029022217

training epoch 417 / 500, batch #400 / 625
Loss:	1.6986193656921387

training epoch 417 / 500, batch #425 / 625
Loss:	1.6793292760849

training epoch 417 / 500, batch #450 / 625
Loss:	1.6490187644958496

training epoch 417 / 500, batch #475 / 625
Loss:	1.5286245346069336

training epoch 417 / 500, batch #500 / 625
Loss:	1.6640832424163818

training epoch 417 / 500, batch #525 / 625
Loss:	1.6660585403442383

training epoch 417 / 500, batch #550 / 625
Loss:	1.8089317083358765

training epoch 417 / 500, batch #575 / 625
Loss:	2.070612668991089

training epoch 417 / 500, batch #600 / 625
Loss:	1.6270791292190552

training epoch 418 / 500, batch #0 / 625
Loss:	1.8654924631118774

training epoch 418 / 500, batch #25 / 625
Loss:	1.8920316696166992

training epoch 418 / 500, batch #50 / 625
Loss:	1.7332326173782349

training epoch 418 / 500, batch #75 / 625
Loss:	1.602534532546997

training epoch 418 / 500, batch #100 / 625
Loss:	1.5813406705856323

training epoch 418 / 500, batch #125 / 625
Loss:	1.5885052680969238

training epoch 418 / 500, batch #150 / 625
Loss:	1.5889079570770264

training epoch 418 / 500, batch #175 / 625
Loss:	1.8296928405761719

training epoch 418 / 500, batch #200 / 625
Loss:	1.8304232358932495

training epoch 418 / 500, batch #225 / 625
Loss:	1.6818616390228271

training epoch 418 / 500, batch #250 / 625
Loss:	1.6457792520523071

training epoch 418 / 500, batch #275 / 625
Loss:	1.7891117334365845

training epoch 418 / 500, batch #300 / 625
Loss:	2.0581350326538086

training epoch 418 / 500, batch #325 / 625
Loss:	1.6045268774032593

training epoch 418 / 500, batch #350 / 625
Loss:	1.6081011295318604

training epoch 418 / 500, batch #375 / 625
Loss:	1.8750499486923218

training epoch 418 / 500, batch #400 / 625
Loss:	1.8986339569091797

training epoch 418 / 500, batch #425 / 625
Loss:	2.0122461318969727

training epoch 418 / 500, batch #450 / 625
Loss:	1.4341638088226318

training epoch 418 / 500, batch #475 / 625
Loss:	1.684867024421692

training epoch 418 / 500, batch #500 / 625
Loss:	1.744820475578308

training epoch 418 / 500, batch #525 / 625
Loss:	1.468201994895935

training epoch 418 / 500, batch #550 / 625
Loss:	1.6678224802017212

training epoch 418 / 500, batch #575 / 625
Loss:	1.5984282493591309

training epoch 418 / 500, batch #600 / 625
Loss:	1.8253803253173828

training epoch 419 / 500, batch #0 / 625
Loss:	1.6878395080566406

training epoch 419 / 500, batch #25 / 625
Loss:	1.6454136371612549

training epoch 419 / 500, batch #50 / 625
Loss:	1.6989269256591797

training epoch 419 / 500, batch #75 / 625
Loss:	1.8652280569076538

training epoch 419 / 500, batch #100 / 625
Loss:	1.7029129266738892

training epoch 419 / 500, batch #125 / 625
Loss:	1.6687462329864502

training epoch 419 / 500, batch #150 / 625
Loss:	1.6395978927612305

training epoch 419 / 500, batch #175 / 625
Loss:	1.4800337553024292

training epoch 419 / 500, batch #200 / 625
Loss:	1.4563244581222534

training epoch 419 / 500, batch #225 / 625
Loss:	1.8313279151916504

training epoch 419 / 500, batch #250 / 625
Loss:	1.6712353229522705

training epoch 419 / 500, batch #275 / 625
Loss:	1.7150601148605347

training epoch 419 / 500, batch #300 / 625
Loss:	2.071697950363159

training epoch 419 / 500, batch #325 / 625
Loss:	1.5769398212432861

training epoch 419 / 500, batch #350 / 625
Loss:	1.36564302444458

training epoch 419 / 500, batch #375 / 625
Loss:	1.8108477592468262

training epoch 419 / 500, batch #400 / 625
Loss:	1.5983941555023193

training epoch 419 / 500, batch #425 / 625
Loss:	1.748382568359375

training epoch 419 / 500, batch #450 / 625
Loss:	1.606141448020935

training epoch 419 / 500, batch #475 / 625
Loss:	1.6385213136672974

training epoch 419 / 500, batch #500 / 625
Loss:	1.8270491361618042

training epoch 419 / 500, batch #525 / 625
Loss:	1.7208197116851807

training epoch 419 / 500, batch #550 / 625
Loss:	1.8091225624084473

training epoch 419 / 500, batch #575 / 625
Loss:	1.6009833812713623

training epoch 419 / 500, batch #600 / 625
Loss:	1.6261332035064697

training epoch 420 / 500, batch #0 / 625
Loss:	1.934911847114563

training epoch 420 / 500, batch #25 / 625
Loss:	1.7706667184829712

training epoch 420 / 500, batch #50 / 625
Loss:	1.7689249515533447

training epoch 420 / 500, batch #75 / 625
Loss:	1.6946558952331543

training epoch 420 / 500, batch #100 / 625
Loss:	1.6517666578292847

training epoch 420 / 500, batch #125 / 625
Loss:	1.8377636671066284

training epoch 420 / 500, batch #150 / 625
Loss:	1.629525899887085

training epoch 420 / 500, batch #175 / 625
Loss:	1.9844141006469727

training epoch 420 / 500, batch #200 / 625
Loss:	1.9813835620880127

training epoch 420 / 500, batch #225 / 625
Loss:	1.8362923860549927

training epoch 420 / 500, batch #250 / 625
Loss:	1.717559576034546

training epoch 420 / 500, batch #275 / 625
Loss:	1.9229626655578613

training epoch 420 / 500, batch #300 / 625
Loss:	1.6142045259475708

training epoch 420 / 500, batch #325 / 625
Loss:	1.4980440139770508

training epoch 420 / 500, batch #350 / 625
Loss:	1.6967055797576904

training epoch 420 / 500, batch #375 / 625
Loss:	1.9469377994537354

training epoch 420 / 500, batch #400 / 625
Loss:	1.6124017238616943

training epoch 420 / 500, batch #425 / 625
Loss:	1.528480887413025

training epoch 420 / 500, batch #450 / 625
Loss:	1.918674349784851

training epoch 420 / 500, batch #475 / 625
Loss:	1.7134302854537964

training epoch 420 / 500, batch #500 / 625
Loss:	1.7794064283370972

training epoch 420 / 500, batch #525 / 625
Loss:	1.7151597738265991

training epoch 420 / 500, batch #550 / 625
Loss:	1.7787864208221436

training epoch 420 / 500, batch #575 / 625
Loss:	1.5369181632995605

training epoch 420 / 500, batch #600 / 625
Loss:	1.7953180074691772

training epoch 421 / 500, batch #0 / 625
Loss:	1.8695021867752075

training epoch 421 / 500, batch #25 / 625
Loss:	1.5400340557098389

training epoch 421 / 500, batch #50 / 625
Loss:	1.6577365398406982

training epoch 421 / 500, batch #75 / 625
Loss:	1.6641770601272583

training epoch 421 / 500, batch #100 / 625
Loss:	1.7699456214904785

training epoch 421 / 500, batch #125 / 625
Loss:	1.645356297492981

training epoch 421 / 500, batch #150 / 625
Loss:	1.7194290161132812

training epoch 421 / 500, batch #175 / 625
Loss:	1.8368412256240845

training epoch 421 / 500, batch #200 / 625
Loss:	1.5430686473846436

training epoch 421 / 500, batch #225 / 625
Loss:	1.7560770511627197

training epoch 421 / 500, batch #250 / 625
Loss:	1.7141780853271484

training epoch 421 / 500, batch #275 / 625
Loss:	1.7531880140304565

training epoch 421 / 500, batch #300 / 625
Loss:	1.6585580110549927

training epoch 421 / 500, batch #325 / 625
Loss:	1.6761225461959839

training epoch 421 / 500, batch #350 / 625
Loss:	2.099886417388916

training epoch 421 / 500, batch #375 / 625
Loss:	1.6859725713729858

training epoch 421 / 500, batch #400 / 625
Loss:	1.6944009065628052

training epoch 421 / 500, batch #425 / 625
Loss:	1.509607195854187

training epoch 421 / 500, batch #450 / 625
Loss:	2.018486261367798

training epoch 421 / 500, batch #475 / 625
Loss:	1.7464885711669922

training epoch 421 / 500, batch #500 / 625
Loss:	1.7200177907943726

training epoch 421 / 500, batch #525 / 625
Loss:	1.792785882949829

training epoch 421 / 500, batch #550 / 625
Loss:	1.7646809816360474

training epoch 421 / 500, batch #575 / 625
Loss:	1.637946605682373

training epoch 421 / 500, batch #600 / 625
Loss:	1.6755532026290894

training epoch 422 / 500, batch #0 / 625
Loss:	1.877975344657898

training epoch 422 / 500, batch #25 / 625
Loss:	1.5378350019454956

training epoch 422 / 500, batch #50 / 625
Loss:	1.6095545291900635

training epoch 422 / 500, batch #75 / 625
Loss:	1.9212000370025635

training epoch 422 / 500, batch #100 / 625
Loss:	1.5072311162948608

training epoch 422 / 500, batch #125 / 625
Loss:	1.5753967761993408

training epoch 422 / 500, batch #150 / 625
Loss:	1.9290889501571655

training epoch 422 / 500, batch #175 / 625
Loss:	1.9329947233200073

training epoch 422 / 500, batch #200 / 625
Loss:	1.8308539390563965

training epoch 422 / 500, batch #225 / 625
Loss:	1.7220326662063599

training epoch 422 / 500, batch #250 / 625
Loss:	1.7011977434158325

training epoch 422 / 500, batch #275 / 625
Loss:	1.7210288047790527

training epoch 422 / 500, batch #300 / 625
Loss:	1.667175531387329

training epoch 422 / 500, batch #325 / 625
Loss:	1.8655991554260254

training epoch 422 / 500, batch #350 / 625
Loss:	1.7173949480056763

training epoch 422 / 500, batch #375 / 625
Loss:	1.5888515710830688

training epoch 422 / 500, batch #400 / 625
Loss:	1.9745482206344604

training epoch 422 / 500, batch #425 / 625
Loss:	1.823316216468811

training epoch 422 / 500, batch #450 / 625
Loss:	1.701506495475769

training epoch 422 / 500, batch #475 / 625
Loss:	1.5552647113800049

training epoch 422 / 500, batch #500 / 625
Loss:	1.527823805809021

training epoch 422 / 500, batch #525 / 625
Loss:	1.4837279319763184

training epoch 422 / 500, batch #550 / 625
Loss:	1.6398181915283203

training epoch 422 / 500, batch #575 / 625
Loss:	1.7095391750335693

training epoch 422 / 500, batch #600 / 625
Loss:	1.778573989868164

training epoch 423 / 500, batch #0 / 625
Loss:	1.8138539791107178

training epoch 423 / 500, batch #25 / 625
Loss:	1.5837576389312744

training epoch 423 / 500, batch #50 / 625
Loss:	2.045922040939331

training epoch 423 / 500, batch #75 / 625
Loss:	1.7626817226409912

training epoch 423 / 500, batch #100 / 625
Loss:	1.9052056074142456

training epoch 423 / 500, batch #125 / 625
Loss:	1.6003578901290894

training epoch 423 / 500, batch #150 / 625
Loss:	1.5060293674468994

training epoch 423 / 500, batch #175 / 625
Loss:	1.5747498273849487

training epoch 423 / 500, batch #200 / 625
Loss:	1.6808744668960571

training epoch 423 / 500, batch #225 / 625
Loss:	1.864811658859253

training epoch 423 / 500, batch #250 / 625
Loss:	1.7004677057266235

training epoch 423 / 500, batch #275 / 625
Loss:	1.8464211225509644

training epoch 423 / 500, batch #300 / 625
Loss:	2.061915636062622

training epoch 423 / 500, batch #325 / 625
Loss:	1.691330909729004

training epoch 423 / 500, batch #350 / 625
Loss:	1.6632736921310425

training epoch 423 / 500, batch #375 / 625
Loss:	1.6914293766021729

training epoch 423 / 500, batch #400 / 625
Loss:	1.8287519216537476

training epoch 423 / 500, batch #425 / 625
Loss:	1.7565346956253052

training epoch 423 / 500, batch #450 / 625
Loss:	1.921299934387207

training epoch 423 / 500, batch #475 / 625
Loss:	1.8351716995239258

training epoch 423 / 500, batch #500 / 625
Loss:	1.7342196702957153

training epoch 423 / 500, batch #525 / 625
Loss:	1.6733075380325317

training epoch 423 / 500, batch #550 / 625
Loss:	1.7159324884414673

training epoch 423 / 500, batch #575 / 625
Loss:	1.6525121927261353

training epoch 423 / 500, batch #600 / 625
Loss:	1.6282662153244019

training epoch 424 / 500, batch #0 / 625
Loss:	1.7665170431137085

training epoch 424 / 500, batch #25 / 625
Loss:	1.7756690979003906

training epoch 424 / 500, batch #50 / 625
Loss:	1.6523250341415405

training epoch 424 / 500, batch #75 / 625
Loss:	1.9397965669631958

training epoch 424 / 500, batch #100 / 625
Loss:	1.603535771369934

training epoch 424 / 500, batch #125 / 625
Loss:	1.8597391843795776

training epoch 424 / 500, batch #150 / 625
Loss:	1.6689581871032715

training epoch 424 / 500, batch #175 / 625
Loss:	1.7539325952529907

training epoch 424 / 500, batch #200 / 625
Loss:	1.849473476409912

training epoch 424 / 500, batch #225 / 625
Loss:	1.6360220909118652

training epoch 424 / 500, batch #250 / 625
Loss:	1.5953460931777954

training epoch 424 / 500, batch #275 / 625
Loss:	1.7345043420791626

training epoch 424 / 500, batch #300 / 625
Loss:	1.7492674589157104

training epoch 424 / 500, batch #325 / 625
Loss:	1.7278422117233276

training epoch 424 / 500, batch #350 / 625
Loss:	1.6546311378479004

training epoch 424 / 500, batch #375 / 625
Loss:	1.8638325929641724

training epoch 424 / 500, batch #400 / 625
Loss:	1.568449854850769

training epoch 424 / 500, batch #425 / 625
Loss:	1.7764105796813965

training epoch 424 / 500, batch #450 / 625
Loss:	1.6646511554718018

training epoch 424 / 500, batch #475 / 625
Loss:	1.7965643405914307

training epoch 424 / 500, batch #500 / 625
Loss:	1.5696982145309448

training epoch 424 / 500, batch #525 / 625
Loss:	1.8684403896331787

training epoch 424 / 500, batch #550 / 625
Loss:	1.7429219484329224

training epoch 424 / 500, batch #575 / 625
Loss:	1.6502577066421509

training epoch 424 / 500, batch #600 / 625
Loss:	1.8437620401382446

training epoch 425 / 500, batch #0 / 625
Loss:	1.7538565397262573

training epoch 425 / 500, batch #25 / 625
Loss:	1.8798505067825317

training epoch 425 / 500, batch #50 / 625
Loss:	1.52585768699646

training epoch 425 / 500, batch #75 / 625
Loss:	1.6232962608337402

training epoch 425 / 500, batch #100 / 625
Loss:	1.6546181440353394

training epoch 425 / 500, batch #125 / 625
Loss:	1.514701247215271

training epoch 425 / 500, batch #150 / 625
Loss:	1.6225212812423706

training epoch 425 / 500, batch #175 / 625
Loss:	1.6056649684906006

training epoch 425 / 500, batch #200 / 625
Loss:	1.660740613937378

training epoch 425 / 500, batch #225 / 625
Loss:	1.6311699151992798

training epoch 425 / 500, batch #250 / 625
Loss:	1.7428532838821411

training epoch 425 / 500, batch #275 / 625
Loss:	1.799752116203308

training epoch 425 / 500, batch #300 / 625
Loss:	1.7216352224349976

training epoch 425 / 500, batch #325 / 625
Loss:	1.9938043355941772

training epoch 425 / 500, batch #350 / 625
Loss:	1.602968454360962

training epoch 425 / 500, batch #375 / 625
Loss:	1.6506963968276978

training epoch 425 / 500, batch #400 / 625
Loss:	1.6686370372772217

training epoch 425 / 500, batch #425 / 625
Loss:	1.8130240440368652

training epoch 425 / 500, batch #450 / 625
Loss:	1.5802745819091797

training epoch 425 / 500, batch #475 / 625
Loss:	1.8499600887298584

training epoch 425 / 500, batch #500 / 625
Loss:	1.7207226753234863

training epoch 425 / 500, batch #525 / 625
Loss:	1.5436550378799438

training epoch 425 / 500, batch #550 / 625
Loss:	1.6099927425384521

training epoch 425 / 500, batch #575 / 625
Loss:	2.046516180038452

training epoch 425 / 500, batch #600 / 625
Loss:	1.6211845874786377

training epoch 426 / 500, batch #0 / 625
Loss:	1.974072813987732

training epoch 426 / 500, batch #25 / 625
Loss:	1.7037296295166016

training epoch 426 / 500, batch #50 / 625
Loss:	1.7415374517440796

training epoch 426 / 500, batch #75 / 625
Loss:	1.9215484857559204

training epoch 426 / 500, batch #100 / 625
Loss:	1.7067523002624512

training epoch 426 / 500, batch #125 / 625
Loss:	1.6665202379226685

training epoch 426 / 500, batch #150 / 625
Loss:	1.7851908206939697

training epoch 426 / 500, batch #175 / 625
Loss:	1.729661226272583

training epoch 426 / 500, batch #200 / 625
Loss:	1.7486295700073242

training epoch 426 / 500, batch #225 / 625
Loss:	1.748440146446228

training epoch 426 / 500, batch #250 / 625
Loss:	1.8107191324234009

training epoch 426 / 500, batch #275 / 625
Loss:	1.7422575950622559

training epoch 426 / 500, batch #300 / 625
Loss:	1.6333032846450806

training epoch 426 / 500, batch #325 / 625
Loss:	1.6280972957611084

training epoch 426 / 500, batch #350 / 625
Loss:	1.70537269115448

training epoch 426 / 500, batch #375 / 625
Loss:	1.7184299230575562

training epoch 426 / 500, batch #400 / 625
Loss:	1.6955927610397339

training epoch 426 / 500, batch #425 / 625
Loss:	1.7436023950576782

training epoch 426 / 500, batch #450 / 625
Loss:	1.7794631719589233

training epoch 426 / 500, batch #475 / 625
Loss:	1.8415735960006714

training epoch 426 / 500, batch #500 / 625
Loss:	1.5757497549057007

training epoch 426 / 500, batch #525 / 625
Loss:	1.6672990322113037

training epoch 426 / 500, batch #550 / 625
Loss:	1.5510183572769165

training epoch 426 / 500, batch #575 / 625
Loss:	1.781964659690857

training epoch 426 / 500, batch #600 / 625
Loss:	1.8970863819122314

training epoch 427 / 500, batch #0 / 625
Loss:	1.5519425868988037

training epoch 427 / 500, batch #25 / 625
Loss:	2.02341365814209

training epoch 427 / 500, batch #50 / 625
Loss:	1.5746124982833862

training epoch 427 / 500, batch #75 / 625
Loss:	1.8327276706695557

training epoch 427 / 500, batch #100 / 625
Loss:	1.7964372634887695

training epoch 427 / 500, batch #125 / 625
Loss:	1.7998381853103638

training epoch 427 / 500, batch #150 / 625
Loss:	1.8248590230941772

training epoch 427 / 500, batch #175 / 625
Loss:	1.7935409545898438

training epoch 427 / 500, batch #200 / 625
Loss:	1.5788450241088867

training epoch 427 / 500, batch #225 / 625
Loss:	1.6836947202682495

training epoch 427 / 500, batch #250 / 625
Loss:	1.6114959716796875

training epoch 427 / 500, batch #275 / 625
Loss:	1.747902512550354

training epoch 427 / 500, batch #300 / 625
Loss:	1.6098965406417847

training epoch 427 / 500, batch #325 / 625
Loss:	1.6859831809997559

training epoch 427 / 500, batch #350 / 625
Loss:	1.668814778327942

training epoch 427 / 500, batch #375 / 625
Loss:	1.5893818140029907

training epoch 427 / 500, batch #400 / 625
Loss:	1.66580069065094

training epoch 427 / 500, batch #425 / 625
Loss:	1.8017586469650269

training epoch 427 / 500, batch #450 / 625
Loss:	1.8091965913772583

training epoch 427 / 500, batch #475 / 625
Loss:	1.83567214012146

training epoch 427 / 500, batch #500 / 625
Loss:	1.626319169998169

training epoch 427 / 500, batch #525 / 625
Loss:	1.6861032247543335

training epoch 427 / 500, batch #550 / 625
Loss:	1.7279692888259888

training epoch 427 / 500, batch #575 / 625
Loss:	1.9097228050231934

training epoch 427 / 500, batch #600 / 625
Loss:	1.5421346426010132

training epoch 428 / 500, batch #0 / 625
Loss:	1.9047602415084839

training epoch 428 / 500, batch #25 / 625
Loss:	1.6281458139419556

training epoch 428 / 500, batch #50 / 625
Loss:	1.6464684009552002

training epoch 428 / 500, batch #75 / 625
Loss:	1.587260365486145

training epoch 428 / 500, batch #100 / 625
Loss:	1.7158869504928589

training epoch 428 / 500, batch #125 / 625
Loss:	1.936774730682373

training epoch 428 / 500, batch #150 / 625
Loss:	1.5669560432434082

training epoch 428 / 500, batch #175 / 625
Loss:	1.6316797733306885

training epoch 428 / 500, batch #200 / 625
Loss:	1.679038166999817

training epoch 428 / 500, batch #225 / 625
Loss:	1.5174949169158936

training epoch 428 / 500, batch #250 / 625
Loss:	1.5722033977508545

training epoch 428 / 500, batch #275 / 625
Loss:	1.8463133573532104

training epoch 428 / 500, batch #300 / 625
Loss:	1.420907735824585

training epoch 428 / 500, batch #325 / 625
Loss:	1.9180800914764404

training epoch 428 / 500, batch #350 / 625
Loss:	1.5076589584350586

training epoch 428 / 500, batch #375 / 625
Loss:	1.682148814201355

training epoch 428 / 500, batch #400 / 625
Loss:	1.6313098669052124

training epoch 428 / 500, batch #425 / 625
Loss:	1.5749764442443848

training epoch 428 / 500, batch #450 / 625
Loss:	1.631818175315857

training epoch 428 / 500, batch #475 / 625
Loss:	1.6928662061691284

training epoch 428 / 500, batch #500 / 625
Loss:	1.7162679433822632

training epoch 428 / 500, batch #525 / 625
Loss:	1.4747450351715088

training epoch 428 / 500, batch #550 / 625
Loss:	1.585381269454956

training epoch 428 / 500, batch #575 / 625
Loss:	1.800017237663269

training epoch 428 / 500, batch #600 / 625
Loss:	1.9241337776184082

training epoch 429 / 500, batch #0 / 625
Loss:	1.4211313724517822

training epoch 429 / 500, batch #25 / 625
Loss:	1.720410943031311

training epoch 429 / 500, batch #50 / 625
Loss:	1.6434109210968018

training epoch 429 / 500, batch #75 / 625
Loss:	1.7353776693344116

training epoch 429 / 500, batch #100 / 625
Loss:	1.8035938739776611

training epoch 429 / 500, batch #125 / 625
Loss:	1.616028070449829

training epoch 429 / 500, batch #150 / 625
Loss:	1.724438190460205

training epoch 429 / 500, batch #175 / 625
Loss:	1.5828710794448853

training epoch 429 / 500, batch #200 / 625
Loss:	1.7514033317565918

training epoch 429 / 500, batch #225 / 625
Loss:	1.810232162475586

training epoch 429 / 500, batch #250 / 625
Loss:	1.4195010662078857

training epoch 429 / 500, batch #275 / 625
Loss:	1.6944211721420288

training epoch 429 / 500, batch #300 / 625
Loss:	1.3641090393066406

training epoch 429 / 500, batch #325 / 625
Loss:	1.4479018449783325

training epoch 429 / 500, batch #350 / 625
Loss:	1.7396243810653687

training epoch 429 / 500, batch #375 / 625
Loss:	1.9377772808074951

training epoch 429 / 500, batch #400 / 625
Loss:	1.6169291734695435

training epoch 429 / 500, batch #425 / 625
Loss:	1.7601064443588257

training epoch 429 / 500, batch #450 / 625
Loss:	1.6438724994659424

training epoch 429 / 500, batch #475 / 625
Loss:	1.6531387567520142

training epoch 429 / 500, batch #500 / 625
Loss:	1.806471824645996

training epoch 429 / 500, batch #525 / 625
Loss:	1.7618376016616821

training epoch 429 / 500, batch #550 / 625
Loss:	1.7620935440063477

training epoch 429 / 500, batch #575 / 625
Loss:	1.662946105003357

training epoch 429 / 500, batch #600 / 625
Loss:	1.8502272367477417

training epoch 430 / 500, batch #0 / 625
Loss:	1.7518024444580078

training epoch 430 / 500, batch #25 / 625
Loss:	1.7549757957458496

training epoch 430 / 500, batch #50 / 625
Loss:	1.6860244274139404

training epoch 430 / 500, batch #75 / 625
Loss:	1.7606289386749268

training epoch 430 / 500, batch #100 / 625
Loss:	1.6524651050567627

training epoch 430 / 500, batch #125 / 625
Loss:	1.719899296760559

training epoch 430 / 500, batch #150 / 625
Loss:	1.6964747905731201

training epoch 430 / 500, batch #175 / 625
Loss:	1.5663574934005737

training epoch 430 / 500, batch #200 / 625
Loss:	1.790909767150879

training epoch 430 / 500, batch #225 / 625
Loss:	1.9268699884414673

training epoch 430 / 500, batch #250 / 625
Loss:	1.7820113897323608

training epoch 430 / 500, batch #275 / 625
Loss:	1.7867060899734497

training epoch 430 / 500, batch #300 / 625
Loss:	1.613203525543213

training epoch 430 / 500, batch #325 / 625
Loss:	1.716131329536438

training epoch 430 / 500, batch #350 / 625
Loss:	1.6722580194473267

training epoch 430 / 500, batch #375 / 625
Loss:	1.6496706008911133

training epoch 430 / 500, batch #400 / 625
Loss:	1.8591704368591309

training epoch 430 / 500, batch #425 / 625
Loss:	1.721855640411377

training epoch 430 / 500, batch #450 / 625
Loss:	1.649289608001709

training epoch 430 / 500, batch #475 / 625
Loss:	1.9331384897232056

training epoch 430 / 500, batch #500 / 625
Loss:	1.697274088859558

training epoch 430 / 500, batch #525 / 625
Loss:	2.1571152210235596

training epoch 430 / 500, batch #550 / 625
Loss:	1.8668937683105469

training epoch 430 / 500, batch #575 / 625
Loss:	1.8427610397338867

training epoch 430 / 500, batch #600 / 625
Loss:	1.4676743745803833

training epoch 431 / 500, batch #0 / 625
Loss:	1.801729679107666

training epoch 431 / 500, batch #25 / 625
Loss:	1.7256954908370972

training epoch 431 / 500, batch #50 / 625
Loss:	1.8429646492004395

training epoch 431 / 500, batch #75 / 625
Loss:	1.573701024055481

training epoch 431 / 500, batch #100 / 625
Loss:	1.977518081665039

training epoch 431 / 500, batch #125 / 625
Loss:	1.6531414985656738

training epoch 431 / 500, batch #150 / 625
Loss:	1.7383829355239868

training epoch 431 / 500, batch #175 / 625
Loss:	1.431317925453186

training epoch 431 / 500, batch #200 / 625
Loss:	1.9262330532073975

training epoch 431 / 500, batch #225 / 625
Loss:	1.6905268430709839

training epoch 431 / 500, batch #250 / 625
Loss:	1.7097687721252441

training epoch 431 / 500, batch #275 / 625
Loss:	1.7322918176651

training epoch 431 / 500, batch #300 / 625
Loss:	1.5114727020263672

training epoch 431 / 500, batch #325 / 625
Loss:	1.9014958143234253

training epoch 431 / 500, batch #350 / 625
Loss:	1.7162717580795288

training epoch 431 / 500, batch #375 / 625
Loss:	1.701393485069275

training epoch 431 / 500, batch #400 / 625
Loss:	1.6955801248550415

training epoch 431 / 500, batch #425 / 625
Loss:	1.845131278038025

training epoch 431 / 500, batch #450 / 625
Loss:	1.7006359100341797

training epoch 431 / 500, batch #475 / 625
Loss:	1.6235284805297852

training epoch 431 / 500, batch #500 / 625
Loss:	1.9805192947387695

training epoch 431 / 500, batch #525 / 625
Loss:	1.6475424766540527

training epoch 431 / 500, batch #550 / 625
Loss:	1.5119268894195557

training epoch 431 / 500, batch #575 / 625
Loss:	1.895856261253357

training epoch 431 / 500, batch #600 / 625
Loss:	1.6487443447113037

training epoch 432 / 500, batch #0 / 625
Loss:	1.7183012962341309

training epoch 432 / 500, batch #25 / 625
Loss:	1.621867299079895

training epoch 432 / 500, batch #50 / 625
Loss:	1.8168529272079468

training epoch 432 / 500, batch #75 / 625
Loss:	1.9014207124710083

training epoch 432 / 500, batch #100 / 625
Loss:	1.4794453382492065

training epoch 432 / 500, batch #125 / 625
Loss:	1.93143630027771

training epoch 432 / 500, batch #150 / 625
Loss:	1.8723609447479248

training epoch 432 / 500, batch #175 / 625
Loss:	1.743579626083374

training epoch 432 / 500, batch #200 / 625
Loss:	1.6354820728302002

training epoch 432 / 500, batch #225 / 625
Loss:	1.9232118129730225

training epoch 432 / 500, batch #250 / 625
Loss:	1.7127355337142944

training epoch 432 / 500, batch #275 / 625
Loss:	1.8279162645339966

training epoch 432 / 500, batch #300 / 625
Loss:	1.5448089838027954

training epoch 432 / 500, batch #325 / 625
Loss:	1.8883683681488037

training epoch 432 / 500, batch #350 / 625
Loss:	1.6065073013305664

training epoch 432 / 500, batch #375 / 625
Loss:	1.6896857023239136

training epoch 432 / 500, batch #400 / 625
Loss:	1.8769210577011108

training epoch 432 / 500, batch #425 / 625
Loss:	1.564601182937622

training epoch 432 / 500, batch #450 / 625
Loss:	1.7755359411239624

training epoch 432 / 500, batch #475 / 625
Loss:	1.874623417854309

training epoch 432 / 500, batch #500 / 625
Loss:	1.648834466934204

training epoch 432 / 500, batch #525 / 625
Loss:	1.6034059524536133

training epoch 432 / 500, batch #550 / 625
Loss:	1.7850617170333862

training epoch 432 / 500, batch #575 / 625
Loss:	1.584075689315796

training epoch 432 / 500, batch #600 / 625
Loss:	1.7018600702285767

training epoch 433 / 500, batch #0 / 625
Loss:	1.8637313842773438

training epoch 433 / 500, batch #25 / 625
Loss:	1.6287569999694824

training epoch 433 / 500, batch #50 / 625
Loss:	1.9883909225463867

training epoch 433 / 500, batch #75 / 625
Loss:	1.7307428121566772

training epoch 433 / 500, batch #100 / 625
Loss:	1.717794418334961

training epoch 433 / 500, batch #125 / 625
Loss:	1.4415738582611084

training epoch 433 / 500, batch #150 / 625
Loss:	1.7967374324798584

training epoch 433 / 500, batch #175 / 625
Loss:	1.8228857517242432

training epoch 433 / 500, batch #200 / 625
Loss:	1.8363568782806396

training epoch 433 / 500, batch #225 / 625
Loss:	1.5950490236282349

training epoch 433 / 500, batch #250 / 625
Loss:	1.6915533542633057

training epoch 433 / 500, batch #275 / 625
Loss:	1.7569278478622437

training epoch 433 / 500, batch #300 / 625
Loss:	1.6818678379058838

training epoch 433 / 500, batch #325 / 625
Loss:	1.693502426147461

training epoch 433 / 500, batch #350 / 625
Loss:	1.7309374809265137

training epoch 433 / 500, batch #375 / 625
Loss:	1.6984940767288208

training epoch 433 / 500, batch #400 / 625
Loss:	1.7930492162704468

training epoch 433 / 500, batch #425 / 625
Loss:	1.5861397981643677

training epoch 433 / 500, batch #450 / 625
Loss:	1.601109504699707

training epoch 433 / 500, batch #475 / 625
Loss:	1.4856387376785278

training epoch 433 / 500, batch #500 / 625
Loss:	1.8055094480514526

training epoch 433 / 500, batch #525 / 625
Loss:	1.779379963874817

training epoch 433 / 500, batch #550 / 625
Loss:	1.7203181982040405

training epoch 433 / 500, batch #575 / 625
Loss:	1.935704231262207

training epoch 433 / 500, batch #600 / 625
Loss:	1.6078181266784668

training epoch 434 / 500, batch #0 / 625
Loss:	1.501794695854187

training epoch 434 / 500, batch #25 / 625
Loss:	1.643154263496399

training epoch 434 / 500, batch #50 / 625
Loss:	1.6988461017608643

training epoch 434 / 500, batch #75 / 625
Loss:	1.6546000242233276

training epoch 434 / 500, batch #100 / 625
Loss:	1.8874828815460205

training epoch 434 / 500, batch #125 / 625
Loss:	1.6198837757110596

training epoch 434 / 500, batch #150 / 625
Loss:	1.984354853630066

training epoch 434 / 500, batch #175 / 625
Loss:	1.6220877170562744

training epoch 434 / 500, batch #200 / 625
Loss:	1.8384777307510376

training epoch 434 / 500, batch #225 / 625
Loss:	1.7464430332183838

training epoch 434 / 500, batch #250 / 625
Loss:	1.8365089893341064

training epoch 434 / 500, batch #275 / 625
Loss:	1.6478227376937866

training epoch 434 / 500, batch #300 / 625
Loss:	1.4302438497543335

training epoch 434 / 500, batch #325 / 625
Loss:	1.9062988758087158

training epoch 434 / 500, batch #350 / 625
Loss:	1.7137224674224854

training epoch 434 / 500, batch #375 / 625
Loss:	1.8794395923614502

training epoch 434 / 500, batch #400 / 625
Loss:	1.7726737260818481

training epoch 434 / 500, batch #425 / 625
Loss:	1.6254802942276

training epoch 434 / 500, batch #450 / 625
Loss:	1.8967201709747314

training epoch 434 / 500, batch #475 / 625
Loss:	1.7633113861083984

training epoch 434 / 500, batch #500 / 625
Loss:	1.71219801902771

training epoch 434 / 500, batch #525 / 625
Loss:	1.795592188835144

training epoch 434 / 500, batch #550 / 625
Loss:	1.5381450653076172

training epoch 434 / 500, batch #575 / 625
Loss:	1.6342743635177612

training epoch 434 / 500, batch #600 / 625
Loss:	1.7467244863510132

training epoch 435 / 500, batch #0 / 625
Loss:	1.7968573570251465

training epoch 435 / 500, batch #25 / 625
Loss:	1.4938453435897827

training epoch 435 / 500, batch #50 / 625
Loss:	1.5915961265563965

training epoch 435 / 500, batch #75 / 625
Loss:	1.5583568811416626

training epoch 435 / 500, batch #100 / 625
Loss:	1.8067132234573364

training epoch 435 / 500, batch #125 / 625
Loss:	1.5786110162734985

training epoch 435 / 500, batch #150 / 625
Loss:	1.906317949295044

training epoch 435 / 500, batch #175 / 625
Loss:	1.5622624158859253

training epoch 435 / 500, batch #200 / 625
Loss:	1.60006582736969

training epoch 435 / 500, batch #225 / 625
Loss:	1.7924466133117676

training epoch 435 / 500, batch #250 / 625
Loss:	1.819121241569519

training epoch 435 / 500, batch #275 / 625
Loss:	1.7752881050109863

training epoch 435 / 500, batch #300 / 625
Loss:	1.600014328956604

training epoch 435 / 500, batch #325 / 625
Loss:	1.6616482734680176

training epoch 435 / 500, batch #350 / 625
Loss:	1.8040616512298584

training epoch 435 / 500, batch #375 / 625
Loss:	1.8370919227600098

training epoch 435 / 500, batch #400 / 625
Loss:	1.7185364961624146

training epoch 435 / 500, batch #425 / 625
Loss:	1.7713121175765991

training epoch 435 / 500, batch #450 / 625
Loss:	1.6991064548492432

training epoch 435 / 500, batch #475 / 625
Loss:	2.112790822982788

training epoch 435 / 500, batch #500 / 625
Loss:	1.9664664268493652

training epoch 435 / 500, batch #525 / 625
Loss:	1.6300404071807861

training epoch 435 / 500, batch #550 / 625
Loss:	1.7475534677505493

training epoch 435 / 500, batch #575 / 625
Loss:	1.6010072231292725

training epoch 435 / 500, batch #600 / 625
Loss:	1.6958144903182983

training epoch 436 / 500, batch #0 / 625
Loss:	1.8395905494689941

training epoch 436 / 500, batch #25 / 625
Loss:	1.7148984670639038

training epoch 436 / 500, batch #50 / 625
Loss:	1.8097704648971558

training epoch 436 / 500, batch #75 / 625
Loss:	1.6864356994628906

training epoch 436 / 500, batch #100 / 625
Loss:	1.8549697399139404

training epoch 436 / 500, batch #125 / 625
Loss:	1.661313772201538

training epoch 436 / 500, batch #150 / 625
Loss:	1.6260477304458618

training epoch 436 / 500, batch #175 / 625
Loss:	1.6615958213806152

training epoch 436 / 500, batch #200 / 625
Loss:	1.663351058959961

training epoch 436 / 500, batch #225 / 625
Loss:	1.6708065271377563

training epoch 436 / 500, batch #250 / 625
Loss:	1.8529657125473022

training epoch 436 / 500, batch #275 / 625
Loss:	1.7953572273254395

training epoch 436 / 500, batch #300 / 625
Loss:	1.7105181217193604

training epoch 436 / 500, batch #325 / 625
Loss:	1.7020975351333618

training epoch 436 / 500, batch #350 / 625
Loss:	1.6415176391601562

training epoch 436 / 500, batch #375 / 625
Loss:	1.7709848880767822

training epoch 436 / 500, batch #400 / 625
Loss:	1.4957706928253174

training epoch 436 / 500, batch #425 / 625
Loss:	1.7178618907928467

training epoch 436 / 500, batch #450 / 625
Loss:	1.6966971158981323

training epoch 436 / 500, batch #475 / 625
Loss:	1.7194832563400269

training epoch 436 / 500, batch #500 / 625
Loss:	1.6535677909851074

training epoch 436 / 500, batch #525 / 625
Loss:	1.6981040239334106

training epoch 436 / 500, batch #550 / 625
Loss:	1.5807517766952515

training epoch 436 / 500, batch #575 / 625
Loss:	1.718331217765808

training epoch 436 / 500, batch #600 / 625
Loss:	1.823870301246643

training epoch 437 / 500, batch #0 / 625
Loss:	1.617337942123413

training epoch 437 / 500, batch #25 / 625
Loss:	1.4450076818466187

training epoch 437 / 500, batch #50 / 625
Loss:	1.6352040767669678

training epoch 437 / 500, batch #75 / 625
Loss:	1.7000386714935303

training epoch 437 / 500, batch #100 / 625
Loss:	1.7446967363357544

training epoch 437 / 500, batch #125 / 625
Loss:	1.5568294525146484

training epoch 437 / 500, batch #150 / 625
Loss:	1.9868677854537964

training epoch 437 / 500, batch #175 / 625
Loss:	1.966947317123413

training epoch 437 / 500, batch #200 / 625
Loss:	1.7250142097473145

training epoch 437 / 500, batch #225 / 625
Loss:	2.1042065620422363

training epoch 437 / 500, batch #250 / 625
Loss:	1.9282891750335693

training epoch 437 / 500, batch #275 / 625
Loss:	1.7999014854431152

training epoch 437 / 500, batch #300 / 625
Loss:	1.5197573900222778

training epoch 437 / 500, batch #325 / 625
Loss:	1.7245138883590698

training epoch 437 / 500, batch #350 / 625
Loss:	1.6897659301757812

training epoch 437 / 500, batch #375 / 625
Loss:	1.6427541971206665

training epoch 437 / 500, batch #400 / 625
Loss:	1.6277124881744385

training epoch 437 / 500, batch #425 / 625
Loss:	1.554662823677063

training epoch 437 / 500, batch #450 / 625
Loss:	1.448413610458374

training epoch 437 / 500, batch #475 / 625
Loss:	1.7879406213760376

training epoch 437 / 500, batch #500 / 625
Loss:	1.7066293954849243

training epoch 437 / 500, batch #525 / 625
Loss:	1.7085843086242676

training epoch 437 / 500, batch #550 / 625
Loss:	1.7508327960968018

training epoch 437 / 500, batch #575 / 625
Loss:	1.965694546699524

training epoch 437 / 500, batch #600 / 625
Loss:	1.9777860641479492

training epoch 438 / 500, batch #0 / 625
Loss:	2.0297257900238037

training epoch 438 / 500, batch #25 / 625
Loss:	1.7396219968795776

training epoch 438 / 500, batch #50 / 625
Loss:	1.5841667652130127

training epoch 438 / 500, batch #75 / 625
Loss:	1.7522757053375244

training epoch 438 / 500, batch #100 / 625
Loss:	1.8142169713974

training epoch 438 / 500, batch #125 / 625
Loss:	1.8203270435333252

training epoch 438 / 500, batch #150 / 625
Loss:	1.9186222553253174

training epoch 438 / 500, batch #175 / 625
Loss:	1.9377778768539429

training epoch 438 / 500, batch #200 / 625
Loss:	1.733779788017273

training epoch 438 / 500, batch #225 / 625
Loss:	1.8667738437652588

training epoch 438 / 500, batch #250 / 625
Loss:	1.6582105159759521

training epoch 438 / 500, batch #275 / 625
Loss:	1.8109784126281738

training epoch 438 / 500, batch #300 / 625
Loss:	1.745019555091858

training epoch 438 / 500, batch #325 / 625
Loss:	1.8078316450119019

training epoch 438 / 500, batch #350 / 625
Loss:	1.7147899866104126

training epoch 438 / 500, batch #375 / 625
Loss:	1.8518747091293335

training epoch 438 / 500, batch #400 / 625
Loss:	1.6119844913482666

training epoch 438 / 500, batch #425 / 625
Loss:	1.8184483051300049

training epoch 438 / 500, batch #450 / 625
Loss:	1.6991957426071167

training epoch 438 / 500, batch #475 / 625
Loss:	1.624542236328125

training epoch 438 / 500, batch #500 / 625
Loss:	1.6815972328186035

training epoch 438 / 500, batch #525 / 625
Loss:	2.0496723651885986

training epoch 438 / 500, batch #550 / 625
Loss:	1.7177730798721313

training epoch 438 / 500, batch #575 / 625
Loss:	1.639317512512207

training epoch 438 / 500, batch #600 / 625
Loss:	1.850576639175415

training epoch 439 / 500, batch #0 / 625
Loss:	1.8009017705917358

training epoch 439 / 500, batch #25 / 625
Loss:	1.8203059434890747

training epoch 439 / 500, batch #50 / 625
Loss:	1.5559314489364624

training epoch 439 / 500, batch #75 / 625
Loss:	1.6114296913146973

training epoch 439 / 500, batch #100 / 625
Loss:	1.711607575416565

training epoch 439 / 500, batch #125 / 625
Loss:	1.4659409523010254

training epoch 439 / 500, batch #150 / 625
Loss:	1.715103268623352

training epoch 439 / 500, batch #175 / 625
Loss:	1.6420464515686035

training epoch 439 / 500, batch #200 / 625
Loss:	1.6552330255508423

training epoch 439 / 500, batch #225 / 625
Loss:	1.6434837579727173

training epoch 439 / 500, batch #250 / 625
Loss:	1.8515130281448364

training epoch 439 / 500, batch #275 / 625
Loss:	1.6287935972213745

training epoch 439 / 500, batch #300 / 625
Loss:	1.5521694421768188

training epoch 439 / 500, batch #325 / 625
Loss:	1.7892385721206665

training epoch 439 / 500, batch #350 / 625
Loss:	1.7912635803222656

training epoch 439 / 500, batch #375 / 625
Loss:	1.8325259685516357

training epoch 439 / 500, batch #400 / 625
Loss:	1.5460541248321533

training epoch 439 / 500, batch #425 / 625
Loss:	1.4719377756118774

training epoch 439 / 500, batch #450 / 625
Loss:	1.7895874977111816

training epoch 439 / 500, batch #475 / 625
Loss:	1.9065077304840088

training epoch 439 / 500, batch #500 / 625
Loss:	1.6336562633514404

training epoch 439 / 500, batch #525 / 625
Loss:	1.6551700830459595

training epoch 439 / 500, batch #550 / 625
Loss:	1.7057960033416748

training epoch 439 / 500, batch #575 / 625
Loss:	1.5901461839675903

training epoch 439 / 500, batch #600 / 625
Loss:	1.908829927444458

training epoch 440 / 500, batch #0 / 625
Loss:	1.9363691806793213

training epoch 440 / 500, batch #25 / 625
Loss:	1.7573517560958862

training epoch 440 / 500, batch #50 / 625
Loss:	1.697922945022583

training epoch 440 / 500, batch #75 / 625
Loss:	1.5975948572158813

training epoch 440 / 500, batch #100 / 625
Loss:	1.7238342761993408

training epoch 440 / 500, batch #125 / 625
Loss:	1.870858907699585

training epoch 440 / 500, batch #150 / 625
Loss:	1.6180551052093506

training epoch 440 / 500, batch #175 / 625
Loss:	1.6678507328033447

training epoch 440 / 500, batch #200 / 625
Loss:	1.8310834169387817

training epoch 440 / 500, batch #225 / 625
Loss:	1.6827510595321655

training epoch 440 / 500, batch #250 / 625
Loss:	2.0015921592712402

training epoch 440 / 500, batch #275 / 625
Loss:	1.7331207990646362

training epoch 440 / 500, batch #300 / 625
Loss:	1.6941519975662231

training epoch 440 / 500, batch #325 / 625
Loss:	1.6194308996200562

training epoch 440 / 500, batch #350 / 625
Loss:	1.6877790689468384

training epoch 440 / 500, batch #375 / 625
Loss:	1.7720715999603271

training epoch 440 / 500, batch #400 / 625
Loss:	1.7293994426727295

training epoch 440 / 500, batch #425 / 625
Loss:	1.6054255962371826

training epoch 440 / 500, batch #450 / 625
Loss:	1.5001481771469116

training epoch 440 / 500, batch #475 / 625
Loss:	1.8873841762542725

training epoch 440 / 500, batch #500 / 625
Loss:	1.9087330102920532

training epoch 440 / 500, batch #525 / 625
Loss:	1.8051056861877441

training epoch 440 / 500, batch #550 / 625
Loss:	1.7667014598846436

training epoch 440 / 500, batch #575 / 625
Loss:	1.740309238433838

training epoch 440 / 500, batch #600 / 625
Loss:	1.5866801738739014

training epoch 441 / 500, batch #0 / 625
Loss:	1.719643235206604

training epoch 441 / 500, batch #25 / 625
Loss:	1.942598581314087

training epoch 441 / 500, batch #50 / 625
Loss:	1.7763115167617798

training epoch 441 / 500, batch #75 / 625
Loss:	1.7397795915603638

training epoch 441 / 500, batch #100 / 625
Loss:	1.7301064729690552

training epoch 441 / 500, batch #125 / 625
Loss:	1.8048672676086426

training epoch 441 / 500, batch #150 / 625
Loss:	1.6499762535095215

training epoch 441 / 500, batch #175 / 625
Loss:	1.7380032539367676

training epoch 441 / 500, batch #200 / 625
Loss:	1.983954668045044

training epoch 441 / 500, batch #225 / 625
Loss:	1.838241696357727

training epoch 441 / 500, batch #250 / 625
Loss:	1.773738145828247

training epoch 441 / 500, batch #275 / 625
Loss:	1.4923630952835083

training epoch 441 / 500, batch #300 / 625
Loss:	1.6127402782440186

training epoch 441 / 500, batch #325 / 625
Loss:	1.8493672609329224

training epoch 441 / 500, batch #350 / 625
Loss:	1.5200563669204712

training epoch 441 / 500, batch #375 / 625
Loss:	1.6918619871139526

training epoch 441 / 500, batch #400 / 625
Loss:	1.417270302772522

training epoch 441 / 500, batch #425 / 625
Loss:	1.9116500616073608

training epoch 441 / 500, batch #450 / 625
Loss:	1.854655385017395

training epoch 441 / 500, batch #475 / 625
Loss:	1.8376375436782837

training epoch 441 / 500, batch #500 / 625
Loss:	1.6352319717407227

training epoch 441 / 500, batch #525 / 625
Loss:	1.6218998432159424

training epoch 441 / 500, batch #550 / 625
Loss:	1.648813247680664

training epoch 441 / 500, batch #575 / 625
Loss:	1.6227741241455078

training epoch 441 / 500, batch #600 / 625
Loss:	1.5444978475570679

training epoch 442 / 500, batch #0 / 625
Loss:	1.5513187646865845

training epoch 442 / 500, batch #25 / 625
Loss:	1.6730762720108032

training epoch 442 / 500, batch #50 / 625
Loss:	1.8168785572052002

training epoch 442 / 500, batch #75 / 625
Loss:	1.5973621606826782

training epoch 442 / 500, batch #100 / 625
Loss:	1.8172941207885742

training epoch 442 / 500, batch #125 / 625
Loss:	1.669151782989502

training epoch 442 / 500, batch #150 / 625
Loss:	1.636937141418457

training epoch 442 / 500, batch #175 / 625
Loss:	1.8634058237075806

training epoch 442 / 500, batch #200 / 625
Loss:	1.5131112337112427

training epoch 442 / 500, batch #225 / 625
Loss:	1.647142767906189

training epoch 442 / 500, batch #250 / 625
Loss:	1.6249728202819824

training epoch 442 / 500, batch #275 / 625
Loss:	1.781398892402649

training epoch 442 / 500, batch #300 / 625
Loss:	1.703891396522522

training epoch 442 / 500, batch #325 / 625
Loss:	1.7094917297363281

training epoch 442 / 500, batch #350 / 625
Loss:	1.5745398998260498

training epoch 442 / 500, batch #375 / 625
Loss:	1.5551012754440308

training epoch 442 / 500, batch #400 / 625
Loss:	1.4940431118011475

training epoch 442 / 500, batch #425 / 625
Loss:	1.6862787008285522

training epoch 442 / 500, batch #450 / 625
Loss:	1.7379460334777832

training epoch 442 / 500, batch #475 / 625
Loss:	1.7736332416534424

training epoch 442 / 500, batch #500 / 625
Loss:	1.807135820388794

training epoch 442 / 500, batch #525 / 625
Loss:	1.7024751901626587

training epoch 442 / 500, batch #550 / 625
Loss:	1.654733419418335

training epoch 442 / 500, batch #575 / 625
Loss:	1.4937628507614136

training epoch 442 / 500, batch #600 / 625
Loss:	1.7739100456237793

training epoch 443 / 500, batch #0 / 625
Loss:	1.8273292779922485

training epoch 443 / 500, batch #25 / 625
Loss:	1.5787581205368042

training epoch 443 / 500, batch #50 / 625
Loss:	1.6427429914474487

training epoch 443 / 500, batch #75 / 625
Loss:	1.7234240770339966

training epoch 443 / 500, batch #100 / 625
Loss:	1.5649466514587402

training epoch 443 / 500, batch #125 / 625
Loss:	1.6843160390853882

training epoch 443 / 500, batch #150 / 625
Loss:	1.7264368534088135

training epoch 443 / 500, batch #175 / 625
Loss:	1.8918414115905762

training epoch 443 / 500, batch #200 / 625
Loss:	1.944409966468811

training epoch 443 / 500, batch #225 / 625
Loss:	1.6177105903625488

training epoch 443 / 500, batch #250 / 625
Loss:	1.786946177482605

training epoch 443 / 500, batch #275 / 625
Loss:	1.8218475580215454

training epoch 443 / 500, batch #300 / 625
Loss:	1.8446844816207886

training epoch 443 / 500, batch #325 / 625
Loss:	1.741359829902649

training epoch 443 / 500, batch #350 / 625
Loss:	1.8469207286834717

training epoch 443 / 500, batch #375 / 625
Loss:	1.9192811250686646

training epoch 443 / 500, batch #400 / 625
Loss:	1.5340394973754883

training epoch 443 / 500, batch #425 / 625
Loss:	1.5402605533599854

training epoch 443 / 500, batch #450 / 625
Loss:	1.8981983661651611

training epoch 443 / 500, batch #475 / 625
Loss:	1.941368579864502

training epoch 443 / 500, batch #500 / 625
Loss:	1.7020552158355713

training epoch 443 / 500, batch #525 / 625
Loss:	1.9731874465942383

training epoch 443 / 500, batch #550 / 625
Loss:	1.612612247467041

training epoch 443 / 500, batch #575 / 625
Loss:	1.6310573816299438

training epoch 443 / 500, batch #600 / 625
Loss:	1.4906672239303589

training epoch 444 / 500, batch #0 / 625
Loss:	1.7791882753372192

training epoch 444 / 500, batch #25 / 625
Loss:	1.6670680046081543

training epoch 444 / 500, batch #50 / 625
Loss:	1.6360036134719849

training epoch 444 / 500, batch #75 / 625
Loss:	1.752244472503662

training epoch 444 / 500, batch #100 / 625
Loss:	1.767999529838562

training epoch 444 / 500, batch #125 / 625
Loss:	1.6791648864746094

training epoch 444 / 500, batch #150 / 625
Loss:	1.877829909324646

training epoch 444 / 500, batch #175 / 625
Loss:	1.7037886381149292

training epoch 444 / 500, batch #200 / 625
Loss:	1.8014198541641235

training epoch 444 / 500, batch #225 / 625
Loss:	1.755513072013855

training epoch 444 / 500, batch #250 / 625
Loss:	1.6629170179367065

training epoch 444 / 500, batch #275 / 625
Loss:	1.707932949066162

training epoch 444 / 500, batch #300 / 625
Loss:	1.9160678386688232

training epoch 444 / 500, batch #325 / 625
Loss:	1.5769460201263428

training epoch 444 / 500, batch #350 / 625
Loss:	1.7307718992233276

training epoch 444 / 500, batch #375 / 625
Loss:	1.799340844154358

training epoch 444 / 500, batch #400 / 625
Loss:	1.566681146621704

training epoch 444 / 500, batch #425 / 625
Loss:	1.646532654762268

training epoch 444 / 500, batch #450 / 625
Loss:	1.5897620916366577

training epoch 444 / 500, batch #475 / 625
Loss:	1.8089627027511597

training epoch 444 / 500, batch #500 / 625
Loss:	1.6867856979370117

training epoch 444 / 500, batch #525 / 625
Loss:	1.6286375522613525

training epoch 444 / 500, batch #550 / 625
Loss:	1.8839836120605469

training epoch 444 / 500, batch #575 / 625
Loss:	1.4748491048812866

training epoch 444 / 500, batch #600 / 625
Loss:	1.7941057682037354

training epoch 445 / 500, batch #0 / 625
Loss:	1.8027470111846924

training epoch 445 / 500, batch #25 / 625
Loss:	1.6215009689331055

training epoch 445 / 500, batch #50 / 625
Loss:	1.7590113878250122

training epoch 445 / 500, batch #75 / 625
Loss:	1.557004451751709

training epoch 445 / 500, batch #100 / 625
Loss:	1.6764276027679443

training epoch 445 / 500, batch #125 / 625
Loss:	1.5143471956253052

training epoch 445 / 500, batch #150 / 625
Loss:	1.702758550643921

training epoch 445 / 500, batch #175 / 625
Loss:	1.8533341884613037

training epoch 445 / 500, batch #200 / 625
Loss:	1.607862949371338

training epoch 445 / 500, batch #225 / 625
Loss:	1.7348148822784424

training epoch 445 / 500, batch #250 / 625
Loss:	1.8035815954208374

training epoch 445 / 500, batch #275 / 625
Loss:	1.8932735919952393

training epoch 445 / 500, batch #300 / 625
Loss:	1.7551053762435913

training epoch 445 / 500, batch #325 / 625
Loss:	1.8314323425292969

training epoch 445 / 500, batch #350 / 625
Loss:	1.730936050415039

training epoch 445 / 500, batch #375 / 625
Loss:	1.9024420976638794

training epoch 445 / 500, batch #400 / 625
Loss:	1.9563993215560913

training epoch 445 / 500, batch #425 / 625
Loss:	1.6409626007080078

training epoch 445 / 500, batch #450 / 625
Loss:	1.6563770771026611

training epoch 445 / 500, batch #475 / 625
Loss:	1.8403857946395874

training epoch 445 / 500, batch #500 / 625
Loss:	1.6940385103225708

training epoch 445 / 500, batch #525 / 625
Loss:	1.769046664237976

training epoch 445 / 500, batch #550 / 625
Loss:	1.4799960851669312

training epoch 445 / 500, batch #575 / 625
Loss:	1.8370293378829956

training epoch 445 / 500, batch #600 / 625
Loss:	1.7578479051589966

training epoch 446 / 500, batch #0 / 625
Loss:	1.728922963142395

training epoch 446 / 500, batch #25 / 625
Loss:	1.7774507999420166

training epoch 446 / 500, batch #50 / 625
Loss:	1.7841726541519165

training epoch 446 / 500, batch #75 / 625
Loss:	1.6896405220031738

training epoch 446 / 500, batch #100 / 625
Loss:	1.7619656324386597

training epoch 446 / 500, batch #125 / 625
Loss:	1.6836938858032227

training epoch 446 / 500, batch #150 / 625
Loss:	1.5593124628067017

training epoch 446 / 500, batch #175 / 625
Loss:	1.729997992515564

training epoch 446 / 500, batch #200 / 625
Loss:	1.5927268266677856

training epoch 446 / 500, batch #225 / 625
Loss:	1.6267873048782349

training epoch 446 / 500, batch #250 / 625
Loss:	1.8521353006362915

training epoch 446 / 500, batch #275 / 625
Loss:	1.6947050094604492

training epoch 446 / 500, batch #300 / 625
Loss:	1.6811401844024658

training epoch 446 / 500, batch #325 / 625
Loss:	1.5274624824523926

training epoch 446 / 500, batch #350 / 625
Loss:	1.5695445537567139

training epoch 446 / 500, batch #375 / 625
Loss:	1.8360027074813843

training epoch 446 / 500, batch #400 / 625
Loss:	1.7645301818847656

training epoch 446 / 500, batch #425 / 625
Loss:	1.9066275358200073

training epoch 446 / 500, batch #450 / 625
Loss:	1.8951935768127441

training epoch 446 / 500, batch #475 / 625
Loss:	1.8292465209960938

training epoch 446 / 500, batch #500 / 625
Loss:	2.012690782546997

training epoch 446 / 500, batch #525 / 625
Loss:	1.9481825828552246

training epoch 446 / 500, batch #550 / 625
Loss:	1.5007069110870361

training epoch 446 / 500, batch #575 / 625
Loss:	1.8403725624084473

training epoch 446 / 500, batch #600 / 625
Loss:	1.7787134647369385

training epoch 447 / 500, batch #0 / 625
Loss:	1.7134631872177124

training epoch 447 / 500, batch #25 / 625
Loss:	1.7292954921722412

training epoch 447 / 500, batch #50 / 625
Loss:	1.8868348598480225

training epoch 447 / 500, batch #75 / 625
Loss:	1.6148693561553955

training epoch 447 / 500, batch #100 / 625
Loss:	1.6799386739730835

training epoch 447 / 500, batch #125 / 625
Loss:	1.952645182609558

training epoch 447 / 500, batch #150 / 625
Loss:	1.8960634469985962

training epoch 447 / 500, batch #175 / 625
Loss:	1.7293587923049927

training epoch 447 / 500, batch #200 / 625
Loss:	1.7022265195846558

training epoch 447 / 500, batch #225 / 625
Loss:	1.8318469524383545

training epoch 447 / 500, batch #250 / 625
Loss:	1.5945076942443848

training epoch 447 / 500, batch #275 / 625
Loss:	1.6983617544174194

training epoch 447 / 500, batch #300 / 625
Loss:	1.902166485786438

training epoch 447 / 500, batch #325 / 625
Loss:	1.7367581129074097

training epoch 447 / 500, batch #350 / 625
Loss:	1.6775422096252441

training epoch 447 / 500, batch #375 / 625
Loss:	1.675531268119812

training epoch 447 / 500, batch #400 / 625
Loss:	1.6322532892227173

training epoch 447 / 500, batch #425 / 625
Loss:	1.6033152341842651

training epoch 447 / 500, batch #450 / 625
Loss:	1.694449782371521

training epoch 447 / 500, batch #475 / 625
Loss:	1.6496323347091675

training epoch 447 / 500, batch #500 / 625
Loss:	1.6500120162963867

training epoch 447 / 500, batch #525 / 625
Loss:	1.8238425254821777

training epoch 447 / 500, batch #550 / 625
Loss:	1.4569003582000732

training epoch 447 / 500, batch #575 / 625
Loss:	1.7240824699401855

training epoch 447 / 500, batch #600 / 625
Loss:	1.7539795637130737

training epoch 448 / 500, batch #0 / 625
Loss:	1.6126482486724854

training epoch 448 / 500, batch #25 / 625
Loss:	1.6641486883163452

training epoch 448 / 500, batch #50 / 625
Loss:	1.7246696949005127

training epoch 448 / 500, batch #75 / 625
Loss:	1.509513020515442

training epoch 448 / 500, batch #100 / 625
Loss:	1.8502248525619507

training epoch 448 / 500, batch #125 / 625
Loss:	1.7553642988204956

training epoch 448 / 500, batch #150 / 625
Loss:	1.8984882831573486

training epoch 448 / 500, batch #175 / 625
Loss:	1.6926850080490112

training epoch 448 / 500, batch #200 / 625
Loss:	1.5698198080062866

training epoch 448 / 500, batch #225 / 625
Loss:	1.7640137672424316

training epoch 448 / 500, batch #250 / 625
Loss:	1.6406896114349365

training epoch 448 / 500, batch #275 / 625
Loss:	1.6150827407836914

training epoch 448 / 500, batch #300 / 625
Loss:	1.6214332580566406

training epoch 448 / 500, batch #325 / 625
Loss:	1.760460615158081

training epoch 448 / 500, batch #350 / 625
Loss:	1.886493444442749

training epoch 448 / 500, batch #375 / 625
Loss:	1.7613290548324585

training epoch 448 / 500, batch #400 / 625
Loss:	1.8280290365219116

training epoch 448 / 500, batch #425 / 625
Loss:	1.7005516290664673

training epoch 448 / 500, batch #450 / 625
Loss:	1.7858355045318604

training epoch 448 / 500, batch #475 / 625
Loss:	1.7229077816009521

training epoch 448 / 500, batch #500 / 625
Loss:	1.718017816543579

training epoch 448 / 500, batch #525 / 625
Loss:	1.6181668043136597

training epoch 448 / 500, batch #550 / 625
Loss:	1.7572883367538452

training epoch 448 / 500, batch #575 / 625
Loss:	1.8422877788543701

training epoch 448 / 500, batch #600 / 625
Loss:	1.5398708581924438

training epoch 449 / 500, batch #0 / 625
Loss:	1.8586217164993286

training epoch 449 / 500, batch #25 / 625
Loss:	2.127822160720825

training epoch 449 / 500, batch #50 / 625
Loss:	1.7143241167068481

training epoch 449 / 500, batch #75 / 625
Loss:	1.8914611339569092

training epoch 449 / 500, batch #100 / 625
Loss:	1.632538914680481

training epoch 449 / 500, batch #125 / 625
Loss:	1.3634155988693237

training epoch 449 / 500, batch #150 / 625
Loss:	1.9330365657806396

training epoch 449 / 500, batch #175 / 625
Loss:	1.8207762241363525

training epoch 449 / 500, batch #200 / 625
Loss:	1.7985057830810547

training epoch 449 / 500, batch #225 / 625
Loss:	1.5502485036849976

training epoch 449 / 500, batch #250 / 625
Loss:	1.6719675064086914

training epoch 449 / 500, batch #275 / 625
Loss:	1.4898786544799805

training epoch 449 / 500, batch #300 / 625
Loss:	1.5074492692947388

training epoch 449 / 500, batch #325 / 625
Loss:	1.789163589477539

training epoch 449 / 500, batch #350 / 625
Loss:	1.8477816581726074

training epoch 449 / 500, batch #375 / 625
Loss:	1.9122629165649414

training epoch 449 / 500, batch #400 / 625
Loss:	1.8247655630111694

training epoch 449 / 500, batch #425 / 625
Loss:	1.8098946809768677

training epoch 449 / 500, batch #450 / 625
Loss:	1.5001857280731201

training epoch 449 / 500, batch #475 / 625
Loss:	1.6835222244262695

training epoch 449 / 500, batch #500 / 625
Loss:	1.736090898513794

training epoch 449 / 500, batch #525 / 625
Loss:	1.7725234031677246

training epoch 449 / 500, batch #550 / 625
Loss:	1.6346372365951538

training epoch 449 / 500, batch #575 / 625
Loss:	1.572274923324585

training epoch 449 / 500, batch #600 / 625
Loss:	1.852403998374939

training epoch 450 / 500, batch #0 / 625
Loss:	1.829925537109375

training epoch 450 / 500, batch #25 / 625
Loss:	1.7116272449493408

training epoch 450 / 500, batch #50 / 625
Loss:	1.5913294553756714

training epoch 450 / 500, batch #75 / 625
Loss:	1.517316460609436

training epoch 450 / 500, batch #100 / 625
Loss:	1.5745983123779297

training epoch 450 / 500, batch #125 / 625
Loss:	1.5349397659301758

training epoch 450 / 500, batch #150 / 625
Loss:	1.6511704921722412

training epoch 450 / 500, batch #175 / 625
Loss:	1.701116681098938

training epoch 450 / 500, batch #200 / 625
Loss:	1.5535987615585327

training epoch 450 / 500, batch #225 / 625
Loss:	1.6700056791305542

training epoch 450 / 500, batch #250 / 625
Loss:	1.6654858589172363

training epoch 450 / 500, batch #275 / 625
Loss:	1.8674918413162231

training epoch 450 / 500, batch #300 / 625
Loss:	1.6197221279144287

training epoch 450 / 500, batch #325 / 625
Loss:	1.5716356039047241

training epoch 450 / 500, batch #350 / 625
Loss:	1.6185152530670166

training epoch 450 / 500, batch #375 / 625
Loss:	1.7430895566940308

training epoch 450 / 500, batch #400 / 625
Loss:	1.8509658575057983

training epoch 450 / 500, batch #425 / 625
Loss:	1.754573941230774

training epoch 450 / 500, batch #450 / 625
Loss:	1.8095166683197021

training epoch 450 / 500, batch #475 / 625
Loss:	1.614465594291687

training epoch 450 / 500, batch #500 / 625
Loss:	1.7769763469696045

training epoch 450 / 500, batch #525 / 625
Loss:	1.688517689704895

training epoch 450 / 500, batch #550 / 625
Loss:	1.6361184120178223

training epoch 450 / 500, batch #575 / 625
Loss:	1.8920423984527588

training epoch 450 / 500, batch #600 / 625
Loss:	1.7087898254394531

training epoch 451 / 500, batch #0 / 625
Loss:	1.7868611812591553

training epoch 451 / 500, batch #25 / 625
Loss:	1.6595458984375

training epoch 451 / 500, batch #50 / 625
Loss:	1.5961023569107056

training epoch 451 / 500, batch #75 / 625
Loss:	1.5845153331756592

training epoch 451 / 500, batch #100 / 625
Loss:	1.5687981843948364

training epoch 451 / 500, batch #125 / 625
Loss:	1.6784827709197998

training epoch 451 / 500, batch #150 / 625
Loss:	1.4790652990341187

training epoch 451 / 500, batch #175 / 625
Loss:	1.6317236423492432

training epoch 451 / 500, batch #200 / 625
Loss:	1.4971524477005005

training epoch 451 / 500, batch #225 / 625
Loss:	1.8209441900253296

training epoch 451 / 500, batch #250 / 625
Loss:	1.7006807327270508

training epoch 451 / 500, batch #275 / 625
Loss:	1.9565818309783936

training epoch 451 / 500, batch #300 / 625
Loss:	1.6470308303833008

training epoch 451 / 500, batch #325 / 625
Loss:	1.4886672496795654

training epoch 451 / 500, batch #350 / 625
Loss:	2.0659139156341553

training epoch 451 / 500, batch #375 / 625
Loss:	1.6316405534744263

training epoch 451 / 500, batch #400 / 625
Loss:	1.594417691230774

training epoch 451 / 500, batch #425 / 625
Loss:	1.8522030115127563

training epoch 451 / 500, batch #450 / 625
Loss:	1.543117642402649

training epoch 451 / 500, batch #475 / 625
Loss:	1.5826003551483154

training epoch 451 / 500, batch #500 / 625
Loss:	1.6370413303375244

training epoch 451 / 500, batch #525 / 625
Loss:	1.706004023551941

training epoch 451 / 500, batch #550 / 625
Loss:	1.7437855005264282

training epoch 451 / 500, batch #575 / 625
Loss:	1.5528082847595215

training epoch 451 / 500, batch #600 / 625
Loss:	1.8090556859970093

training epoch 452 / 500, batch #0 / 625
Loss:	1.544541835784912

training epoch 452 / 500, batch #25 / 625
Loss:	1.750889778137207

training epoch 452 / 500, batch #50 / 625
Loss:	1.5898572206497192

training epoch 452 / 500, batch #75 / 625
Loss:	1.6654106378555298

training epoch 452 / 500, batch #100 / 625
Loss:	1.4866483211517334

training epoch 452 / 500, batch #125 / 625
Loss:	1.4438930749893188

training epoch 452 / 500, batch #150 / 625
Loss:	1.8300572633743286

training epoch 452 / 500, batch #175 / 625
Loss:	1.8542370796203613

training epoch 452 / 500, batch #200 / 625
Loss:	1.5295844078063965

training epoch 452 / 500, batch #225 / 625
Loss:	1.6188942193984985

training epoch 452 / 500, batch #250 / 625
Loss:	1.4361902475357056

training epoch 452 / 500, batch #275 / 625
Loss:	1.676530122756958

training epoch 452 / 500, batch #300 / 625
Loss:	1.8174982070922852

training epoch 452 / 500, batch #325 / 625
Loss:	1.5740587711334229

training epoch 452 / 500, batch #350 / 625
Loss:	1.7777907848358154

training epoch 452 / 500, batch #375 / 625
Loss:	1.6521469354629517

training epoch 452 / 500, batch #400 / 625
Loss:	1.780367136001587

training epoch 452 / 500, batch #425 / 625
Loss:	1.843318223953247

training epoch 452 / 500, batch #450 / 625
Loss:	1.7544081211090088

training epoch 452 / 500, batch #475 / 625
Loss:	1.7044215202331543

training epoch 452 / 500, batch #500 / 625
Loss:	1.9511563777923584

training epoch 452 / 500, batch #525 / 625
Loss:	1.9746427536010742

training epoch 452 / 500, batch #550 / 625
Loss:	1.6702507734298706

training epoch 452 / 500, batch #575 / 625
Loss:	1.5285245180130005

training epoch 452 / 500, batch #600 / 625
Loss:	1.8293999433517456

training epoch 453 / 500, batch #0 / 625
Loss:	1.730055332183838

training epoch 453 / 500, batch #25 / 625
Loss:	1.6563172340393066

training epoch 453 / 500, batch #50 / 625
Loss:	1.833106517791748

training epoch 453 / 500, batch #75 / 625
Loss:	1.517463207244873

training epoch 453 / 500, batch #100 / 625
Loss:	1.587408423423767

training epoch 453 / 500, batch #125 / 625
Loss:	1.725805401802063

training epoch 453 / 500, batch #150 / 625
Loss:	1.4966473579406738

training epoch 453 / 500, batch #175 / 625
Loss:	1.5241856575012207

training epoch 453 / 500, batch #200 / 625
Loss:	1.8357748985290527

training epoch 453 / 500, batch #225 / 625
Loss:	1.6429853439331055

training epoch 453 / 500, batch #250 / 625
Loss:	1.720173716545105

training epoch 453 / 500, batch #275 / 625
Loss:	1.5900638103485107

training epoch 453 / 500, batch #300 / 625
Loss:	1.7279603481292725

training epoch 453 / 500, batch #325 / 625
Loss:	1.764926791191101

training epoch 453 / 500, batch #350 / 625
Loss:	1.6663408279418945

training epoch 453 / 500, batch #375 / 625
Loss:	1.6513097286224365

training epoch 453 / 500, batch #400 / 625
Loss:	1.5943433046340942

training epoch 453 / 500, batch #425 / 625
Loss:	1.773615837097168

training epoch 453 / 500, batch #450 / 625
Loss:	1.7755117416381836

training epoch 453 / 500, batch #475 / 625
Loss:	1.4452861547470093

training epoch 453 / 500, batch #500 / 625
Loss:	1.9950251579284668

training epoch 453 / 500, batch #525 / 625
Loss:	1.7536016702651978

training epoch 453 / 500, batch #550 / 625
Loss:	1.5889109373092651

training epoch 453 / 500, batch #575 / 625
Loss:	1.8539530038833618

training epoch 453 / 500, batch #600 / 625
Loss:	1.7845914363861084

training epoch 454 / 500, batch #0 / 625
Loss:	1.5548171997070312

training epoch 454 / 500, batch #25 / 625
Loss:	1.7716200351715088

training epoch 454 / 500, batch #50 / 625
Loss:	1.6845755577087402

training epoch 454 / 500, batch #75 / 625
Loss:	1.7941226959228516

training epoch 454 / 500, batch #100 / 625
Loss:	1.8575869798660278

training epoch 454 / 500, batch #125 / 625
Loss:	1.527450442314148

training epoch 454 / 500, batch #150 / 625
Loss:	1.5247116088867188

training epoch 454 / 500, batch #175 / 625
Loss:	1.6114656925201416

training epoch 454 / 500, batch #200 / 625
Loss:	1.3675646781921387

training epoch 454 / 500, batch #225 / 625
Loss:	1.6980493068695068

training epoch 454 / 500, batch #250 / 625
Loss:	1.6132664680480957

training epoch 454 / 500, batch #275 / 625
Loss:	1.884730339050293

training epoch 454 / 500, batch #300 / 625
Loss:	1.6407411098480225

training epoch 454 / 500, batch #325 / 625
Loss:	1.5812628269195557

training epoch 454 / 500, batch #350 / 625
Loss:	1.670642375946045

training epoch 454 / 500, batch #375 / 625
Loss:	1.580952763557434

training epoch 454 / 500, batch #400 / 625
Loss:	1.79856276512146

training epoch 454 / 500, batch #425 / 625
Loss:	1.6913442611694336

training epoch 454 / 500, batch #450 / 625
Loss:	1.821427822113037

training epoch 454 / 500, batch #475 / 625
Loss:	1.708200216293335

training epoch 454 / 500, batch #500 / 625
Loss:	1.7024272680282593

training epoch 454 / 500, batch #525 / 625
Loss:	1.4885413646697998

training epoch 454 / 500, batch #550 / 625
Loss:	1.7143524885177612

training epoch 454 / 500, batch #575 / 625
Loss:	1.7126826047897339

training epoch 454 / 500, batch #600 / 625
Loss:	1.8190065622329712

training epoch 455 / 500, batch #0 / 625
Loss:	1.6886777877807617

training epoch 455 / 500, batch #25 / 625
Loss:	2.0449678897857666

training epoch 455 / 500, batch #50 / 625
Loss:	1.8265502452850342

training epoch 455 / 500, batch #75 / 625
Loss:	1.5873523950576782

training epoch 455 / 500, batch #100 / 625
Loss:	1.932907223701477

training epoch 455 / 500, batch #125 / 625
Loss:	1.7801272869110107

training epoch 455 / 500, batch #150 / 625
Loss:	1.7658482789993286

training epoch 455 / 500, batch #175 / 625
Loss:	1.8902344703674316

training epoch 455 / 500, batch #200 / 625
Loss:	1.7857621908187866

training epoch 455 / 500, batch #225 / 625
Loss:	1.7503561973571777

training epoch 455 / 500, batch #250 / 625
Loss:	1.7639601230621338

training epoch 455 / 500, batch #275 / 625
Loss:	1.5978456735610962

training epoch 455 / 500, batch #300 / 625
Loss:	1.6135262250900269

training epoch 455 / 500, batch #325 / 625
Loss:	1.7022126913070679

training epoch 455 / 500, batch #350 / 625
Loss:	1.7576237916946411

training epoch 455 / 500, batch #375 / 625
Loss:	1.6798596382141113

training epoch 455 / 500, batch #400 / 625
Loss:	1.614270567893982

training epoch 455 / 500, batch #425 / 625
Loss:	1.6570173501968384

training epoch 455 / 500, batch #450 / 625
Loss:	1.7588180303573608

training epoch 455 / 500, batch #475 / 625
Loss:	2.090092897415161

training epoch 455 / 500, batch #500 / 625
Loss:	1.7999603748321533

training epoch 455 / 500, batch #525 / 625
Loss:	1.8312430381774902

training epoch 455 / 500, batch #550 / 625
Loss:	1.6352994441986084

training epoch 455 / 500, batch #575 / 625
Loss:	1.7601187229156494

training epoch 455 / 500, batch #600 / 625
Loss:	1.7553898096084595

training epoch 456 / 500, batch #0 / 625
Loss:	1.7989954948425293

training epoch 456 / 500, batch #25 / 625
Loss:	1.677164077758789

training epoch 456 / 500, batch #50 / 625
Loss:	1.6906262636184692

training epoch 456 / 500, batch #75 / 625
Loss:	1.606338381767273

training epoch 456 / 500, batch #100 / 625
Loss:	1.4608948230743408

training epoch 456 / 500, batch #125 / 625
Loss:	1.6656255722045898

training epoch 456 / 500, batch #150 / 625
Loss:	1.8304221630096436

training epoch 456 / 500, batch #175 / 625
Loss:	1.6105509996414185

training epoch 456 / 500, batch #200 / 625
Loss:	1.8168082237243652

training epoch 456 / 500, batch #225 / 625
Loss:	1.7416799068450928

training epoch 456 / 500, batch #250 / 625
Loss:	1.8772060871124268

training epoch 456 / 500, batch #275 / 625
Loss:	1.7934694290161133

training epoch 456 / 500, batch #300 / 625
Loss:	1.8913555145263672

training epoch 456 / 500, batch #325 / 625
Loss:	1.6771185398101807

training epoch 456 / 500, batch #350 / 625
Loss:	1.6805561780929565

training epoch 456 / 500, batch #375 / 625
Loss:	1.5697522163391113

training epoch 456 / 500, batch #400 / 625
Loss:	2.067343235015869

training epoch 456 / 500, batch #425 / 625
Loss:	2.0464096069335938

training epoch 456 / 500, batch #450 / 625
Loss:	1.556765079498291

training epoch 456 / 500, batch #475 / 625
Loss:	1.716970682144165

training epoch 456 / 500, batch #500 / 625
Loss:	1.7639307975769043

training epoch 456 / 500, batch #525 / 625
Loss:	1.5810856819152832

training epoch 456 / 500, batch #550 / 625
Loss:	1.5734951496124268

training epoch 456 / 500, batch #575 / 625
Loss:	1.5961048603057861

training epoch 456 / 500, batch #600 / 625
Loss:	1.7259656190872192

training epoch 457 / 500, batch #0 / 625
Loss:	1.6626383066177368

training epoch 457 / 500, batch #25 / 625
Loss:	1.8265806436538696

training epoch 457 / 500, batch #50 / 625
Loss:	1.903551697731018

training epoch 457 / 500, batch #75 / 625
Loss:	1.6882214546203613

training epoch 457 / 500, batch #100 / 625
Loss:	1.8068636655807495

training epoch 457 / 500, batch #125 / 625
Loss:	2.043356418609619

training epoch 457 / 500, batch #150 / 625
Loss:	1.8947466611862183

training epoch 457 / 500, batch #175 / 625
Loss:	1.7804545164108276

training epoch 457 / 500, batch #200 / 625
Loss:	1.8806421756744385

training epoch 457 / 500, batch #225 / 625
Loss:	1.8777612447738647

training epoch 457 / 500, batch #250 / 625
Loss:	1.730756402015686

training epoch 457 / 500, batch #275 / 625
Loss:	1.5170565843582153

training epoch 457 / 500, batch #300 / 625
Loss:	1.6619514226913452

training epoch 457 / 500, batch #325 / 625
Loss:	1.7338416576385498

training epoch 457 / 500, batch #350 / 625
Loss:	1.7247717380523682

training epoch 457 / 500, batch #375 / 625
Loss:	1.7478408813476562

training epoch 457 / 500, batch #400 / 625
Loss:	1.5213112831115723

training epoch 457 / 500, batch #425 / 625
Loss:	1.6242872476577759

training epoch 457 / 500, batch #450 / 625
Loss:	1.779749870300293

training epoch 457 / 500, batch #475 / 625
Loss:	1.7179782390594482

training epoch 457 / 500, batch #500 / 625
Loss:	1.7824653387069702

training epoch 457 / 500, batch #525 / 625
Loss:	1.813657283782959

training epoch 457 / 500, batch #550 / 625
Loss:	1.8998476266860962

training epoch 457 / 500, batch #575 / 625
Loss:	1.7365357875823975

training epoch 457 / 500, batch #600 / 625
Loss:	1.532906174659729

training epoch 458 / 500, batch #0 / 625
Loss:	1.6969693899154663

training epoch 458 / 500, batch #25 / 625
Loss:	1.7322665452957153

training epoch 458 / 500, batch #50 / 625
Loss:	1.8311340808868408

training epoch 458 / 500, batch #75 / 625
Loss:	1.6000250577926636

training epoch 458 / 500, batch #100 / 625
Loss:	1.7195911407470703

training epoch 458 / 500, batch #125 / 625
Loss:	1.7107651233673096

training epoch 458 / 500, batch #150 / 625
Loss:	1.8946712017059326

training epoch 458 / 500, batch #175 / 625
Loss:	1.7748380899429321

training epoch 458 / 500, batch #200 / 625
Loss:	1.5801208019256592

training epoch 458 / 500, batch #225 / 625
Loss:	1.6045620441436768

training epoch 458 / 500, batch #250 / 625
Loss:	1.5920650959014893

training epoch 458 / 500, batch #275 / 625
Loss:	1.773644208908081

training epoch 458 / 500, batch #300 / 625
Loss:	1.8084335327148438

training epoch 458 / 500, batch #325 / 625
Loss:	1.5107762813568115

training epoch 458 / 500, batch #350 / 625
Loss:	1.5657802820205688

training epoch 458 / 500, batch #375 / 625
Loss:	1.5466468334197998

training epoch 458 / 500, batch #400 / 625
Loss:	1.9155948162078857

training epoch 458 / 500, batch #425 / 625
Loss:	1.6486462354660034

training epoch 458 / 500, batch #450 / 625
Loss:	1.7643108367919922

training epoch 458 / 500, batch #475 / 625
Loss:	1.6501554250717163

training epoch 458 / 500, batch #500 / 625
Loss:	1.6700265407562256

training epoch 458 / 500, batch #525 / 625
Loss:	1.7263343334197998

training epoch 458 / 500, batch #550 / 625
Loss:	1.9697216749191284

training epoch 458 / 500, batch #575 / 625
Loss:	1.7126010656356812

training epoch 458 / 500, batch #600 / 625
Loss:	1.9501800537109375

training epoch 459 / 500, batch #0 / 625
Loss:	1.8170851469039917

training epoch 459 / 500, batch #25 / 625
Loss:	1.9075502157211304

training epoch 459 / 500, batch #50 / 625
Loss:	1.7820227146148682

training epoch 459 / 500, batch #75 / 625
Loss:	1.63654363155365

training epoch 459 / 500, batch #100 / 625
Loss:	1.6904606819152832

training epoch 459 / 500, batch #125 / 625
Loss:	1.738584041595459

training epoch 459 / 500, batch #150 / 625
Loss:	1.79854154586792

training epoch 459 / 500, batch #175 / 625
Loss:	1.711747169494629

training epoch 459 / 500, batch #200 / 625
Loss:	1.8079463243484497

training epoch 459 / 500, batch #225 / 625
Loss:	1.5473066568374634

training epoch 459 / 500, batch #250 / 625
Loss:	1.8823332786560059

training epoch 459 / 500, batch #275 / 625
Loss:	1.7873954772949219

training epoch 459 / 500, batch #300 / 625
Loss:	1.776494026184082

training epoch 459 / 500, batch #325 / 625
Loss:	1.693001627922058

training epoch 459 / 500, batch #350 / 625
Loss:	1.7181448936462402

training epoch 459 / 500, batch #375 / 625
Loss:	1.882918357849121

training epoch 459 / 500, batch #400 / 625
Loss:	1.6655415296554565

training epoch 459 / 500, batch #425 / 625
Loss:	2.1043765544891357

training epoch 459 / 500, batch #450 / 625
Loss:	1.644777774810791

training epoch 459 / 500, batch #475 / 625
Loss:	1.799771785736084

training epoch 459 / 500, batch #500 / 625
Loss:	1.6373711824417114

training epoch 459 / 500, batch #525 / 625
Loss:	2.0666394233703613

training epoch 459 / 500, batch #550 / 625
Loss:	1.6114656925201416

training epoch 459 / 500, batch #575 / 625
Loss:	1.8036835193634033

training epoch 459 / 500, batch #600 / 625
Loss:	1.7213245630264282

training epoch 460 / 500, batch #0 / 625
Loss:	1.959269404411316

training epoch 460 / 500, batch #25 / 625
Loss:	1.3870269060134888

training epoch 460 / 500, batch #50 / 625
Loss:	1.7435038089752197

training epoch 460 / 500, batch #75 / 625
Loss:	1.6633087396621704

training epoch 460 / 500, batch #100 / 625
Loss:	1.575789213180542

training epoch 460 / 500, batch #125 / 625
Loss:	1.7611874341964722

training epoch 460 / 500, batch #150 / 625
Loss:	1.512302041053772

training epoch 460 / 500, batch #175 / 625
Loss:	1.751569151878357

training epoch 460 / 500, batch #200 / 625
Loss:	1.6300084590911865

training epoch 460 / 500, batch #225 / 625
Loss:	1.9153293371200562

training epoch 460 / 500, batch #250 / 625
Loss:	1.734761357307434

training epoch 460 / 500, batch #275 / 625
Loss:	1.705444097518921

training epoch 460 / 500, batch #300 / 625
Loss:	1.642611026763916

training epoch 460 / 500, batch #325 / 625
Loss:	1.7277311086654663

training epoch 460 / 500, batch #350 / 625
Loss:	1.7611091136932373

training epoch 460 / 500, batch #375 / 625
Loss:	1.76953125

training epoch 460 / 500, batch #400 / 625
Loss:	1.678084373474121

training epoch 460 / 500, batch #425 / 625
Loss:	1.6805847883224487

training epoch 460 / 500, batch #450 / 625
Loss:	1.7373919486999512

training epoch 460 / 500, batch #475 / 625
Loss:	1.6423918008804321

training epoch 460 / 500, batch #500 / 625
Loss:	1.7240428924560547

training epoch 460 / 500, batch #525 / 625
Loss:	1.6343600749969482

training epoch 460 / 500, batch #550 / 625
Loss:	1.889390230178833

training epoch 460 / 500, batch #575 / 625
Loss:	1.3394476175308228

training epoch 460 / 500, batch #600 / 625
Loss:	1.8115001916885376

training epoch 461 / 500, batch #0 / 625
Loss:	1.6025290489196777

training epoch 461 / 500, batch #25 / 625
Loss:	1.644899606704712

training epoch 461 / 500, batch #50 / 625
Loss:	1.5039070844650269

training epoch 461 / 500, batch #75 / 625
Loss:	2.045520544052124

training epoch 461 / 500, batch #100 / 625
Loss:	1.9202356338500977

training epoch 461 / 500, batch #125 / 625
Loss:	1.6390916109085083

training epoch 461 / 500, batch #150 / 625
Loss:	1.6544208526611328

training epoch 461 / 500, batch #175 / 625
Loss:	1.6921850442886353

training epoch 461 / 500, batch #200 / 625
Loss:	1.9966570138931274

training epoch 461 / 500, batch #225 / 625
Loss:	1.7522610425949097

training epoch 461 / 500, batch #250 / 625
Loss:	1.8691996335983276

training epoch 461 / 500, batch #275 / 625
Loss:	1.7158575057983398

training epoch 461 / 500, batch #300 / 625
Loss:	1.8566681146621704

training epoch 461 / 500, batch #325 / 625
Loss:	1.6573089361190796

training epoch 461 / 500, batch #350 / 625
Loss:	1.8326174020767212

training epoch 461 / 500, batch #375 / 625
Loss:	1.8272496461868286

training epoch 461 / 500, batch #400 / 625
Loss:	1.5558260679244995

training epoch 461 / 500, batch #425 / 625
Loss:	1.5581430196762085

training epoch 461 / 500, batch #450 / 625
Loss:	1.5134090185165405

training epoch 461 / 500, batch #475 / 625
Loss:	1.7568272352218628

training epoch 461 / 500, batch #500 / 625
Loss:	1.7477507591247559

training epoch 461 / 500, batch #525 / 625
Loss:	1.806646704673767

training epoch 461 / 500, batch #550 / 625
Loss:	1.5266088247299194

training epoch 461 / 500, batch #575 / 625
Loss:	1.893844485282898

training epoch 461 / 500, batch #600 / 625
Loss:	1.7826402187347412

training epoch 462 / 500, batch #0 / 625
Loss:	1.772395133972168

training epoch 462 / 500, batch #25 / 625
Loss:	1.4646276235580444

training epoch 462 / 500, batch #50 / 625
Loss:	1.8201277256011963

training epoch 462 / 500, batch #75 / 625
Loss:	1.522375464439392

training epoch 462 / 500, batch #100 / 625
Loss:	1.7665131092071533

training epoch 462 / 500, batch #125 / 625
Loss:	1.614492654800415

training epoch 462 / 500, batch #150 / 625
Loss:	1.8703622817993164

training epoch 462 / 500, batch #175 / 625
Loss:	1.701185703277588

training epoch 462 / 500, batch #200 / 625
Loss:	1.6388435363769531

training epoch 462 / 500, batch #225 / 625
Loss:	1.5987160205841064

training epoch 462 / 500, batch #250 / 625
Loss:	1.4802616834640503

training epoch 462 / 500, batch #275 / 625
Loss:	1.6979304552078247

training epoch 462 / 500, batch #300 / 625
Loss:	1.7431424856185913

training epoch 462 / 500, batch #325 / 625
Loss:	1.8168649673461914

training epoch 462 / 500, batch #350 / 625
Loss:	1.736365795135498

training epoch 462 / 500, batch #375 / 625
Loss:	1.6915411949157715

training epoch 462 / 500, batch #400 / 625
Loss:	1.5207922458648682

training epoch 462 / 500, batch #425 / 625
Loss:	1.613332748413086

training epoch 462 / 500, batch #450 / 625
Loss:	1.8614487648010254

training epoch 462 / 500, batch #475 / 625
Loss:	1.7780500650405884

training epoch 462 / 500, batch #500 / 625
Loss:	1.777707815170288

training epoch 462 / 500, batch #525 / 625
Loss:	1.7238975763320923

training epoch 462 / 500, batch #550 / 625
Loss:	1.7280936241149902

training epoch 462 / 500, batch #575 / 625
Loss:	1.6837292909622192

training epoch 462 / 500, batch #600 / 625
Loss:	1.4582899808883667

training epoch 463 / 500, batch #0 / 625
Loss:	1.642226219177246

training epoch 463 / 500, batch #25 / 625
Loss:	1.631347894668579

training epoch 463 / 500, batch #50 / 625
Loss:	1.8817675113677979

training epoch 463 / 500, batch #75 / 625
Loss:	1.8005740642547607

training epoch 463 / 500, batch #100 / 625
Loss:	1.535444736480713

training epoch 463 / 500, batch #125 / 625
Loss:	1.7629988193511963

training epoch 463 / 500, batch #150 / 625
Loss:	1.415727972984314

training epoch 463 / 500, batch #175 / 625
Loss:	1.8922148942947388

training epoch 463 / 500, batch #200 / 625
Loss:	1.7728121280670166

training epoch 463 / 500, batch #225 / 625
Loss:	1.6828229427337646

training epoch 463 / 500, batch #250 / 625
Loss:	1.7330328226089478

training epoch 463 / 500, batch #275 / 625
Loss:	1.7014111280441284

training epoch 463 / 500, batch #300 / 625
Loss:	1.8198094367980957

training epoch 463 / 500, batch #325 / 625
Loss:	1.6776553392410278

training epoch 463 / 500, batch #350 / 625
Loss:	1.8195475339889526

training epoch 463 / 500, batch #375 / 625
Loss:	1.7086422443389893

training epoch 463 / 500, batch #400 / 625
Loss:	1.78340744972229

training epoch 463 / 500, batch #425 / 625
Loss:	1.711760401725769

training epoch 463 / 500, batch #450 / 625
Loss:	1.7241826057434082

training epoch 463 / 500, batch #475 / 625
Loss:	1.7249411344528198

training epoch 463 / 500, batch #500 / 625
Loss:	1.5324301719665527

training epoch 463 / 500, batch #525 / 625
Loss:	1.8798041343688965

training epoch 463 / 500, batch #550 / 625
Loss:	1.5911208391189575

training epoch 463 / 500, batch #575 / 625
Loss:	1.748507022857666

training epoch 463 / 500, batch #600 / 625
Loss:	1.8618948459625244

training epoch 464 / 500, batch #0 / 625
Loss:	1.8516324758529663

training epoch 464 / 500, batch #25 / 625
Loss:	1.888513445854187

training epoch 464 / 500, batch #50 / 625
Loss:	1.761492133140564

training epoch 464 / 500, batch #75 / 625
Loss:	1.638595461845398

training epoch 464 / 500, batch #100 / 625
Loss:	1.5488361120224

training epoch 464 / 500, batch #125 / 625
Loss:	1.6607987880706787

training epoch 464 / 500, batch #150 / 625
Loss:	1.5974782705307007

training epoch 464 / 500, batch #175 / 625
Loss:	1.7228423357009888

training epoch 464 / 500, batch #200 / 625
Loss:	1.6085525751113892

training epoch 464 / 500, batch #225 / 625
Loss:	1.6669515371322632

training epoch 464 / 500, batch #250 / 625
Loss:	1.7236536741256714

training epoch 464 / 500, batch #275 / 625
Loss:	1.766566276550293

training epoch 464 / 500, batch #300 / 625
Loss:	1.7339701652526855

training epoch 464 / 500, batch #325 / 625
Loss:	1.8490591049194336

training epoch 464 / 500, batch #350 / 625
Loss:	1.8056681156158447

training epoch 464 / 500, batch #375 / 625
Loss:	1.8574838638305664

training epoch 464 / 500, batch #400 / 625
Loss:	1.7347652912139893

training epoch 464 / 500, batch #425 / 625
Loss:	1.7401025295257568

training epoch 464 / 500, batch #450 / 625
Loss:	2.3085086345672607

training epoch 464 / 500, batch #475 / 625
Loss:	1.7296496629714966

training epoch 464 / 500, batch #500 / 625
Loss:	1.6500470638275146

training epoch 464 / 500, batch #525 / 625
Loss:	1.5723768472671509

training epoch 464 / 500, batch #550 / 625
Loss:	1.613408088684082

training epoch 464 / 500, batch #575 / 625
Loss:	1.5365347862243652

training epoch 464 / 500, batch #600 / 625
Loss:	1.7156192064285278

training epoch 465 / 500, batch #0 / 625
Loss:	1.6259130239486694

training epoch 465 / 500, batch #25 / 625
Loss:	1.7340319156646729

training epoch 465 / 500, batch #50 / 625
Loss:	1.7073956727981567

training epoch 465 / 500, batch #75 / 625
Loss:	1.719220757484436

training epoch 465 / 500, batch #100 / 625
Loss:	1.8507298231124878

training epoch 465 / 500, batch #125 / 625
Loss:	1.8851646184921265

training epoch 465 / 500, batch #150 / 625
Loss:	1.7631686925888062

training epoch 465 / 500, batch #175 / 625
Loss:	1.8750298023223877

training epoch 465 / 500, batch #200 / 625
Loss:	1.746396541595459

training epoch 465 / 500, batch #225 / 625
Loss:	1.8208253383636475

training epoch 465 / 500, batch #250 / 625
Loss:	1.6255375146865845

training epoch 465 / 500, batch #275 / 625
Loss:	1.5917015075683594

training epoch 465 / 500, batch #300 / 625
Loss:	1.7456066608428955

training epoch 465 / 500, batch #325 / 625
Loss:	1.744140625

training epoch 465 / 500, batch #350 / 625
Loss:	1.7522954940795898

training epoch 465 / 500, batch #375 / 625
Loss:	1.4907253980636597

training epoch 465 / 500, batch #400 / 625
Loss:	1.7563852071762085

training epoch 465 / 500, batch #425 / 625
Loss:	1.7478121519088745

training epoch 465 / 500, batch #450 / 625
Loss:	1.739857792854309

training epoch 465 / 500, batch #475 / 625
Loss:	1.6557209491729736

training epoch 465 / 500, batch #500 / 625
Loss:	1.4002432823181152

training epoch 465 / 500, batch #525 / 625
Loss:	1.9063509702682495

training epoch 465 / 500, batch #550 / 625
Loss:	1.765830636024475

training epoch 465 / 500, batch #575 / 625
Loss:	1.7254128456115723

training epoch 465 / 500, batch #600 / 625
Loss:	1.7796400785446167

training epoch 466 / 500, batch #0 / 625
Loss:	1.7231836318969727

training epoch 466 / 500, batch #25 / 625
Loss:	1.669605016708374

training epoch 466 / 500, batch #50 / 625
Loss:	1.7473561763763428

training epoch 466 / 500, batch #75 / 625
Loss:	1.7426190376281738

training epoch 466 / 500, batch #100 / 625
Loss:	1.6450939178466797

training epoch 466 / 500, batch #125 / 625
Loss:	1.7210220098495483

training epoch 466 / 500, batch #150 / 625
Loss:	1.637609839439392

training epoch 466 / 500, batch #175 / 625
Loss:	1.4671831130981445

training epoch 466 / 500, batch #200 / 625
Loss:	1.5615211725234985

training epoch 466 / 500, batch #225 / 625
Loss:	1.7584285736083984

training epoch 466 / 500, batch #250 / 625
Loss:	1.5860772132873535

training epoch 466 / 500, batch #275 / 625
Loss:	1.7441918849945068

training epoch 466 / 500, batch #300 / 625
Loss:	1.717480182647705

training epoch 466 / 500, batch #325 / 625
Loss:	1.7793835401535034

training epoch 466 / 500, batch #350 / 625
Loss:	1.5364879369735718

training epoch 466 / 500, batch #375 / 625
Loss:	1.4362772703170776

training epoch 466 / 500, batch #400 / 625
Loss:	1.687098741531372

training epoch 466 / 500, batch #425 / 625
Loss:	1.6646349430084229

training epoch 466 / 500, batch #450 / 625
Loss:	1.675067663192749

training epoch 466 / 500, batch #475 / 625
Loss:	1.5879729986190796

training epoch 466 / 500, batch #500 / 625
Loss:	2.005375623703003

training epoch 466 / 500, batch #525 / 625
Loss:	1.7770912647247314

training epoch 466 / 500, batch #550 / 625
Loss:	1.662548542022705

training epoch 466 / 500, batch #575 / 625
Loss:	1.637560486793518

training epoch 466 / 500, batch #600 / 625
Loss:	1.5743852853775024

training epoch 467 / 500, batch #0 / 625
Loss:	1.498180866241455

training epoch 467 / 500, batch #25 / 625
Loss:	1.738194227218628

training epoch 467 / 500, batch #50 / 625
Loss:	1.475842833518982

training epoch 467 / 500, batch #75 / 625
Loss:	1.373044490814209

training epoch 467 / 500, batch #100 / 625
Loss:	1.6786047220230103

training epoch 467 / 500, batch #125 / 625
Loss:	1.6938308477401733

training epoch 467 / 500, batch #150 / 625
Loss:	1.6817760467529297

training epoch 467 / 500, batch #175 / 625
Loss:	1.6489986181259155

training epoch 467 / 500, batch #200 / 625
Loss:	1.9570046663284302

training epoch 467 / 500, batch #225 / 625
Loss:	1.6404463052749634

training epoch 467 / 500, batch #250 / 625
Loss:	1.9187687635421753

training epoch 467 / 500, batch #275 / 625
Loss:	1.7590007781982422

training epoch 467 / 500, batch #300 / 625
Loss:	1.7817432880401611

training epoch 467 / 500, batch #325 / 625
Loss:	1.6649411916732788

training epoch 467 / 500, batch #350 / 625
Loss:	2.0201101303100586

training epoch 467 / 500, batch #375 / 625
Loss:	1.8647851943969727

training epoch 467 / 500, batch #400 / 625
Loss:	1.7328860759735107

training epoch 467 / 500, batch #425 / 625
Loss:	1.669294834136963

training epoch 467 / 500, batch #450 / 625
Loss:	1.6450976133346558

training epoch 467 / 500, batch #475 / 625
Loss:	1.828046441078186

training epoch 467 / 500, batch #500 / 625
Loss:	1.9378552436828613

training epoch 467 / 500, batch #525 / 625
Loss:	1.7120492458343506

training epoch 467 / 500, batch #550 / 625
Loss:	1.7729010581970215

training epoch 467 / 500, batch #575 / 625
Loss:	1.7196192741394043

training epoch 467 / 500, batch #600 / 625
Loss:	1.5517032146453857

training epoch 468 / 500, batch #0 / 625
Loss:	1.7142037153244019

training epoch 468 / 500, batch #25 / 625
Loss:	1.896690845489502

training epoch 468 / 500, batch #50 / 625
Loss:	1.7877583503723145

training epoch 468 / 500, batch #75 / 625
Loss:	2.097553253173828

training epoch 468 / 500, batch #100 / 625
Loss:	1.4686921834945679

training epoch 468 / 500, batch #125 / 625
Loss:	1.799211859703064

training epoch 468 / 500, batch #150 / 625
Loss:	1.65299391746521

training epoch 468 / 500, batch #175 / 625
Loss:	1.8644827604293823

training epoch 468 / 500, batch #200 / 625
Loss:	1.4959800243377686

training epoch 468 / 500, batch #225 / 625
Loss:	1.8770432472229004

training epoch 468 / 500, batch #250 / 625
Loss:	1.9398002624511719

training epoch 468 / 500, batch #275 / 625
Loss:	1.7379176616668701

training epoch 468 / 500, batch #300 / 625
Loss:	1.8294800519943237

training epoch 468 / 500, batch #325 / 625
Loss:	1.8163284063339233

training epoch 468 / 500, batch #350 / 625
Loss:	1.5606555938720703

training epoch 468 / 500, batch #375 / 625
Loss:	2.066843032836914

training epoch 468 / 500, batch #400 / 625
Loss:	1.8225338459014893

training epoch 468 / 500, batch #425 / 625
Loss:	1.8432847261428833

training epoch 468 / 500, batch #450 / 625
Loss:	1.7566355466842651

training epoch 468 / 500, batch #475 / 625
Loss:	1.6802181005477905

training epoch 468 / 500, batch #500 / 625
Loss:	1.6562697887420654

training epoch 468 / 500, batch #525 / 625
Loss:	1.758325219154358

training epoch 468 / 500, batch #550 / 625
Loss:	1.884582281112671

training epoch 468 / 500, batch #575 / 625
Loss:	1.8932945728302002

training epoch 468 / 500, batch #600 / 625
Loss:	1.4368656873703003

training epoch 469 / 500, batch #0 / 625
Loss:	1.6391026973724365

training epoch 469 / 500, batch #25 / 625
Loss:	1.6064624786376953

training epoch 469 / 500, batch #50 / 625
Loss:	1.4662009477615356

training epoch 469 / 500, batch #75 / 625
Loss:	1.687822699546814

training epoch 469 / 500, batch #100 / 625
Loss:	1.637181282043457

training epoch 469 / 500, batch #125 / 625
Loss:	1.5985573530197144

training epoch 469 / 500, batch #150 / 625
Loss:	1.8690627813339233

training epoch 469 / 500, batch #175 / 625
Loss:	1.5828241109848022

training epoch 469 / 500, batch #200 / 625
Loss:	1.5050843954086304

training epoch 469 / 500, batch #225 / 625
Loss:	1.7085016965866089

training epoch 469 / 500, batch #250 / 625
Loss:	1.6426236629486084

training epoch 469 / 500, batch #275 / 625
Loss:	1.558684229850769

training epoch 469 / 500, batch #300 / 625
Loss:	1.7746524810791016

training epoch 469 / 500, batch #325 / 625
Loss:	1.9140790700912476

training epoch 469 / 500, batch #350 / 625
Loss:	1.8135594129562378

training epoch 469 / 500, batch #375 / 625
Loss:	1.8409430980682373

training epoch 469 / 500, batch #400 / 625
Loss:	1.6409894227981567

training epoch 469 / 500, batch #425 / 625
Loss:	1.749434471130371

training epoch 469 / 500, batch #450 / 625
Loss:	1.6320092678070068

training epoch 469 / 500, batch #475 / 625
Loss:	1.7208589315414429

training epoch 469 / 500, batch #500 / 625
Loss:	1.9933979511260986

training epoch 469 / 500, batch #525 / 625
Loss:	1.6552013158798218

training epoch 469 / 500, batch #550 / 625
Loss:	1.7089520692825317

training epoch 469 / 500, batch #575 / 625
Loss:	1.844892978668213

training epoch 469 / 500, batch #600 / 625
Loss:	1.6493488550186157

training epoch 470 / 500, batch #0 / 625
Loss:	1.7788254022598267

training epoch 470 / 500, batch #25 / 625
Loss:	1.6087877750396729

training epoch 470 / 500, batch #50 / 625
Loss:	1.5880026817321777

training epoch 470 / 500, batch #75 / 625
Loss:	1.6453981399536133

training epoch 470 / 500, batch #100 / 625
Loss:	1.735003113746643

training epoch 470 / 500, batch #125 / 625
Loss:	1.9056878089904785

training epoch 470 / 500, batch #150 / 625
Loss:	1.7027415037155151

training epoch 470 / 500, batch #175 / 625
Loss:	1.6157108545303345

training epoch 470 / 500, batch #200 / 625
Loss:	1.4664511680603027

training epoch 470 / 500, batch #225 / 625
Loss:	1.7621309757232666

training epoch 470 / 500, batch #250 / 625
Loss:	1.737919807434082

training epoch 470 / 500, batch #275 / 625
Loss:	1.6252765655517578

training epoch 470 / 500, batch #300 / 625
Loss:	1.8785167932510376

training epoch 470 / 500, batch #325 / 625
Loss:	1.7826673984527588

training epoch 470 / 500, batch #350 / 625
Loss:	1.6260168552398682

training epoch 470 / 500, batch #375 / 625
Loss:	1.8394205570220947

training epoch 470 / 500, batch #400 / 625
Loss:	1.4769562482833862

training epoch 470 / 500, batch #425 / 625
Loss:	1.6704045534133911

training epoch 470 / 500, batch #450 / 625
Loss:	1.7810920476913452

training epoch 470 / 500, batch #475 / 625
Loss:	1.661084532737732

training epoch 470 / 500, batch #500 / 625
Loss:	1.883746862411499

training epoch 470 / 500, batch #525 / 625
Loss:	1.671014666557312

training epoch 470 / 500, batch #550 / 625
Loss:	1.4730219841003418

training epoch 470 / 500, batch #575 / 625
Loss:	1.8937718868255615

training epoch 470 / 500, batch #600 / 625
Loss:	1.8184453248977661

training epoch 471 / 500, batch #0 / 625
Loss:	1.5997365713119507

training epoch 471 / 500, batch #25 / 625
Loss:	1.6293671131134033

training epoch 471 / 500, batch #50 / 625
Loss:	1.6694691181182861

training epoch 471 / 500, batch #75 / 625
Loss:	1.617498755455017

training epoch 471 / 500, batch #100 / 625
Loss:	1.6884820461273193

training epoch 471 / 500, batch #125 / 625
Loss:	1.8519861698150635

training epoch 471 / 500, batch #150 / 625
Loss:	1.6299940347671509

training epoch 471 / 500, batch #175 / 625
Loss:	1.8354127407073975

training epoch 471 / 500, batch #200 / 625
Loss:	1.6582601070404053

training epoch 471 / 500, batch #225 / 625
Loss:	1.7580666542053223

training epoch 471 / 500, batch #250 / 625
Loss:	1.7200034856796265

training epoch 471 / 500, batch #275 / 625
Loss:	1.7757982015609741

training epoch 471 / 500, batch #300 / 625
Loss:	1.6427496671676636

training epoch 471 / 500, batch #325 / 625
Loss:	1.783267617225647

training epoch 471 / 500, batch #350 / 625
Loss:	1.732177972793579

training epoch 471 / 500, batch #375 / 625
Loss:	1.8063009977340698

training epoch 471 / 500, batch #400 / 625
Loss:	1.7890714406967163

training epoch 471 / 500, batch #425 / 625
Loss:	1.6516340970993042

training epoch 471 / 500, batch #450 / 625
Loss:	1.712347149848938

training epoch 471 / 500, batch #475 / 625
Loss:	1.542248249053955

training epoch 471 / 500, batch #500 / 625
Loss:	1.6624165773391724

training epoch 471 / 500, batch #525 / 625
Loss:	1.4203271865844727

training epoch 471 / 500, batch #550 / 625
Loss:	1.8558545112609863

training epoch 471 / 500, batch #575 / 625
Loss:	1.6404672861099243

training epoch 471 / 500, batch #600 / 625
Loss:	1.7171635627746582

training epoch 472 / 500, batch #0 / 625
Loss:	1.5947414636611938

training epoch 472 / 500, batch #25 / 625
Loss:	1.5367659330368042

training epoch 472 / 500, batch #50 / 625
Loss:	1.840320110321045

training epoch 472 / 500, batch #75 / 625
Loss:	1.502309799194336

training epoch 472 / 500, batch #100 / 625
Loss:	1.7375153303146362

training epoch 472 / 500, batch #125 / 625
Loss:	1.5066370964050293

training epoch 472 / 500, batch #150 / 625
Loss:	1.4348787069320679

training epoch 472 / 500, batch #175 / 625
Loss:	1.5848357677459717

training epoch 472 / 500, batch #200 / 625
Loss:	1.8580197095870972

training epoch 472 / 500, batch #225 / 625
Loss:	1.7690016031265259

training epoch 472 / 500, batch #250 / 625
Loss:	1.7168539762496948

training epoch 472 / 500, batch #275 / 625
Loss:	1.5819754600524902

training epoch 472 / 500, batch #300 / 625
Loss:	1.715513825416565

training epoch 472 / 500, batch #325 / 625
Loss:	1.8652710914611816

training epoch 472 / 500, batch #350 / 625
Loss:	1.701538324356079

training epoch 472 / 500, batch #375 / 625
Loss:	1.6422090530395508

training epoch 472 / 500, batch #400 / 625
Loss:	1.8466863632202148

training epoch 472 / 500, batch #425 / 625
Loss:	1.8563895225524902

training epoch 472 / 500, batch #450 / 625
Loss:	1.7058414220809937

training epoch 472 / 500, batch #475 / 625
Loss:	2.006596565246582

training epoch 472 / 500, batch #500 / 625
Loss:	1.7734777927398682

training epoch 472 / 500, batch #525 / 625
Loss:	1.5712864398956299

training epoch 472 / 500, batch #550 / 625
Loss:	1.8501050472259521

training epoch 472 / 500, batch #575 / 625
Loss:	1.6737147569656372

training epoch 472 / 500, batch #600 / 625
Loss:	1.5456370115280151

training epoch 473 / 500, batch #0 / 625
Loss:	1.568339228630066

training epoch 473 / 500, batch #25 / 625
Loss:	1.7348302602767944

training epoch 473 / 500, batch #50 / 625
Loss:	1.5763195753097534

training epoch 473 / 500, batch #75 / 625
Loss:	1.495557188987732

training epoch 473 / 500, batch #100 / 625
Loss:	1.702340841293335

training epoch 473 / 500, batch #125 / 625
Loss:	1.671823501586914

training epoch 473 / 500, batch #150 / 625
Loss:	1.684532880783081

training epoch 473 / 500, batch #175 / 625
Loss:	1.941133975982666

training epoch 473 / 500, batch #200 / 625
Loss:	1.5966107845306396

training epoch 473 / 500, batch #225 / 625
Loss:	1.9258049726486206

training epoch 473 / 500, batch #250 / 625
Loss:	1.3012945652008057

training epoch 473 / 500, batch #275 / 625
Loss:	1.3693203926086426

training epoch 473 / 500, batch #300 / 625
Loss:	1.6390942335128784

training epoch 473 / 500, batch #325 / 625
Loss:	1.8585237264633179

training epoch 473 / 500, batch #350 / 625
Loss:	1.593823790550232

training epoch 473 / 500, batch #375 / 625
Loss:	1.5966846942901611

training epoch 473 / 500, batch #400 / 625
Loss:	1.9526938199996948

training epoch 473 / 500, batch #425 / 625
Loss:	1.7996060848236084

training epoch 473 / 500, batch #450 / 625
Loss:	1.8660993576049805

training epoch 473 / 500, batch #475 / 625
Loss:	1.638763427734375

training epoch 473 / 500, batch #500 / 625
Loss:	1.502109408378601

training epoch 473 / 500, batch #525 / 625
Loss:	1.6994431018829346

training epoch 473 / 500, batch #550 / 625
Loss:	1.5485873222351074

training epoch 473 / 500, batch #575 / 625
Loss:	1.6033525466918945

training epoch 473 / 500, batch #600 / 625
Loss:	2.1123273372650146

training epoch 474 / 500, batch #0 / 625
Loss:	1.7621901035308838

training epoch 474 / 500, batch #25 / 625
Loss:	1.7488051652908325

training epoch 474 / 500, batch #50 / 625
Loss:	1.6338763236999512

training epoch 474 / 500, batch #75 / 625
Loss:	1.6445274353027344

training epoch 474 / 500, batch #100 / 625
Loss:	1.60545814037323

training epoch 474 / 500, batch #125 / 625
Loss:	1.7420504093170166

training epoch 474 / 500, batch #150 / 625
Loss:	1.6549232006072998

training epoch 474 / 500, batch #175 / 625
Loss:	1.7683862447738647

training epoch 474 / 500, batch #200 / 625
Loss:	1.6246322393417358

training epoch 474 / 500, batch #225 / 625
Loss:	1.800024390220642

training epoch 474 / 500, batch #250 / 625
Loss:	1.7429330348968506

training epoch 474 / 500, batch #275 / 625
Loss:	1.9200347661972046

training epoch 474 / 500, batch #300 / 625
Loss:	1.7938421964645386

training epoch 474 / 500, batch #325 / 625
Loss:	1.5733003616333008

training epoch 474 / 500, batch #350 / 625
Loss:	1.7836248874664307

training epoch 474 / 500, batch #375 / 625
Loss:	1.7967833280563354

training epoch 474 / 500, batch #400 / 625
Loss:	1.7043639421463013

training epoch 474 / 500, batch #425 / 625
Loss:	1.7994117736816406

training epoch 474 / 500, batch #450 / 625
Loss:	1.50669264793396

training epoch 474 / 500, batch #475 / 625
Loss:	1.545278787612915

training epoch 474 / 500, batch #500 / 625
Loss:	1.8330700397491455

training epoch 474 / 500, batch #525 / 625
Loss:	1.6887015104293823

training epoch 474 / 500, batch #550 / 625
Loss:	1.5706889629364014

training epoch 474 / 500, batch #575 / 625
Loss:	1.7420275211334229

training epoch 474 / 500, batch #600 / 625
Loss:	1.8678672313690186

training epoch 475 / 500, batch #0 / 625
Loss:	1.8444138765335083

training epoch 475 / 500, batch #25 / 625
Loss:	1.7212965488433838

training epoch 475 / 500, batch #50 / 625
Loss:	1.610561490058899

training epoch 475 / 500, batch #75 / 625
Loss:	1.9532036781311035

training epoch 475 / 500, batch #100 / 625
Loss:	1.7490549087524414

training epoch 475 / 500, batch #125 / 625
Loss:	2.004532814025879

training epoch 475 / 500, batch #150 / 625
Loss:	1.5283530950546265

training epoch 475 / 500, batch #175 / 625
Loss:	1.6054577827453613

training epoch 475 / 500, batch #200 / 625
Loss:	1.8418867588043213

training epoch 475 / 500, batch #225 / 625
Loss:	1.870495319366455

training epoch 475 / 500, batch #250 / 625
Loss:	1.6512534618377686

training epoch 475 / 500, batch #275 / 625
Loss:	2.0294861793518066

training epoch 475 / 500, batch #300 / 625
Loss:	1.4987266063690186

training epoch 475 / 500, batch #325 / 625
Loss:	1.7124487161636353

training epoch 475 / 500, batch #350 / 625
Loss:	1.768523097038269

training epoch 475 / 500, batch #375 / 625
Loss:	1.7682859897613525

training epoch 475 / 500, batch #400 / 625
Loss:	1.8250584602355957

training epoch 475 / 500, batch #425 / 625
Loss:	1.9284679889678955

training epoch 475 / 500, batch #450 / 625
Loss:	1.6420845985412598

training epoch 475 / 500, batch #475 / 625
Loss:	1.5048695802688599

training epoch 475 / 500, batch #500 / 625
Loss:	2.0317203998565674

training epoch 475 / 500, batch #525 / 625
Loss:	1.8394416570663452

training epoch 475 / 500, batch #550 / 625
Loss:	1.6811290979385376

training epoch 475 / 500, batch #575 / 625
Loss:	1.8317376375198364

training epoch 475 / 500, batch #600 / 625
Loss:	1.8551921844482422

training epoch 476 / 500, batch #0 / 625
Loss:	1.647133469581604

training epoch 476 / 500, batch #25 / 625
Loss:	1.7225754261016846

training epoch 476 / 500, batch #50 / 625
Loss:	1.52134370803833

training epoch 476 / 500, batch #75 / 625
Loss:	1.624507188796997

training epoch 476 / 500, batch #100 / 625
Loss:	1.7320256233215332

training epoch 476 / 500, batch #125 / 625
Loss:	1.6912226676940918

training epoch 476 / 500, batch #150 / 625
Loss:	1.6843039989471436

training epoch 476 / 500, batch #175 / 625
Loss:	1.704221487045288

training epoch 476 / 500, batch #200 / 625
Loss:	1.6656969785690308

training epoch 476 / 500, batch #225 / 625
Loss:	1.5428454875946045

training epoch 476 / 500, batch #250 / 625
Loss:	1.599526286125183

training epoch 476 / 500, batch #275 / 625
Loss:	1.556627869606018

training epoch 476 / 500, batch #300 / 625
Loss:	1.8114293813705444

training epoch 476 / 500, batch #325 / 625
Loss:	1.6021084785461426

training epoch 476 / 500, batch #350 / 625
Loss:	1.7161999940872192

training epoch 476 / 500, batch #375 / 625
Loss:	1.8206238746643066

training epoch 476 / 500, batch #400 / 625
Loss:	1.8679618835449219

training epoch 476 / 500, batch #425 / 625
Loss:	1.8665874004364014

training epoch 476 / 500, batch #450 / 625
Loss:	1.944992184638977

training epoch 476 / 500, batch #475 / 625
Loss:	1.7127913236618042

training epoch 476 / 500, batch #500 / 625
Loss:	2.0335655212402344

training epoch 476 / 500, batch #525 / 625
Loss:	1.9700493812561035

training epoch 476 / 500, batch #550 / 625
Loss:	2.0246424674987793

training epoch 476 / 500, batch #575 / 625
Loss:	1.9689081907272339

training epoch 476 / 500, batch #600 / 625
Loss:	1.799924373626709

training epoch 477 / 500, batch #0 / 625
Loss:	1.9287607669830322

training epoch 477 / 500, batch #25 / 625
Loss:	1.4135750532150269

training epoch 477 / 500, batch #50 / 625
Loss:	1.8295468091964722

training epoch 477 / 500, batch #75 / 625
Loss:	1.7367347478866577

training epoch 477 / 500, batch #100 / 625
Loss:	1.4731682538986206

training epoch 477 / 500, batch #125 / 625
Loss:	1.9585727453231812

training epoch 477 / 500, batch #150 / 625
Loss:	1.6426187753677368

training epoch 477 / 500, batch #175 / 625
Loss:	1.5679190158843994

training epoch 477 / 500, batch #200 / 625
Loss:	1.5715515613555908

training epoch 477 / 500, batch #225 / 625
Loss:	1.5306992530822754

training epoch 477 / 500, batch #250 / 625
Loss:	1.6950300931930542

training epoch 477 / 500, batch #275 / 625
Loss:	1.5895694494247437

training epoch 477 / 500, batch #300 / 625
Loss:	1.6752872467041016

training epoch 477 / 500, batch #325 / 625
Loss:	1.9316658973693848

training epoch 477 / 500, batch #350 / 625
Loss:	1.8691565990447998

training epoch 477 / 500, batch #375 / 625
Loss:	1.6681262254714966

training epoch 477 / 500, batch #400 / 625
Loss:	1.7702561616897583

training epoch 477 / 500, batch #425 / 625
Loss:	1.7810852527618408

training epoch 477 / 500, batch #450 / 625
Loss:	1.460396647453308

training epoch 477 / 500, batch #475 / 625
Loss:	1.7374485731124878

training epoch 477 / 500, batch #500 / 625
Loss:	1.7705066204071045

training epoch 477 / 500, batch #525 / 625
Loss:	1.8663864135742188

training epoch 477 / 500, batch #550 / 625
Loss:	1.5253559350967407

training epoch 477 / 500, batch #575 / 625
Loss:	1.7919228076934814

training epoch 477 / 500, batch #600 / 625
Loss:	1.8423430919647217

training epoch 478 / 500, batch #0 / 625
Loss:	1.915716528892517

training epoch 478 / 500, batch #25 / 625
Loss:	1.9155175685882568

training epoch 478 / 500, batch #50 / 625
Loss:	1.5574883222579956

training epoch 478 / 500, batch #75 / 625
Loss:	1.6610913276672363

training epoch 478 / 500, batch #100 / 625
Loss:	1.6112825870513916

training epoch 478 / 500, batch #125 / 625
Loss:	1.8964009284973145

training epoch 478 / 500, batch #150 / 625
Loss:	1.7037320137023926

training epoch 478 / 500, batch #175 / 625
Loss:	1.679927945137024

training epoch 478 / 500, batch #200 / 625
Loss:	1.587239384651184

training epoch 478 / 500, batch #225 / 625
Loss:	1.762303113937378

training epoch 478 / 500, batch #250 / 625
Loss:	1.7140213251113892

training epoch 478 / 500, batch #275 / 625
Loss:	1.8615338802337646

training epoch 478 / 500, batch #300 / 625
Loss:	1.7493752241134644

training epoch 478 / 500, batch #325 / 625
Loss:	1.6261528730392456

training epoch 478 / 500, batch #350 / 625
Loss:	1.6564321517944336

training epoch 478 / 500, batch #375 / 625
Loss:	1.8834155797958374

training epoch 478 / 500, batch #400 / 625
Loss:	1.7243938446044922

training epoch 478 / 500, batch #425 / 625
Loss:	1.8814501762390137

training epoch 478 / 500, batch #450 / 625
Loss:	1.3617284297943115

training epoch 478 / 500, batch #475 / 625
Loss:	1.6823018789291382

training epoch 478 / 500, batch #500 / 625
Loss:	1.6011322736740112

training epoch 478 / 500, batch #525 / 625
Loss:	1.6854791641235352

training epoch 478 / 500, batch #550 / 625
Loss:	1.7364046573638916

training epoch 478 / 500, batch #575 / 625
Loss:	1.9313595294952393

training epoch 478 / 500, batch #600 / 625
Loss:	2.0338621139526367

training epoch 479 / 500, batch #0 / 625
Loss:	1.6098196506500244

training epoch 479 / 500, batch #25 / 625
Loss:	1.5464496612548828

training epoch 479 / 500, batch #50 / 625
Loss:	1.700732707977295

training epoch 479 / 500, batch #75 / 625
Loss:	1.6138471364974976

training epoch 479 / 500, batch #100 / 625
Loss:	1.7678879499435425

training epoch 479 / 500, batch #125 / 625
Loss:	1.7635433673858643

training epoch 479 / 500, batch #150 / 625
Loss:	1.7517905235290527

training epoch 479 / 500, batch #175 / 625
Loss:	1.6484280824661255

training epoch 479 / 500, batch #200 / 625
Loss:	1.6079436540603638

training epoch 479 / 500, batch #225 / 625
Loss:	1.905996561050415

training epoch 479 / 500, batch #250 / 625
Loss:	1.5558688640594482

training epoch 479 / 500, batch #275 / 625
Loss:	1.8470735549926758

training epoch 479 / 500, batch #300 / 625
Loss:	1.613175392150879

training epoch 479 / 500, batch #325 / 625
Loss:	1.6701866388320923

training epoch 479 / 500, batch #350 / 625
Loss:	1.6816058158874512

training epoch 479 / 500, batch #375 / 625
Loss:	1.567571759223938

training epoch 479 / 500, batch #400 / 625
Loss:	1.7747827768325806

training epoch 479 / 500, batch #425 / 625
Loss:	1.9085696935653687

training epoch 479 / 500, batch #450 / 625
Loss:	1.562699556350708

training epoch 479 / 500, batch #475 / 625
Loss:	1.6503454446792603

training epoch 479 / 500, batch #500 / 625
Loss:	1.7219510078430176

training epoch 479 / 500, batch #525 / 625
Loss:	1.631113052368164

training epoch 479 / 500, batch #550 / 625
Loss:	1.7349252700805664

training epoch 479 / 500, batch #575 / 625
Loss:	1.8313217163085938

training epoch 479 / 500, batch #600 / 625
Loss:	1.7287795543670654

training epoch 480 / 500, batch #0 / 625
Loss:	1.4995683431625366

training epoch 480 / 500, batch #25 / 625
Loss:	1.6295770406723022

training epoch 480 / 500, batch #50 / 625
Loss:	1.677577257156372

training epoch 480 / 500, batch #75 / 625
Loss:	1.6594796180725098

training epoch 480 / 500, batch #100 / 625
Loss:	1.7278562784194946

training epoch 480 / 500, batch #125 / 625
Loss:	1.8557898998260498

training epoch 480 / 500, batch #150 / 625
Loss:	1.4456181526184082

training epoch 480 / 500, batch #175 / 625
Loss:	1.782160758972168

training epoch 480 / 500, batch #200 / 625
Loss:	1.5194445848464966

training epoch 480 / 500, batch #225 / 625
Loss:	1.8990002870559692

training epoch 480 / 500, batch #250 / 625
Loss:	1.728724479675293

training epoch 480 / 500, batch #275 / 625
Loss:	1.5264430046081543

training epoch 480 / 500, batch #300 / 625
Loss:	1.7692813873291016

training epoch 480 / 500, batch #325 / 625
Loss:	1.7110750675201416

training epoch 480 / 500, batch #350 / 625
Loss:	1.5194063186645508

training epoch 480 / 500, batch #375 / 625
Loss:	1.6457024812698364

training epoch 480 / 500, batch #400 / 625
Loss:	1.4476866722106934

training epoch 480 / 500, batch #425 / 625
Loss:	1.6856977939605713

training epoch 480 / 500, batch #450 / 625
Loss:	1.7137078046798706

training epoch 480 / 500, batch #475 / 625
Loss:	1.8101861476898193

training epoch 480 / 500, batch #500 / 625
Loss:	1.8849406242370605

training epoch 480 / 500, batch #525 / 625
Loss:	1.785767674446106

training epoch 480 / 500, batch #550 / 625
Loss:	1.6851743459701538

training epoch 480 / 500, batch #575 / 625
Loss:	1.7301172018051147

training epoch 480 / 500, batch #600 / 625
Loss:	1.6603524684906006

training epoch 481 / 500, batch #0 / 625
Loss:	1.7318106889724731

training epoch 481 / 500, batch #25 / 625
Loss:	1.949236273765564

training epoch 481 / 500, batch #50 / 625
Loss:	1.869289755821228

training epoch 481 / 500, batch #75 / 625
Loss:	1.5960135459899902

training epoch 481 / 500, batch #100 / 625
Loss:	1.6702021360397339

training epoch 481 / 500, batch #125 / 625
Loss:	1.8409806489944458

training epoch 481 / 500, batch #150 / 625
Loss:	1.6168900728225708

training epoch 481 / 500, batch #175 / 625
Loss:	1.9308199882507324

training epoch 481 / 500, batch #200 / 625
Loss:	1.7789537906646729

training epoch 481 / 500, batch #225 / 625
Loss:	1.5757942199707031

training epoch 481 / 500, batch #250 / 625
Loss:	2.0056729316711426

training epoch 481 / 500, batch #275 / 625
Loss:	1.8035887479782104

training epoch 481 / 500, batch #300 / 625
Loss:	1.6308032274246216

training epoch 481 / 500, batch #325 / 625
Loss:	1.7766904830932617

training epoch 481 / 500, batch #350 / 625
Loss:	1.6533209085464478

training epoch 481 / 500, batch #375 / 625
Loss:	1.604225516319275

training epoch 481 / 500, batch #400 / 625
Loss:	1.8738631010055542

training epoch 481 / 500, batch #425 / 625
Loss:	1.6531362533569336

training epoch 481 / 500, batch #450 / 625
Loss:	1.9039018154144287

training epoch 481 / 500, batch #475 / 625
Loss:	1.588128685951233

training epoch 481 / 500, batch #500 / 625
Loss:	1.553946852684021

training epoch 481 / 500, batch #525 / 625
Loss:	1.5373923778533936

training epoch 481 / 500, batch #550 / 625
Loss:	1.7381060123443604

training epoch 481 / 500, batch #575 / 625
Loss:	2.0890820026397705

training epoch 481 / 500, batch #600 / 625
Loss:	1.768221139907837

training epoch 482 / 500, batch #0 / 625
Loss:	1.8419677019119263

training epoch 482 / 500, batch #25 / 625
Loss:	1.8626271486282349

training epoch 482 / 500, batch #50 / 625
Loss:	1.8543301820755005

training epoch 482 / 500, batch #75 / 625
Loss:	1.8793220520019531

training epoch 482 / 500, batch #100 / 625
Loss:	1.9318609237670898

training epoch 482 / 500, batch #125 / 625
Loss:	1.6817160844802856

training epoch 482 / 500, batch #150 / 625
Loss:	1.9301137924194336

training epoch 482 / 500, batch #175 / 625
Loss:	1.5118980407714844

training epoch 482 / 500, batch #200 / 625
Loss:	1.8132492303848267

training epoch 482 / 500, batch #225 / 625
Loss:	1.6518763303756714

training epoch 482 / 500, batch #250 / 625
Loss:	1.679602861404419

training epoch 482 / 500, batch #275 / 625
Loss:	1.8267484903335571

training epoch 482 / 500, batch #300 / 625
Loss:	1.551037073135376

training epoch 482 / 500, batch #325 / 625
Loss:	1.7714025974273682

training epoch 482 / 500, batch #350 / 625
Loss:	1.582319736480713

training epoch 482 / 500, batch #375 / 625
Loss:	1.7085356712341309

training epoch 482 / 500, batch #400 / 625
Loss:	1.5921539068222046

training epoch 482 / 500, batch #425 / 625
Loss:	1.5085686445236206

training epoch 482 / 500, batch #450 / 625
Loss:	1.6506620645523071

training epoch 482 / 500, batch #475 / 625
Loss:	1.520999550819397

training epoch 482 / 500, batch #500 / 625
Loss:	1.6450443267822266

training epoch 482 / 500, batch #525 / 625
Loss:	2.027254104614258

training epoch 482 / 500, batch #550 / 625
Loss:	1.7749758958816528

training epoch 482 / 500, batch #575 / 625
Loss:	1.73247492313385

training epoch 482 / 500, batch #600 / 625
Loss:	1.9092286825180054

training epoch 483 / 500, batch #0 / 625
Loss:	1.5097992420196533

training epoch 483 / 500, batch #25 / 625
Loss:	1.7382068634033203

training epoch 483 / 500, batch #50 / 625
Loss:	1.7323973178863525

training epoch 483 / 500, batch #75 / 625
Loss:	1.5095210075378418

training epoch 483 / 500, batch #100 / 625
Loss:	1.8472695350646973

training epoch 483 / 500, batch #125 / 625
Loss:	1.6696497201919556

training epoch 483 / 500, batch #150 / 625
Loss:	1.5109963417053223

training epoch 483 / 500, batch #175 / 625
Loss:	1.61589515209198

training epoch 483 / 500, batch #200 / 625
Loss:	1.7153449058532715

training epoch 483 / 500, batch #225 / 625
Loss:	1.6765694618225098

training epoch 483 / 500, batch #250 / 625
Loss:	1.546433687210083

training epoch 483 / 500, batch #275 / 625
Loss:	1.3750534057617188

training epoch 483 / 500, batch #300 / 625
Loss:	1.6935920715332031

training epoch 483 / 500, batch #325 / 625
Loss:	1.6190184354782104

training epoch 483 / 500, batch #350 / 625
Loss:	1.6199437379837036

training epoch 483 / 500, batch #375 / 625
Loss:	1.7233542203903198

training epoch 483 / 500, batch #400 / 625
Loss:	1.5615874528884888

training epoch 483 / 500, batch #425 / 625
Loss:	1.5861402750015259

training epoch 483 / 500, batch #450 / 625
Loss:	1.8054643869400024

training epoch 483 / 500, batch #475 / 625
Loss:	1.983699917793274

training epoch 483 / 500, batch #500 / 625
Loss:	1.8300539255142212

training epoch 483 / 500, batch #525 / 625
Loss:	1.8983463048934937

training epoch 483 / 500, batch #550 / 625
Loss:	1.841203212738037

training epoch 483 / 500, batch #575 / 625
Loss:	1.6195178031921387

training epoch 483 / 500, batch #600 / 625
Loss:	1.4923144578933716

training epoch 484 / 500, batch #0 / 625
Loss:	1.5389772653579712

training epoch 484 / 500, batch #25 / 625
Loss:	1.4842112064361572

training epoch 484 / 500, batch #50 / 625
Loss:	1.7784714698791504

training epoch 484 / 500, batch #75 / 625
Loss:	1.5467402935028076

training epoch 484 / 500, batch #100 / 625
Loss:	1.6640568971633911

training epoch 484 / 500, batch #125 / 625
Loss:	1.6509394645690918

training epoch 484 / 500, batch #150 / 625
Loss:	1.7848039865493774

training epoch 484 / 500, batch #175 / 625
Loss:	1.7168108224868774

training epoch 484 / 500, batch #200 / 625
Loss:	1.9192841053009033

training epoch 484 / 500, batch #225 / 625
Loss:	1.9446825981140137

training epoch 484 / 500, batch #250 / 625
Loss:	1.7303707599639893

training epoch 484 / 500, batch #275 / 625
Loss:	1.6096603870391846

training epoch 484 / 500, batch #300 / 625
Loss:	1.7698252201080322

training epoch 484 / 500, batch #325 / 625
Loss:	1.6211183071136475

training epoch 484 / 500, batch #350 / 625
Loss:	1.6540437936782837

training epoch 484 / 500, batch #375 / 625
Loss:	1.9554845094680786

training epoch 484 / 500, batch #400 / 625
Loss:	1.6203012466430664

training epoch 484 / 500, batch #425 / 625
Loss:	1.6129285097122192

training epoch 484 / 500, batch #450 / 625
Loss:	1.6497514247894287

training epoch 484 / 500, batch #475 / 625
Loss:	1.7236649990081787

training epoch 484 / 500, batch #500 / 625
Loss:	1.6824257373809814

training epoch 484 / 500, batch #525 / 625
Loss:	1.9029276371002197

training epoch 484 / 500, batch #550 / 625
Loss:	1.84651780128479

training epoch 484 / 500, batch #575 / 625
Loss:	1.8405669927597046

training epoch 484 / 500, batch #600 / 625
Loss:	1.8578896522521973

training epoch 485 / 500, batch #0 / 625
Loss:	1.6113439798355103

training epoch 485 / 500, batch #25 / 625
Loss:	1.645713448524475

training epoch 485 / 500, batch #50 / 625
Loss:	1.621336817741394

training epoch 485 / 500, batch #75 / 625
Loss:	1.7037829160690308

training epoch 485 / 500, batch #100 / 625
Loss:	1.9191348552703857

training epoch 485 / 500, batch #125 / 625
Loss:	1.692088007926941

training epoch 485 / 500, batch #150 / 625
Loss:	1.7924981117248535

training epoch 485 / 500, batch #175 / 625
Loss:	1.6908512115478516

training epoch 485 / 500, batch #200 / 625
Loss:	1.3813751935958862

training epoch 485 / 500, batch #225 / 625
Loss:	1.584777593612671

training epoch 485 / 500, batch #250 / 625
Loss:	1.759161353111267

training epoch 485 / 500, batch #275 / 625
Loss:	1.6570852994918823

training epoch 485 / 500, batch #300 / 625
Loss:	1.6994342803955078

training epoch 485 / 500, batch #325 / 625
Loss:	1.4315327405929565

training epoch 485 / 500, batch #350 / 625
Loss:	1.7766728401184082

training epoch 485 / 500, batch #375 / 625
Loss:	1.6731090545654297

training epoch 485 / 500, batch #400 / 625
Loss:	1.822822093963623

training epoch 485 / 500, batch #425 / 625
Loss:	1.6865487098693848

training epoch 485 / 500, batch #450 / 625
Loss:	1.6824493408203125

training epoch 485 / 500, batch #475 / 625
Loss:	1.92252516746521

training epoch 485 / 500, batch #500 / 625
Loss:	1.6734514236450195

training epoch 485 / 500, batch #525 / 625
Loss:	1.7834912538528442

training epoch 485 / 500, batch #550 / 625
Loss:	1.68035888671875

training epoch 485 / 500, batch #575 / 625
Loss:	1.6494520902633667

training epoch 485 / 500, batch #600 / 625
Loss:	1.692678689956665

training epoch 486 / 500, batch #0 / 625
Loss:	1.5489238500595093

training epoch 486 / 500, batch #25 / 625
Loss:	1.5697274208068848

training epoch 486 / 500, batch #50 / 625
Loss:	1.4533319473266602

training epoch 486 / 500, batch #75 / 625
Loss:	1.6663596630096436

training epoch 486 / 500, batch #100 / 625
Loss:	1.7270784378051758

training epoch 486 / 500, batch #125 / 625
Loss:	1.7260370254516602

training epoch 486 / 500, batch #150 / 625
Loss:	1.5871376991271973

training epoch 486 / 500, batch #175 / 625
Loss:	1.8688312768936157

training epoch 486 / 500, batch #200 / 625
Loss:	1.8256429433822632

training epoch 486 / 500, batch #225 / 625
Loss:	1.7202328443527222

training epoch 486 / 500, batch #250 / 625
Loss:	1.6502161026000977

training epoch 486 / 500, batch #275 / 625
Loss:	1.9880279302597046

training epoch 486 / 500, batch #300 / 625
Loss:	1.7058030366897583

training epoch 486 / 500, batch #325 / 625
Loss:	1.7543376684188843

training epoch 486 / 500, batch #350 / 625
Loss:	1.575128436088562

training epoch 486 / 500, batch #375 / 625
Loss:	1.582842469215393

training epoch 486 / 500, batch #400 / 625
Loss:	1.66414475440979

training epoch 486 / 500, batch #425 / 625
Loss:	1.7856088876724243

training epoch 486 / 500, batch #450 / 625
Loss:	1.600300908088684

training epoch 486 / 500, batch #475 / 625
Loss:	1.5672245025634766

training epoch 486 / 500, batch #500 / 625
Loss:	1.8114283084869385

training epoch 486 / 500, batch #525 / 625
Loss:	1.6042894124984741

training epoch 486 / 500, batch #550 / 625
Loss:	1.6875942945480347

training epoch 486 / 500, batch #575 / 625
Loss:	1.7272449731826782

training epoch 486 / 500, batch #600 / 625
Loss:	1.7161338329315186

training epoch 487 / 500, batch #0 / 625
Loss:	1.799731969833374

training epoch 487 / 500, batch #25 / 625
Loss:	1.9186105728149414

training epoch 487 / 500, batch #50 / 625
Loss:	1.4694217443466187

training epoch 487 / 500, batch #75 / 625
Loss:	1.639876127243042

training epoch 487 / 500, batch #100 / 625
Loss:	1.6594828367233276

training epoch 487 / 500, batch #125 / 625
Loss:	1.6888389587402344

training epoch 487 / 500, batch #150 / 625
Loss:	1.9121721982955933

training epoch 487 / 500, batch #175 / 625
Loss:	1.424451231956482

training epoch 487 / 500, batch #200 / 625
Loss:	1.6192258596420288

training epoch 487 / 500, batch #225 / 625
Loss:	1.6014469861984253

training epoch 487 / 500, batch #250 / 625
Loss:	1.6261106729507446

training epoch 487 / 500, batch #275 / 625
Loss:	1.3994312286376953

training epoch 487 / 500, batch #300 / 625
Loss:	1.8466386795043945

training epoch 487 / 500, batch #325 / 625
Loss:	1.760860562324524

training epoch 487 / 500, batch #350 / 625
Loss:	1.4488905668258667

training epoch 487 / 500, batch #375 / 625
Loss:	1.8192346096038818

training epoch 487 / 500, batch #400 / 625
Loss:	1.8599203824996948

training epoch 487 / 500, batch #425 / 625
Loss:	1.8086405992507935

training epoch 487 / 500, batch #450 / 625
Loss:	1.541271448135376

training epoch 487 / 500, batch #475 / 625
Loss:	1.440946340560913

training epoch 487 / 500, batch #500 / 625
Loss:	1.8608609437942505

training epoch 487 / 500, batch #525 / 625
Loss:	2.0833280086517334

training epoch 487 / 500, batch #550 / 625
Loss:	1.721567153930664

training epoch 487 / 500, batch #575 / 625
Loss:	2.0145134925842285

training epoch 487 / 500, batch #600 / 625
Loss:	1.768000841140747

training epoch 488 / 500, batch #0 / 625
Loss:	1.676570177078247

training epoch 488 / 500, batch #25 / 625
Loss:	1.8270097970962524

training epoch 488 / 500, batch #50 / 625
Loss:	1.4729083776474

training epoch 488 / 500, batch #75 / 625
Loss:	1.4813097715377808

training epoch 488 / 500, batch #100 / 625
Loss:	1.5330480337142944

training epoch 488 / 500, batch #125 / 625
Loss:	1.5803700685501099

training epoch 488 / 500, batch #150 / 625
Loss:	1.7125428915023804

training epoch 488 / 500, batch #175 / 625
Loss:	1.7056639194488525

training epoch 488 / 500, batch #200 / 625
Loss:	1.9026812314987183

training epoch 488 / 500, batch #225 / 625
Loss:	1.8108463287353516

training epoch 488 / 500, batch #250 / 625
Loss:	1.799626350402832

training epoch 488 / 500, batch #275 / 625
Loss:	1.6452035903930664

training epoch 488 / 500, batch #300 / 625
Loss:	1.7929233312606812

training epoch 488 / 500, batch #325 / 625
Loss:	1.8423802852630615

training epoch 488 / 500, batch #350 / 625
Loss:	1.7490859031677246

training epoch 488 / 500, batch #375 / 625
Loss:	1.6932176351547241

training epoch 488 / 500, batch #400 / 625
Loss:	1.6808956861495972

training epoch 488 / 500, batch #425 / 625
Loss:	1.5499769449234009

training epoch 488 / 500, batch #450 / 625
Loss:	1.6108026504516602

training epoch 488 / 500, batch #475 / 625
Loss:	1.5767074823379517

training epoch 488 / 500, batch #500 / 625
Loss:	1.4833076000213623

training epoch 488 / 500, batch #525 / 625
Loss:	1.7696257829666138

training epoch 488 / 500, batch #550 / 625
Loss:	1.6777194738388062

training epoch 488 / 500, batch #575 / 625
Loss:	1.7837282419204712

training epoch 488 / 500, batch #600 / 625
Loss:	1.6639437675476074

training epoch 489 / 500, batch #0 / 625
Loss:	1.6582473516464233

training epoch 489 / 500, batch #25 / 625
Loss:	1.7083592414855957

training epoch 489 / 500, batch #50 / 625
Loss:	1.757844090461731

training epoch 489 / 500, batch #75 / 625
Loss:	1.906815528869629

training epoch 489 / 500, batch #100 / 625
Loss:	1.577735185623169

training epoch 489 / 500, batch #125 / 625
Loss:	1.7786809206008911

training epoch 489 / 500, batch #150 / 625
Loss:	1.649275302886963

training epoch 489 / 500, batch #175 / 625
Loss:	1.8129239082336426

training epoch 489 / 500, batch #200 / 625
Loss:	1.6497414112091064

training epoch 489 / 500, batch #225 / 625
Loss:	1.5887975692749023

training epoch 489 / 500, batch #250 / 625
Loss:	1.8760173320770264

training epoch 489 / 500, batch #275 / 625
Loss:	1.616217017173767

training epoch 489 / 500, batch #300 / 625
Loss:	1.746488332748413

training epoch 489 / 500, batch #325 / 625
Loss:	1.6182254552841187

training epoch 489 / 500, batch #350 / 625
Loss:	1.7086073160171509

training epoch 489 / 500, batch #375 / 625
Loss:	1.780816912651062

training epoch 489 / 500, batch #400 / 625
Loss:	1.8053042888641357

training epoch 489 / 500, batch #425 / 625
Loss:	1.829671025276184

training epoch 489 / 500, batch #450 / 625
Loss:	1.6288408041000366

training epoch 489 / 500, batch #475 / 625
Loss:	1.7180581092834473

training epoch 489 / 500, batch #500 / 625
Loss:	1.8221482038497925

training epoch 489 / 500, batch #525 / 625
Loss:	1.7100075483322144

training epoch 489 / 500, batch #550 / 625
Loss:	1.6435065269470215

training epoch 489 / 500, batch #575 / 625
Loss:	1.6832655668258667

training epoch 489 / 500, batch #600 / 625
Loss:	1.9615302085876465

training epoch 490 / 500, batch #0 / 625
Loss:	1.4863276481628418

training epoch 490 / 500, batch #25 / 625
Loss:	1.5754873752593994

training epoch 490 / 500, batch #50 / 625
Loss:	1.5342278480529785

training epoch 490 / 500, batch #75 / 625
Loss:	1.763797640800476

training epoch 490 / 500, batch #100 / 625
Loss:	1.629163384437561

training epoch 490 / 500, batch #125 / 625
Loss:	1.6527782678604126

training epoch 490 / 500, batch #150 / 625
Loss:	1.8475723266601562

training epoch 490 / 500, batch #175 / 625
Loss:	1.8384612798690796

training epoch 490 / 500, batch #200 / 625
Loss:	1.5944751501083374

training epoch 490 / 500, batch #225 / 625
Loss:	1.6192314624786377

training epoch 490 / 500, batch #250 / 625
Loss:	2.028491735458374

training epoch 490 / 500, batch #275 / 625
Loss:	1.6008777618408203

training epoch 490 / 500, batch #300 / 625
Loss:	1.7022982835769653

training epoch 490 / 500, batch #325 / 625
Loss:	1.6974384784698486

training epoch 490 / 500, batch #350 / 625
Loss:	1.5701082944869995

training epoch 490 / 500, batch #375 / 625
Loss:	2.109804391860962

training epoch 490 / 500, batch #400 / 625
Loss:	1.863740086555481

training epoch 490 / 500, batch #425 / 625
Loss:	1.6394652128219604

training epoch 490 / 500, batch #450 / 625
Loss:	1.4653375148773193

training epoch 490 / 500, batch #475 / 625
Loss:	1.6704283952713013

training epoch 490 / 500, batch #500 / 625
Loss:	1.4311885833740234

training epoch 490 / 500, batch #525 / 625
Loss:	1.744755506515503

training epoch 490 / 500, batch #550 / 625
Loss:	1.6645886898040771

training epoch 490 / 500, batch #575 / 625
Loss:	1.6015242338180542

training epoch 490 / 500, batch #600 / 625
Loss:	1.6842968463897705

training epoch 491 / 500, batch #0 / 625
Loss:	1.6485047340393066

training epoch 491 / 500, batch #25 / 625
Loss:	1.7236356735229492

training epoch 491 / 500, batch #50 / 625
Loss:	1.558712363243103

training epoch 491 / 500, batch #75 / 625
Loss:	1.9136613607406616

training epoch 491 / 500, batch #100 / 625
Loss:	1.7151134014129639

training epoch 491 / 500, batch #125 / 625
Loss:	1.834974765777588

training epoch 491 / 500, batch #150 / 625
Loss:	2.218501091003418

training epoch 491 / 500, batch #175 / 625
Loss:	1.7512463331222534

training epoch 491 / 500, batch #200 / 625
Loss:	2.0449306964874268

training epoch 491 / 500, batch #225 / 625
Loss:	1.825715184211731

training epoch 491 / 500, batch #250 / 625
Loss:	1.6767736673355103

training epoch 491 / 500, batch #275 / 625
Loss:	1.8980039358139038

training epoch 491 / 500, batch #300 / 625
Loss:	1.8850374221801758

training epoch 491 / 500, batch #325 / 625
Loss:	1.735746145248413

training epoch 491 / 500, batch #350 / 625
Loss:	1.8185234069824219

training epoch 491 / 500, batch #375 / 625
Loss:	1.7156997919082642

training epoch 491 / 500, batch #400 / 625
Loss:	1.5230629444122314

training epoch 491 / 500, batch #425 / 625
Loss:	1.6650804281234741

training epoch 491 / 500, batch #450 / 625
Loss:	1.6567484140396118

training epoch 491 / 500, batch #475 / 625
Loss:	1.5534268617630005

training epoch 491 / 500, batch #500 / 625
Loss:	1.4755301475524902

training epoch 491 / 500, batch #525 / 625
Loss:	1.736935019493103

training epoch 491 / 500, batch #550 / 625
Loss:	1.6137986183166504

training epoch 491 / 500, batch #575 / 625
Loss:	1.3376474380493164

training epoch 491 / 500, batch #600 / 625
Loss:	1.598238468170166

training epoch 492 / 500, batch #0 / 625
Loss:	1.7296018600463867

training epoch 492 / 500, batch #25 / 625
Loss:	1.7807530164718628

training epoch 492 / 500, batch #50 / 625
Loss:	1.7334189414978027

training epoch 492 / 500, batch #75 / 625
Loss:	1.91019868850708

training epoch 492 / 500, batch #100 / 625
Loss:	1.856629490852356

training epoch 492 / 500, batch #125 / 625
Loss:	1.978657841682434

training epoch 492 / 500, batch #150 / 625
Loss:	1.5648369789123535

training epoch 492 / 500, batch #175 / 625
Loss:	1.5946837663650513

training epoch 492 / 500, batch #200 / 625
Loss:	1.661207914352417

training epoch 492 / 500, batch #225 / 625
Loss:	1.8783085346221924

training epoch 492 / 500, batch #250 / 625
Loss:	1.618107795715332

training epoch 492 / 500, batch #275 / 625
Loss:	1.644370436668396

training epoch 492 / 500, batch #300 / 625
Loss:	1.740409255027771

training epoch 492 / 500, batch #325 / 625
Loss:	2.012450695037842

training epoch 492 / 500, batch #350 / 625
Loss:	1.6111613512039185

training epoch 492 / 500, batch #375 / 625
Loss:	1.7000051736831665

training epoch 492 / 500, batch #400 / 625
Loss:	1.6981276273727417

training epoch 492 / 500, batch #425 / 625
Loss:	1.8846535682678223

training epoch 492 / 500, batch #450 / 625
Loss:	1.7926712036132812

training epoch 492 / 500, batch #475 / 625
Loss:	1.837669014930725

training epoch 492 / 500, batch #500 / 625
Loss:	1.5702213048934937

training epoch 492 / 500, batch #525 / 625
Loss:	1.448796033859253

training epoch 492 / 500, batch #550 / 625
Loss:	1.528855562210083

training epoch 492 / 500, batch #575 / 625
Loss:	1.9372828006744385

training epoch 492 / 500, batch #600 / 625
Loss:	1.7678576707839966

training epoch 493 / 500, batch #0 / 625
Loss:	1.6731984615325928

training epoch 493 / 500, batch #25 / 625
Loss:	1.6512045860290527

training epoch 493 / 500, batch #50 / 625
Loss:	1.6201742887496948

training epoch 493 / 500, batch #75 / 625
Loss:	1.7949730157852173

training epoch 493 / 500, batch #100 / 625
Loss:	1.564605712890625

training epoch 493 / 500, batch #125 / 625
Loss:	1.526693344116211

training epoch 493 / 500, batch #150 / 625
Loss:	1.6354856491088867

training epoch 493 / 500, batch #175 / 625
Loss:	1.6327325105667114

training epoch 493 / 500, batch #200 / 625
Loss:	1.9502397775650024

training epoch 493 / 500, batch #225 / 625
Loss:	1.5442339181900024

training epoch 493 / 500, batch #250 / 625
Loss:	1.841318964958191

training epoch 493 / 500, batch #275 / 625
Loss:	1.8732719421386719

training epoch 493 / 500, batch #300 / 625
Loss:	1.5293608903884888

training epoch 493 / 500, batch #325 / 625
Loss:	1.5442750453948975

training epoch 493 / 500, batch #350 / 625
Loss:	1.7361570596694946

training epoch 493 / 500, batch #375 / 625
Loss:	1.7163677215576172

training epoch 493 / 500, batch #400 / 625
Loss:	1.793801188468933

training epoch 493 / 500, batch #425 / 625
Loss:	1.6224159002304077

training epoch 493 / 500, batch #450 / 625
Loss:	1.6994950771331787

training epoch 493 / 500, batch #475 / 625
Loss:	1.8424781560897827

training epoch 493 / 500, batch #500 / 625
Loss:	1.6459941864013672

training epoch 493 / 500, batch #525 / 625
Loss:	1.6334489583969116

training epoch 493 / 500, batch #550 / 625
Loss:	1.7275415658950806

training epoch 493 / 500, batch #575 / 625
Loss:	1.5933066606521606

training epoch 493 / 500, batch #600 / 625
Loss:	1.7977089881896973

training epoch 494 / 500, batch #0 / 625
Loss:	1.9031752347946167

training epoch 494 / 500, batch #25 / 625
Loss:	1.8348610401153564

training epoch 494 / 500, batch #50 / 625
Loss:	1.6269692182540894

training epoch 494 / 500, batch #75 / 625
Loss:	1.5938290357589722

training epoch 494 / 500, batch #100 / 625
Loss:	1.8153386116027832

training epoch 494 / 500, batch #125 / 625
Loss:	1.786760687828064

training epoch 494 / 500, batch #150 / 625
Loss:	1.8264070749282837

training epoch 494 / 500, batch #175 / 625
Loss:	1.8450168371200562

training epoch 494 / 500, batch #200 / 625
Loss:	1.570515513420105

training epoch 494 / 500, batch #225 / 625
Loss:	1.8580331802368164

training epoch 494 / 500, batch #250 / 625
Loss:	1.8318638801574707

training epoch 494 / 500, batch #275 / 625
Loss:	1.8164067268371582

training epoch 494 / 500, batch #300 / 625
Loss:	1.6111632585525513

training epoch 494 / 500, batch #325 / 625
Loss:	1.7544349431991577

training epoch 494 / 500, batch #350 / 625
Loss:	1.7620494365692139

training epoch 494 / 500, batch #375 / 625
Loss:	1.826722502708435

training epoch 494 / 500, batch #400 / 625
Loss:	1.6053380966186523

training epoch 494 / 500, batch #425 / 625
Loss:	1.7666778564453125

training epoch 494 / 500, batch #450 / 625
Loss:	1.9178670644760132

training epoch 494 / 500, batch #475 / 625
Loss:	1.7806446552276611

training epoch 494 / 500, batch #500 / 625
Loss:	1.6255598068237305

training epoch 494 / 500, batch #525 / 625
Loss:	1.7838531732559204

training epoch 494 / 500, batch #550 / 625
Loss:	1.978928804397583

training epoch 494 / 500, batch #575 / 625
Loss:	1.7445166110992432

training epoch 494 / 500, batch #600 / 625
Loss:	1.7653112411499023

training epoch 495 / 500, batch #0 / 625
Loss:	1.562038779258728

training epoch 495 / 500, batch #25 / 625
Loss:	1.7225128412246704

training epoch 495 / 500, batch #50 / 625
Loss:	1.4079548120498657

training epoch 495 / 500, batch #75 / 625
Loss:	1.932978630065918

training epoch 495 / 500, batch #100 / 625
Loss:	1.5205473899841309

training epoch 495 / 500, batch #125 / 625
Loss:	1.7548754215240479

training epoch 495 / 500, batch #150 / 625
Loss:	1.6103417873382568

training epoch 495 / 500, batch #175 / 625
Loss:	2.1015946865081787

training epoch 495 / 500, batch #200 / 625
Loss:	1.8010716438293457

training epoch 495 / 500, batch #225 / 625
Loss:	1.6260712146759033

training epoch 495 / 500, batch #250 / 625
Loss:	1.687914490699768

training epoch 495 / 500, batch #275 / 625
Loss:	1.4674509763717651

training epoch 495 / 500, batch #300 / 625
Loss:	1.6665395498275757

training epoch 495 / 500, batch #325 / 625
Loss:	1.7675660848617554

training epoch 495 / 500, batch #350 / 625
Loss:	1.838571548461914

training epoch 495 / 500, batch #375 / 625
Loss:	1.7187939882278442

training epoch 495 / 500, batch #400 / 625
Loss:	1.6593561172485352

training epoch 495 / 500, batch #425 / 625
Loss:	1.7926667928695679

training epoch 495 / 500, batch #450 / 625
Loss:	1.8869343996047974

training epoch 495 / 500, batch #475 / 625
Loss:	1.8070095777511597

training epoch 495 / 500, batch #500 / 625
Loss:	1.8488914966583252

training epoch 495 / 500, batch #525 / 625
Loss:	1.607966423034668

training epoch 495 / 500, batch #550 / 625
Loss:	1.7481285333633423

training epoch 495 / 500, batch #575 / 625
Loss:	1.868740200996399

training epoch 495 / 500, batch #600 / 625
Loss:	1.7045832872390747

training epoch 496 / 500, batch #0 / 625
Loss:	1.8310526609420776

training epoch 496 / 500, batch #25 / 625
Loss:	1.5548853874206543

training epoch 496 / 500, batch #50 / 625
Loss:	1.7268766164779663

training epoch 496 / 500, batch #75 / 625
Loss:	1.5866187810897827

training epoch 496 / 500, batch #100 / 625
Loss:	1.813988447189331

training epoch 496 / 500, batch #125 / 625
Loss:	1.8756332397460938

training epoch 496 / 500, batch #150 / 625
Loss:	1.4937719106674194

training epoch 496 / 500, batch #175 / 625
Loss:	1.6538138389587402

training epoch 496 / 500, batch #200 / 625
Loss:	1.595542311668396

training epoch 496 / 500, batch #225 / 625
Loss:	1.8018425703048706

training epoch 496 / 500, batch #250 / 625
Loss:	1.9908199310302734

training epoch 496 / 500, batch #275 / 625
Loss:	1.8972749710083008

training epoch 496 / 500, batch #300 / 625
Loss:	2.1442861557006836

training epoch 496 / 500, batch #325 / 625
Loss:	1.8300431966781616

training epoch 496 / 500, batch #350 / 625
Loss:	1.767116904258728

training epoch 496 / 500, batch #375 / 625
Loss:	1.6287548542022705

training epoch 496 / 500, batch #400 / 625
Loss:	1.5682663917541504

training epoch 496 / 500, batch #425 / 625
Loss:	1.596878170967102

training epoch 496 / 500, batch #450 / 625
Loss:	1.7964940071105957

training epoch 496 / 500, batch #475 / 625
Loss:	1.6331976652145386

training epoch 496 / 500, batch #500 / 625
Loss:	1.6875537633895874

training epoch 496 / 500, batch #525 / 625
Loss:	1.5772422552108765

training epoch 496 / 500, batch #550 / 625
Loss:	1.9229099750518799

training epoch 496 / 500, batch #575 / 625
Loss:	1.7411963939666748

training epoch 496 / 500, batch #600 / 625
Loss:	1.813385009765625

training epoch 497 / 500, batch #0 / 625
Loss:	1.739230990409851

training epoch 497 / 500, batch #25 / 625
Loss:	1.7868297100067139

training epoch 497 / 500, batch #50 / 625
Loss:	1.629793405532837

training epoch 497 / 500, batch #75 / 625
Loss:	1.694962501525879

training epoch 497 / 500, batch #100 / 625
Loss:	1.6561274528503418

training epoch 497 / 500, batch #125 / 625
Loss:	1.656074047088623

training epoch 497 / 500, batch #150 / 625
Loss:	1.9015538692474365

training epoch 497 / 500, batch #175 / 625
Loss:	1.5414527654647827

training epoch 497 / 500, batch #200 / 625
Loss:	1.6751511096954346

training epoch 497 / 500, batch #225 / 625
Loss:	2.0420351028442383

training epoch 497 / 500, batch #250 / 625
Loss:	1.6744388341903687

training epoch 497 / 500, batch #275 / 625
Loss:	1.8300644159317017

training epoch 497 / 500, batch #300 / 625
Loss:	1.9996364116668701

training epoch 497 / 500, batch #325 / 625
Loss:	1.8555536270141602

training epoch 497 / 500, batch #350 / 625
Loss:	1.6644692420959473

training epoch 497 / 500, batch #375 / 625
Loss:	1.5005922317504883

training epoch 497 / 500, batch #400 / 625
Loss:	1.718642234802246

training epoch 497 / 500, batch #425 / 625
Loss:	1.4714200496673584

training epoch 497 / 500, batch #450 / 625
Loss:	1.5291892290115356

training epoch 497 / 500, batch #475 / 625
Loss:	1.8047471046447754

training epoch 497 / 500, batch #500 / 625
Loss:	1.682564377784729

training epoch 497 / 500, batch #525 / 625
Loss:	1.9390778541564941

training epoch 497 / 500, batch #550 / 625
Loss:	1.4627914428710938

training epoch 497 / 500, batch #575 / 625
Loss:	1.6876872777938843

training epoch 497 / 500, batch #600 / 625
Loss:	1.6745786666870117

training epoch 498 / 500, batch #0 / 625
Loss:	1.5942175388336182

training epoch 498 / 500, batch #25 / 625
Loss:	1.8325166702270508

training epoch 498 / 500, batch #50 / 625
Loss:	1.7125319242477417

training epoch 498 / 500, batch #75 / 625
Loss:	1.805346131324768

training epoch 498 / 500, batch #100 / 625
Loss:	1.5263123512268066

training epoch 498 / 500, batch #125 / 625
Loss:	1.6876572370529175

training epoch 498 / 500, batch #150 / 625
Loss:	1.7452560663223267

training epoch 498 / 500, batch #175 / 625
Loss:	1.712609052658081

training epoch 498 / 500, batch #200 / 625
Loss:	1.7358431816101074

training epoch 498 / 500, batch #225 / 625
Loss:	1.6215590238571167

training epoch 498 / 500, batch #250 / 625
Loss:	1.4704135656356812

training epoch 498 / 500, batch #275 / 625
Loss:	1.5135650634765625

training epoch 498 / 500, batch #300 / 625
Loss:	1.7541632652282715

training epoch 498 / 500, batch #325 / 625
Loss:	1.7234264612197876

training epoch 498 / 500, batch #350 / 625
Loss:	1.7746585607528687

training epoch 498 / 500, batch #375 / 625
Loss:	1.9744571447372437

training epoch 498 / 500, batch #400 / 625
Loss:	1.5566879510879517

training epoch 498 / 500, batch #425 / 625
Loss:	2.017591714859009

training epoch 498 / 500, batch #450 / 625
Loss:	1.8751308917999268

training epoch 498 / 500, batch #475 / 625
Loss:	1.572495698928833

training epoch 498 / 500, batch #500 / 625
Loss:	1.8754997253417969

training epoch 498 / 500, batch #525 / 625
Loss:	1.6538869142532349

training epoch 498 / 500, batch #550 / 625
Loss:	1.7625113725662231

training epoch 498 / 500, batch #575 / 625
Loss:	1.776732087135315

training epoch 498 / 500, batch #600 / 625
Loss:	1.6882069110870361

training epoch 499 / 500, batch #0 / 625
Loss:	1.6728318929672241

training epoch 499 / 500, batch #25 / 625
Loss:	1.8816584348678589

training epoch 499 / 500, batch #50 / 625
Loss:	1.6752952337265015

training epoch 499 / 500, batch #75 / 625
Loss:	1.5232175588607788

training epoch 499 / 500, batch #100 / 625
Loss:	1.750311255455017

training epoch 499 / 500, batch #125 / 625
Loss:	1.6865565776824951

training epoch 499 / 500, batch #150 / 625
Loss:	1.5355479717254639

training epoch 499 / 500, batch #175 / 625
Loss:	1.7574400901794434

training epoch 499 / 500, batch #200 / 625
Loss:	1.6537699699401855

training epoch 499 / 500, batch #225 / 625
Loss:	1.6346527338027954

training epoch 499 / 500, batch #250 / 625
Loss:	1.4996376037597656

training epoch 499 / 500, batch #275 / 625
Loss:	1.792496919631958

training epoch 499 / 500, batch #300 / 625
Loss:	1.9720122814178467

training epoch 499 / 500, batch #325 / 625
Loss:	1.5844250917434692

training epoch 499 / 500, batch #350 / 625
Loss:	1.7772374153137207

training epoch 499 / 500, batch #375 / 625
Loss:	1.8693729639053345

training epoch 499 / 500, batch #400 / 625
Loss:	1.591835856437683

training epoch 499 / 500, batch #425 / 625
Loss:	1.5891876220703125

training epoch 499 / 500, batch #450 / 625
Loss:	1.8413506746292114

training epoch 499 / 500, batch #475 / 625
Loss:	1.5436768531799316

training epoch 499 / 500, batch #500 / 625
Loss:	1.8064457178115845

training epoch 499 / 500, batch #525 / 625
Loss:	1.6479089260101318

training epoch 499 / 500, batch #550 / 625
Loss:	1.95724356174469

training epoch 499 / 500, batch #575 / 625
Loss:	1.6649632453918457

training epoch 499 / 500, batch #600 / 625
Loss:	1.5594919919967651

